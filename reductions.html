<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.555">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="Raphael Sonabend and Andreas Bender">
<title>Machine Learning in Survival Analysis - 21&nbsp; Reductions</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./competing.html" rel="next">
<link href="./models_choosing.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script><link rel="stylesheet" href="styles.css">
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./reductions.html">Reduction Techniques</a></li><li class="breadcrumb-item"><a href="./reductions.html"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Reductions</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Machine Learning in Survival Analysis</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/mlsa-book/MLSA/tree/main/book/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./Machine-Learning-in-Survival-Analysis.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./notation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Symbols and Notation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false">
 <span class="menu-text">Survival Analysis and Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">MLSA From Start to Finish</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./machinelearning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Statistical Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./survival.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Survival Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eha.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Event-history Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./survtsk.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Survival Task</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">
 <span class="menu-text">Evaluation</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./meas_what.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">What are Survival Measures?</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./meas_rank.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Discrimination Measures</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./meas_calib.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Calibration Measures</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./meas_rules.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Evaluating Distributions by Scoring Rules</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./meas_time.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Evaluating Survival Time</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./meas_choosing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Choosing Measures</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false">
 <span class="menu-text">Models</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./classical.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Classical Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mlmodels.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Machine Learning Survival Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./forests.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Tree-Based Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./svm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Support Vector Machines</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./boosting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Boosting Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./neuralnetworks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./alternatives.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Alternative Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./models_choosing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Choosing Models</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Reduction Techniques</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./reductions.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Reductions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./competing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Competing Risks Pipelines</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./discretetime.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Discrete Time Survival Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./poisson.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Connections to Poisson Regression and Processes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./pseudo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Connections to Regression and Imputation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./advanced.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Advanced Methods</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false">
 <span class="menu-text">Extensions and Outlook</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./common.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Common problems in survival analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./software.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Survival Software</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./next.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">What’s next for MLSA?</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li><a href="#sec-car-pipes" id="toc-sec-car-pipes" class="nav-link active" data-scroll-target="#sec-car-pipes"><span class="header-section-number">21.1</span> Representing Pipelines</a></li>
  <li>
<a href="#sec-car-comp" id="toc-sec-car-comp" class="nav-link" data-scroll-target="#sec-car-comp"><span class="header-section-number">21.2</span> Introduction to Composition</a>
  <ul class="collapse">
<li><a href="#sec-car-comp-tax" id="toc-sec-car-comp-tax" class="nav-link" data-scroll-target="#sec-car-comp-tax"><span class="header-section-number">21.2.1</span> Taxonomy of Compositors</a></li>
  <li><a href="#sec-car-comp-mot" id="toc-sec-car-comp-mot" class="nav-link" data-scroll-target="#sec-car-comp-mot"><span class="header-section-number">21.2.2</span> Motivation for Composition</a></li>
  </ul>
</li>
  <li>
<a href="#sec-car-redux" id="toc-sec-car-redux" class="nav-link" data-scroll-target="#sec-car-redux"><span class="header-section-number">21.3</span> Introduction to Reduction</a>
  <ul class="collapse">
<li><a href="#sec-car-redux-mot" id="toc-sec-car-redux-mot" class="nav-link" data-scroll-target="#sec-car-redux-mot"><span class="header-section-number">21.3.1</span> Reduction Motivation</a></li>
  <li><a href="#sec-car-redux-task" id="toc-sec-car-redux-task" class="nav-link" data-scroll-target="#sec-car-redux-task"><span class="header-section-number">21.3.2</span> Task, Loss, and Data Reduction</a></li>
  <li><a href="#sec-car-reduxstrats-mistakes" id="toc-sec-car-reduxstrats-mistakes" class="nav-link" data-scroll-target="#sec-car-reduxstrats-mistakes"><span class="header-section-number">21.3.3</span> Common Mistakes in Implementation of Reduction</a></li>
  </ul>
</li>
  <li>
<a href="#sec-car-pipelines" id="toc-sec-car-pipelines" class="nav-link" data-scroll-target="#sec-car-pipelines"><span class="header-section-number">21.4</span> Composition Strategies for Survival Analysis</a>
  <ul class="collapse">
<li><a href="#sec-car-pipelines-distr" id="toc-sec-car-pipelines-distr" class="nav-link" data-scroll-target="#sec-car-pipelines-distr"><span class="header-section-number">21.4.1</span> C1) Linear Predictor <span class="math inline">\(\rightarrow\)</span> Distribution</a></li>
  <li><a href="#sec-car-pipelines-time" id="toc-sec-car-pipelines-time" class="nav-link" data-scroll-target="#sec-car-pipelines-time"><span class="header-section-number">21.4.2</span> C2) Survival Time <span class="math inline">\(\rightarrow\)</span> Distribution</a></li>
  <li><a href="#sec-car-pipelines-crank" id="toc-sec-car-pipelines-crank" class="nav-link" data-scroll-target="#sec-car-pipelines-crank"><span class="header-section-number">21.4.3</span> C3) Distribution <span class="math inline">\(\rightarrow\)</span> Survival Time Composition</a></li>
  <li><a href="#sec-car-pipelines-avg" id="toc-sec-car-pipelines-avg" class="nav-link" data-scroll-target="#sec-car-pipelines-avg"><span class="header-section-number">21.4.4</span> C4) Survival Model Averaging</a></li>
  </ul>
</li>
  <li>
<a href="#sec-car-reduxes" id="toc-sec-car-reduxes" class="nav-link" data-scroll-target="#sec-car-reduxes"><span class="header-section-number">21.5</span> Novel Survival Reductions</a>
  <ul class="collapse">
<li><a href="#sec-car-reduxes-r7r8" id="toc-sec-car-reduxes-r7r8" class="nav-link" data-scroll-target="#sec-car-reduxes-r7r8"><span class="header-section-number">21.5.1</span> R7-R8) Survival <span class="math inline">\(\rightarrow\)</span> Probabilistic Classification</a></li>
  </ul>
</li>
  <li><a href="#sec-car-conc" id="toc-sec-car-conc" class="nav-link" data-scroll-target="#sec-car-conc"><span class="header-section-number">21.6</span> Conclusions</a></li>
  </ul><div class="toc-actions"><ul><li><a href="https://github.com/mlsa-book/MLSA/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li><li><a href="https://github.com/mlsa-book/MLSA/edit/main/book/reductions.qmd" class="toc-action"><i class="bi empty"></i>Edit this page</a></li><li><a href="https://github.com/mlsa-book/MLSA/blob/main/book/reductions.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./reductions.html">Reduction Techniques</a></li><li class="breadcrumb-item"><a href="./reductions.html"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Reductions</span></a></li></ol></nav><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-car" class="quarto-section-identifier"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Reductions</span></span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="block-title">Abstract</div>
    TODO (150-200 WORDS)
  </div>
</div>


</header><div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Major changes expected!
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>This page is a work in progress and major changes will be made over time.</strong></p>
</div>
</div>
<p>In this chapter, composition and reduction are formally introduced, defined and demonstrated within survival analysis. Neither of these are novel concepts in general or in survival, with several applications already seen earlier when reviewing models (particularly in neural networks), however a lack of formalisation has led to much repeated work and at times questionable applications (<a href="neuralnetworks.html#sec-surv-ml-models-nn" class="quarto-xref"><span>Section 18.1</span></a>). The primary purpose of this chapter is to formalise composition and reduction for survival and to unify references and strategies for future use. These strategies are introduced in the context of minimal ‘workflows’ and graphical ‘pipelines’ in order to maximise their generalisability. The pipelines discussed in this chapter are implemented in <a href="https://cran.r-project.org/package=mlr3proba"><code>mlr3proba</code></a>. <!-- %The compositions discussed in this chapter are important for understanding how classical and machine learning models are routinely discussed and implemented in survival analysis. Whereas the reductions in this chapter are more conceptual and relate specifically to solving machine learning tasks algorithmically. The frameworks discussed in this chapter are all implemented in [`mlr3proba`](https://cran.r-project.org/package=mlr3proba)\index{\texttt{mlr3proba}}. --></p>
<p>A <em>workflow</em> is a generic term given to a series of sequential operations. For example a standard ML workflow is fit/predict/evaluate, which means a model is fit, predictions are made, and these are evaluated. In this book, a <em>pipeline</em> is the name given to a concrete workflow. <a href="#sec-car-pipes" class="quarto-xref"><span>Section 21.1</span></a> demonstrates how pipelines are represented in this book.</p>
<p>Composition (<a href="#sec-car-comp" class="quarto-xref"><span>Section 21.2</span></a>) is a general process in which an object is built (or composed) from other objects and parameters. Reduction (<a href="#sec-car-redux" class="quarto-xref"><span>Section 21.3</span></a>) is a closely related concept that utilises composition in order to transform one problem into another. Concrete strategies for composition and reduction are detailed in sections <a href="#sec-car-pipelines" class="quarto-xref"><span>Section 21.4</span></a> and <a href="#sec-car-reduxes" class="quarto-xref"><span>Section 21.5</span></a>.</p>
<section id="notation-and-terminology" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="notation-and-terminology">Notation and Terminology</h4>
<p>The notation introduced in <a href="survival.html" class="quarto-xref"><span>Chapter 4</span></a> is recapped for use in this chapter: the generative survival template for the survival setting is given by <span class="math inline">\((X,T,\Delta,Y,C) \ t.v.i. \ \mathcal{X}\times \mathcal{T}\times \{0,1\}\times \mathcal{T}\times \mathcal{T}\)</span> where <span class="math inline">\(\mathcal{X}\subseteq \mathbb{R}^p\)</span> and <span class="math inline">\(\mathcal{T}\subseteq \mathbb{R}_{\geq 0}\)</span>, where <span class="math inline">\(C,Y\)</span> are unobservable, <span class="math inline">\(T := \min\{Y,C\}\)</span>, and <span class="math inline">\(\Delta = \mathbb{I}(Y = T)\)</span>. Random survival data is given by <span class="math inline">\((X_i,T_i,\Delta_i,Y_i,C_i) \stackrel{i.i.d.}\sim(X,T,\Delta,Y,C)\)</span>. Usually data will instead be presented as a training dataset, <span class="math inline">\(\mathcal{D}_{train}= \{(X_1,T_1,\Delta_1),...,(X_n,T_n,\Delta_n)\}\)</span> where <span class="math inline">\((X_i,T_i,\Delta_i) \stackrel{i.i.d.}\sim(X,T,\Delta)\)</span>, and some test data <span class="math inline">\(\mathcal{D}_{test}= (X^*,T^*,\Delta^*) \sim (X,T,\Delta)\)</span>.</p>
<p>For regression models the generative template is given by <span class="math inline">\((X,Y)\)</span> t.v.i. <span class="math inline">\(\mathcal{X}\subseteq \mathbb{R}^p\)</span> and <span class="math inline">\(Y \subseteq \mathbb{R}\)</span>. As with the survival setting, a regression training set is given by <span class="math inline">\(\{(X_1,Y_1),...,(X_n,Y_n)\}\)</span> where <span class="math inline">\((X_i,Y_i) \stackrel{i.i.d.}\sim(X,Y)\)</span> and some test data <span class="math inline">\((X^*,Y^*) \sim (X,Y)\)</span>.</p>
</section><section id="sec-car-pipes" class="level2" data-number="21.1"><h2 data-number="21.1" class="anchored" data-anchor-id="sec-car-pipes">
<span class="header-section-number">21.1</span> Representing Pipelines</h2>
<p>Before introducing concrete composition and reduction algorithms, this section briefly demonstrates how these pipelines will be represented in this book.</p>
<p>Pipelines are represented by graphs designed in the following way: all are drawn with operations progressing sequentially from left to right; graphs are comprised of nodes (or ‘vertices’) and arrows (or ‘directed edges’); a rounded rectangular node represents a process such as a function or model fitting/predicting; a (regular) rectangular node represents objects such as data or hyper-parameters. Output from rounded nodes are sometimes explicitly drawn but when omitted the output from the node is the input to the next.</p>
<p>These features are demonstrated in <span class="quarto-unresolved-ref">?fig-car-example</span>. Say <span class="math inline">\(y = 2\)</span> and <span class="math inline">\(a = 2\)</span>, then: data is provided (<span class="math inline">\(y = 2\)</span>) and passed to the shift function (<span class="math inline">\(f(x)=x + 2)\)</span>, the output of this function (<span class="math inline">\(y=4\)</span>) is passed directly to the next <span class="math inline">\((h(x|a)=x^a)\)</span>, this function requires a parameter which is also input (<span class="math inline">\(a = 2\)</span>), finally the resulting output is returned (<span class="math inline">\(y^*=16\)</span>). Programmatically, <span class="math inline">\(a = 2\)</span> would be a hyper-parameter that is stored and passed to the required function when the function is called.</p>
<p>This pipeline is represented as a pseudo-algorithm in <span class="citation" data-cites="alg-car-ex">(<a href="references.html#ref-alg-car-ex" role="doc-biblioref"><strong>alg-car-ex?</strong></a>)</span>, though of course is overly complicated and in practice one would just code <span class="math inline">\((y+2)^\wedge a\)</span>.</p>
<!-- \begin{figure}[H]
\centering
\begin{tikzpicture}[framed]
\node (t0)[objnode] {$y$};
\node (t1)[funnode, right=of t0]{$f(x) = x+2$};
\node (t2)[funnode,right=of t1]{$h(x|a) = x^a$};
\node (t3)[objnode, right=of t2]{$y^*$};
\node (t4)[objnode, above=of t2]{$a$};

\path[->]
   (t0)  edge  (t1)
   (t1)  edge  (t2)
   (t2)  edge  (t3)
   (t4)  edge  (t2);
\end{tikzpicture}
\caption[Example of a pipeline]{Example of a pipeline.}\label{fig:car_example}
\end{figure} -->
<!-- \begin{algorithm}[H]
\caption{Example pipeline. \\
**Input** Data, $y \in \Reals$. Parameter, $a \in \Reals$. \\
**Output** Transformed data, $x \in \Reals$.}
\begin{algorithmic}
\State $x \gets y$
\State $x \gets x + 2$
\State $x \gets x^\wedge a$
\Return $x$
\end{algorithmic}
\end{algorithm} -->
<!-- {#alg-car-ex} -->
</section><section id="sec-car-comp" class="level2" data-number="21.2"><h2 data-number="21.2" class="anchored" data-anchor-id="sec-car-comp">
<span class="header-section-number">21.2</span> Introduction to Composition</h2>
<p>This section introduces composition, defines a taxonomy for describing compositors (<a href="#sec-car-comp-tax" class="quarto-xref"><span>Section 21.2.1</span></a>), and provides some motivating examples of composition in survival analysis (<a href="#sec-car-comp-mot" class="quarto-xref"><span>Section 21.2.2</span></a>).</p>
<p>In the simplest definition, a model (be it mathematical, computational, machine learning, etc.) is called a <em>composite model</em> if it is built of two or more constituent parts. This can be simplest defined in terms of objects. Just as objects in the real-world can be combined in some way, so can mathematical objects. The exact ‘combining’ process (or ‘compositor’) depends on the specific composition, so too do the inputs and outputs. By example, a wooden table can be thought of as a composite object (<a href="#fig-car-comp-ex" class="quarto-xref">Figure&nbsp;<span>21.1</span></a>). The inputs are wood and nails, the combining process is hammering (assuming the wood is pre-chopped), and the output is a surface for eating. In mathematics, this process is mirrored. Take the example of a shifted linear regression model. This is defined by a linear regression model, <span class="math inline">\(f(x) = \beta_0 + x\beta_1\)</span>, a shifting parameter, <span class="math inline">\(\alpha\)</span>, and a compositor <span class="math inline">\(g(x|\alpha) = f(x) + \alpha\)</span>. Mathematically this example is overly trivial as this could be directly modelled with <span class="math inline">\(f(x) = \alpha + \beta_0 + x\beta_1\)</span>, but algorithmically there is a difference. The composite model <span class="math inline">\(g\)</span>, is defined by first fitting the linear regression model, <span class="math inline">\(f\)</span>, and then applying a shift, <span class="math inline">\(\alpha\)</span>; as opposed to fitting a directly shifted model.</p>
<div id="fig-car-comp-ex" class="quarto-figure quarto-figure-center quarto-float anchored" alt="TODO">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-car-comp-ex-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/car/comp.png" class="img-fluid figure-img" alt="TODO">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-car-comp-ex-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;21.1: Visualising composition in the real-world. A table is a composite object built from nails and wood, which are combined with a hammer ‘compositor’. Figure not to scale.
</figcaption></figure>
</div>
<section id="why-composition" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="why-composition">Why Composition?</h4>
<p>Tables tend to be better surfaces for eating your dinner than bundles of wood. Or in modelling terms, it is well-known that ensemble methods (e.g.&nbsp;random forests) will generally outperform their components (e.g.&nbsp;decision trees). All ensemble methods are composite models and this demonstrates one of the key use-cases of composition: improved predictive performance. The second key use-case is reduction, which is fully discussed in <a href="#sec-car-redux" class="quarto-xref"><span>Section 21.3</span></a>. <a href="#sec-car-comp-mot" class="quarto-xref"><span>Section 21.2.2</span></a> motivates composition in survival analysis by demonstrating how it is already prevalent but requires formalisation to make compositions more transparent and accessible.</p>
</section><section id="composite-model-vs.-sub-models" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="composite-model-vs.-sub-models">Composite Model vs.&nbsp;Sub-models</h4>
<p>A bundle of wood and nails is not a table and <span class="math inline">\(1,000\)</span> decision trees are not a random forest, both require a compositor. The compositor in a composite model combines the components into a single model. Considering a composite model as a single model enables the hyper-parameters of the compositor and the component model(s) to be efficiently tuned whilst being evaluated as a single model. This further allows the composite to be compared to other models, including its own components, which is required to justify complexity instead of parsimony in model building (<span class="quarto-unresolved-ref">?sec-eval-why-why</span>).</p>
</section><section id="sec-car-comp-tax" class="level3" data-number="21.2.1"><h3 data-number="21.2.1" class="anchored" data-anchor-id="sec-car-comp-tax">
<span class="header-section-number">21.2.1</span> Taxonomy of Compositors</h3>
<p>Just as there are an infinite number of ways to make a table, composition can come in infinite forms. However there are relatively few categories that these can be grouped into. Two primary taxonomies are identified here. The first is the ‘composition type’ and relates to the number of objects composed:</p>
<p>[i)] i. Single-Object Composition (SOC) – This form of composition either makes use of parameters or a transformation to alter a single object. The shifted linear regression model above is one example of this, another is given in <a href="#sec-car-pipelines-crank" class="quarto-xref"><span>Section 21.4.3</span></a>. i. Multi-Object Composition (MOC) – In contrast, this form of composition combines multiple objects into a single one. Both examples in <a href="#sec-car-comp-mot" class="quarto-xref"><span>Section 21.2.2</span></a> are multi-object compositions.</p>
<p>The second grouping is the ‘composition level’ and determines at what ‘level’ the composition takes place:</p>
<p>[i)] i. Prediction Composition – This applies at the level of predictions; the component models could be forgotten at this point. Predictions may be combined from multiple models (MOC) or transformed from a single model (SOC). Both examples in <a href="#sec-car-comp-mot" class="quarto-xref"><span>Section 21.2.2</span></a> are prediction compositions. i. Task Composition – This occurs when one task (e.g.&nbsp;regression) is transformed to one or more others (e.g.&nbsp;classification), therefore always SOC. This is seen mainly in the context of reduction (<a href="#sec-car-redux" class="quarto-xref"><span>Section 21.3</span></a>). i. Model Composition – This is commonly seen in the context of wrappers (<a href="#sec-car-reduxes-r7-mlc" class="quarto-xref"><span>Section 21.5.1.4</span></a>), in which one model is contained within another. i. Data Composition – This is transformation of training/testing data types, which occurs at the first stage of every pipeline.</p>
</section><section id="sec-car-comp-mot" class="level3" data-number="21.2.2"><h3 data-number="21.2.2" class="anchored" data-anchor-id="sec-car-comp-mot">
<span class="header-section-number">21.2.2</span> Motivation for Composition</h3>
<p>Two examples are provided below to demonstrate common uses of composition in survival analysis and to motivate the compositions introduced in <a href="#sec-car-pipelines" class="quarto-xref"><span>Section 21.4</span></a>.</p>
<section id="example-1-cox-proportional-hazards" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="example-1-cox-proportional-hazards">Example 1: Cox Proportional Hazards</h4>
<p>Common implementations of well-known models can themselves be viewed as composite models, the Cox PH is the most prominent example in survival analysis. Recall the model defined by</p>
<p><span class="math display">\[
h(\tau|X_i) = h_0(\tau)\exp(\beta X_i)
\]</span> where <span class="math inline">\(h_0\)</span> is the baseline hazard and <span class="math inline">\(\beta\)</span> are the model coefficients.</p>
<p>This can be seen as a composite model as Cox defines the model in two stages <span class="citation" data-cites="Cox1972">(<a href="references.html#ref-Cox1972" role="doc-biblioref">Cox 1972</a>)</span>: first fitting the <span class="math inline">\(\beta\)</span>-coefficients using the partial likelihood and then by suggesting an estimate for the baseline distribution. This first stage produces a linear predictor return type (<a href="survtsk.html#sec-surv-set-types" class="quarto-xref"><span>Section 6.1</span></a>) and the second stage returns a survival distribution prediction. Therefore the Cox model for linear predictions is a single (non-composite) model, however when used to make distribution predictions then it is a composite. Cox implicitly describes the model as a composite by writing ‘’alternative simpler procedures would be worth having’’ <span class="citation" data-cites="Cox1972">(<a href="references.html#ref-Cox1972" role="doc-biblioref">Cox 1972</a>)</span>, which implies a decision in fitting (a key feature of composition). This composition is formalised in <a href="#sec-car-pipelines-distr" class="quarto-xref"><span>Section 21.4.1</span></a> as a general pipeline . The Cox model utilises the pipeline with a PH form and Kaplan-Meier baseline.</p>
</section><section id="example-2-random-survival-forests" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="example-2-random-survival-forests">Example 2: Random Survival Forests</h4>
<p>Fully discussed in <a href="forests.html#sec-surv-ml-models-ranfor" class="quarto-xref"><span>Section 15.1</span></a>, random survival forests are composed from many individual decision trees via a prediction composition algorithm (<span class="citation" data-cites="alg-rsf-pred">(<a href="references.html#ref-alg-rsf-pred" role="doc-biblioref"><strong>alg-rsf-pred?</strong></a>)</span>). In general, random forests perform better than their component decision trees, which tends to be true of all ensemble methods. Aggregation of predictions in survival analysis requires slightly more care than other fields due to the multiple prediction types, however this is still possible and is formalised in <a href="#sec-car-pipelines-avg" class="quarto-xref"><span>Section 21.4.4</span></a>.</p>
</section></section></section><section id="sec-car-redux" class="level2" data-number="21.3"><h2 data-number="21.3" class="anchored" data-anchor-id="sec-car-redux">
<span class="header-section-number">21.3</span> Introduction to Reduction</h2>
<p>This section introduces reduction, motivates its use in survival analysis (<a href="#sec-car-redux-mot" class="quarto-xref"><span>Section 21.3.1</span></a>), details an abstract reduction pipeline and defines the difference between a complete/incomplete reduction (<a href="#sec-car-redux-task" class="quarto-xref"><span>Section 21.3.2</span></a>), and outlines some common mistakes that have been observed in the literature when applying reduction (<a href="#sec-car-reduxstrats-mistakes" class="quarto-xref"><span>Section 21.3.3</span></a>).</p>
<p>Reduction is a concept found across disciplines with varying definitions. This report uses the Langford definition: reduction is ‘’a complex problem decomposed into simpler subproblems so that a solution to the subproblems gives a solution to the complex problem’’ <span class="citation" data-cites="Langford2016">(<a href="references.html#ref-Langford2016" role="doc-biblioref">Langford et al. 2016</a>)</span>. Generalisation (or induction) is a common real-world use of reduction, for example sampling a subset of a population in order to estimate population-level results. The true answer (population-level values) may not always be found in this way but very good approximations can be made with simpler sub-problems (sub-sampling).</p>
<p>Reductions are workflows that utilise composition. By including hyper-parameters, even complex reduction strategies can remain relatively flexible. To illustrate reduction by example, recall the table-building example (<a href="#sec-car-comp" class="quarto-xref"><span>Section 21.2</span></a>) in which the task of interest is to acquire a table. The most direct but complex solution is to fell a tree and directly saw it into a table (<a href="#fig-car-redux" class="quarto-xref">Figure&nbsp;<span>21.2</span></a>, top), clearly this is not a sensible process. Instead the problem can be reduced into simpler sub-problems: saw the tree into bundles of wood, acquire nails, and then use the ‘hammer compositor’ (<a href="#fig-car-comp-ex" class="quarto-xref">Figure&nbsp;<span>21.1</span></a>) to create a table (<a href="#fig-car-redux" class="quarto-xref">Figure&nbsp;<span>21.2</span></a>, bottom).</p>
<div id="fig-car-redux" class="quarto-figure quarto-figure-center quarto-float anchored" alt="TODO">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-car-redux-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/car/redux.png" class="img-fluid figure-img" alt="TODO">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-car-redux-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;21.2: Visualising reduction in the real-world. The complex process (top) of directly sawing a tree into a table is inefficient and unnecessarily complex. The reduction (bottom) that involves first creating bundles of wood is simpler, more efficient, and yields the same result, though technically requiring more steps.
</figcaption></figure>
</div>
<p>In a modelling example, predicting a survival distribution with the Cox model can be viewed as a reduction in which two sub-problems are solved and composed:</p>
<ol type="i">
<li>predict continuous ranking;</li>
<li>estimate baseline hazard; and</li>
<li>compose with (<a href="#sec-car-pipelines-distr" class="quarto-xref"><span>Section 21.4.1</span></a>).</li>
</ol>
<p>This is visualised as a reduction strategy in <span class="quarto-unresolved-ref">?fig-car-cargraph</span>. The entire process from defining the original problem, to combining the simpler sub-solutions (in green), is the reduction (in red).</p>
<!-- \begin{figure}[h]
\centering
\begin{tikzpicture}
\node (t0) [objnode, minimum width = 6.2cm]  {Task: Predict Distribution};
\node (t1) [objnode, above=of t0, minimum width = 6.2cm] {Sub-Task: Predict Ranking};
\node (t2) [objnode, below=of t0, minimum width = 6.2cm] {Sub-Task: Estimate Baseline};
\node (t3) [objnode, right=of t1,xshift=1.5cm] {$\hat{\eta}$};
\node (t6) [funnode, below=of t3, fill = orange!30] {$C$};
\node (t4) [objnode, below=of t6] {$\hatS_0$};
\node (t5) [objnode, left=of t6] {$S$};
\node (t7) [objnode, right=of t6] {$\zeta$};
\node (t8) [below=of t7, minimum width=10mm, minimum height = 5mm] {};

\path[->]
   (t0)  edge (t1)
   (t0)  edge (t2)
   (t1)  edge (t3)
   (t2)  edge (t4)
   (t3)  edge (t6)
   (t4)  edge (t6)
   (t5)  edge (t6)
   (t6)  edge (t7);

\begin{pgfonlayer}{background}
  \draw[fill=red!30,fill opacity = 0.5,rounded corners]
($(t1.north west)+(-0.1,0.2)$) rectangle ($(t8.south east)+(0.1,-0.4)$);
  \draw[fill=green!30,fill opacity = 0.5,rounded corners]
($(t3.north west)+(-2,0.1)$) rectangle ($(t4.south east) +(0.1,-0.1)$);
 \end{pgfonlayer}
\end{tikzpicture}
\caption[Probabilistic survival task reduction]{Solving a survival distribution task by utilising reduction and (C1) (@sec-car-pipelines-distr). $S$, $\hat{\eta}$, $C$, $\hatS_0$ are fully described in @fig-car-comp-distr. The nodes in the green area are part of the composite model, all nodes combined form the reduction.}\label{fig:car_cargraph}
\end{figure} -->
<section id="sec-car-redux-mot" class="level3" data-number="21.3.1"><h3 data-number="21.3.1" class="anchored" data-anchor-id="sec-car-redux-mot">
<span class="header-section-number">21.3.1</span> Reduction Motivation</h3>
<p>Formalisation of reduction positively impacts upon accessibility, transparency, and predictive performance. Improvements to predictive performance have already been demonstrated when comparing random forests to decision trees. In addition, a reduction with multiple stages and many hyper-parameters allows for fine tuning for improved transparency and model performance (usual overfitting caveat applies, as does the trade-off described in <span class="quarto-unresolved-ref">?sec-car-pipelines-trade</span>).</p>
<p>The survey of ANNs (<a href="neuralnetworks.html#sec-surv-ml-models-nn" class="quarto-xref"><span>Section 18.1</span></a>) demonstrated how reduction is currently utilised without transparency. Many of these ANNs are implicitly reductions to probabilistic classification (<a href="#sec-car-reduxes-r7" class="quarto-xref"><span>Section 21.5.1.6</span></a>) however none include details about how the reduction is performed. Furthermore in implementation, none provide interface points to the reduction hyper-parameters. Formalisation encourages consistent terminology, methodology and transparent implementation, which can only improve model performance by exposing further hyper-parameters.</p>
<p>Accessibility is improved by formalising specific reduction workflows that previously demanded expert knowledge in deriving, building, and running these pipelines. All regression reductions in this chapter, are implemented in \ <a href="https://cran.r-project.org/package=mlr3proba"><code>mlr3proba</code></a> <span class="citation" data-cites="pkgmlr3proba">(<a href="references.html#ref-pkgmlr3proba" role="doc-biblioref">R. Sonabend et al. 2021</a>)</span> and can be utilised with any possible survival model.</p>
<p>Finally there is an economic and efficiency advantage to reduction. A reduction model is relatively ‘cheap’ to explore as they utilise pre-established models and components to solve a new problem. Therefore if a certain degree of predictive ability can be demonstrated from reduction models, it may not be worth the expense of pursuing more novel ideas and hence reduction can help direct future research.</p>
</section><section id="sec-car-redux-task" class="level3" data-number="21.3.2"><h3 data-number="21.3.2" class="anchored" data-anchor-id="sec-car-redux-task">
<span class="header-section-number">21.3.2</span> Task, Loss, and Data Reduction</h3>
<p>Reduction can be categorised into task, loss, and data reduction, often these must be used in conjunction with each other. The direction of the reductions may be one- or two-way; this is visualised in <span class="quarto-unresolved-ref">?fig-car-reduxdiag</span>. This diagram should not be viewed as a strict fit/predict/evaluation workflow but instead as a guidance for which tasks, <span class="math inline">\(T\)</span>, data, <span class="math inline">\(D\)</span>, models, <span class="math inline">\(M\)</span>, and losses, <span class="math inline">\(L\)</span>, are required for each other. The subscript <span class="math inline">\(O\)</span> refers to the original object ‘level’ before reduction, whereas the subscript <span class="math inline">\(R\)</span> is in reference to the reduced object.</p>
<!-- \begin{figure}[H]
\centering
\begin{tikzpicture}
\node (t0) {$L_O$};

\node (t2)  [below=0.3cm of t0] {$D_O$};
\node (t3)  [below=0.3cm of t2] {$D_R$};

\node (t4)  [right=2cm of t0] {$M_O$};
\node (t5)  [right=2cm of t3] {$M_R$};

\node (t6)  [right=2cm of t4] {$T_O$};
\node (t7)  [right=2cm of t5] {$T_R$};

\path[->]
   (t2) edge (t0)
   (t2) edge (t3)

   (t3) edge (t5)

   (t4) edge (t0)
   (t4) edge (t6)

   (t5) edge (t4)

   (t6) edge (t7)

   (t7) edge (t5);
\end{tikzpicture}
\caption[Task, loss, and data reduction]{Task, loss, and data reduction to and from the original complex problem to sub-problems.}
\label{fig:car_reduxdiag}
\end{figure} -->
<p>The individual task, model, and data compositions in the diagram are listed below, the reduction from survival to classification (<a href="#sec-car-reduxes-r7r8" class="quarto-xref"><span>Section 21.5.1</span></a>) is utilised as a running example to help exposition.</p>
<ul>
<li>
<span class="math inline">\(T_O \rightarrow T_R\)</span>: By definition of a machine learning reduction, task reduction will always be one way. A more complex task, <span class="math inline">\(T_O\)</span>, is reduced to a simpler one, <span class="math inline">\(T_R\)</span>, for solving. <span class="math inline">\(T_R\)</span> could also be multiple simpler tasks. For example, solving a survival task, <span class="math inline">\(T_O\)</span>, by classification, <span class="math inline">\(T_R\)</span> (<a href="#sec-car-reduxes-r7r8" class="quarto-xref"><span>Section 21.5.1</span></a>).</li>
<li>
<span class="math inline">\(T_R \rightarrow M_R\)</span>: All machine learning tasks have models that are designed to solve them. For example logistic regression, <span class="math inline">\(M_R\)</span>, for classification tasks, <span class="math inline">\(T_R\)</span>.</li>
<li>
<span class="math inline">\(M_R \rightarrow M_O\)</span>: The simpler models, <span class="math inline">\(M_R\)</span>, are used for the express purpose to solve the original task, <span class="math inline">\(T_O\)</span>, via solving the simpler ones. To solve <span class="math inline">\(T_O\)</span>, a compositor must be applied, which may transform one (SOC) or multiple models (MOC) at a model- or prediction-level, thus creating <span class="math inline">\(M_O\)</span>. For example predicting survival probabilities with logistic regression, <span class="math inline">\(M_R\)</span>, at times <span class="math inline">\(1,...,\tau^*\)</span> for some <span class="math inline">\(\tau^* \in \mathbb{N}_{&gt; 0}\)</span> (<a href="#sec-car-reduxes-r7-mlc" class="quarto-xref"><span>Section 21.5.1.4</span></a>).</li>
<li>
<span class="math inline">\(M_O \rightarrow T_O\)</span>: The original task should be solvable by the composite model. For example predicting a discrete survival distribution by concatenating probabilistic predictions at the times <span class="math inline">\(1,...,\tau^*\)</span> (<a href="#sec-car-reduxes-r7" class="quarto-xref"><span>Section 21.5.1.6</span></a>).</li>
<li>
<span class="math inline">\(D_O \rightarrow D_R\)</span>: Just as the tasks and models are reduced, the data required to fit these must likewise be reduced. Similarly to task reduction, data reduction can usually only take place in one direction, to see why this is the case take an example of data reduction by summaries. If presented with 10 data-points <span class="math inline">\(\{1,1,1,5,7,3,5,4,3,3\}\)</span> then these could be reduced to a single point by calculating the sample mean, <span class="math inline">\(3.3\)</span>. Clearly given only the number <span class="math inline">\(3.3\)</span> there is no strategy to recover the original data. There are very few (if any) data reduction strategies that allow recovery of the original data. Continuing the running example, survival data, <span class="math inline">\(D_O\)</span>, can be binned (<a href="#sec-car-reduxes-r7-binning" class="quarto-xref"><span>Section 21.5.1.1</span></a>) to classification data, <span class="math inline">\(D_R\)</span>.</li>
</ul>
<p>There is no arrow between <span class="math inline">\(D_O\)</span> and <span class="math inline">\(M_O\)</span> as the composite model is never fit directly, only via composition from <span class="math inline">\(M_R \rightarrow M_O\)</span>. However, the original data, <span class="math inline">\(D_O\)</span>, is required when evaluating the composite model against the respective loss, <span class="math inline">\(L_O\)</span>. Reduction should be directly comparable to non-reduction models, hence this diagram does not include loss reduction and instead insists that all models are compared against the same loss <span class="math inline">\(L_O\)</span>.</p>
<p>A reduction is said to be <em>complete</em> if there is a full pipeline from <span class="math inline">\(T_O \rightarrow M_O\)</span> and the original task is solved, otherwise it is <em>incomplete</em>. The simplest complete reduction is comprised of the pipeline <span class="math inline">\(T_O \rightarrow T_R \rightarrow M_R \rightarrow M_O\)</span>. Usually this is not sufficient on its own as the reduced models are fit on the reduced data, <span class="math inline">\(D_R \rightarrow M_R\)</span>.</p>
<p>A complete reduction can be specified by detailing:</p>
<ol type="i">
<li>the original task and the sub-task(s) to be solved, <span class="math inline">\(T_O \rightarrow T_R\)</span>;</li>
<li>the original dataset and the transformation to the reduced one, <span class="math inline">\(D_O \rightarrow D_R\)</span> (if required); and</li>
<li>the composition from the simpler model to the complex one, <span class="math inline">\(M_R \rightarrow M_O\)</span>.</li>
</ol></section><section id="sec-car-reduxstrats-mistakes" class="level3" data-number="21.3.3"><h3 data-number="21.3.3" class="anchored" data-anchor-id="sec-car-reduxstrats-mistakes">
<span class="header-section-number">21.3.3</span> Common Mistakes in Implementation of Reduction</h3>
<p>In surveying models and measures, several common mistakes in the implementation of reduction and composition were found to be particularly prevalent and problematic throughout the literature. It is assumed that these are indeed mistakes (not deliberate) and result from a lack of prior formalisation. These mistakes were even identified 20 years ago <span class="citation" data-cites="Schwarzer2000">(<a href="references.html#ref-Schwarzer2000" role="doc-biblioref">Schwarzer, Vach, and Schumacher 2010</a>)</span> but are provided in more detail in order to highlight their current prevalence and why they cannot be ignored.</p>
<p>RM1. Incomplete reduction. This occurs when a reduction workflow is presented as if it solves the original task but fails to do so and only the reduction strategy is solved. A common example is claiming to solve the survival task by using binary classification, e.g.&nbsp;erroneously claiming that a model predicts survival probabilities (which implies distribution) when it actually predicts a five year probability of death (<span class="citation" data-cites="box-task-classif">(<a href="references.html#ref-box-task-classif" role="doc-biblioref"><strong>box-task-classif?</strong></a>)</span>). This is a mistake as it misleads readers into believing that the model solves a survival task (<span class="citation" data-cites="box-task-surv">(<a href="references.html#ref-box-task-surv" role="doc-biblioref"><strong>box-task-surv?</strong></a>)</span>) when it does not. This is usually a semantic not mathematical error and results from misuse of terminology. It is important to be clear about model predict types (<a href="survtsk.html#sec-surv-set-types" class="quarto-xref"><span>Section 6.1</span></a>) and general terms such as ‘survival predictions’ should be avoided unless they refer to one of the three prediction tasks. RM2. Inappropriate comparisons. This is a direct consequence of (RM1) and the two are often seen together. (RM2) occurs when an incomplete reduction is directly compared to a survival model (or complete reduction model) using a measure appropriate for the reduction. This may lead to a reduction model appearing erroneously superior. For example, comparing a logistic regression to a random survival forest (RSF) (<a href="forests.html#sec-surv-ml-models-ranfor" class="quarto-xref"><span>Section 15.1</span></a>) for predicting survival probabilities at a single time using the accuracy measure is an unfair comparison as the RSF is optimised for distribution predictions. This would be non-problematic if a suitable composition is clearly utilised. For example a regression SSVM predicting survival time cannot be directly compared to a Cox PH. However the SSVM can be compared to a CPH composed with the probabilistic to deterministic compositor , then conclusions can be drawn about comparison to the composite survival time Cox model (and not simply a Cox PH). RM3. Na"ive censoring deletion. This common mistake occurs when trying to reduce survival to regression or classification by simply deleting all censored observations, even if censoring is informative. This is a mistake as it creates bias in the dataset, which can be substantial if the proportion of censoring is high and informative. More robust deletion methods are described in <a href="pseudo.html" class="quarto-xref"><span>Chapter 25</span></a>. RM4. Oversampling uncensored observations. This is often seen when trying to reduce survival to regression or classification, and often alongside (RM3). Oversampling is the process of replicating observations to artificially inflate the sample size of the data. Whilst this process does not create any new information, it can help a model detect important features in the data. However, by only oversampling uncensored observations, this creates a source of bias in the data and ignores the potentially informative information provided by the proportion of censoring.</p>
</section></section><section id="sec-car-pipelines" class="level2" data-number="21.4"><h2 data-number="21.4" class="anchored" data-anchor-id="sec-car-pipelines">
<span class="header-section-number">21.4</span> Composition Strategies for Survival Analysis</h2>
<p>Though composition is common practice in survival analysis, with the Cox model being a prominent example, a lack of formalisation means a lack of consensus in simple operations. For example, it is often asked in survival analysis how a model predicting a survival distribution can be used to return a survival time prediction. A common strategy is to define the survival time prediction as the median of the predicted survival curve however there is no clear reason why this should be more sensible than returning the distribution mean, mode, or some random quantile. Formalisation allow these choices to be analytically compared both theoretically and practically as hyper-parameters in a workflow. Four prediction compositions are discussed in this section (<span class="citation" data-cites="tab-car-taxredcar">(<a href="references.html#ref-tab-car-taxredcar" role="doc-biblioref"><strong>tab-car-taxredcar?</strong></a>)</span>), three are utilised to convert prediction types between one another, the fourth is for aggregating multiple predictions. One data composition is discussed for converting survival to regression data. Each is first graphically represented and then the components are discussed in detail. As with losses in the previous chapter, compositions are discussed at an individual observation level but extend trivially to multiple observations.</p>
<table class="caption-top table">
<caption>Compositions formalised in <a href="#sec-car-pipelines" class="quarto-xref"><span>Section 21.4</span></a>.</caption>
<thead><tr class="header">
<th>ID<span class="math inline">\(^1\)</span>
</th>
<th>Composition</th>
<th>Type<span class="math inline">\(^2\)</span>
</th>
<th>Level<span class="math inline">\(^3\)</span>
</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>C1)</td>
<td>Linear predictor to distribution</td>
<td>MOC</td>
<td>Prediction</td>
</tr>
<tr class="even">
<td>C2)</td>
<td>Survival time to distribution</td>
<td>MOC</td>
<td>Prediction</td>
</tr>
<tr class="odd">
<td>C3)</td>
<td>Distribution to survival time</td>
<td>SOC</td>
<td>Prediction</td>
</tr>
<tr class="even">
<td>C4)</td>
<td>Survival model averaging</td>
<td>MOC</td>
<td>Prediction</td>
</tr>
<tr class="odd">
<td>C5)</td>
<td>Survival to regression</td>
<td>SOC</td>
<td>Data</td>
</tr>
</tbody>
</table>
<p><sup> 1. ID for reference throughout this book. 2. Composition type. Multi-object composition (MOC) or single-object composition (SOC). 3. Composition level. </sup></p>
<section id="sec-car-pipelines-distr" class="level3" data-number="21.4.1"><h3 data-number="21.4.1" class="anchored" data-anchor-id="sec-car-pipelines-distr">
<span class="header-section-number">21.4.1</span> C1) Linear Predictor <span class="math inline">\(\rightarrow\)</span> Distribution</h3>
<!-- \begin{figure}[H]
\centering
\begin{tikzpicture}[framed]
\node (t0)[objnode] {$\hat{\eta}$};
\node (t3)[funnode,right=of t0,fill=orange!30]{$C$};
\node (t1)[objnode,above=of t3]{$M$};
\node (t2)[objnode,below=of t3]{$\hatS_0$};
\node (t4)[objnode, right=of t3]{$\zeta$};

\path[->]
   (t0) edge  (t3)
   (t1) edge  (t3)
   (t2) edge  (t3)
   (t3) edge  (t4);
\end{tikzpicture}
\caption[Linear predictor to distribution composition]{Linear predictor ($\hat{\eta}$) to survival distribution ($\zeta$) composition. Parameters: $M$ -- Model form; $\hatS_0$ -- Estimated baseline survival function.}
\label{fig:car_comp_distr}
\end{figure} -->
<p>This is a prediction-level MOC that composes a survival distribution from a predicted linear predictor and estimated baseline survival distribution. The composition (<span class="quarto-unresolved-ref">?fig-car-comp-distr</span>) requires:</p>
<ul>
<li><p><span class="math inline">\(\hat{\eta}\)</span>: Predicted linear predictor. <span class="math inline">\(\hat{\eta}\)</span> can be tuned by including this composition multiple times in a benchmark experiment with different models predicting <span class="math inline">\(\hat{\eta}\)</span>. In theory any continuous ranking could be utilised instead of a linear predictor though results may be less sensible (<span class="quarto-unresolved-ref">?sec-car-pipelines-trade</span>).</p></li>
<li><p><span class="math inline">\(\hat{S}_0\)</span>: Estimated baseline survival function. This is usually estimated by the Kaplan-Meier estimator fit on training data, <span class="math inline">\(\hat{S}_{KM}\)</span>. However any model that can predict a survival distribution can estimate the baseline distribution (caveat: see <span class="quarto-unresolved-ref">?sec-car-pipelines-trade</span>) by taking a uniform mixture of the predicted individual distributions: say <span class="math inline">\(\xi_1,...,\xi_m\)</span> are m predicted distributions, then <span class="math inline">\(\hat{S}_0(\tau) = \frac{1}{m} \sum^{m}_{i = 1} \xi_i.S(\tau)\)</span>. The mixture is required as the baseline must be the same for all observations. Alternatively, parametric distributions can be assumed for the baseline, e.g.&nbsp;<span class="math inline">\(\xi = \operatorname{Exp}(2)\)</span> and <span class="math inline">\(\xi.S(t) = \exp(-2t)\)</span>. As with <span class="math inline">\(\hat{\eta}\)</span>, this parameter is also tunable.</p></li>
<li><p><span class="math inline">\(M\)</span>: Chosen model form, which theoretically can be any non-increasing right-continuous function but is usually one of:</p></li>
<li><p>Proportional Hazards (PH): <span class="math inline">\(S_{PH}(\tau|\eta, S_0) = S_0(\tau)^{\exp(\eta)}\)</span></p></li>
<li><p>Accelerated Failure Time (AFT): <span class="math inline">\(S_{AFT}(\tau|\eta, S_0) = S_0(\frac{\tau}{\exp(\eta)})\)</span></p></li>
<li><p>Proportional Odds (PO): <span class="math inline">\(S_{PO}(\tau|\eta, S_0) = \frac{S_0(\tau)}{\exp(-\eta) + (1-\exp(-\eta)) S_0(\tau)}\)</span></p></li>
</ul>
<p>Models that predict linear predictors will make assumptions about the model form and therefore dictate sensible choices of <span class="math inline">\(M\)</span>, for example the Cox model assumes a PH form. This does not mean other choices of <span class="math inline">\(M\)</span> cannot be specified but that interpretation may be more difficult (<span class="quarto-unresolved-ref">?sec-car-pipelines-trade</span>). The model form can be treated as a hyper-parameter to tune. * <span class="math inline">\(C\)</span>: Compositor returning the composed distribution, <span class="math inline">\(\zeta := C(M, \hat{\eta}, \hat{S}_0)\)</span> where <span class="math inline">\(\zeta\)</span> has survival function <span class="math inline">\(\zeta.S(\tau) = M(\tau|\hat{\eta}, \hat{S}_0)\)</span>.</p>
<p>Pseudo-code for training (<span class="citation" data-cites="alg-car-comp-distr-fit">(<a href="references.html#ref-alg-car-comp-distr-fit" role="doc-biblioref"><strong>alg-car-comp-distr-fit?</strong></a>)</span>) and predicting (<span class="citation" data-cites="alg-car-comp-distr-pred">(<a href="references.html#ref-alg-car-comp-distr-pred" role="doc-biblioref"><strong>alg-car-comp-distr-pred?</strong></a>)</span>) this composition as a model ‘wrapper’ with sensible parameter choices (<span class="quarto-unresolved-ref">?sec-car-pipelines-trade</span>) is provided in appendix <span class="citation" data-cites="app-car">(<a href="references.html#ref-app-car" role="doc-biblioref"><strong>app-car?</strong></a>)</span>.</p>
</section><section id="sec-car-pipelines-time" class="level3" data-number="21.4.2"><h3 data-number="21.4.2" class="anchored" data-anchor-id="sec-car-pipelines-time">
<span class="header-section-number">21.4.2</span> C2) Survival Time <span class="math inline">\(\rightarrow\)</span> Distribution</h3>
<!-- \begin{figure}[H]
\centering
\begin{tikzpicture}[framed]
\node (t4)[objnode]{$\hatT$};
\node (t3)[funnode,right=of t4,fill=orange!30]{$C$};
\node (t1)[objnode,above=of t3]{$\xi$};
\node (t6)[objnode, below=of t3]{$\hat{\sigma}$};
\node (t5)[objnode, right=of t3]{$\zeta$};

\path[->]
   (t1) edge  (t3)
   (t6) edge (t3)
   (t4) edge  (t3)
   (t3) edge  (t5);
\end{tikzpicture}
\caption[Survival time to distribution composition]{Survival time ($\hatT$) to distribution ($\zeta$) composition. Parameters: $\hat{\sigma}$ -- Estimated scale parameter; $\xi$ -- Assumed survival distribution.}
\label{fig:car_comp_response}
\end{figure} -->
<p>This is a prediction-level MOC that composes a distribution from a predicted survival time and assumed location-scale distribution. The composition (<span class="quarto-unresolved-ref">?fig-car-comp-response</span>) requires:</p>
<ul>
<li>
<span class="math inline">\(\hat{T}\)</span>: A predicted survival time. As with the previous composition, this is tunable. In theory any continuous ranking could replace <span class="math inline">\(\hat{T}\)</span>, though the resulting distribution may not be sensible (<span class="quarto-unresolved-ref">?sec-car-pipelines-trade</span>).</li>
<li>
<span class="math inline">\(\xi\)</span>: A specified location-scale distribution, <span class="math inline">\(\xi(\mu, \sigma)\)</span>, e.g.&nbsp;Normal distribution.</li>
<li>
<span class="math inline">\(\hat{\sigma}\)</span>: Estimated scale parameter for the distribution. This can be treated as a hyper-parameter or predicted by another model.</li>
<li>
<span class="math inline">\(C\)</span>: Compositor returning the composed distribution <span class="math inline">\(\zeta := C(\xi, \hat{T}, \hat{\sigma}) = \xi(\hat{T}, \hat{\sigma})\)</span>.</li>
</ul>
<p>Pseudo-code for training (<span class="citation" data-cites="alg-car-comp-response-fit">(<a href="references.html#ref-alg-car-comp-response-fit" role="doc-biblioref"><strong>alg-car-comp-response-fit?</strong></a>)</span>) and predicting (<span class="citation" data-cites="alg-car-comp-response-pred">(<a href="references.html#ref-alg-car-comp-response-pred" role="doc-biblioref"><strong>alg-car-comp-response-pred?</strong></a>)</span>) this composition as a model ‘wrapper’ with sensible parameter choices (<span class="quarto-unresolved-ref">?sec-car-pipelines-trade</span>) is provided in appendix <span class="citation" data-cites="app-car">(<a href="references.html#ref-app-car" role="doc-biblioref"><strong>app-car?</strong></a>)</span>.</p>
</section><section id="sec-car-pipelines-crank" class="level3" data-number="21.4.3"><h3 data-number="21.4.3" class="anchored" data-anchor-id="sec-car-pipelines-crank">
<span class="header-section-number">21.4.3</span> C3) Distribution <span class="math inline">\(\rightarrow\)</span> Survival Time Composition</h3>
<!-- \begin{figure}[H]
\centering
\begin{tikzpicture}[framed]
\node (t1)[funnode, right=of t0]{$\zeta$};
\node (t2)[funnode, right=of t1, fill = orange!30]{$C$};
\node (t4)[objnode, above=of t2]{$\phi$};
\node (t3)[objnode, right=of t2]{$\hatT$};

\path[->]
   (t1) edge  (t2)
   (t4) edge  (t2)
   (t2) edge  (t3);
\end{tikzpicture}
\caption[Distribution to survival time composition]{Distribution ($\zeta$) to survival time ($\hatT$) composition. Parameters: $\phi$ -- Summary method.}
\label{fig:car_comp_crank}
\end{figure} -->
<p>This is a prediction-level SOC that composes a survival time from a predicted distribution. Any paper that evaluates a distribution on concordance is implicitly using this composition in some manner. Not acknowledging the composition leads to unfair model comparison (<a href="#sec-car-reduxstrats-mistakes" class="quarto-xref"><span>Section 21.3.3</span></a>). The composition (<span class="quarto-unresolved-ref">?fig-car-comp-crank</span>) requires:</p>
<ul>
<li>
<span class="math inline">\(\zeta\)</span>: A predicted survival distribution, which again is ‘tunable’.</li>
<li>
<span class="math inline">\(\phi\)</span>: A distribution summary method. Common examples include the mean, median and mode. Other alternatives include distribution quantiles, <span class="math inline">\(\zeta.F^{-1}(\alpha)\)</span>,\<span class="math inline">\(\alpha \in [0,1]\)</span>; <span class="math inline">\(\alpha\)</span> could be tuned as a hyper-parameter.</li>
<li>
<span class="math inline">\(C\)</span>: Compositor returning composed survival time predictions, <span class="math inline">\(\hat{T}:= C(\phi, \zeta) = \phi(\zeta)\)</span>.</li>
</ul>
<p>Pseudo-code for training (<span class="citation" data-cites="alg-car-comp-crank-fit">(<a href="references.html#ref-alg-car-comp-crank-fit" role="doc-biblioref"><strong>alg-car-comp-crank-fit?</strong></a>)</span>) and predicting (<span class="citation" data-cites="alg-car-comp-crank-pred">(<a href="references.html#ref-alg-car-comp-crank-pred" role="doc-biblioref"><strong>alg-car-comp-crank-pred?</strong></a>)</span>) this composition as a model ‘wrapper’ with sensible parameter choices (<span class="quarto-unresolved-ref">?sec-car-pipelines-trade</span>) is provided in appendix <span class="citation" data-cites="app-car">(<a href="references.html#ref-app-car" role="doc-biblioref"><strong>app-car?</strong></a>)</span>.</p>
</section><section id="sec-car-pipelines-avg" class="level3" data-number="21.4.4"><h3 data-number="21.4.4" class="anchored" data-anchor-id="sec-car-pipelines-avg">
<span class="header-section-number">21.4.4</span> C4) Survival Model Averaging</h3>
<!-- \begin{figure}[H]
\centering
\begin{tikzpicture}[framed]
\node (t2)[funnode, above right=of t0,yshift=-10mm]{$\rho_2$};
\node (t1)[funnode, above=of t2, yshift=-5mm]{$\rho_1$};
\node (t3)[funnode, below right=of t0,yshift=10mm]{...};
\node (t4)[funnode, below=of t3,yshift=5mm]{$\rho_B$};
\node (t5)[funnode, right=of t0, fill=orange!30,xshift=20mm]{$C$};
\node (t6)[objnode, right=of t5]{$\hat{\rho}$};
\node (t7)[objnode, below=of t5, yshift = 0.2cm]{$w$};

\path[->]
   (t1) edge  (t5)
   (t2) edge  (t5)
   (t3) edge  (t5)
   (t4) edge  (t5)
   (t5) edge  (t6)
   (t7) edge (t5);

\end{tikzpicture}
\caption[Survival model averaging composition]{Survival model averaging composition. $\rho_1,...,\rho_B$ are $B$ predictions of the same return type (time, ranking, distribution) and $\hat{\rho}$ is the averaged prediction. Parameters: $w = w_1,...,w_B$ -- Weights summing to one.}
\label{fig:car_comp_avg}
\end{figure} -->
<p>Ensembling is likely the most common composition in machine learning. In survival it is complicated slightly as multiple prediction types means one of two possible compositions is utilised to average predictions. The (<span class="quarto-unresolved-ref">?fig-car-comp-avg</span>) composition requires:</p>
<ul>
<li>
<span class="math inline">\(\rho = \rho_1,...,\rho_B\)</span>: <span class="math inline">\(B\)</span> predictions (not necessarily from the same model) of the same type: ranking, survival time or distribution; again ‘tunable’.</li>
<li>
<span class="math inline">\(w = w_1,...,w_B\)</span>: Weights that sum to one.</li>
<li>
<span class="math inline">\(C\)</span>: Compositor returning combined predictions, <span class="math inline">\(\hat{\rho} := C(\rho, w)\)</span> where <span class="math inline">\(C(\rho, w) = \frac{1}{B} \sum^{B}_{i = 1} w_i \rho_i\)</span>, if <span class="math inline">\(\rho\)</span> are ranking of survival time predictions; or <span class="math inline">\(C(\rho, w) = \zeta\)</span> where <span class="math inline">\(\zeta\)</span> is the distribution defined by the survival function <span class="math inline">\(\zeta.S(\tau) = \frac{1}{B} \sum^{B}_{i = 1} w_i \rho_i.S(\tau)\)</span>, if <span class="math inline">\(\rho\)</span> are distribution predictions.</li>
</ul>
<p>Pseudo-code for training (<span class="citation" data-cites="alg-car-comp-avg-fit">(<a href="references.html#ref-alg-car-comp-avg-fit" role="doc-biblioref"><strong>alg-car-comp-avg-fit?</strong></a>)</span>) and predicting (<span class="citation" data-cites="alg-car-comp-avg-pred">(<a href="references.html#ref-alg-car-comp-avg-pred" role="doc-biblioref"><strong>alg-car-comp-avg-pred?</strong></a>)</span>) this composition as a model ‘wrapper’ with sensible parameter choices (<span class="quarto-unresolved-ref">?sec-car-pipelines-trade</span>) is provided in appendix <span class="citation" data-cites="app-car">(<a href="references.html#ref-app-car" role="doc-biblioref"><strong>app-car?</strong></a>)</span>.</p>
</section></section><section id="sec-car-reduxes" class="level2" data-number="21.5"><h2 data-number="21.5" class="anchored" data-anchor-id="sec-car-reduxes">
<span class="header-section-number">21.5</span> Novel Survival Reductions</h2>
<p>This section collects the various strategies and settings discussed previously into complete reduction workflows. <span class="citation" data-cites="tab-car-reduxes">(<a href="references.html#ref-tab-car-reduxes" role="doc-biblioref"><strong>tab-car-reduxes?</strong></a>)</span> lists the reductions discussed in this section with IDs for future reference. All strategies are described by visualising a graphical pipeline and then listing the composition steps required in fitting and predicting.</p>
<p>This section only includes novel reduction strategies and does not provide a survey of pre-existing strategies. This limitation is primarily due to time (and page) constraints as every method has very distinct workflows that require complex exposition. Well-established strategies are briefly mentioned below and future research is planned to survey and compare all strategies with respect to empirical performance (i.e.&nbsp;in benchmark experiments).</p>
<p>Two prominent reductions are ‘landmarking’ <span class="citation" data-cites="VanHouwelingen2007">(<a href="references.html#ref-VanHouwelingen2007" role="doc-biblioref">Van Houwelingen 2007</a>)</span> and piecewise exponential models <span class="citation" data-cites="Friedman1982">(<a href="references.html#ref-Friedman1982" role="doc-biblioref">Friedman 1982</a>)</span>. Both are reductions for time-varying covariates and hence outside the scope of this book. Relevant to this book scope is a large class of strategies that utilise ‘discrete time survival analysis’ <span class="citation" data-cites="Tutz2016">(<a href="references.html#ref-Tutz2016" role="doc-biblioref">Tutz and Schmid 2016</a>)</span>; these strategies include reductions (R7) and (R8). Methodology for discrete time survival analysis has been seen in the literature for the past three decades <span class="citation" data-cites="Liestol1994">(<a href="references.html#ref-Liestol1994" role="doc-biblioref">Liestol, Andersen, and Andersen 1994</a>)</span>. The primary reduction strategy for discrete time survival analysis is implemented in the <span class="math inline">\(\textsf{R}\)</span> package <a href="https://cran.r-project.org/package=discSurv"><code>discSurv</code></a> <span class="citation" data-cites="pkgdiscsurv">(<a href="references.html#ref-pkgdiscsurv" role="doc-biblioref">Welchowski and Schmid 2019</a>)</span>; this is very similar to (R7) except that it enforces stricter constraints in the composition procedures and forces a ‘discrete-hazard’ instead of ‘discrete-survival’ representation (<a href="#sec-car-reduxes-r7-out" class="quarto-xref"><span>Section 21.5.1.2</span></a>).</p>
<section id="sec-car-reduxes-r7r8" class="level3" data-number="21.5.1"><h3 data-number="21.5.1" class="anchored" data-anchor-id="sec-car-reduxes-r7r8">
<span class="header-section-number">21.5.1</span> R7-R8) Survival <span class="math inline">\(\rightarrow\)</span> Probabilistic Classification</h3>
<!-- \begin{figure}[H]
\centering
\begin{tikzpicture}[framed]
\node (t0) [objnode]  {$\dtrain$};
\node (t1) [funnode,right=of t0] {$B(\dtrain|w)$};
\node (t2) [objnode,right=of t1] {$D_B$};
\node (t3) [funnode, below=of t2] {$C_C$};
\node (t4) [funnode, right=of t3] {$g_C(D_B|\phi)$};
\node (t5) [funnode, above=of t2] {$C_B$};
\node (t6) [funnode, right=of t5] {$g_B(D_B|\varphi)$};
\node (t7) [funnode,right=of t2] {$g_L(D_B|\theta)$};
\node (t8) [objnode,right=of t7] {$\hatg$};

\node (t9) [objnode, below=of t0, yshift = -15mm] {$\dtest$};
\node (t10) [funnode, right=of t9] {$\hat{g}(\dtest|\Theta)$};
\node (t11) [objnode, right=of t10] {$\tilde{S}$};
\node (t12) [funnode, right=of t11] {$T_1(\tilde{S})$};
\node (t13) [funnode, below=of t12] {$T_2(\tilde{S})$};
\node (t14) [objnode, right=of t12] {$\zeta$};
\node (t15) [objnode, right=of t13] {$\hatT$};

\path[->]
   (t0)  edge (t1)
   (t1)  edge (t2)
   (t2)  edge[dashed] (t3)
   (t2)  edge[dashed] (t5)
   (t2)  edge[dashed] (t7)
   (t3)  edge (t4)
   (t4)  edge (t8)
   (t6)  edge (t8)
   (t7)  edge (t8)
   (t5)  edge (t6)

   (t9) edge (t10)
   (t10) edge (t11)
   (t11) edge[dotted,color=red] (t12)
   (t11) edge[dash dot,color=blue] (t13)
   (t12) edge[dotted,color=red] (t14)
   (t13) edge[dash dot,color=blue] (t15);

\draw[dashed, line width=0.1mm] (-1,-2.5) -- (11,-2.5);
\end{tikzpicture}
\caption[Survival to classification reduction]{Survival to classification reduction. Top row is fitting and bottom row is predicting. Dashed lines represent a choice in the reduction (alternative compositions). Red dotted lines complete the probabilistic survival reduction (R7) and the blue dash-dotted lines complete the deterministic survival reduction (R8). Key: training data, $\dtrain$; binning function, $B$, with weights, $w$; binned data, $D_B$; composition to binary-class classification, $C_B$; composition to multi-class classification, $C_C$; binary-class classifier, $g_B$, with parameters, $\varphi$; multi-label classifier, $g_L$, with parameters, $\theta$; multi-class classifier, $g_C$, with parameters $\phi$; trained classifier, $\hat{g}$ with parameters $\Theta$; testing data, $\dtest$; pseudo-survival probabilities, $\tilde{S}$; composition, $T_1$, to distribution, $\zeta$; composition, $T_2$, to survival time, $\hatT$.}
\label{fig:car_R7R8}
\end{figure} -->
<p>Two separate reductions are presented in <span class="quarto-unresolved-ref">?fig-car-R7R8</span> however as both are reductions to probabilistic classification and are only different in the very last step, both are presented in this section. Steps and compositions of the reduction (<span class="quarto-unresolved-ref">?fig-car-R7R8</span>):</p>
<p><strong>Fit</strong> F1) A survival dataset, <span class="math inline">\(\mathcal{D}_{train}\)</span>, is binned, <span class="math inline">\(B\)</span>, with a continuous to discrete data composition (<a href="#sec-car-reduxes-r7-binning" class="quarto-xref"><span>Section 21.5.1.1</span></a>). F2) A multi-label classification model, with adaptations for censoring, <span class="math inline">\(g_L(D_B|\theta)\)</span>, is fit on the transformed dataset, <span class="math inline">\(D_B\)</span>. Optionally, <span class="math inline">\(g_L\)</span> could be further reduced to binary, <span class="math inline">\(g_B\)</span>, or multi-class classification, <span class="math inline">\(g_c\)</span>, (<a href="#sec-car-reduxes-r7-mlc" class="quarto-xref"><span>Section 21.5.1.4</span></a>). <strong>Predict</strong> P1) Testing survival data, <span class="math inline">\(\mathcal{D}_{test}\)</span>, is passed to the trained classification model, <span class="math inline">\(\hat{g}\)</span>, to predict pseudo-survival probabilities <span class="math inline">\(\tilde{S}\)</span> (or optionally hazards (<a href="#sec-car-reduxes-r7-out" class="quarto-xref"><span>Section 21.5.1.2</span></a>)). P2a) Predictions can be composed, <span class="math inline">\(T_1\)</span>, into a survival distribution prediction, <span class="math inline">\(\zeta = \zeta_1,...,\zeta_m\)</span> (<a href="#sec-car-reduxes-r7" class="quarto-xref"><span>Section 21.5.1.6</span></a>); or, P2b) Predictions can be composed, <span class="math inline">\(T_2\)</span>, to survival time predictions, <span class="math inline">\(\hat{T}= \hat{T}_1,...,\hat{T}_m\)</span> (<a href="#sec-car-reduxes-r8" class="quarto-xref"><span>Section 21.5.1.7</span></a>).</p>
<p>Further details for binning, multi-label classification, and transformation of pseudo-survival probabilities are now provided.</p>
<section id="sec-car-reduxes-r7-binning" class="level4" data-number="21.5.1.1"><h4 data-number="21.5.1.1" class="anchored" data-anchor-id="sec-car-reduxes-r7-binning">
<span class="header-section-number">21.5.1.1</span> Composition: Binning Survival Times</h4>
<p>An essential part of the reduction is the transformation from a survival dataset to a classification dataset, which requires two separate compositions. The first (discussed here) is to discretise the survival times (<span class="math inline">\(B(\mathcal{D}_{train}|w)\)</span> in <span class="quarto-unresolved-ref">?fig-car-R7R8</span>) and the second is to merge the survival time and censoring indicator into a single outcome (<a href="#sec-car-reduxes-r7-out" class="quarto-xref"><span>Section 21.5.1.2</span></a>).</p>
<p>Discretising survival times is achieved by the common ‘binning’ composition, in which a continuous outcome is discretised into ‘bins’ according to specified thresholds. These thresholds are usually determined by specifying the width of the bins as a hyper-parameter <span class="math inline">\(w\)</span>. This is a common transformation and therefore further discussion is not provided here. An example is given below with the original survival data on the left and the binned data on the right (<span class="math inline">\(w = 1\)</span>).</p>
<table class="caption-top table">
<thead><tr class="header">
<th>X</th>
<th>Time (Cont.)</th>
<th>Died</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>1.56</td>
<td>0</td>
</tr>
<tr class="even">
<td>2</td>
<td>2</td>
<td>1</td>
</tr>
<tr class="odd">
<td>3</td>
<td>3.3</td>
<td>1</td>
</tr>
<tr class="even">
<td>4</td>
<td>3.6</td>
<td>0</td>
</tr>
<tr class="odd">
<td>5</td>
<td>4</td>
<td>0</td>
</tr>
</tbody>
</table>
<table class="caption-top table">
<thead><tr class="header">
<th>X</th>
<th>Time (Disc.)</th>
<th>Died</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>[1, 2)</td>
<td>0</td>
</tr>
<tr class="even">
<td>2</td>
<td>[2, 3)</td>
<td>1</td>
</tr>
<tr class="odd">
<td>3</td>
<td>[3, 4)</td>
<td>1</td>
</tr>
<tr class="even">
<td>4</td>
<td>[3, 4)</td>
<td>0</td>
</tr>
<tr class="odd">
<td>5</td>
<td>[4, 5)</td>
<td>0</td>
</tr>
</tbody>
</table></section><section id="sec-car-reduxes-r7-out" class="level4" data-number="21.5.1.2"><h4 data-number="21.5.1.2" class="anchored" data-anchor-id="sec-car-reduxes-r7-out">
<span class="header-section-number">21.5.1.2</span> Composition: Survival to Classification Outcome</h4>
<p>The binned dataset still has the unique survival data format of utilising two outcomes for training (time and status) but only making a prediction for one outcome (distribution). In order for this to be compatible with classification, the two outcome variables are composed into a single variable. This is achieved by casting the survival times into a ‘wide’ format and creating a new outcome indicator. Two outcome transformations are possible, the first represents a discrete survival function and the second represents a discrete hazard function.</p>
</section><section id="discrete-survival-function-composition" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="discrete-survival-function-composition">Discrete Survival Function Composition</h4>
<p>In this composition, the data in the transformed dataset represents the discrete survival function. The new indicator is defined as follows, <span class="math display">\[
Y_{i;\tau} :=
\begin{cases}
1, &amp; T_i &gt; \tau \\
0, &amp; T_i \leq \tau \cap \Delta_i = 1 \\
-1, &amp; T_i \leq \tau \cap \Delta_i = 0
\end{cases}
\]</span> At a given discrete time <span class="math inline">\(\tau\)</span>, an observation, <span class="math inline">\(i\)</span>, is either alive (<span class="math inline">\(Y_{i;\tau} = 1\)</span>), dead (<span class="math inline">\(Y_{i;\tau} = 0\)</span>), or censored (<span class="math inline">\(Y_{i;\tau} = -1\)</span>). Therefore <span class="math inline">\(\hat{P}(Y_{i;\tau} = 1) = \hat{S}_i(\tau)\)</span>, motivating this particular choice of representation.</p>
<p>This composition is demonstrated below with the binned data (left) and the composed classification data (right).</p>
<table class="caption-top table">
<thead><tr class="header">
<th>X</th>
<th>Time (Disc.)</th>
<th>Died</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>[1, 2)</td>
<td>0</td>
</tr>
<tr class="even">
<td>2</td>
<td>[2, 3)</td>
<td>1</td>
</tr>
<tr class="odd">
<td>3</td>
<td>[3, 4)</td>
<td>1</td>
</tr>
<tr class="even">
<td>4</td>
<td>[3, 4)</td>
<td>0</td>
</tr>
<tr class="odd">
<td>5</td>
<td>[4, 5)</td>
<td>0</td>
</tr>
</tbody>
</table>
<table class="caption-top table">
<thead><tr class="header">
<th>X</th>
<th>[1,2)</th>
<th>[2,3)</th>
<th>[3,4)</th>
<th>[4,5)</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>-1</td>
<td>-1</td>
<td>-1</td>
<td>-1</td>
</tr>
<tr class="even">
<td>2</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td>3</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>4</td>
<td>1</td>
<td>1</td>
<td>-1</td>
<td>-1</td>
</tr>
<tr class="odd">
<td>5</td>
<td>1</td>
<td>1</td>
<td>-1</td>
<td>-1</td>
</tr>
</tbody>
</table></section><section id="discrete-hazard-function-composition" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="discrete-hazard-function-composition">Discrete Hazard Function Composition</h4>
<p>In this composition, the data in the transformed dataset represents the discrete hazard function. The new indicator is defined as follows, <span class="math display">\[
Y^*_{i;\tau} :=
\begin{cases}
1, &amp; T_i = \tau \cap \Delta_i = 1 \\
-1, &amp; T_i = \tau \cap \Delta_i = 0 \\
0, &amp; \text{otherwise}
\end{cases}
\]</span> At a given discrete time <span class="math inline">\(\tau\)</span>, an observation, <span class="math inline">\(i\)</span>, either experiences the event (<span class="math inline">\(Y^*_{i;\tau} = 1\)</span>), experiences censoring (<span class="math inline">\(Y_{i;\tau} = -1\)</span>), or neither (<span class="math inline">\(Y_{i;\tau} = 0\)</span>). Utilising sequential multi-label classification problem transformation methods (<a href="#sec-car-reduxes-r7-mlc" class="quarto-xref"><span>Section 21.5.1.4</span></a>) results in <span class="math inline">\(\hat{P}(Y^*_{i;\tau} = 1) = \hat{h}_i(\tau)\)</span>. If methods are utilised that do not ‘look back’ at predictions then <span class="math inline">\(\hat{P}(Y^*_{i;\tau} = 1) = \hat{p}_i(\tau)\)</span> (<a href="#sec-car-reduxes-r7-mlc" class="quarto-xref"><span>Section 21.5.1.4</span></a>).</p>
<p>This composition is demonstrated below with the binned data (left) and the composed classification data (right).</p>
<table class="caption-top table">
<thead><tr class="header">
<th>X</th>
<th>Time (Disc.)</th>
<th>Died</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>[1, 2)</td>
<td>0</td>
</tr>
<tr class="even">
<td>2</td>
<td>[2, 3)</td>
<td>1</td>
</tr>
<tr class="odd">
<td>3</td>
<td>[3, 4)</td>
<td>1</td>
</tr>
<tr class="even">
<td>4</td>
<td>[3, 4)</td>
<td>0</td>
</tr>
<tr class="odd">
<td>5</td>
<td>[4, 5)</td>
<td>0</td>
</tr>
</tbody>
</table>
<table class="caption-top table">
<thead><tr class="header">
<th>X</th>
<th>[1,2)</th>
<th>[2,3)</th>
<th>[3,4)</th>
<th>[4,5)</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>-1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>2</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td>3</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="even">
<td>4</td>
<td>0</td>
<td>0</td>
<td>-1</td>
<td>0</td>
</tr>
<tr class="odd">
<td>5</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>-1</td>
</tr>
</tbody>
</table></section><section id="multi-label-classification-data" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="multi-label-classification-data">Multi-Label Classification Data</h4>
<p>In both compositions, survival data t.v.i. <span class="math inline">\(\mathbb{R}^p \times \mathbb{R}_{\geq 0}\times \{0,1\}\)</span> is transformed to multi-label classification data t.v.i. <span class="math inline">\(\mathbb{R}^p \times \{-1,0,1\}^K\)</span> for <span class="math inline">\(K\)</span> binned time-intervals. The multi-label classification task is defined in <a href="#sec-car-reduxes-r7-mlc" class="quarto-xref"><span>Section 21.5.1.4</span></a> with possible algorithms.</p>
<p>The discrete survival representation has a slightly more natural interpretation and is ‘easier’ for classifiers to use for training as there are more positive events (i.e.&nbsp;more observations alive) to train on, whereas the discrete hazard representation will have relatively few events in each time-point. However the hazard representation leads to more natural predictions (<a href="#sec-car-reduxes-r7" class="quarto-xref"><span>Section 21.5.1.6</span></a>).</p>
<p>A particular bias that may easily result from the composition of survival to classification data is now discussed.</p>
</section><section id="reduction-to-classification-bias" class="level4" data-number="21.5.1.3"><h4 data-number="21.5.1.3" class="anchored" data-anchor-id="reduction-to-classification-bias">
<span class="header-section-number">21.5.1.3</span> Reduction to Classification Bias</h4>
<p>The reduction to classification bias is commonly known <span class="citation" data-cites="Zhou2005">(<a href="references.html#ref-Zhou2005" role="doc-biblioref">Zhou et al. 2005</a>)</span> but is reiterated briefly here as it must be accounted for in any automated reduction to classification workflow. This bias occurs when making classification predictions about survival at a given time and incorrectly censoring patients who have not been observed long enough, instead of removing them.</p>
<p>By example, say the prediction of interest is five-year survival probabilities after a particular diagnosis, clearly a patient who has only been diagnosed for three years cannot inform this prediction. The bias is introduced if this patient is censored at five-years instead of being removed from the dataset. The result of this bias is to artificially inflate the probability of survival at each time-point as an unknown outcome is treated as censored and therefore alive.</p>
<p>This bias is simply dealt with by removing patients who have not been alive ‘long enough’. Paradoxically, even if a patient is observed to die before the time-point of interest, they should still be removed if they have not been in the dataset ‘long enough’ as failing to do so will result in a bias in the opposite direction, thus over-inflating the proportion of dead observations.</p>
<p>Accounting for this bias is particularly important in the multi-label reduction as the number of observable patients will decrease over time due to censoring.</p>
</section><section id="sec-car-reduxes-r7-mlc" class="level4" data-number="21.5.1.4"><h4 data-number="21.5.1.4" class="anchored" data-anchor-id="sec-car-reduxes-r7-mlc">
<span class="header-section-number">21.5.1.4</span> Multi-Label Classification Algorithms</h4>
<p>As the work in this section is completely out of the book scope, the full text is in appendix <span class="citation" data-cites="app-mlc">(<a href="references.html#ref-app-mlc" role="doc-biblioref"><strong>app-mlc?</strong></a>)</span>. The most important contributions from this section are:</p>
<ul>
<li>Reviewing problem transformation methods <span class="citation" data-cites="Tsoumakas2007">(<a href="references.html#ref-Tsoumakas2007" role="doc-biblioref">Tsoumakas and Katakis 2007</a>)</span> for multi-label classification;</li>
<li>Identifying that only binary relevance, nested stacking, and classifier chains are appropriate in this reduction; and</li>
<li>Generalising these methods into a single wrapper for any binary classifier, the ‘LWrapper’.</li>
</ul></section><section id="censoring-in-classification" class="level4" data-number="21.5.1.5"><h4 data-number="21.5.1.5" class="anchored" data-anchor-id="censoring-in-classification">
<span class="header-section-number">21.5.1.5</span> Censoring in Classification</h4>
<p>Classification algorithms cannot natively handle the censoring that is included in the survival reduction, but this can be incorporated using one of two approaches.</p>
</section><section id="multi-class-classification" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="multi-class-classification">Multi-Class Classification</h4>
<p>All multi-label datasets can also handle multi-class data, hence the simplest way in which to handle censoring is to make multi-class predictions in each label for the outcome <span class="math inline">\(Y_\tau \ t.v.i. \{-1, 0, 1\}\)</span>. Many off-shelf classification learners can make multi-class predictions natively and simple reductions exist for those that cannot. As a disadvantage to this method, classifiers would then predict if an individual is dead or alive or censored (each mutually exclusive), and not simply alive or dead. Though this could be perceived as an advantage when censoring is informative as this will accurately reflect a real-world competing-risks set-up.</p>
</section><section id="subsettinghurdle-models" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="subsettinghurdle-models">Subsetting/Hurdle Models</h4>
<p>For this approach, the multi-class task is reduced to two binary class tasks: first predict if a subject is censored or not (dead or alive) and only if the prediction for censoring is below some threshold, <span class="math inline">\(\alpha \in [0, 1]\)</span>, then predict if the subject is alive or not (dead or censored). If the probability of censoring is high in the first task then the probability of being alive is automatically set to zero in the final prediction, otherwise the prediction from the second task is used. Any classifier can utilise this approach and it has a meaningful interpretation, additionally <span class="math inline">\(\alpha\)</span> is a tunable hyper-parameter. The main disadvantage is increases to storage and run-time requirements as double the number of models may be fit.</p>
<p>Once the datasets have been composed to classification datasets and censoring is suitably incorporated by either approach, then any probabilistic classification model can be fit on the data. Predictions from these models can either be composed to a distribution prediction (R7) or a survival time prediction (R8).</p>
</section><section id="sec-car-reduxes-r7" class="level4" data-number="21.5.1.6"><h4 data-number="21.5.1.6" class="anchored" data-anchor-id="sec-car-reduxes-r7">
<span class="header-section-number">21.5.1.6</span> R7) Probabilistic Survival <span class="math inline">\(\rightarrow\)</span> Probabilistic Classification</h4>
<!-- \begin{figure}[H]
\centering
\begin{tikzpicture}[framed]
\node (t0) [objnode]  {$\dtrain$};
\node (t1) [funnode,right=of t0] {$B(\dtrain|w)$};
\node (t2) [objnode,right=of t1] {$D_B$};
\node (t3) [funnode, below=of t2] {$C_C$};
\node (t4) [funnode, right=of t3] {$g_C(D_B|\phi)$};
\node (t5) [funnode, above=of t2] {$C_B$};
\node (t6) [funnode, right=of t5] {$g_B(D_B|\varphi)$};
\node (t7) [funnode,right=of t2] {$g_L(D_B|\theta)$};
\node (t8) [objnode,right=of t7] {$\hatg$};

\node (t9) [objnode, below=of t0, yshift = -15mm] {$\dtest$};
\node (t10) [funnode, right=of t9] {$\hat{g}(\dtest|\Theta)$};
\node (t11) [objnode, right=of t10] {$\tilde{S}$};
\node (t12) [funnode, right=of t11] {$T_1(\tilde{S})$};
\node (t14) [objnode, right=of t12] {$\zeta$};

\path[->]
   (t0)  edge (t1)
   (t1)  edge (t2)
   (t2)  edge[dashed] (t3)
   (t2)  edge[dashed] (t5)
   (t2)  edge[dashed] (t7)
   (t3)  edge (t4)
   (t4)  edge (t8)
   (t6)  edge (t8)
   (t7)  edge (t8)
   (t5)  edge (t6)

   (t9) edge (t10)
   (t10) edge (t11)
   (t11) edge (t12)
   (t12) edge (t14);

\draw[dashed, line width=0.1mm] (-1,-2.5) -- (11,-2.5);
\end{tikzpicture}
\caption[Probabilistic survival to probabilistic classification reduction]{Probabilistic survival to probabilistic reduction. See @fig-car-R7R8 for key.}
\label{fig:car_R7}
\end{figure} -->
<p>This final part of the (R7) reduction is described separately for discrete hazard and survival representations of the data (<a href="#sec-car-reduxes-r7-out" class="quarto-xref"><span>Section 21.5.1.2</span></a>).</p>
</section><section id="discrete-hazard-representation" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="discrete-hazard-representation">Discrete Hazard Representation</h4>
<p>In this representation recall that predictions of the positive class, <span class="math inline">\(P(Y_\tau = 1)\)</span>, are estimating the quantity <span class="math inline">\(h(\tau)\)</span>. These predictions provide a natural and efficient transformation from predicted hazards to survival probabilities. Let <span class="math inline">\(\hat{h}_i\)</span> be a predicted hazard function for some observation <span class="math inline">\(i\)</span>, then the survival function for that observation can be found with a Kaplan-Meier type estimator, <span class="math display">\[
\tilde{S}_i(\tau^*) = \prod_\tau 1 - \hat{h}_i(\tau)
\]</span> Now predictions are for a pseudo-survival function, which is ‘pseudo’ as it is not right-continuous. Resolving this is discussed below.</p>
</section><section id="discrete-survival-representation" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="discrete-survival-representation">Discrete Survival Representation</h4>
<p>In this representation, <span class="math inline">\(P(Y_\tau = 1)\)</span> is estimating <span class="math inline">\(S(\tau)\)</span>, which means that predictions from a classification model result in discrete point predictions and not a right-continuous function. More importantly, there is no guarantee that a non-increasing function will be predicted, i.e.&nbsp;there is no guarantee that <span class="math inline">\(P(Y_j = 1) &lt; P(Y_i = 1)\)</span>, for time-points <span class="math inline">\(j &gt; i\)</span>.</p>
<p>Unfortunately there is no optimal way of dealing with predictions of this sort and ‘mistakes’ of this kind have been observed in some software implementation. One point to note is that in practice these are quite rare as the probability of survival will always decrease over time. Therefore the ‘usual’ approach is quite ‘hacky’ and involves imputing increasing predictions with the previous prediction, formally, <span class="math display">\[
\tilde{S}({i+1}) := \min\{P(Y_{i+1} = 1), P(Y_i = 1)\}, \forall i = \mathbb{R}_{\geq 0}
\]</span> assuming <span class="math inline">\(\tilde{S}(0) = 1\)</span>. Future research should seek more robust alternatives.</p>
</section><section id="right-continuous-survival-function" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="right-continuous-survival-function">Right-Continuous Survival Function</h4>
<p>From either representation, a \ non-increasing but non-continuous pseudo-survival function, <span class="math inline">\(\tilde{S}\)</span>, is now predicted. Creating a right-continuous function (‘<span class="math inline">\(T_1(\tilde{S})\)</span>’ in <span class="quarto-unresolved-ref">?fig-car-R7</span>) from these point predictions (<a href="#fig-car-survclass" class="quarto-xref">Figure&nbsp;<span>21.3</span></a> (a)) is relatively simple and well-known with accessible off-shelf software. At the very least, one can assume a constant hazard rate between predictions and cast them into a step function (<a href="#fig-car-survclass" class="quarto-xref">Figure&nbsp;<span>21.3</span></a> (b)). This is a fairly common assumption and is usually valid as bin-width decreases. Alternatively, the point predictions can be smoothed into a continuous function with off-shelf software, for example with polynomial local regression smoothing (<a href="#fig-car-survclass" class="quarto-xref">Figure&nbsp;<span>21.3</span></a> (c)) or generalised linear smoothing (<a href="#fig-car-survclass" class="quarto-xref">Figure&nbsp;<span>21.3</span></a> (d)). Whichever method is chosen, the survival function is now non-increasing right-continuous and the (R7) reduction is complete.</p>
<div id="fig-car-survclass" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-car-survclass-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-car-survclass" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-car-survclass-a" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure"><div aria-describedby="fig-car-survclass-a-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/car/surv_points.png" class="img-fluid figure-img" data-ref-parent="fig-car-survclass">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-car-survclass-a-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Point Predictions
</figcaption></figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-car-survclass" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-car-survclass-b" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure"><div aria-describedby="fig-car-survclass-b-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/car/surv_step.png" class="img-fluid figure-img" data-ref-parent="fig-car-survclass">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-car-survclass-b-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Survival Step Function
</figcaption></figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-car-survclass" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-car-survclass-c" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure"><div aria-describedby="fig-car-survclass-c-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/car/surv_loess.png" class="img-fluid figure-img" data-ref-parent="fig-car-survclass">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-car-survclass-c-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(c) Local polynomial regression smoothing
</figcaption></figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-car-survclass" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-car-survclass-d" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure"><div aria-describedby="fig-car-survclass-d-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/car/surv_glm.png" class="img-fluid figure-img" data-ref-parent="fig-car-survclass">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-car-survclass-d-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(d) Generalised linear smoothing
</figcaption></figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-car-survclass-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;21.3: Survival function as a: point prediction (a), step function assuming constant risk (b), local polynomial regression smoothing (c), and generalised linear smoothing (d). (c) and (d) computed with <a href="https://cran.r-project.org/package=ggplot2"><code>ggplot2</code></a> <span class="citation" data-cites="pkgggplot2">(<a href="references.html#ref-pkgggplot2" role="doc-biblioref">Wickham 2016</a>)</span>.
</figcaption></figure>
</div>
</section><section id="sec-car-reduxes-r8" class="level4" data-number="21.5.1.7"><h4 data-number="21.5.1.7" class="anchored" data-anchor-id="sec-car-reduxes-r8">
<span class="header-section-number">21.5.1.7</span> R8) Deterministic Survival <span class="math inline">\(\rightarrow\)</span> Probabilistic Classification</h4>
<!-- \begin{figure}[H]
\centering
\begin{tikzpicture}[framed]
\node (t0) [objnode]  {$\dtrain$};
\node (t1) [funnode,right=of t0] {$B(\dtrain|w)$};
\node (t2) [objnode,right=of t1] {$D_B$};
\node (t3) [funnode, below=of t2] {$C_C$};
\node (t4) [funnode, right=of t3] {$g_C(D_B|\phi)$};
\node (t5) [funnode, above=of t2] {$C_B$};
\node (t6) [funnode, right=of t5] {$g_B(D_B|\varphi)$};
\node (t7) [funnode,right=of t2] {$g_L(D_B|\theta)$};
\node (t8) [objnode,right=of t7] {$\hatg$};

\node (t9) [objnode, below=of t0, yshift = -15mm] {$\dtest$};
\node (t10) [funnode, right=of t9] {$\hat{g}(\dtest|\Theta)$};
\node (t11) [objnode, right=of t10] {$\tilde{S}$};
\node (t13) [funnode, right=of t11] {$T_2(\tilde{S})$};
\node (t15) [objnode, right=of t13] {$\hatT$};

\path[->]
   (t0)  edge (t1)
   (t1)  edge (t2)
   (t2)  edge[dashed] (t3)
   (t2)  edge[dashed] (t5)
   (t2)  edge[dashed] (t7)
   (t3)  edge (t4)
   (t4)  edge (t8)
   (t6)  edge (t8)
   (t7)  edge (t8)
   (t5)  edge (t6)

   (t9) edge (t10)
   (t10) edge (t11)
   (t11) edge (t13)
   (t13) edge (t15);

\draw[dashed, line width=0.1mm] (-1,-2.5) -- (11,-2.5);
\end{tikzpicture}
\caption[Deterministic survival to probabilistic classification reduction]{Deterministic survival to probabilistic reduction. See @fig-car-R7R8 for key.}
\label{fig:car_R8}
\end{figure} -->
<p>Predicting a deterministic survival time from the multi-label classification predictions is relatively straightforward and can be viewed as a discrete analogue to (C3) (<a href="#sec-car-pipelines-crank" class="quarto-xref"><span>Section 21.4.3</span></a>). For the discrete hazard representation, one can simply take the predicted time-point for an individual to be time at which the predicted hazard probability is highest however this could easily be problematic as there may be multiple time-points at which the predicted hazard equals <span class="math inline">\(1\)</span>. Instead it is cleaner to first cast the hazard to a pseudo-survival probability (<a href="#sec-car-reduxes-r7" class="quarto-xref"><span>Section 21.5.1.6</span></a>) and then treat both representations the same.</p>
<p>Let <span class="math inline">\(\tilde{S}_i\)</span> be the predicted multi-label survival probabilities for an observation <span class="math inline">\(i\)</span> such that <span class="math inline">\(\tilde{S}_i(\tau)\)</span> corresponds with <span class="math inline">\(\hat{P}(Y_{i;\tau} = 1)\)</span> for label <span class="math inline">\(\tau \in \mathcal{K}\)</span> where <span class="math inline">\(Y_{i;\tau}\)</span> is defined in <a href="#sec-car-reduxes-r7-out" class="quarto-xref"><span>Section 21.5.1.2</span></a> and <span class="math inline">\(\mathcal{K} = \{1,...,K\}\)</span> is the set of labels for which to make predictions. Then the survival time transformation is defined by <span class="math display">\[
T_2(\tilde{S}_i) = \inf \{\tau \in \mathcal{K} : \tilde{S}_i(\tau) \leq \beta\}
\]</span> for some <span class="math inline">\(\beta \in [0, 1]\)</span>.</p>
<p>This is interpreted as defining the predicted survival time as the first time-point in which the predicted probability of being alive drops below a certain threshold <span class="math inline">\(\beta\)</span>. Usually <span class="math inline">\(\beta = 0.5\)</span>, though this can be treated as a hyper-parameter for tuning. This composition can be utilised even if predictions are not non-increasing, as only the first time the predicted survival probability drops below the threshold is considered. With this composition the (R8) reduction is now complete.</p>
</section></section></section><section id="sec-car-conc" class="level2" data-number="21.6"><h2 data-number="21.6" class="anchored" data-anchor-id="sec-car-conc">
<span class="header-section-number">21.6</span> Conclusions</h2>
<p>This chapter introduced composition and reduction to survival analysis and formalised specific strategies. Formalising these concepts allows for better quality of research and most importantly improved transparency. Clear interface points for hyper-parameters and compositions allow for reproducibility that was previously obfuscated by unclear workflows and imprecise documentation for pipelines.</p>
<p>Additionally, composition and reduction improves accessibility. Reduction workflows vastly increase the number of machine learning models that can be utilised in survival analysis, thus opening the field to those whose experience is limited to regression or classification. Formalisation of workflows allows for precise implementation of model-agnostic pipelines as computational objects, as opposed to functions that are built directly into an algorithm without external interface points.</p>
<p>Finally, predictive performance is also increased by these methods, which is most prominently the case for the survival model averaging compositor (as demonstrated by RSFs).</p>
<p>All compositions in this chapter, as well as (R1)-(R6), have been implemented in <a href="https://cran.r-project.org/package=mlr3proba"><code>mlr3proba</code></a> with the <a href="https://cran.r-project.org/package=mlr3pipelines"><code>mlr3pipelines</code></a> <span class="citation" data-cites="pkgmlr3pipelines">(<a href="references.html#ref-pkgmlr3pipelines" role="doc-biblioref">Binder et al. 2019</a>)</span> interface. The reductions to classification will be implemented in a near-future update. Additionally the <a href="https://cran.r-project.org/package=discSurv"><code>discSurv</code></a> package <span class="citation" data-cites="pkgdiscsurv">(<a href="references.html#ref-pkgdiscsurv" role="doc-biblioref">Welchowski and Schmid 2019</a>)</span> will be interfaced as a <a href="https://cran.r-project.org/package=mlr3proba"><code>mlr3proba</code></a> pipeline to incorporate further discrete-time strategies.</p>
<p>The compositions and are included in the benchmark experiment in <span class="citation" data-cites="Sonabend2021b">R. E. B. Sonabend (<a href="references.html#ref-Sonabend2021b" role="doc-biblioref">2021</a>)</span> so that every tested model can make probabilistic survival distribution predictions as well as deterministic survival time predictions. Future research will benchmark all the pipelines in this chapter and will cover algorithm and model selection, tuning, and comparison of performance. Strategies from other papers will also be explored.</p>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-pkgmlr3pipelines" class="csl-entry" role="listitem">
Binder, Martin, Florian Pfisterer, Bernd Bischl, Michel Lang, and Susanne Dandl. 2019. <span>“<span class="nocase">mlr3pipelines: Preprocessing Operators and Pipelines for ’mlr3’</span>.”</span> CRAN. <a href="https://cran.r-project.org/package=mlr3pipelines">https://cran.r-project.org/package=mlr3pipelines</a>.
</div>
<div id="ref-Cox1972" class="csl-entry" role="listitem">
Cox, D. R. 1972. <span>“<span class="nocase">Regression Models and Life-Tables</span>.”</span> <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 34 (2): 187–220.
</div>
<div id="ref-Friedman1982" class="csl-entry" role="listitem">
Friedman, Michael. 1982. <span>“<span class="nocase">Piecewise exponential models for survival data with covariates</span>.”</span> <em>The Annals of Statistics</em> 10 (1): 101–13.
</div>
<div id="ref-Langford2016" class="csl-entry" role="listitem">
Langford, John, Paul Mineiro, Alina Beygelzimer, and Hal Daume. 2016. <span>“<span class="nocase">Learning Reductions that Really Work</span>.”</span> <em>Proceedings of the IEEE</em> 104 (1).
</div>
<div id="ref-Liestol1994" class="csl-entry" role="listitem">
Liestol, Knut, Per Kragh Andersen, and Ulrich Andersen. 1994. <span>“<span class="nocase">Survival analysis and neural nets</span>.”</span> <em>Statistics in Medicine</em> 13 (12): 1189–1200. <a href="https://doi.org/10.1002/sim.4780131202">https://doi.org/10.1002/sim.4780131202</a>.
</div>
<div id="ref-Schwarzer2000" class="csl-entry" role="listitem">
Schwarzer, Guido, Werner Vach, and Martin Schumacher. 2010. <span>“<span class="nocase">Estimation of prediction error for survival models</span>.”</span> <em>Statistics in Medicine</em> 29 (2): 262–74. <a href="https://doi.org/10.1002/(SICI)1097-0258(20000229)19:4<541::AID-SIM355>3.0.CO;2-V">https://doi.org/10.1002/(SICI)1097-0258(20000229)19:4&lt;541::AID-SIM355&gt;3.0.CO;2-V</a>.
</div>
<div id="ref-Sonabend2021b" class="csl-entry" role="listitem">
Sonabend, Raphael Edward Benjamin. 2021. <span>“<span class="nocase">A Theoretical and Methodological Framework for Machine Learning in Survival Analysis: Enabling Transparent and Accessible Predictive Modelling on Right-Censored Time-to-Event Data</span>.”</span> PhD, University College London (UCL). <a href="https://discovery.ucl.ac.uk/id/eprint/10129352/">https://discovery.ucl.ac.uk/id/eprint/10129352/</a>.
</div>
<div id="ref-pkgmlr3proba" class="csl-entry" role="listitem">
Sonabend, Raphael, Franz J Király, Andreas Bender, Bernd Bischl, and Michel Lang. 2021. <span>“<span class="nocase">mlr3proba: an R package for machine learning in survival analysis</span>.”</span> Edited by Jonathan Wren. <em>Bioinformatics</em> 37 (17): 2789–91. <a href="https://doi.org/10.1093/bioinformatics/btab039">https://doi.org/10.1093/bioinformatics/btab039</a>.
</div>
<div id="ref-Tsoumakas2007" class="csl-entry" role="listitem">
Tsoumakas, Grigorios, and Ioannis Katakis. 2007. <span>“<span>Multi-Label Classification: An Overview</span>.”</span> <em>International Journal of Data Warehousing and Mining</em> 3 (3): 1–13. <a href="https://doi.org/10.4018/jdwm.2007070101">https://doi.org/10.4018/jdwm.2007070101</a>.
</div>
<div id="ref-Tutz2016" class="csl-entry" role="listitem">
Tutz, Gerhard, and Matthias Schmid. 2016. <em><span class="nocase">Modeling Discrete Time-to-Event Data</span></em>. Springer Series in Statistics. Cham: Springer International Publishing. <a href="https://doi.org/10.1007/978-3-319-28158-2">https://doi.org/10.1007/978-3-319-28158-2</a>.
</div>
<div id="ref-VanHouwelingen2007" class="csl-entry" role="listitem">
Van Houwelingen, Hans C. 2007. <span>“<span class="nocase">Dynamic prediction by landmarking in event history analysis</span>.”</span> <em>Scandinavian Journal of Statistics</em> 34 (1): 70–85. <a href="https://doi.org/10.1111/j.1467-9469.2006.00529.x">https://doi.org/10.1111/j.1467-9469.2006.00529.x</a>.
</div>
<div id="ref-pkgdiscsurv" class="csl-entry" role="listitem">
Welchowski, Thomas, and Matthias Schmid. 2019. <span>“<span class="nocase">discSurv: Discrete Time Survival Analysis</span>.”</span> CRAN. <a href="https://cran.r-project.org/package=discSurv">https://cran.r-project.org/package=discSurv</a>.
</div>
<div id="ref-pkgggplot2" class="csl-entry" role="listitem">
Wickham, Hadley. 2016. <em><span class="nocase">ggplot2: Elegant Graphics for Data Analysis</span></em>. Springer-Verlag New York. <a href="https://ggplot2.tidyverse.org">https://ggplot2.tidyverse.org</a>.
</div>
<div id="ref-Zhou2005" class="csl-entry" role="listitem">
Zhou, Zheng, Elham Rahme, Michal Abrahamowicz, and Louise Pilote. 2005. <span>“<span class="nocase">Survival Bias Associated with Time-to-Treatment Initiation in Drug Effectiveness Evaluation: A Comparison of Methods</span>.”</span> <em>American Journal of Epidemiology</em> 162 (10): 1016–23. <a href="https://doi.org/10.1093/aje/kwi307">https://doi.org/10.1093/aje/kwi307</a>.
</div>
</div>
</section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./models_choosing.html" class="pagination-link" aria-label="Choosing Models">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Choosing Models</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./competing.html" class="pagination-link" aria-label="Competing Risks Pipelines">
        <span class="nav-page-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Competing Risks Pipelines</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="an">abstract:</span><span class="co"> TODO (150-200 WORDS)</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>{{&lt; include _setup.qmd &gt;}}</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu"># Reductions {#sec-car}</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>{{&lt; include _wip.qmd &gt;}}</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>In this chapter, composition and reduction are formally introduced, defined and demonstrated within survival analysis. Neither of these are novel concepts in general or in survival, with several applications already seen earlier when reviewing models (particularly in neural networks), however a lack of formalisation has led to much repeated work and at times questionable applications (@sec-surv-ml-models-nn). The primary purpose of this chapter is to formalise composition and reduction for survival and to unify references and strategies for future use. These strategies are introduced in the context of minimal 'workflows' and graphical 'pipelines' in order to maximise their generalisability. The pipelines discussed in this chapter are implemented in <span class="in">`r pkg("mlr3proba")`</span>.</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- %The compositions discussed in this chapter are important for understanding how classical and machine learning models are routinely discussed and implemented in survival analysis. Whereas the reductions in this chapter are more conceptual and relate specifically to solving machine learning tasks algorithmically. The frameworks discussed in this chapter are all implemented in `r pkg("mlr3proba")`. --&gt;</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>A *workflow* is a generic term given to a series of sequential operations. For example a standard ML workflow is fit/predict/evaluate, which means a model is fit, predictions are made, and these are evaluated. In this book, a *pipeline* is the name given to a concrete workflow. @sec-car-pipes demonstrates how pipelines are represented in this book.</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>Composition (@sec-car-comp) is a general process in which an object is built (or composed) from other objects and parameters. Reduction (@sec-car-redux) is a closely related concept that utilises composition in order to transform one problem into another. Concrete strategies for composition and reduction are detailed in sections @sec-car-pipelines and @sec-car-reduxes.</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Notation and Terminology {.unnumbered .unlisted}</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>The notation introduced in @sec-surv is recapped for use in this chapter: the generative survival template for the survival setting is given by $(X,T,\Delta,Y,C) \ t.v.i. \ \calX \times \calT \times \bset \times \calT \times \calT$ where $\calX \subseteq \Reals^p$ and $\calT \subseteq \NNReals$, where $C,Y$ are unobservable, $T := \min<span class="sc">\{</span>Y,C<span class="sc">\}</span>$, and $\Delta = \II(Y = T)$. Random survival data is given by $(X_i,T_i,\Delta_i,Y_i,C_i) \iid (X,T,\Delta,Y,C)$. Usually data will instead be presented as a training dataset, $\dtrain = <span class="sc">\{</span>(X_1,T_1,\Delta_1),...,(X_n,T_n,\Delta_n)<span class="sc">\}</span>$ where $(X_i,T_i,\Delta_i) \iid (X,T,\Delta)$, and some test data $\dtest = (X^*,T^*,\Delta^*) \sim (X,T,\Delta)$.</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>For regression models the generative template is given by $(X,Y)$ t.v.i. $\calX \subseteq \Reals^p$ and $Y \subseteq \Reals$. As with the survival setting, a regression training set is given by $<span class="sc">\{</span>(X_1,Y_1),...,(X_n,Y_n)<span class="sc">\}</span>$ where $(X_i,Y_i) \iid (X,Y)$ and some test data $(X^*,Y^*) \sim (X,Y)$.</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="fu">## Representing Pipelines {#sec-car-pipes}</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>Before introducing concrete composition and reduction algorithms, this section briefly demonstrates how these pipelines will be represented in this book.</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>Pipelines are represented by graphs designed in the following way: all are drawn with operations progressing sequentially from left to right; graphs are comprised of nodes (or 'vertices') and arrows (or 'directed edges'); a rounded rectangular node represents a process such as a function or model fitting/predicting; a (regular) rectangular node represents objects such as data or hyper-parameters. Output from rounded nodes are sometimes explicitly drawn but when omitted the output from the node is the input to the next.</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>These features are demonstrated in @fig-car-example. Say $y = 2$ and $a = 2$, then: data is provided ($y = 2$) and passed to the shift function ($f(x)=x + 2)$, the output of this function ($y=4$) is passed directly to the next $(h(x|a)=x^a)$, this function requires a parameter which is also input ($a = 2$), finally the resulting output is returned ($y^*=16$). Programmatically, $a = 2$ would be a hyper-parameter that is stored and passed to the required function when the function is called.</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>This pipeline is represented as a pseudo-algorithm in @alg-car-ex, though of course is overly complicated and in practice one would just code $(y+2)^\wedge a$.</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{figure}[H]</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="co">\centering</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="co">\begin{tikzpicture}[framed]</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t0)[objnode] {$y$};</span></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t1)[funnode, right=of t0]{$f(x) = x+2$};</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t2)[funnode,right=of t1]{$h(x|a) = x^a$};</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t3)[objnode, right=of t2]{$y^*$};</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t4)[objnode, above=of t2]{$a$};</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="co">\path[-&gt;]</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="co">   (t0)  edge  (t1)</span></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="co">   (t1)  edge  (t2)</span></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="co">   (t2)  edge  (t3)</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="co">   (t4)  edge  (t2);</span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="co">\end{tikzpicture}</span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="co">\caption[Example of a pipeline]{Example of a pipeline.}\label{fig:car_example}</span></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="co">\end{figure} --&gt;</span></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{algorithm}[H]</span></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="co">\caption{Example pipeline. \\</span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a><span class="co">**Input** Data, $y \in \Reals$. Parameter, $a \in \Reals$. \\</span></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a><span class="co">**Output** Transformed data, $x \in \Reals$.}</span></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a><span class="co">\begin{algorithmic}</span></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a><span class="co">\State $x \gets y$</span></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a><span class="co">\State $x \gets x + 2$</span></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a><span class="co">\State $x \gets x^\wedge a$</span></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a><span class="co">\Return $x$</span></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a><span class="co">\end{algorithmic}</span></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a><span class="co">\end{algorithm} --&gt;</span></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- {#alg-car-ex} --&gt;</span></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction to Composition {#sec-car-comp}</span></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>This section introduces composition, defines a taxonomy for describing compositors (@sec-car-comp-tax), and provides some motivating examples of composition in survival analysis (@sec-car-comp-mot).</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>In the simplest definition, a model (be it mathematical, computational, machine learning, etc.) is called a *composite model* if it is built of two or more constituent parts. This can be simplest defined in terms of objects. Just as objects in the real-world can be combined in some way, so can mathematical objects. The exact 'combining' process (or 'compositor') depends on the specific composition, so too do the inputs and outputs. By example, a wooden table can be thought of as a composite object (@fig-car-comp-ex). The inputs are wood and nails, the combining process is hammering (assuming the wood is pre-chopped), and the output is a surface for eating. In mathematics, this process is mirrored. Take the example of a shifted linear regression model. This is defined by a linear regression model, $f(x) = \beta_0 + x\beta_1$, a shifting parameter, $\alpha$, and a compositor $g(x|\alpha) = f(x) + \alpha$. Mathematically this example is overly trivial as this could be directly modelled with $f(x) = \alpha + \beta_0 + x\beta_1$, but algorithmically there is a difference. The composite model $g$, is defined by first fitting the linear regression model, $f$, and then applying a shift, $\alpha$; as opposed to fitting a directly shifted model.</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a><span class="al">![Visualising composition in the real-world. A table is a composite object built from nails and wood, which are combined with a hammer 'compositor'. Figure not to scale.](Figures/car/comp.png)</span>{#fig-car-comp-ex fig-alt="TODO"}</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Why Composition? {.unnumbered .unlisted}</span></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>Tables tend to be better surfaces for eating your dinner than bundles of wood. Or in modelling terms, it is well-known that ensemble methods (e.g. random forests) will generally outperform their components (e.g. decision trees). All ensemble methods are composite models and this demonstrates one of the key use-cases of composition: improved predictive performance. The second key use-case is reduction, which is fully discussed in @sec-car-redux. @sec-car-comp-mot motivates composition in survival analysis by demonstrating how it is already prevalent but requires formalisation to make compositions more transparent and accessible.</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Composite Model vs. Sub-models {.unnumbered .unlisted}</span></span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>A bundle of wood and nails is not a table and $1,000$ decision trees are not a random forest, both require a compositor. The compositor in a composite model combines the components into a single model. Considering a composite model as a single model enables the hyper-parameters of the compositor and the component model(s) to be efficiently tuned whilst being evaluated as a single model. This further allows the composite to be compared to other models, including its own components, which is required to justify complexity instead of parsimony in model building (@sec-eval-why-why).</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a><span class="fu">### Taxonomy of Compositors {#sec-car-comp-tax}</span></span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>Just as there are an infinite number of ways to make a table, composition can come in infinite forms. However there are relatively few categories that these can be grouped into. Two primary taxonomies are identified here. The first is the 'composition type' and relates to the number of objects composed:</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">i)</span><span class="co">]</span></span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>i. Single-Object Composition (SOC) -- This form of composition either makes use of parameters or a transformation to alter a single object. The shifted linear regression model above is one example of this, another is given in @sec-car-pipelines-crank.</span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>i. Multi-Object Composition (MOC) -- In contrast, this form of composition combines multiple objects into a single one. Both examples in @sec-car-comp-mot are multi-object compositions.</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>The second grouping is the 'composition level' and determines at what 'level' the composition takes place:</span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">i)</span><span class="co">]</span></span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a>i. Prediction Composition -- This applies at the level of predictions; the component models could be forgotten at this point. Predictions may be combined from multiple models (MOC) or transformed from a single model (SOC). Both examples in @sec-car-comp-mot are prediction compositions.</span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a>i. Task Composition -- This occurs when one task (e.g. regression) is transformed to one or more others (e.g. classification), therefore always SOC. This is seen mainly in the context of reduction (@sec-car-redux).</span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a>i. Model Composition -- This is commonly seen in the context of wrappers (@sec-car-reduxes-r7-mlc), in which one model is contained within another.</span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a>i. Data Composition -- This is transformation of training/testing data types, which occurs at the first stage of every pipeline.</span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a><span class="fu">### Motivation for Composition {#sec-car-comp-mot}</span></span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a>Two examples are provided below to demonstrate common uses of composition in survival analysis and to motivate the compositions introduced in @sec-car-pipelines.</span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Example 1: Cox Proportional Hazards {.unnumbered .unlisted}</span></span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a>Common implementations of well-known models can themselves be viewed as composite models, the Cox PH is the most prominent example in survival analysis. Recall the model defined by</span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a>h(\tau|X_i) = h_0(\tau)\exp(\beta X_i)</span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a>where $h_0$ is the baseline hazard and $\beta$ are the model coefficients.</span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a>This can be seen as a composite model as Cox defines the model in two stages  <span class="co">[</span><span class="ot">@Cox1972</span><span class="co">]</span>: first fitting the $\beta$-coefficients using the partial likelihood and then by suggesting an estimate for the baseline distribution. This first stage produces a linear predictor return type (@sec-surv-set-types) and the second stage returns a survival distribution prediction. Therefore the Cox model for linear predictions is a single (non-composite) model, however when used to make distribution predictions then it is a composite. Cox implicitly describes the model as a composite by writing ''alternative simpler procedures would be worth having''  <span class="co">[</span><span class="ot">@Cox1972</span><span class="co">]</span>, which implies a decision in fitting (a key feature of composition). This composition is formalised in @sec-car-pipelines-distr as a general pipeline \CDetI. The Cox model utilises the \CDetI pipeline with a PH form and Kaplan-Meier baseline.</span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Example 2: Random Survival Forests {.unnumbered .unlisted}</span></span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a>Fully discussed in @sec-surv-ml-models-ranfor, random survival forests are composed from many individual decision trees via a prediction composition algorithm (@alg-rsf-pred). In general, random forests perform better than their component decision trees, which tends to be true of all ensemble methods. Aggregation of predictions in survival analysis requires slightly more care than other fields due to the multiple prediction types, however this is still possible and is formalised in @sec-car-pipelines-avg.</span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction to Reduction {#sec-car-redux}</span></span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a>This section introduces reduction, motivates its use in survival analysis (@sec-car-redux-mot), details an abstract reduction pipeline and defines the difference between a complete/incomplete reduction (@sec-car-redux-task), and outlines some common mistakes that have been observed in the literature when applying reduction (@sec-car-reduxstrats-mistakes).</span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a>Reduction is a concept found across disciplines with varying definitions. This report uses the Langford definition: reduction is ''a complex problem decomposed into simpler subproblems so that a solution to the subproblems gives a solution to the complex problem''  <span class="co">[</span><span class="ot">@Langford2016</span><span class="co">]</span>. Generalisation (or induction) is a common real-world use of reduction, for example sampling a subset of a population in order to estimate population-level results. The true answer (population-level values) may not always be found in this way but very good approximations can be made with simpler sub-problems (sub-sampling).</span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a>Reductions are workflows that utilise composition. By including hyper-parameters, even complex reduction strategies can remain relatively flexible. To illustrate reduction by example, recall the table-building example (@sec-car-comp) in which the task of interest is to acquire a table. The most direct but complex solution is to fell a tree and directly saw it into a table (@fig-car-redux, top), clearly this is not a sensible process. Instead the problem can be reduced into simpler sub-problems: saw the tree into bundles of wood, acquire nails, and then use the 'hammer compositor' (@fig-car-comp-ex) to create a table (@fig-car-redux, bottom).</span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a><span class="al">![Visualising reduction in the real-world. The complex process (top) of directly sawing a tree into a table is inefficient and unnecessarily complex. The reduction (bottom) that involves first creating bundles of wood is simpler, more efficient, and yields the same result, though technically requiring more steps.](Figures/car/redux.png)</span>{#fig-car-redux fig-alt="TODO"}</span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a>In a modelling example, predicting a survival distribution with the Cox model can be viewed as a reduction in which two sub-problems are solved and composed:</span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a>i. predict continuous ranking;</span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a>i. estimate baseline hazard; and</span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a>i. compose with \CDetI (@sec-car-pipelines-distr).</span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a>This is visualised as a reduction strategy in @fig-car-cargraph. The entire process from defining the original problem, to combining the simpler sub-solutions (in green), is the reduction (in red).</span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{figure}[h]</span></span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a><span class="co">\centering</span></span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a><span class="co">\begin{tikzpicture}</span></span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t0) [objnode, minimum width = 6.2cm]  {Task: Predict Distribution};</span></span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t1) [objnode, above=of t0, minimum width = 6.2cm] {Sub-Task: Predict Ranking};</span></span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t2) [objnode, below=of t0, minimum width = 6.2cm] {Sub-Task: Estimate Baseline};</span></span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t3) [objnode, right=of t1,xshift=1.5cm] {$\hat{\eta}$};</span></span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t6) [funnode, below=of t3, fill = orange!30] {$C$};</span></span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t4) [objnode, below=of t6] {$\hatS_0$};</span></span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t5) [objnode, left=of t6] {$S$};</span></span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t7) [objnode, right=of t6] {$\zeta$};</span></span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t8) [below=of t7, minimum width=10mm, minimum height = 5mm] {};</span></span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a><span class="co">\path[-&gt;]</span></span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a><span class="co">   (t0)  edge (t1)</span></span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a><span class="co">   (t0)  edge (t2)</span></span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a><span class="co">   (t1)  edge (t3)</span></span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a><span class="co">   (t2)  edge (t4)</span></span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a><span class="co">   (t3)  edge (t6)</span></span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a><span class="co">   (t4)  edge (t6)</span></span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a><span class="co">   (t5)  edge (t6)</span></span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a><span class="co">   (t6)  edge (t7);</span></span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a><span class="co">\begin{pgfonlayer}{background}</span></span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a><span class="co">  \draw[fill=red!30,fill opacity = 0.5,rounded corners]</span></span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a><span class="co">($(t1.north west)+(-0.1,0.2)$) rectangle ($(t8.south east)+(0.1,-0.4)$);</span></span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a><span class="co">  \draw[fill=green!30,fill opacity = 0.5,rounded corners]</span></span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a><span class="co">($(t3.north west)+(-2,0.1)$) rectangle ($(t4.south east) +(0.1,-0.1)$);</span></span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a><span class="co"> \end{pgfonlayer}</span></span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a><span class="co">\end{tikzpicture}</span></span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a><span class="co">\caption[Probabilistic survival task reduction]{Solving a survival distribution task by utilising reduction and (C1) (@sec-car-pipelines-distr). $S$, $\hat{\eta}$, $C$, $\hatS_0$ are fully described in @fig-car-comp-distr. The nodes in the green area are part of the composite model, all nodes combined form the reduction.}\label{fig:car_cargraph}</span></span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a><span class="co">\end{figure} --&gt;</span></span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a><span class="fu">### Reduction Motivation {#sec-car-redux-mot}</span></span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a>Formalisation of reduction positively impacts upon accessibility, transparency, and predictive performance. Improvements to predictive performance have already been demonstrated when comparing random forests to decision trees. In addition, a reduction with multiple stages and many hyper-parameters allows for fine tuning for improved transparency and model performance (usual overfitting caveat applies, as does the trade-off described in @sec-car-pipelines-trade).</span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a>The survey of ANNs (@sec-surv-ml-models-nn) demonstrated how reduction is currently utilised without transparency. Many of these ANNs are implicitly reductions to probabilistic classification (@sec-car-reduxes-r7) however none include details about how the reduction is performed. Furthermore in implementation, none provide interface points to the reduction hyper-parameters. Formalisation encourages consistent terminology, methodology and transparent implementation, which can only improve model performance by exposing further hyper-parameters.</span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a>Accessibility is improved by formalising specific reduction workflows that previously demanded expert knowledge in deriving, building, and running these pipelines. All regression reductions in this chapter, are implemented in <span class="sc">\\</span> <span class="in">`r pkg("mlr3proba")`</span>  <span class="co">[</span><span class="ot">@pkgmlr3proba</span><span class="co">]</span> and can be utilised with any possible survival model.</span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a>Finally there is an economic and efficiency advantage to reduction. A reduction model is relatively 'cheap' to explore as they utilise pre-established models and components to solve a new problem. Therefore if a certain degree of predictive ability can be demonstrated from reduction models, it may not be worth the expense of pursuing more novel ideas and hence reduction can help direct future research.</span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a><span class="fu">### Task, Loss, and Data Reduction {#sec-car-redux-task}</span></span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a>Reduction can be categorised into task, loss, and data reduction, often these must be used in conjunction with each other. The direction of the reductions may be one- or two-way; this is visualised in @fig-car-reduxdiag. This diagram should not be viewed as a strict fit/predict/evaluation workflow but instead as a guidance for which tasks, $T$, data, $D$, models, $M$, and losses, $L$, are required for each other. The subscript $O$ refers to the original object 'level' before reduction, whereas the subscript $R$ is in reference to the reduced object.</span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{figure}[H]</span></span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a><span class="co">\centering</span></span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a><span class="co">\begin{tikzpicture}</span></span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t0) {$L_O$};</span></span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t2)  [below=0.3cm of t0] {$D_O$};</span></span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t3)  [below=0.3cm of t2] {$D_R$};</span></span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t4)  [right=2cm of t0] {$M_O$};</span></span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t5)  [right=2cm of t3] {$M_R$};</span></span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t6)  [right=2cm of t4] {$T_O$};</span></span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t7)  [right=2cm of t5] {$T_R$};</span></span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a><span class="co">\path[-&gt;]</span></span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a><span class="co">   (t2) edge (t0)</span></span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a><span class="co">   (t2) edge (t3)</span></span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a><span class="co">   (t3) edge (t5)</span></span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a><span class="co">   (t4) edge (t0)</span></span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a><span class="co">   (t4) edge (t6)</span></span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a><span class="co">   (t5) edge (t4)</span></span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a><span class="co">   (t6) edge (t7)</span></span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a><span class="co">   (t7) edge (t5);</span></span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a><span class="co">\end{tikzpicture}</span></span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a><span class="co">\caption[Task, loss, and data reduction]{Task, loss, and data reduction to and from the original complex problem to sub-problems.}</span></span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a><span class="co">\label{fig:car_reduxdiag}</span></span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a><span class="co">\end{figure} --&gt;</span></span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a>The individual task, model, and data compositions in the diagram are listed below, the reduction from survival to classification (@sec-car-reduxes-r7r8) is utilised as a running example to help exposition.</span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$T_O \rightarrow T_R$: By definition of a machine learning reduction, task reduction will always be one way. A more complex task, $T_O$, is reduced to a simpler one, $T_R$, for solving. $T_R$ could also be multiple simpler tasks. For example, solving a survival task, $T_O$, by classification, $T_R$ (@sec-car-reduxes-r7r8).</span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$T_R \rightarrow M_R$:  All machine learning tasks have models that are designed to solve them. For example logistic regression, $M_R$, for classification tasks, $T_R$.</span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$M_R \rightarrow M_O$: The simpler models, $M_R$, are used for the express purpose to solve the original task, $T_O$, via solving the simpler ones. To solve $T_O$, a compositor must be applied, which may transform one (SOC) or multiple models (MOC) at a model- or prediction-level, thus creating $M_O$. For example predicting survival probabilities with logistic regression, $M_R$, at times $1,...,\tau^*$ for some $\tau^* \in \PNaturals$ (@sec-car-reduxes-r7-mlc).</span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$M_O \rightarrow T_O$: The original task should be solvable by the composite model. For example predicting a discrete survival distribution by concatenating probabilistic predictions at the times $1,...,\tau^*$ (@sec-car-reduxes-r7).</span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$D_O \rightarrow D_R$: Just as the tasks and models are reduced, the data required to fit these must likewise be reduced. Similarly to task reduction, data reduction can usually only take place in one direction, to see why this is the case take an example of data reduction by summaries. If presented with 10 data-points $<span class="sc">\{</span>1,1,1,5,7,3,5,4,3,3<span class="sc">\}</span>$ then these could be reduced to a single point by calculating the sample mean, $3.3$. Clearly given only the number $3.3$ there is no strategy to recover the original data. There are very few (if any) data reduction strategies that allow recovery of the original data. Continuing the running example, survival data, $D_O$, can be binned (@sec-car-reduxes-r7-binning) to classification data, $D_R$.</span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a>There is no arrow between $D_O$ and $M_O$ as the composite model is never fit directly, only via composition from $M_R \rightarrow M_O$. However, the original data, $D_O$, is required when evaluating the composite model against the respective loss, $L_O$.\footnote{A complete diagram would indicate that $D_O$ is split into training data, which is subsequently reduced, and test data, which is passed to $L_O$. All reductions in this section can be applied to any data splitting process.} Reduction should be directly comparable to non-reduction models, hence this diagram does not include loss reduction and instead insists that all models are compared against the same loss $L_O$.</span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a>A reduction is said to be *complete* if there is a full pipeline from $T_O \rightarrow M_O$ and the original task is solved, otherwise it is *incomplete*. The simplest complete reduction is comprised of the pipeline $T_O \rightarrow T_R \rightarrow M_R \rightarrow M_O$. Usually this is not sufficient on its own as the reduced models are fit on the reduced data, $D_R \rightarrow M_R$.</span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a>A complete reduction can be specified by detailing:</span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a>i. the original task and the sub-task(s) to be solved, $T_O \rightarrow T_R$;</span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a>i. the original dataset and the transformation to the reduced one, $D_O \rightarrow D_R$ (if required); and</span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a>i. the composition from the simpler model to the complex one, $M_R \rightarrow M_O$.</span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a><span class="fu">### Common Mistakes in Implementation of Reduction {#sec-car-reduxstrats-mistakes}</span></span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a>In surveying models and measures, several common mistakes in the implementation of reduction and composition were found to be particularly prevalent and problematic throughout the literature. It is assumed that these are indeed mistakes (not deliberate) and result from a lack of prior formalisation. These mistakes were even identified 20 years ago  <span class="co">[</span><span class="ot">@Schwarzer2000</span><span class="co">]</span> but are provided in more detail in order to highlight their current prevalence and why they cannot be ignored.</span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a>RM1. Incomplete reduction. This occurs when a reduction workflow is presented as if it solves the original task but fails to do so and only the reduction strategy is solved. A common example is claiming to solve the survival task by using binary classification, e.g. erroneously claiming that a model predicts survival probabilities (which implies distribution) when it actually predicts a five year probability of death (@box-task-classif). This is a mistake as it misleads readers into believing that the model solves a survival task (@box-task-surv) when it does not. This is usually a semantic not mathematical error and results from misuse of terminology. It is important to be clear about model predict types  (@sec-surv-set-types) and general terms such as 'survival predictions' should be avoided unless they refer to one of the three prediction tasks.</span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a>RM2. Inappropriate comparisons. This is a direct consequence of (RM1) and the two are often seen together. (RM2) occurs when an incomplete reduction is directly compared to a survival model (or complete reduction model) using a measure appropriate for the reduction. This may lead to a reduction model appearing erroneously superior. For example, comparing a logistic regression to a random survival forest (RSF) (@sec-surv-ml-models-ranfor) for predicting survival probabilities at a single time using the accuracy measure is an unfair comparison as the RSF is optimised for distribution predictions. This would be non-problematic if a suitable composition is clearly utilised. For example a regression SSVM predicting survival time cannot be directly compared to a Cox PH. However the SSVM can be compared to a CPH composed with the probabilistic to deterministic compositor \CProb, then conclusions can be drawn about comparison to the composite survival time Cox model (and not simply a Cox PH).</span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a>RM3. Na\"ive censoring deletion. This common mistake occurs when trying to reduce survival to regression or classification by simply deleting all censored observations, even if censoring is informative. This is a mistake as it creates bias in the dataset, which can be substantial if the proportion of censoring is high and informative. More robust deletion methods are described in @sec-redux-regr.</span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a>RM4. Oversampling uncensored observations. This is often seen when trying to reduce survival to regression or classification, and often alongside (RM3). Oversampling is the process of replicating observations to artificially inflate the sample size of the data. Whilst this process does not create any new information, it can help a model  detect important features in the data. However, by only oversampling uncensored observations, this creates a source of bias in the data and ignores the potentially informative information provided by the proportion of censoring.</span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a><span class="fu">## Composition Strategies for Survival Analysis {#sec-car-pipelines}</span></span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a>Though composition is common practice in survival analysis, with the Cox model being a prominent example, a lack of formalisation means a lack of consensus in simple operations. For example, it is often asked in survival analysis how a model predicting a survival distribution can be used to return a survival time prediction. A common strategy is to define the survival time prediction as the median of the predicted survival curve however there is no clear reason why this should be more sensible than returning the distribution mean, mode, or some random quantile. Formalisation allow these choices to be analytically compared both theoretically and practically as hyper-parameters in a workflow. Four prediction compositions are discussed in this section (@tab-car-taxredcar), three are utilised to convert prediction types between one another, the fourth is for aggregating multiple predictions. One data composition is discussed for converting survival to regression data. Each is first graphically represented and then the components are discussed in detail. As with losses in the previous chapter, compositions are discussed at an individual observation level but extend trivially to multiple observations.</span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a>| ID$^1$ | Composition | Type$^2$ | Level$^3$ |</span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a>| --- | --- | --- | --- |</span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a>| C1) | Linear predictor to distribution | MOC | Prediction |</span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a>| C2) | Survival time to distribution | MOC | Prediction |</span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a>| C3) | Distribution to survival time | SOC | Prediction |</span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a>| C4) | Survival model averaging | MOC | Prediction |</span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a>| C5) | Survival to regression | SOC | Data |</span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a>: Compositions formalised in @sec-car-pipelines. {tbl-car-taxredcar}</span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a>&lt;sup&gt;</span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>ID for reference throughout this book.</span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Composition type. Multi-object composition (MOC) or single-object composition (SOC).</span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Composition level.</span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a>&lt;/sup&gt;</span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a><span class="fu">### C1) Linear Predictor $\rightarrow$ Distribution {#sec-car-pipelines-distr}</span></span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{figure}[H]</span></span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a><span class="co">\centering</span></span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a><span class="co">\begin{tikzpicture}[framed]</span></span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t0)[objnode] {$\hat{\eta}$};</span></span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t3)[funnode,right=of t0,fill=orange!30]{$C$};</span></span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t1)[objnode,above=of t3]{$M$};</span></span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t2)[objnode,below=of t3]{$\hatS_0$};</span></span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t4)[objnode, right=of t3]{$\zeta$};</span></span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a><span class="co">\path[-&gt;]</span></span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a><span class="co">   (t0) edge  (t3)</span></span>
<span id="cb1-274"><a href="#cb1-274" aria-hidden="true" tabindex="-1"></a><span class="co">   (t1) edge  (t3)</span></span>
<span id="cb1-275"><a href="#cb1-275" aria-hidden="true" tabindex="-1"></a><span class="co">   (t2) edge  (t3)</span></span>
<span id="cb1-276"><a href="#cb1-276" aria-hidden="true" tabindex="-1"></a><span class="co">   (t3) edge  (t4);</span></span>
<span id="cb1-277"><a href="#cb1-277" aria-hidden="true" tabindex="-1"></a><span class="co">\end{tikzpicture}</span></span>
<span id="cb1-278"><a href="#cb1-278" aria-hidden="true" tabindex="-1"></a><span class="co">\caption[Linear predictor to distribution composition]{Linear predictor ($\hat{\eta}$) to survival distribution ($\zeta$) composition. Parameters: $M$ -- Model form; $\hatS_0$ -- Estimated baseline survival function.}</span></span>
<span id="cb1-279"><a href="#cb1-279" aria-hidden="true" tabindex="-1"></a><span class="co">\label{fig:car_comp_distr}</span></span>
<span id="cb1-280"><a href="#cb1-280" aria-hidden="true" tabindex="-1"></a><span class="co">\end{figure} --&gt;</span></span>
<span id="cb1-281"><a href="#cb1-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-282"><a href="#cb1-282" aria-hidden="true" tabindex="-1"></a>This is a prediction-level MOC that composes a survival distribution from a predicted linear predictor and estimated baseline survival distribution. The composition (@fig-car-comp-distr) requires:</span>
<span id="cb1-283"><a href="#cb1-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-284"><a href="#cb1-284" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$\hat{\eta}$: Predicted linear predictor. $\hat{\eta}$ can be tuned by including this composition multiple times in a benchmark experiment with different models predicting $\hat{\eta}$. In theory any continuous ranking could be utilised instead of a linear predictor though results may be less sensible (@sec-car-pipelines-trade).</span>
<span id="cb1-285"><a href="#cb1-285" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$\hatS_0$: Estimated baseline survival function. This is usually estimated by the Kaplan-Meier estimator fit on training data, $\KMS$. However any model that can predict a survival distribution can estimate the baseline distribution (caveat: see @sec-car-pipelines-trade) by taking a uniform mixture of the predicted individual distributions: say $\xi_1,...,\xi_m$ are m predicted distributions, then $\hatS_0(\tau) = \mean<span class="co">[</span><span class="ot">m</span><span class="co">]</span>{\xi_i.S(\tau)}$. The mixture is required as the baseline must be the same for all observations. Alternatively, parametric distributions can be assumed for the baseline, e.g. $\xi = \Exp(2)$ and $\xi.S(t) = \exp(-2t)$. As with $\hat{\eta}$, this parameter is also tunable.</span>
<span id="cb1-286"><a href="#cb1-286" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$M$: Chosen model form, which theoretically can be any non-increasing right-continuous function but is usually one of:</span>
<span id="cb1-287"><a href="#cb1-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-288"><a href="#cb1-288" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Proportional Hazards (PH): $S_{PH}(\tau|\eta, S_0) = S_0(\tau)^{\exp(\eta)}$</span>
<span id="cb1-289"><a href="#cb1-289" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Accelerated Failure Time (AFT): $S_{AFT}(\tau|\eta, S_0) = S_0(\frac{\tau}{\exp(\eta)})$</span>
<span id="cb1-290"><a href="#cb1-290" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Proportional Odds (PO): $S_{PO}(\tau|\eta, S_0) = \frac{S_0(\tau)}{\exp(-\eta) + (1-\exp(-\eta)) S_0(\tau)}$</span>
<span id="cb1-291"><a href="#cb1-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-292"><a href="#cb1-292" aria-hidden="true" tabindex="-1"></a>Models that predict linear predictors will make assumptions about the model form and therefore dictate sensible choices of $M$, for example the Cox model assumes a PH form. This does not mean other choices of $M$ cannot be specified but that interpretation may be more difficult (@sec-car-pipelines-trade). The model form can be treated as a hyper-parameter to tune.</span>
<span id="cb1-293"><a href="#cb1-293" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$C$: Compositor returning the composed distribution, $\zeta := C(M, \hat{\eta}, \hatS_0)$ where $\zeta$ has survival function $\zeta.S(\tau) = M(\tau|\hat{\eta}, \hatS_0)$.</span>
<span id="cb1-294"><a href="#cb1-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-295"><a href="#cb1-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-296"><a href="#cb1-296" aria-hidden="true" tabindex="-1"></a>Pseudo-code for training (@alg-car-comp-distr-fit) and predicting (@alg-car-comp-distr-pred) this composition as a model 'wrapper' with sensible parameter choices (@sec-car-pipelines-trade) is provided in appendix @app-car.</span>
<span id="cb1-297"><a href="#cb1-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-298"><a href="#cb1-298" aria-hidden="true" tabindex="-1"></a><span class="fu">### C2) Survival Time $\rightarrow$ Distribution {#sec-car-pipelines-time}</span></span>
<span id="cb1-299"><a href="#cb1-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-300"><a href="#cb1-300" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{figure}[H]</span></span>
<span id="cb1-301"><a href="#cb1-301" aria-hidden="true" tabindex="-1"></a><span class="co">\centering</span></span>
<span id="cb1-302"><a href="#cb1-302" aria-hidden="true" tabindex="-1"></a><span class="co">\begin{tikzpicture}[framed]</span></span>
<span id="cb1-303"><a href="#cb1-303" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t4)[objnode]{$\hatT$};</span></span>
<span id="cb1-304"><a href="#cb1-304" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t3)[funnode,right=of t4,fill=orange!30]{$C$};</span></span>
<span id="cb1-305"><a href="#cb1-305" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t1)[objnode,above=of t3]{$\xi$};</span></span>
<span id="cb1-306"><a href="#cb1-306" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t6)[objnode, below=of t3]{$\hat{\sigma}$};</span></span>
<span id="cb1-307"><a href="#cb1-307" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t5)[objnode, right=of t3]{$\zeta$};</span></span>
<span id="cb1-308"><a href="#cb1-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-309"><a href="#cb1-309" aria-hidden="true" tabindex="-1"></a><span class="co">\path[-&gt;]</span></span>
<span id="cb1-310"><a href="#cb1-310" aria-hidden="true" tabindex="-1"></a><span class="co">   (t1) edge  (t3)</span></span>
<span id="cb1-311"><a href="#cb1-311" aria-hidden="true" tabindex="-1"></a><span class="co">   (t6) edge (t3)</span></span>
<span id="cb1-312"><a href="#cb1-312" aria-hidden="true" tabindex="-1"></a><span class="co">   (t4) edge  (t3)</span></span>
<span id="cb1-313"><a href="#cb1-313" aria-hidden="true" tabindex="-1"></a><span class="co">   (t3) edge  (t5);</span></span>
<span id="cb1-314"><a href="#cb1-314" aria-hidden="true" tabindex="-1"></a><span class="co">\end{tikzpicture}</span></span>
<span id="cb1-315"><a href="#cb1-315" aria-hidden="true" tabindex="-1"></a><span class="co">\caption[Survival time to distribution composition]{Survival time ($\hatT$) to distribution ($\zeta$) composition. Parameters: $\hat{\sigma}$ -- Estimated scale parameter; $\xi$ -- Assumed survival distribution.}</span></span>
<span id="cb1-316"><a href="#cb1-316" aria-hidden="true" tabindex="-1"></a><span class="co">\label{fig:car_comp_response}</span></span>
<span id="cb1-317"><a href="#cb1-317" aria-hidden="true" tabindex="-1"></a><span class="co">\end{figure} --&gt;</span></span>
<span id="cb1-318"><a href="#cb1-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-319"><a href="#cb1-319" aria-hidden="true" tabindex="-1"></a>This is a prediction-level MOC that composes a distribution from a predicted survival time and assumed location-scale distribution. The composition (@fig-car-comp-response) requires:</span>
<span id="cb1-320"><a href="#cb1-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-321"><a href="#cb1-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-322"><a href="#cb1-322" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$\hatT$: A predicted survival time. As with the previous composition, this is tunable. In theory any continuous ranking could replace $\hatT$, though the resulting distribution may not be sensible (@sec-car-pipelines-trade).</span>
<span id="cb1-323"><a href="#cb1-323" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$\xi$: A specified location-scale distribution, $\xi(\mu, \sigma)$, e.g. Normal distribution.</span>
<span id="cb1-324"><a href="#cb1-324" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$\hat{\sigma}$: Estimated scale parameter for the distribution. This can be treated as a hyper-parameter or predicted by another model.</span>
<span id="cb1-325"><a href="#cb1-325" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$C$: Compositor returning the composed distribution $\zeta := C(\xi, \hatT, \hat{\sigma}) = \xi(\hatT, \hat{\sigma})$.</span>
<span id="cb1-326"><a href="#cb1-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-327"><a href="#cb1-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-328"><a href="#cb1-328" aria-hidden="true" tabindex="-1"></a>Pseudo-code for training (@alg-car-comp-response-fit) and predicting (@alg-car-comp-response-pred) this composition as a model 'wrapper' with sensible parameter choices (@sec-car-pipelines-trade) is provided in appendix @app-car.</span>
<span id="cb1-329"><a href="#cb1-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-330"><a href="#cb1-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-331"><a href="#cb1-331" aria-hidden="true" tabindex="-1"></a><span class="fu">### C3) Distribution $\rightarrow$ Survival Time Composition {#sec-car-pipelines-crank}</span></span>
<span id="cb1-332"><a href="#cb1-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-333"><a href="#cb1-333" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{figure}[H]</span></span>
<span id="cb1-334"><a href="#cb1-334" aria-hidden="true" tabindex="-1"></a><span class="co">\centering</span></span>
<span id="cb1-335"><a href="#cb1-335" aria-hidden="true" tabindex="-1"></a><span class="co">\begin{tikzpicture}[framed]</span></span>
<span id="cb1-336"><a href="#cb1-336" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t1)[funnode, right=of t0]{$\zeta$};</span></span>
<span id="cb1-337"><a href="#cb1-337" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t2)[funnode, right=of t1, fill = orange!30]{$C$};</span></span>
<span id="cb1-338"><a href="#cb1-338" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t4)[objnode, above=of t2]{$\phi$};</span></span>
<span id="cb1-339"><a href="#cb1-339" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t3)[objnode, right=of t2]{$\hatT$};</span></span>
<span id="cb1-340"><a href="#cb1-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-341"><a href="#cb1-341" aria-hidden="true" tabindex="-1"></a><span class="co">\path[-&gt;]</span></span>
<span id="cb1-342"><a href="#cb1-342" aria-hidden="true" tabindex="-1"></a><span class="co">   (t1) edge  (t2)</span></span>
<span id="cb1-343"><a href="#cb1-343" aria-hidden="true" tabindex="-1"></a><span class="co">   (t4) edge  (t2)</span></span>
<span id="cb1-344"><a href="#cb1-344" aria-hidden="true" tabindex="-1"></a><span class="co">   (t2) edge  (t3);</span></span>
<span id="cb1-345"><a href="#cb1-345" aria-hidden="true" tabindex="-1"></a><span class="co">\end{tikzpicture}</span></span>
<span id="cb1-346"><a href="#cb1-346" aria-hidden="true" tabindex="-1"></a><span class="co">\caption[Distribution to survival time composition]{Distribution ($\zeta$) to survival time ($\hatT$) composition. Parameters: $\phi$ -- Summary method.}</span></span>
<span id="cb1-347"><a href="#cb1-347" aria-hidden="true" tabindex="-1"></a><span class="co">\label{fig:car_comp_crank}</span></span>
<span id="cb1-348"><a href="#cb1-348" aria-hidden="true" tabindex="-1"></a><span class="co">\end{figure} --&gt;</span></span>
<span id="cb1-349"><a href="#cb1-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-350"><a href="#cb1-350" aria-hidden="true" tabindex="-1"></a>This is a prediction-level SOC that composes a survival time from a predicted distribution. Any paper that evaluates a distribution on concordance is implicitly using this composition in some manner. Not acknowledging the composition leads to unfair model comparison (@sec-car-reduxstrats-mistakes). The composition (@fig-car-comp-crank) requires:</span>
<span id="cb1-351"><a href="#cb1-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-352"><a href="#cb1-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-353"><a href="#cb1-353" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$\zeta$: A predicted survival distribution, which again is 'tunable'.</span>
<span id="cb1-354"><a href="#cb1-354" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$\phi$: A distribution summary method. Common examples include the mean, median and mode. Other alternatives include distribution quantiles, $\zeta.F^{-1}(\alpha)$,<span class="sc">\\</span>$\alpha \in <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$; $\alpha$ could be tuned as a hyper-parameter.</span>
<span id="cb1-355"><a href="#cb1-355" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$C$: Compositor returning composed survival time predictions, $\hatT := C(\phi, \zeta) = \phi(\zeta)$.</span>
<span id="cb1-356"><a href="#cb1-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-357"><a href="#cb1-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-358"><a href="#cb1-358" aria-hidden="true" tabindex="-1"></a>Pseudo-code for training (@alg-car-comp-crank-fit) and predicting (@alg-car-comp-crank-pred) this composition as a model 'wrapper' with sensible parameter choices (@sec-car-pipelines-trade) is provided in appendix @app-car.</span>
<span id="cb1-359"><a href="#cb1-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-360"><a href="#cb1-360" aria-hidden="true" tabindex="-1"></a><span class="fu">### C4) Survival Model Averaging {#sec-car-pipelines-avg}</span></span>
<span id="cb1-361"><a href="#cb1-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-362"><a href="#cb1-362" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{figure}[H]</span></span>
<span id="cb1-363"><a href="#cb1-363" aria-hidden="true" tabindex="-1"></a><span class="co">\centering</span></span>
<span id="cb1-364"><a href="#cb1-364" aria-hidden="true" tabindex="-1"></a><span class="co">\begin{tikzpicture}[framed]</span></span>
<span id="cb1-365"><a href="#cb1-365" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t2)[funnode, above right=of t0,yshift=-10mm]{$\rho_2$};</span></span>
<span id="cb1-366"><a href="#cb1-366" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t1)[funnode, above=of t2, yshift=-5mm]{$\rho_1$};</span></span>
<span id="cb1-367"><a href="#cb1-367" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t3)[funnode, below right=of t0,yshift=10mm]{...};</span></span>
<span id="cb1-368"><a href="#cb1-368" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t4)[funnode, below=of t3,yshift=5mm]{$\rho_B$};</span></span>
<span id="cb1-369"><a href="#cb1-369" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t5)[funnode, right=of t0, fill=orange!30,xshift=20mm]{$C$};</span></span>
<span id="cb1-370"><a href="#cb1-370" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t6)[objnode, right=of t5]{$\hat{\rho}$};</span></span>
<span id="cb1-371"><a href="#cb1-371" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t7)[objnode, below=of t5, yshift = 0.2cm]{$w$};</span></span>
<span id="cb1-372"><a href="#cb1-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-373"><a href="#cb1-373" aria-hidden="true" tabindex="-1"></a><span class="co">\path[-&gt;]</span></span>
<span id="cb1-374"><a href="#cb1-374" aria-hidden="true" tabindex="-1"></a><span class="co">   (t1) edge  (t5)</span></span>
<span id="cb1-375"><a href="#cb1-375" aria-hidden="true" tabindex="-1"></a><span class="co">   (t2) edge  (t5)</span></span>
<span id="cb1-376"><a href="#cb1-376" aria-hidden="true" tabindex="-1"></a><span class="co">   (t3) edge  (t5)</span></span>
<span id="cb1-377"><a href="#cb1-377" aria-hidden="true" tabindex="-1"></a><span class="co">   (t4) edge  (t5)</span></span>
<span id="cb1-378"><a href="#cb1-378" aria-hidden="true" tabindex="-1"></a><span class="co">   (t5) edge  (t6)</span></span>
<span id="cb1-379"><a href="#cb1-379" aria-hidden="true" tabindex="-1"></a><span class="co">   (t7) edge (t5);</span></span>
<span id="cb1-380"><a href="#cb1-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-381"><a href="#cb1-381" aria-hidden="true" tabindex="-1"></a><span class="co">\end{tikzpicture}</span></span>
<span id="cb1-382"><a href="#cb1-382" aria-hidden="true" tabindex="-1"></a><span class="co">\caption[Survival model averaging composition]{Survival model averaging composition. $\rho_1,...,\rho_B$ are $B$ predictions of the same return type (time, ranking, distribution) and $\hat{\rho}$ is the averaged prediction. Parameters: $w = w_1,...,w_B$ -- Weights summing to one.}</span></span>
<span id="cb1-383"><a href="#cb1-383" aria-hidden="true" tabindex="-1"></a><span class="co">\label{fig:car_comp_avg}</span></span>
<span id="cb1-384"><a href="#cb1-384" aria-hidden="true" tabindex="-1"></a><span class="co">\end{figure} --&gt;</span></span>
<span id="cb1-385"><a href="#cb1-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-386"><a href="#cb1-386" aria-hidden="true" tabindex="-1"></a>Ensembling is likely the most common composition in machine learning. In survival it is complicated slightly as multiple prediction types means one of two possible compositions is utilised to average predictions. The (@fig-car-comp-avg) composition requires:</span>
<span id="cb1-387"><a href="#cb1-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-388"><a href="#cb1-388" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$\rho = \rho_1,...,\rho_B$: $B$ predictions (not necessarily from the same model) of the same type: ranking, survival time or distribution; again 'tunable'.</span>
<span id="cb1-389"><a href="#cb1-389" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$w = w_1,...,w_B$: Weights that sum to one.</span>
<span id="cb1-390"><a href="#cb1-390" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$C$: Compositor returning combined predictions, $\hat{\rho} := C(\rho, w)$ where $C(\rho, w) = \mean<span class="co">[</span><span class="ot">B</span><span class="co">]</span>{w_i \rho_i}$, if $\rho$ are ranking of survival time predictions; or $C(\rho, w) = \zeta$ where $\zeta$ is the distribution defined by the survival function $\zeta.S(\tau) = \mean<span class="co">[</span><span class="ot">B</span><span class="co">]</span>{w_i \rho_i.S(\tau)}$, if $\rho$ are distribution predictions.</span>
<span id="cb1-391"><a href="#cb1-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-392"><a href="#cb1-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-393"><a href="#cb1-393" aria-hidden="true" tabindex="-1"></a>Pseudo-code for training (@alg-car-comp-avg-fit) and predicting (@alg-car-comp-avg-pred) this composition as a model 'wrapper' with sensible parameter choices (@sec-car-pipelines-trade) is provided in appendix @app-car.</span>
<span id="cb1-394"><a href="#cb1-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-395"><a href="#cb1-395" aria-hidden="true" tabindex="-1"></a><span class="fu">## Novel Survival Reductions {#sec-car-reduxes}</span></span>
<span id="cb1-396"><a href="#cb1-396" aria-hidden="true" tabindex="-1"></a>This section collects the various strategies and settings discussed previously into complete reduction workflows. @tab-car-reduxes lists the reductions discussed in this section with IDs for future reference. All strategies are described by visualising a graphical pipeline and then listing the composition steps required in fitting and predicting.</span>
<span id="cb1-397"><a href="#cb1-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-398"><a href="#cb1-398" aria-hidden="true" tabindex="-1"></a>This section only includes novel reduction strategies and does not provide a survey of pre-existing strategies. This limitation is primarily due to time (and page) constraints as every method has very distinct workflows that require complex exposition. Well-established strategies are briefly mentioned below and future research is planned to survey and compare all strategies with respect to empirical performance (i.e. in benchmark experiments).</span>
<span id="cb1-399"><a href="#cb1-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-400"><a href="#cb1-400" aria-hidden="true" tabindex="-1"></a>Two prominent reductions are 'landmarking'  <span class="co">[</span><span class="ot">@VanHouwelingen2007</span><span class="co">]</span> and piecewise exponential models  <span class="co">[</span><span class="ot">@Friedman1982</span><span class="co">]</span>. Both are reductions for time-varying covariates and hence outside the scope of this book. Relevant to this book scope is a large class of strategies that utilise 'discrete time survival analysis'  <span class="co">[</span><span class="ot">@Tutz2016</span><span class="co">]</span>; these strategies include reductions (R7) and (R8). Methodology for discrete time survival analysis has been seen in the literature for the past three decades  <span class="co">[</span><span class="ot">@Liestol1994</span><span class="co">]</span>. The primary reduction strategy for discrete time survival analysis is implemented in the $\Rstats$ package <span class="in">`r pkg("discSurv")`</span>  <span class="co">[</span><span class="ot">@pkgdiscsurv</span><span class="co">]</span>; this is very similar to (R7) except that it enforces stricter constraints in the composition procedures and forces a 'discrete-hazard' instead of 'discrete-survival' representation (@sec-car-reduxes-r7-out).</span>
<span id="cb1-401"><a href="#cb1-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-402"><a href="#cb1-402" aria-hidden="true" tabindex="-1"></a><span class="fu">### R7-R8) Survival $\rightarrow$ Probabilistic Classification {#sec-car-reduxes-r7r8}</span></span>
<span id="cb1-403"><a href="#cb1-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-404"><a href="#cb1-404" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{figure}[H]</span></span>
<span id="cb1-405"><a href="#cb1-405" aria-hidden="true" tabindex="-1"></a><span class="co">\centering</span></span>
<span id="cb1-406"><a href="#cb1-406" aria-hidden="true" tabindex="-1"></a><span class="co">\begin{tikzpicture}[framed]</span></span>
<span id="cb1-407"><a href="#cb1-407" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t0) [objnode]  {$\dtrain$};</span></span>
<span id="cb1-408"><a href="#cb1-408" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t1) [funnode,right=of t0] {$B(\dtrain|w)$};</span></span>
<span id="cb1-409"><a href="#cb1-409" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t2) [objnode,right=of t1] {$D_B$};</span></span>
<span id="cb1-410"><a href="#cb1-410" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t3) [funnode, below=of t2] {$C_C$};</span></span>
<span id="cb1-411"><a href="#cb1-411" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t4) [funnode, right=of t3] {$g_C(D_B|\phi)$};</span></span>
<span id="cb1-412"><a href="#cb1-412" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t5) [funnode, above=of t2] {$C_B$};</span></span>
<span id="cb1-413"><a href="#cb1-413" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t6) [funnode, right=of t5] {$g_B(D_B|\varphi)$};</span></span>
<span id="cb1-414"><a href="#cb1-414" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t7) [funnode,right=of t2] {$g_L(D_B|\theta)$};</span></span>
<span id="cb1-415"><a href="#cb1-415" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t8) [objnode,right=of t7] {$\hatg$};</span></span>
<span id="cb1-416"><a href="#cb1-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-417"><a href="#cb1-417" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t9) [objnode, below=of t0, yshift = -15mm] {$\dtest$};</span></span>
<span id="cb1-418"><a href="#cb1-418" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t10) [funnode, right=of t9] {$\hat{g}(\dtest|\Theta)$};</span></span>
<span id="cb1-419"><a href="#cb1-419" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t11) [objnode, right=of t10] {$\tilde{S}$};</span></span>
<span id="cb1-420"><a href="#cb1-420" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t12) [funnode, right=of t11] {$T_1(\tilde{S})$};</span></span>
<span id="cb1-421"><a href="#cb1-421" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t13) [funnode, below=of t12] {$T_2(\tilde{S})$};</span></span>
<span id="cb1-422"><a href="#cb1-422" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t14) [objnode, right=of t12] {$\zeta$};</span></span>
<span id="cb1-423"><a href="#cb1-423" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t15) [objnode, right=of t13] {$\hatT$};</span></span>
<span id="cb1-424"><a href="#cb1-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-425"><a href="#cb1-425" aria-hidden="true" tabindex="-1"></a><span class="co">\path[-&gt;]</span></span>
<span id="cb1-426"><a href="#cb1-426" aria-hidden="true" tabindex="-1"></a><span class="co">   (t0)  edge (t1)</span></span>
<span id="cb1-427"><a href="#cb1-427" aria-hidden="true" tabindex="-1"></a><span class="co">   (t1)  edge (t2)</span></span>
<span id="cb1-428"><a href="#cb1-428" aria-hidden="true" tabindex="-1"></a><span class="co">   (t2)  edge[dashed] (t3)</span></span>
<span id="cb1-429"><a href="#cb1-429" aria-hidden="true" tabindex="-1"></a><span class="co">   (t2)  edge[dashed] (t5)</span></span>
<span id="cb1-430"><a href="#cb1-430" aria-hidden="true" tabindex="-1"></a><span class="co">   (t2)  edge[dashed] (t7)</span></span>
<span id="cb1-431"><a href="#cb1-431" aria-hidden="true" tabindex="-1"></a><span class="co">   (t3)  edge (t4)</span></span>
<span id="cb1-432"><a href="#cb1-432" aria-hidden="true" tabindex="-1"></a><span class="co">   (t4)  edge (t8)</span></span>
<span id="cb1-433"><a href="#cb1-433" aria-hidden="true" tabindex="-1"></a><span class="co">   (t6)  edge (t8)</span></span>
<span id="cb1-434"><a href="#cb1-434" aria-hidden="true" tabindex="-1"></a><span class="co">   (t7)  edge (t8)</span></span>
<span id="cb1-435"><a href="#cb1-435" aria-hidden="true" tabindex="-1"></a><span class="co">   (t5)  edge (t6)</span></span>
<span id="cb1-436"><a href="#cb1-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-437"><a href="#cb1-437" aria-hidden="true" tabindex="-1"></a><span class="co">   (t9) edge (t10)</span></span>
<span id="cb1-438"><a href="#cb1-438" aria-hidden="true" tabindex="-1"></a><span class="co">   (t10) edge (t11)</span></span>
<span id="cb1-439"><a href="#cb1-439" aria-hidden="true" tabindex="-1"></a><span class="co">   (t11) edge[dotted,color=red] (t12)</span></span>
<span id="cb1-440"><a href="#cb1-440" aria-hidden="true" tabindex="-1"></a><span class="co">   (t11) edge[dash dot,color=blue] (t13)</span></span>
<span id="cb1-441"><a href="#cb1-441" aria-hidden="true" tabindex="-1"></a><span class="co">   (t12) edge[dotted,color=red] (t14)</span></span>
<span id="cb1-442"><a href="#cb1-442" aria-hidden="true" tabindex="-1"></a><span class="co">   (t13) edge[dash dot,color=blue] (t15);</span></span>
<span id="cb1-443"><a href="#cb1-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-444"><a href="#cb1-444" aria-hidden="true" tabindex="-1"></a><span class="co">\draw[dashed, line width=0.1mm] (-1,-2.5) -- (11,-2.5);</span></span>
<span id="cb1-445"><a href="#cb1-445" aria-hidden="true" tabindex="-1"></a><span class="co">\end{tikzpicture}</span></span>
<span id="cb1-446"><a href="#cb1-446" aria-hidden="true" tabindex="-1"></a><span class="co">\caption[Survival to classification reduction]{Survival to classification reduction. Top row is fitting and bottom row is predicting. Dashed lines represent a choice in the reduction (alternative compositions). Red dotted lines complete the probabilistic survival reduction (R7) and the blue dash-dotted lines complete the deterministic survival reduction (R8). Key: training data, $\dtrain$; binning function, $B$, with weights, $w$; binned data, $D_B$; composition to binary-class classification, $C_B$; composition to multi-class classification, $C_C$; binary-class classifier, $g_B$, with parameters, $\varphi$; multi-label classifier, $g_L$, with parameters, $\theta$; multi-class classifier, $g_C$, with parameters $\phi$; trained classifier, $\hat{g}$ with parameters $\Theta$; testing data, $\dtest$; pseudo-survival probabilities, $\tilde{S}$; composition, $T_1$, to distribution, $\zeta$; composition, $T_2$, to survival time, $\hatT$.}</span></span>
<span id="cb1-447"><a href="#cb1-447" aria-hidden="true" tabindex="-1"></a><span class="co">\label{fig:car_R7R8}</span></span>
<span id="cb1-448"><a href="#cb1-448" aria-hidden="true" tabindex="-1"></a><span class="co">\end{figure} --&gt;</span></span>
<span id="cb1-449"><a href="#cb1-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-450"><a href="#cb1-450" aria-hidden="true" tabindex="-1"></a>Two separate reductions are presented in @fig-car-R7R8 however as both are reductions to probabilistic classification and are only different in the very last step, both are presented in this section. Steps and compositions of the reduction (@fig-car-R7R8):</span>
<span id="cb1-451"><a href="#cb1-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-452"><a href="#cb1-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-453"><a href="#cb1-453" aria-hidden="true" tabindex="-1"></a>  **Fit**</span>
<span id="cb1-454"><a href="#cb1-454" aria-hidden="true" tabindex="-1"></a>F1) A survival dataset, $\dtrain$, is binned, $B$, with a continuous to discrete data composition (@sec-car-reduxes-r7-binning).</span>
<span id="cb1-455"><a href="#cb1-455" aria-hidden="true" tabindex="-1"></a>F2)  A multi-label classification model, with adaptations for censoring, $g_L(D_B|\theta)$, is fit on the transformed dataset, $D_B$. Optionally, $g_L$ could be further reduced to binary, $g_B$, or multi-class classification, $g_c$, (@sec-car-reduxes-r7-mlc).</span>
<span id="cb1-456"><a href="#cb1-456" aria-hidden="true" tabindex="-1"></a>  **Predict**</span>
<span id="cb1-457"><a href="#cb1-457" aria-hidden="true" tabindex="-1"></a>P1)  Testing survival data, $\dtest$, is passed to the trained classification model, $\hatg$, to predict pseudo-survival probabilities $\tilde{S}$ (or optionally hazards (@sec-car-reduxes-r7-out)).</span>
<span id="cb1-458"><a href="#cb1-458" aria-hidden="true" tabindex="-1"></a>P2a) Predictions can be composed, $T_1$, into a survival distribution prediction, $\zeta = \zeta_1,...,\zeta_m$ (@sec-car-reduxes-r7); or,</span>
<span id="cb1-459"><a href="#cb1-459" aria-hidden="true" tabindex="-1"></a>P2b) Predictions can be composed, $T_2$, to survival time predictions, $\hatT = \hatT_1,...,\hatT_m$ (@sec-car-reduxes-r8).</span>
<span id="cb1-460"><a href="#cb1-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-461"><a href="#cb1-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-462"><a href="#cb1-462" aria-hidden="true" tabindex="-1"></a>Further details for binning, multi-label classification, and transformation of pseudo-survival probabilities are now provided.</span>
<span id="cb1-463"><a href="#cb1-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-464"><a href="#cb1-464" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Composition: Binning Survival Times {#sec-car-reduxes-r7-binning}</span></span>
<span id="cb1-465"><a href="#cb1-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-466"><a href="#cb1-466" aria-hidden="true" tabindex="-1"></a>An essential part of the reduction is the transformation from a survival dataset to a classification dataset, which requires two separate compositions. The first (discussed here) is to discretise the survival times ($B(\dtrain|w)$ in @fig-car-R7R8)  and the second is to merge the survival time and censoring indicator into a single outcome (@sec-car-reduxes-r7-out).</span>
<span id="cb1-467"><a href="#cb1-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-468"><a href="#cb1-468" aria-hidden="true" tabindex="-1"></a>Discretising survival times is achieved by the common 'binning' composition, in which a continuous outcome is discretised into 'bins' according to specified thresholds. These thresholds are usually determined by specifying the width of the bins as a hyper-parameter $w$.\footnote{Binning is described here with equal widths but generalises to unequal widths trivially.} This is a common transformation and therefore further discussion is not provided here. An example is given below with the original survival data on the left and the binned data on the right ($w = 1$).</span>
<span id="cb1-469"><a href="#cb1-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-470"><a href="#cb1-470" aria-hidden="true" tabindex="-1"></a>| X | Time (Cont.) | Died |</span>
<span id="cb1-471"><a href="#cb1-471" aria-hidden="true" tabindex="-1"></a>| --- | --- | --- |</span>
<span id="cb1-472"><a href="#cb1-472" aria-hidden="true" tabindex="-1"></a>| 1 | 1.56 | 0|</span>
<span id="cb1-473"><a href="#cb1-473" aria-hidden="true" tabindex="-1"></a>| 2 | 2 | 1|</span>
<span id="cb1-474"><a href="#cb1-474" aria-hidden="true" tabindex="-1"></a>| 3 | 3.3 | 1 |</span>
<span id="cb1-475"><a href="#cb1-475" aria-hidden="true" tabindex="-1"></a>| 4 | 3.6 | 0|</span>
<span id="cb1-476"><a href="#cb1-476" aria-hidden="true" tabindex="-1"></a>| 5 | 4 | 0 |</span>
<span id="cb1-477"><a href="#cb1-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-478"><a href="#cb1-478" aria-hidden="true" tabindex="-1"></a>| X | Time (Disc.) | Died |</span>
<span id="cb1-479"><a href="#cb1-479" aria-hidden="true" tabindex="-1"></a>| --- | --- | --- |</span>
<span id="cb1-480"><a href="#cb1-480" aria-hidden="true" tabindex="-1"></a>| 1 | [1, 2) | 0|</span>
<span id="cb1-481"><a href="#cb1-481" aria-hidden="true" tabindex="-1"></a>| 2 | [2, 3) | 1|</span>
<span id="cb1-482"><a href="#cb1-482" aria-hidden="true" tabindex="-1"></a>| 3 | [3, 4) | 1 |</span>
<span id="cb1-483"><a href="#cb1-483" aria-hidden="true" tabindex="-1"></a>| 4 | [3, 4) | 0|</span>
<span id="cb1-484"><a href="#cb1-484" aria-hidden="true" tabindex="-1"></a>| 5 | [4, 5) | 0 |</span>
<span id="cb1-485"><a href="#cb1-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-486"><a href="#cb1-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-487"><a href="#cb1-487" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Composition: Survival to Classification Outcome {#sec-car-reduxes-r7-out}</span></span>
<span id="cb1-488"><a href="#cb1-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-489"><a href="#cb1-489" aria-hidden="true" tabindex="-1"></a>The binned dataset still has the unique survival data format of utilising two outcomes for training (time and status) but only making a prediction for one outcome (distribution). In order for this to be compatible with classification, the two outcome variables are composed into a single variable.\footnote{This is the first key divergence from other discrete-time classification strategies, which use the censoring indicator as the outcome and the time outcome as a feature.} This is achieved by casting the survival times into a 'wide' format and creating a new outcome indicator.\footnote{This is the second key divergence from other discrete-time classification strategies, which keep the data in a 'long' format.} Two outcome transformations are possible, the first represents a discrete survival function and the second represents a discrete hazard function.\footnote{This is the final key divergence from other discrete-time classification strategies, which enforce the discrete hazard representation.}</span>
<span id="cb1-490"><a href="#cb1-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-491"><a href="#cb1-491" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Discrete Survival Function Composition {.unnumbered .unlisted}</span></span>
<span id="cb1-492"><a href="#cb1-492" aria-hidden="true" tabindex="-1"></a>In this composition, the data in the transformed dataset represents the discrete survival function. The new indicator is defined as follows,</span>
<span id="cb1-493"><a href="#cb1-493" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-494"><a href="#cb1-494" aria-hidden="true" tabindex="-1"></a>Y_{i;\tau} :=</span>
<span id="cb1-495"><a href="#cb1-495" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb1-496"><a href="#cb1-496" aria-hidden="true" tabindex="-1"></a>1, &amp; T_i &gt; \tau <span class="sc">\\</span></span>
<span id="cb1-497"><a href="#cb1-497" aria-hidden="true" tabindex="-1"></a>0, &amp; T_i \leq \tau \cap \Delta_i = 1 <span class="sc">\\</span></span>
<span id="cb1-498"><a href="#cb1-498" aria-hidden="true" tabindex="-1"></a>-1, &amp; T_i \leq \tau \cap \Delta_i = 0</span>
<span id="cb1-499"><a href="#cb1-499" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-500"><a href="#cb1-500" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-501"><a href="#cb1-501" aria-hidden="true" tabindex="-1"></a>At a given discrete time $\tau$, an observation, $i$, is either alive ($Y_{i;\tau} = 1$), dead ($Y_{i;\tau} = 0$), or censored ($Y_{i;\tau} = -1$). Therefore $\hat{P}(Y_{i;\tau} = 1) = \hatS_i(\tau)$, motivating this particular choice of representation.</span>
<span id="cb1-502"><a href="#cb1-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-503"><a href="#cb1-503" aria-hidden="true" tabindex="-1"></a>This composition is demonstrated below with the binned data (left) and the composed classification data (right).</span>
<span id="cb1-504"><a href="#cb1-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-505"><a href="#cb1-505" aria-hidden="true" tabindex="-1"></a>| X | Time (Disc.) | Died |</span>
<span id="cb1-506"><a href="#cb1-506" aria-hidden="true" tabindex="-1"></a>| --- | --- | --- |</span>
<span id="cb1-507"><a href="#cb1-507" aria-hidden="true" tabindex="-1"></a>| 1 | [1, 2) | 0|</span>
<span id="cb1-508"><a href="#cb1-508" aria-hidden="true" tabindex="-1"></a>| 2 | [2, 3) | 1|</span>
<span id="cb1-509"><a href="#cb1-509" aria-hidden="true" tabindex="-1"></a>| 3 | [3, 4) | 1 |</span>
<span id="cb1-510"><a href="#cb1-510" aria-hidden="true" tabindex="-1"></a>| 4 | [3, 4) | 0|</span>
<span id="cb1-511"><a href="#cb1-511" aria-hidden="true" tabindex="-1"></a>| 5 | [4, 5) | 0 |</span>
<span id="cb1-512"><a href="#cb1-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-513"><a href="#cb1-513" aria-hidden="true" tabindex="-1"></a>| X | [1,2) | [2,3) | [3,4) | [4,5) |</span>
<span id="cb1-514"><a href="#cb1-514" aria-hidden="true" tabindex="-1"></a>| --- | --- | --- | --- | --- |</span>
<span id="cb1-515"><a href="#cb1-515" aria-hidden="true" tabindex="-1"></a>| 1 | -1 | -1 | -1 | -1 |</span>
<span id="cb1-516"><a href="#cb1-516" aria-hidden="true" tabindex="-1"></a>| 2 | 1 | 0 | 0 | 0 |</span>
<span id="cb1-517"><a href="#cb1-517" aria-hidden="true" tabindex="-1"></a>| 3 | 1 | 1 | 0 | 0 |</span>
<span id="cb1-518"><a href="#cb1-518" aria-hidden="true" tabindex="-1"></a>| 4 | 1 | 1 | -1 | -1 |</span>
<span id="cb1-519"><a href="#cb1-519" aria-hidden="true" tabindex="-1"></a>| 5 | 1 | 1 | -1 | -1 |</span>
<span id="cb1-520"><a href="#cb1-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-521"><a href="#cb1-521" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Discrete Hazard Function Composition {.unnumbered .unlisted}</span></span>
<span id="cb1-522"><a href="#cb1-522" aria-hidden="true" tabindex="-1"></a>In this composition, the data in the transformed dataset represents the discrete hazard function. The new indicator is defined as follows,</span>
<span id="cb1-523"><a href="#cb1-523" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-524"><a href="#cb1-524" aria-hidden="true" tabindex="-1"></a>Y^*_{i;\tau} :=</span>
<span id="cb1-525"><a href="#cb1-525" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb1-526"><a href="#cb1-526" aria-hidden="true" tabindex="-1"></a>1, &amp; T_i = \tau \cap \Delta_i = 1 <span class="sc">\\</span></span>
<span id="cb1-527"><a href="#cb1-527" aria-hidden="true" tabindex="-1"></a>-1, &amp; T_i = \tau \cap \Delta_i = 0 <span class="sc">\\</span></span>
<span id="cb1-528"><a href="#cb1-528" aria-hidden="true" tabindex="-1"></a>0, &amp; \otherw</span>
<span id="cb1-529"><a href="#cb1-529" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-530"><a href="#cb1-530" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-531"><a href="#cb1-531" aria-hidden="true" tabindex="-1"></a>At a given discrete time $\tau$, an observation, $i$, either experiences the event ($Y^*_{i;\tau} = 1$), experiences censoring ($Y_{i;\tau} = -1$), or neither ($Y_{i;\tau} = 0$). Utilising sequential multi-label classification problem transformation methods (@sec-car-reduxes-r7-mlc) results in $\hat{P}(Y^*_{i;\tau} = 1) = \hat{h}_i(\tau)$. If methods are utilised that do not 'look back' at predictions then $\hat{P}(Y^*_{i;\tau} = 1) = \hat{p}_i(\tau)$ (@sec-car-reduxes-r7-mlc).\footnote{This important distinction is not required in other discrete-time reduction strategies that automatically condition the prediction by including time as a feature.}</span>
<span id="cb1-532"><a href="#cb1-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-533"><a href="#cb1-533" aria-hidden="true" tabindex="-1"></a>This composition is demonstrated below with the binned data (left) and the composed classification data (right).</span>
<span id="cb1-534"><a href="#cb1-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-535"><a href="#cb1-535" aria-hidden="true" tabindex="-1"></a>| X | Time (Disc.) | Died |</span>
<span id="cb1-536"><a href="#cb1-536" aria-hidden="true" tabindex="-1"></a>| --- | --- | --- |</span>
<span id="cb1-537"><a href="#cb1-537" aria-hidden="true" tabindex="-1"></a>| 1 | [1, 2) | 0|</span>
<span id="cb1-538"><a href="#cb1-538" aria-hidden="true" tabindex="-1"></a>| 2 | [2, 3) | 1|</span>
<span id="cb1-539"><a href="#cb1-539" aria-hidden="true" tabindex="-1"></a>| 3 | [3, 4) | 1 |</span>
<span id="cb1-540"><a href="#cb1-540" aria-hidden="true" tabindex="-1"></a>| 4 | [3, 4) | 0|</span>
<span id="cb1-541"><a href="#cb1-541" aria-hidden="true" tabindex="-1"></a>| 5 | [4, 5) | 0 |</span>
<span id="cb1-542"><a href="#cb1-542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-543"><a href="#cb1-543" aria-hidden="true" tabindex="-1"></a>| X | [1,2) | [2,3) | [3,4) | [4,5) |</span>
<span id="cb1-544"><a href="#cb1-544" aria-hidden="true" tabindex="-1"></a>| --- | --- | --- | --- | --- |</span>
<span id="cb1-545"><a href="#cb1-545" aria-hidden="true" tabindex="-1"></a>| 1 | -1 | 0 | 0 | 0 |</span>
<span id="cb1-546"><a href="#cb1-546" aria-hidden="true" tabindex="-1"></a>| 2 | 0 | 1 | 0 | 0 |</span>
<span id="cb1-547"><a href="#cb1-547" aria-hidden="true" tabindex="-1"></a>| 3 | 0 | 0 | 1 | 0 |</span>
<span id="cb1-548"><a href="#cb1-548" aria-hidden="true" tabindex="-1"></a>| 4 | 0 | 0 | -1 | 0 |</span>
<span id="cb1-549"><a href="#cb1-549" aria-hidden="true" tabindex="-1"></a>| 5 | 0 | 0 | 0 | -1 |</span>
<span id="cb1-550"><a href="#cb1-550" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-551"><a href="#cb1-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-552"><a href="#cb1-552" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Multi-Label Classification Data {.unnumbered .unlisted}</span></span>
<span id="cb1-553"><a href="#cb1-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-554"><a href="#cb1-554" aria-hidden="true" tabindex="-1"></a>In both compositions, survival data t.v.i. $\Reals^p \times \NNReals \times \bset$ is transformed to multi-label classification data t.v.i. $\Reals^p \times <span class="sc">\{</span>-1,0,1<span class="sc">\}</span>^K$ for $K$ binned time-intervals. The multi-label classification task is defined in @sec-car-reduxes-r7-mlc with possible algorithms.</span>
<span id="cb1-555"><a href="#cb1-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-556"><a href="#cb1-556" aria-hidden="true" tabindex="-1"></a>The discrete survival representation has a slightly more natural interpretation and is 'easier' for classifiers to use for training as there are more positive events (i.e. more observations alive) to train on, whereas the discrete hazard representation will have relatively few events in each time-point. However the hazard representation leads to more natural predictions (@sec-car-reduxes-r7).</span>
<span id="cb1-557"><a href="#cb1-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-558"><a href="#cb1-558" aria-hidden="true" tabindex="-1"></a>A particular bias that may easily result from the composition of survival to classification data is now discussed.</span>
<span id="cb1-559"><a href="#cb1-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-560"><a href="#cb1-560" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Reduction to Classification Bias</span></span>
<span id="cb1-561"><a href="#cb1-561" aria-hidden="true" tabindex="-1"></a>The reduction to classification bias is commonly known  <span class="co">[</span><span class="ot">@Zhou2005</span><span class="co">]</span> but is reiterated briefly here as it must be accounted for in any automated reduction to classification workflow. This bias occurs when making classification predictions about survival at a given time and incorrectly censoring patients who have not been observed long enough, instead of removing them.</span>
<span id="cb1-562"><a href="#cb1-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-563"><a href="#cb1-563" aria-hidden="true" tabindex="-1"></a>By example, say the prediction of interest is five-year survival probabilities after a particular diagnosis, clearly a patient who has only been diagnosed for three years cannot inform this prediction. The bias is introduced if this patient is censored at five-years instead of being removed from the dataset. The result of this bias is to artificially inflate the probability of survival at each time-point as an unknown outcome is treated as censored and therefore alive.</span>
<span id="cb1-564"><a href="#cb1-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-565"><a href="#cb1-565" aria-hidden="true" tabindex="-1"></a>This bias is simply dealt with by removing patients who have not been alive 'long enough'.\footnote{Accounting for this bias is only possible if the study start and end dates are known, as well as the date the patient entered the study.} Paradoxically, even if a patient is observed to die before the time-point of interest, they should still be removed if they have not been in the dataset 'long enough' as failing to do so will result in a bias in the opposite direction, thus over-inflating the proportion of dead observations.</span>
<span id="cb1-566"><a href="#cb1-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-567"><a href="#cb1-567" aria-hidden="true" tabindex="-1"></a>Accounting for this bias is particularly important in the multi-label reduction as the number of observable patients will decrease over time due to censoring.</span>
<span id="cb1-568"><a href="#cb1-568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-569"><a href="#cb1-569" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Multi-Label Classification Algorithms {#sec-car-reduxes-r7-mlc}</span></span>
<span id="cb1-570"><a href="#cb1-570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-571"><a href="#cb1-571" aria-hidden="true" tabindex="-1"></a>As the work in this section is completely out of the book scope, the full text is in appendix @app-mlc. The most important contributions from this section are:</span>
<span id="cb1-572"><a href="#cb1-572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-573"><a href="#cb1-573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-574"><a href="#cb1-574" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Reviewing problem transformation methods  <span class="co">[</span><span class="ot">@Tsoumakas2007</span><span class="co">]</span> for multi-label classification;</span>
<span id="cb1-575"><a href="#cb1-575" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Identifying that only binary relevance, nested stacking, and classifier chains are appropriate in this reduction; and</span>
<span id="cb1-576"><a href="#cb1-576" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Generalising these methods into a single wrapper for any binary classifier, the 'LWrapper'.</span>
<span id="cb1-577"><a href="#cb1-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-578"><a href="#cb1-578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-579"><a href="#cb1-579" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Censoring in Classification</span></span>
<span id="cb1-580"><a href="#cb1-580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-581"><a href="#cb1-581" aria-hidden="true" tabindex="-1"></a>Classification algorithms cannot natively handle the censoring that is included in the survival reduction, but this can be incorporated using one of two approaches.</span>
<span id="cb1-582"><a href="#cb1-582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-583"><a href="#cb1-583" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Multi-Class Classification {.unnumbered .unlisted}</span></span>
<span id="cb1-584"><a href="#cb1-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-585"><a href="#cb1-585" aria-hidden="true" tabindex="-1"></a>All multi-label datasets can also handle multi-class data, hence the simplest way in which to handle censoring is to make multi-class predictions in each label for the outcome $Y_\tau \ t.v.i. <span class="sc">\{</span>-1, 0, 1<span class="sc">\}</span>$. Many off-shelf classification learners can make multi-class predictions natively and simple reductions exist for those that cannot. As a disadvantage to this method, classifiers would then predict if an individual is dead or alive or censored (each mutually exclusive), and not simply alive or dead. Though this could be perceived as an advantage when censoring is informative as this will accurately reflect a real-world competing-risks set-up.</span>
<span id="cb1-586"><a href="#cb1-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-587"><a href="#cb1-587" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Subsetting/Hurdle Models {.unnumbered .unlisted}</span></span>
<span id="cb1-588"><a href="#cb1-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-589"><a href="#cb1-589" aria-hidden="true" tabindex="-1"></a>For this approach, the multi-class task is reduced to two binary class tasks: first predict if a subject is censored or not (dead or alive) and only if the prediction for censoring is below some threshold, $\alpha \in <span class="co">[</span><span class="ot">0, 1</span><span class="co">]</span>$, then predict if the subject is alive or not (dead or censored). If the probability of censoring is high in the first task then the probability of being alive is automatically set to zero in the final prediction, otherwise the prediction from the second task is used. Any classifier can utilise this approach and it has a meaningful interpretation, additionally $\alpha$ is a tunable hyper-parameter. The main disadvantage is increases to storage and run-time requirements as double the number of models may be fit.</span>
<span id="cb1-590"><a href="#cb1-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-591"><a href="#cb1-591" aria-hidden="true" tabindex="-1"></a>Once the datasets have been composed to classification datasets and censoring is suitably incorporated by either approach, then any probabilistic classification model can be fit on the data. Predictions from these models can either be composed to a distribution prediction (R7) or a survival time prediction (R8).</span>
<span id="cb1-592"><a href="#cb1-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-593"><a href="#cb1-593" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R7) Probabilistic Survival $\rightarrow$ Probabilistic Classification {#sec-car-reduxes-r7}</span></span>
<span id="cb1-594"><a href="#cb1-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-595"><a href="#cb1-595" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{figure}[H]</span></span>
<span id="cb1-596"><a href="#cb1-596" aria-hidden="true" tabindex="-1"></a><span class="co">\centering</span></span>
<span id="cb1-597"><a href="#cb1-597" aria-hidden="true" tabindex="-1"></a><span class="co">\begin{tikzpicture}[framed]</span></span>
<span id="cb1-598"><a href="#cb1-598" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t0) [objnode]  {$\dtrain$};</span></span>
<span id="cb1-599"><a href="#cb1-599" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t1) [funnode,right=of t0] {$B(\dtrain|w)$};</span></span>
<span id="cb1-600"><a href="#cb1-600" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t2) [objnode,right=of t1] {$D_B$};</span></span>
<span id="cb1-601"><a href="#cb1-601" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t3) [funnode, below=of t2] {$C_C$};</span></span>
<span id="cb1-602"><a href="#cb1-602" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t4) [funnode, right=of t3] {$g_C(D_B|\phi)$};</span></span>
<span id="cb1-603"><a href="#cb1-603" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t5) [funnode, above=of t2] {$C_B$};</span></span>
<span id="cb1-604"><a href="#cb1-604" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t6) [funnode, right=of t5] {$g_B(D_B|\varphi)$};</span></span>
<span id="cb1-605"><a href="#cb1-605" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t7) [funnode,right=of t2] {$g_L(D_B|\theta)$};</span></span>
<span id="cb1-606"><a href="#cb1-606" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t8) [objnode,right=of t7] {$\hatg$};</span></span>
<span id="cb1-607"><a href="#cb1-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-608"><a href="#cb1-608" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t9) [objnode, below=of t0, yshift = -15mm] {$\dtest$};</span></span>
<span id="cb1-609"><a href="#cb1-609" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t10) [funnode, right=of t9] {$\hat{g}(\dtest|\Theta)$};</span></span>
<span id="cb1-610"><a href="#cb1-610" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t11) [objnode, right=of t10] {$\tilde{S}$};</span></span>
<span id="cb1-611"><a href="#cb1-611" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t12) [funnode, right=of t11] {$T_1(\tilde{S})$};</span></span>
<span id="cb1-612"><a href="#cb1-612" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t14) [objnode, right=of t12] {$\zeta$};</span></span>
<span id="cb1-613"><a href="#cb1-613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-614"><a href="#cb1-614" aria-hidden="true" tabindex="-1"></a><span class="co">\path[-&gt;]</span></span>
<span id="cb1-615"><a href="#cb1-615" aria-hidden="true" tabindex="-1"></a><span class="co">   (t0)  edge (t1)</span></span>
<span id="cb1-616"><a href="#cb1-616" aria-hidden="true" tabindex="-1"></a><span class="co">   (t1)  edge (t2)</span></span>
<span id="cb1-617"><a href="#cb1-617" aria-hidden="true" tabindex="-1"></a><span class="co">   (t2)  edge[dashed] (t3)</span></span>
<span id="cb1-618"><a href="#cb1-618" aria-hidden="true" tabindex="-1"></a><span class="co">   (t2)  edge[dashed] (t5)</span></span>
<span id="cb1-619"><a href="#cb1-619" aria-hidden="true" tabindex="-1"></a><span class="co">   (t2)  edge[dashed] (t7)</span></span>
<span id="cb1-620"><a href="#cb1-620" aria-hidden="true" tabindex="-1"></a><span class="co">   (t3)  edge (t4)</span></span>
<span id="cb1-621"><a href="#cb1-621" aria-hidden="true" tabindex="-1"></a><span class="co">   (t4)  edge (t8)</span></span>
<span id="cb1-622"><a href="#cb1-622" aria-hidden="true" tabindex="-1"></a><span class="co">   (t6)  edge (t8)</span></span>
<span id="cb1-623"><a href="#cb1-623" aria-hidden="true" tabindex="-1"></a><span class="co">   (t7)  edge (t8)</span></span>
<span id="cb1-624"><a href="#cb1-624" aria-hidden="true" tabindex="-1"></a><span class="co">   (t5)  edge (t6)</span></span>
<span id="cb1-625"><a href="#cb1-625" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-626"><a href="#cb1-626" aria-hidden="true" tabindex="-1"></a><span class="co">   (t9) edge (t10)</span></span>
<span id="cb1-627"><a href="#cb1-627" aria-hidden="true" tabindex="-1"></a><span class="co">   (t10) edge (t11)</span></span>
<span id="cb1-628"><a href="#cb1-628" aria-hidden="true" tabindex="-1"></a><span class="co">   (t11) edge (t12)</span></span>
<span id="cb1-629"><a href="#cb1-629" aria-hidden="true" tabindex="-1"></a><span class="co">   (t12) edge (t14);</span></span>
<span id="cb1-630"><a href="#cb1-630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-631"><a href="#cb1-631" aria-hidden="true" tabindex="-1"></a><span class="co">\draw[dashed, line width=0.1mm] (-1,-2.5) -- (11,-2.5);</span></span>
<span id="cb1-632"><a href="#cb1-632" aria-hidden="true" tabindex="-1"></a><span class="co">\end{tikzpicture}</span></span>
<span id="cb1-633"><a href="#cb1-633" aria-hidden="true" tabindex="-1"></a><span class="co">\caption[Probabilistic survival to probabilistic classification reduction]{Probabilistic survival to probabilistic reduction. See @fig-car-R7R8 for key.}</span></span>
<span id="cb1-634"><a href="#cb1-634" aria-hidden="true" tabindex="-1"></a><span class="co">\label{fig:car_R7}</span></span>
<span id="cb1-635"><a href="#cb1-635" aria-hidden="true" tabindex="-1"></a><span class="co">\end{figure} --&gt;</span></span>
<span id="cb1-636"><a href="#cb1-636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-637"><a href="#cb1-637" aria-hidden="true" tabindex="-1"></a>This final part of the (R7) reduction is described separately for discrete hazard and survival representations of the data (@sec-car-reduxes-r7-out).</span>
<span id="cb1-638"><a href="#cb1-638" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-639"><a href="#cb1-639" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Discrete Hazard Representation {.unnumbered .unlisted}</span></span>
<span id="cb1-640"><a href="#cb1-640" aria-hidden="true" tabindex="-1"></a>In this representation recall that predictions of the positive class, $P(Y_\tau = 1)$, are estimating the quantity $h(\tau)$. These predictions provide a natural and efficient transformation from predicted hazards to survival probabilities. Let $\hat{h}_i$ be a predicted hazard function for some observation $i$, then the survival function for that observation can be found with a Kaplan-Meier type estimator,</span>
<span id="cb1-641"><a href="#cb1-641" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-642"><a href="#cb1-642" aria-hidden="true" tabindex="-1"></a>\tilde{S}_i(\tau^*) = \prod_\tau 1 - \hat{h}_i(\tau)</span>
<span id="cb1-643"><a href="#cb1-643" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-644"><a href="#cb1-644" aria-hidden="true" tabindex="-1"></a>Now predictions are for a pseudo-survival function, which is 'pseudo' as it is not right-continuous. Resolving this is discussed below.</span>
<span id="cb1-645"><a href="#cb1-645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-646"><a href="#cb1-646" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Discrete Survival Representation {.unnumbered .unlisted}</span></span>
<span id="cb1-647"><a href="#cb1-647" aria-hidden="true" tabindex="-1"></a>In this representation, $P(Y_\tau = 1)$ is estimating $S(\tau)$, which means that predictions from a classification model result in discrete point predictions and not a right-continuous function. More importantly, there is no guarantee that a non-increasing function will be predicted, i.e. there is no guarantee that $P(Y_j = 1) &lt; P(Y_i = 1)$, for time-points $j &gt; i$.</span>
<span id="cb1-648"><a href="#cb1-648" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-649"><a href="#cb1-649" aria-hidden="true" tabindex="-1"></a>Unfortunately there is no optimal way of dealing with predictions of this sort and 'mistakes' of this kind have been observed in some software implementation. One point to note is that in practice these are quite rare as the probability of survival will always decrease over time. Therefore the 'usual' approach is quite 'hacky' and involves imputing increasing predictions with the previous prediction, formally,</span>
<span id="cb1-650"><a href="#cb1-650" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-651"><a href="#cb1-651" aria-hidden="true" tabindex="-1"></a>\tilde{S}({i+1}) := \min<span class="sc">\{</span>P(Y_{i+1} = 1), P(Y_i = 1)<span class="sc">\}</span>, \forall i = \NNReals</span>
<span id="cb1-652"><a href="#cb1-652" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-653"><a href="#cb1-653" aria-hidden="true" tabindex="-1"></a>assuming $\tilde{S}(0) = 1$.</span>
<span id="cb1-654"><a href="#cb1-654" aria-hidden="true" tabindex="-1"></a>Future research should seek more robust alternatives.</span>
<span id="cb1-655"><a href="#cb1-655" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-656"><a href="#cb1-656" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Right-Continuous Survival Function {.unnumbered .unlisted}</span></span>
<span id="cb1-657"><a href="#cb1-657" aria-hidden="true" tabindex="-1"></a>From either representation, a <span class="sc">\\</span> non-increasing but non-continuous pseudo-survival function, $\tilde{S}$, is now predicted. Creating a right-continuous function ('$T_1(\tilde{S})$' in @fig-car-R7) from these point predictions  (@fig-car-survclass (a)) is relatively simple and well-known with accessible off-shelf software. At the very least, one can assume a constant hazard rate between predictions and cast them into a step function (@fig-car-survclass (b)). This is a fairly common assumption and is usually valid as bin-width decreases. Alternatively, the point predictions can be smoothed into a continuous function with off-shelf software, for example with polynomial local regression smoothing (@fig-car-survclass (c)) or generalised linear smoothing (@fig-car-survclass (d)). Whichever method is chosen, the survival function is now non-increasing right-continuous and the (R7) reduction is complete.</span>
<span id="cb1-658"><a href="#cb1-658" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-659"><a href="#cb1-659" aria-hidden="true" tabindex="-1"></a>::: {#fig-car-survclass layout-ncol=2}</span>
<span id="cb1-660"><a href="#cb1-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-661"><a href="#cb1-661" aria-hidden="true" tabindex="-1"></a><span class="al">![Point Predictions](Figures/car/surv_points.png)</span>{#fig-car-survclass-a}</span>
<span id="cb1-662"><a href="#cb1-662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-663"><a href="#cb1-663" aria-hidden="true" tabindex="-1"></a><span class="al">![Survival Step Function](Figures/car/surv_step.png)</span>{#fig-car-survclass-b}</span>
<span id="cb1-664"><a href="#cb1-664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-665"><a href="#cb1-665" aria-hidden="true" tabindex="-1"></a><span class="al">![Local polynomial regression smoothing](Figures/car/surv_loess.png)</span>{#fig-car-survclass-c}</span>
<span id="cb1-666"><a href="#cb1-666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-667"><a href="#cb1-667" aria-hidden="true" tabindex="-1"></a><span class="al">![Generalised linear smoothing](Figures/car/surv_glm.png)</span>{#fig-car-survclass-d}</span>
<span id="cb1-668"><a href="#cb1-668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-669"><a href="#cb1-669" aria-hidden="true" tabindex="-1"></a>Survival function as a: point prediction (a), step function assuming constant risk (b), local polynomial regression smoothing (c), and generalised linear smoothing (d). (c) and (d) computed with <span class="in">`r pkg("ggplot2")`</span>  <span class="co">[</span><span class="ot">@pkgggplot2</span><span class="co">]</span>.</span>
<span id="cb1-670"><a href="#cb1-670" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-671"><a href="#cb1-671" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-672"><a href="#cb1-672" aria-hidden="true" tabindex="-1"></a><span class="fu">#### R8) Deterministic Survival $\rightarrow$ Probabilistic Classification {#sec-car-reduxes-r8}</span></span>
<span id="cb1-673"><a href="#cb1-673" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-674"><a href="#cb1-674" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{figure}[H]</span></span>
<span id="cb1-675"><a href="#cb1-675" aria-hidden="true" tabindex="-1"></a><span class="co">\centering</span></span>
<span id="cb1-676"><a href="#cb1-676" aria-hidden="true" tabindex="-1"></a><span class="co">\begin{tikzpicture}[framed]</span></span>
<span id="cb1-677"><a href="#cb1-677" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t0) [objnode]  {$\dtrain$};</span></span>
<span id="cb1-678"><a href="#cb1-678" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t1) [funnode,right=of t0] {$B(\dtrain|w)$};</span></span>
<span id="cb1-679"><a href="#cb1-679" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t2) [objnode,right=of t1] {$D_B$};</span></span>
<span id="cb1-680"><a href="#cb1-680" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t3) [funnode, below=of t2] {$C_C$};</span></span>
<span id="cb1-681"><a href="#cb1-681" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t4) [funnode, right=of t3] {$g_C(D_B|\phi)$};</span></span>
<span id="cb1-682"><a href="#cb1-682" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t5) [funnode, above=of t2] {$C_B$};</span></span>
<span id="cb1-683"><a href="#cb1-683" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t6) [funnode, right=of t5] {$g_B(D_B|\varphi)$};</span></span>
<span id="cb1-684"><a href="#cb1-684" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t7) [funnode,right=of t2] {$g_L(D_B|\theta)$};</span></span>
<span id="cb1-685"><a href="#cb1-685" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t8) [objnode,right=of t7] {$\hatg$};</span></span>
<span id="cb1-686"><a href="#cb1-686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-687"><a href="#cb1-687" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t9) [objnode, below=of t0, yshift = -15mm] {$\dtest$};</span></span>
<span id="cb1-688"><a href="#cb1-688" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t10) [funnode, right=of t9] {$\hat{g}(\dtest|\Theta)$};</span></span>
<span id="cb1-689"><a href="#cb1-689" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t11) [objnode, right=of t10] {$\tilde{S}$};</span></span>
<span id="cb1-690"><a href="#cb1-690" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t13) [funnode, right=of t11] {$T_2(\tilde{S})$};</span></span>
<span id="cb1-691"><a href="#cb1-691" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t15) [objnode, right=of t13] {$\hatT$};</span></span>
<span id="cb1-692"><a href="#cb1-692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-693"><a href="#cb1-693" aria-hidden="true" tabindex="-1"></a><span class="co">\path[-&gt;]</span></span>
<span id="cb1-694"><a href="#cb1-694" aria-hidden="true" tabindex="-1"></a><span class="co">   (t0)  edge (t1)</span></span>
<span id="cb1-695"><a href="#cb1-695" aria-hidden="true" tabindex="-1"></a><span class="co">   (t1)  edge (t2)</span></span>
<span id="cb1-696"><a href="#cb1-696" aria-hidden="true" tabindex="-1"></a><span class="co">   (t2)  edge[dashed] (t3)</span></span>
<span id="cb1-697"><a href="#cb1-697" aria-hidden="true" tabindex="-1"></a><span class="co">   (t2)  edge[dashed] (t5)</span></span>
<span id="cb1-698"><a href="#cb1-698" aria-hidden="true" tabindex="-1"></a><span class="co">   (t2)  edge[dashed] (t7)</span></span>
<span id="cb1-699"><a href="#cb1-699" aria-hidden="true" tabindex="-1"></a><span class="co">   (t3)  edge (t4)</span></span>
<span id="cb1-700"><a href="#cb1-700" aria-hidden="true" tabindex="-1"></a><span class="co">   (t4)  edge (t8)</span></span>
<span id="cb1-701"><a href="#cb1-701" aria-hidden="true" tabindex="-1"></a><span class="co">   (t6)  edge (t8)</span></span>
<span id="cb1-702"><a href="#cb1-702" aria-hidden="true" tabindex="-1"></a><span class="co">   (t7)  edge (t8)</span></span>
<span id="cb1-703"><a href="#cb1-703" aria-hidden="true" tabindex="-1"></a><span class="co">   (t5)  edge (t6)</span></span>
<span id="cb1-704"><a href="#cb1-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-705"><a href="#cb1-705" aria-hidden="true" tabindex="-1"></a><span class="co">   (t9) edge (t10)</span></span>
<span id="cb1-706"><a href="#cb1-706" aria-hidden="true" tabindex="-1"></a><span class="co">   (t10) edge (t11)</span></span>
<span id="cb1-707"><a href="#cb1-707" aria-hidden="true" tabindex="-1"></a><span class="co">   (t11) edge (t13)</span></span>
<span id="cb1-708"><a href="#cb1-708" aria-hidden="true" tabindex="-1"></a><span class="co">   (t13) edge (t15);</span></span>
<span id="cb1-709"><a href="#cb1-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-710"><a href="#cb1-710" aria-hidden="true" tabindex="-1"></a><span class="co">\draw[dashed, line width=0.1mm] (-1,-2.5) -- (11,-2.5);</span></span>
<span id="cb1-711"><a href="#cb1-711" aria-hidden="true" tabindex="-1"></a><span class="co">\end{tikzpicture}</span></span>
<span id="cb1-712"><a href="#cb1-712" aria-hidden="true" tabindex="-1"></a><span class="co">\caption[Deterministic survival to probabilistic classification reduction]{Deterministic survival to probabilistic reduction. See @fig-car-R7R8 for key.}</span></span>
<span id="cb1-713"><a href="#cb1-713" aria-hidden="true" tabindex="-1"></a><span class="co">\label{fig:car_R8}</span></span>
<span id="cb1-714"><a href="#cb1-714" aria-hidden="true" tabindex="-1"></a><span class="co">\end{figure} --&gt;</span></span>
<span id="cb1-715"><a href="#cb1-715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-716"><a href="#cb1-716" aria-hidden="true" tabindex="-1"></a>Predicting a deterministic survival time from the multi-label classification predictions is relatively straightforward and can be viewed as a discrete analogue to (C3) (@sec-car-pipelines-crank). For the discrete hazard representation, one can simply take the predicted time-point for an individual to be time at which the predicted hazard probability is highest however this could easily be problematic as there may be multiple time-points at which the predicted hazard equals $1$. Instead it is cleaner to first cast the hazard to a pseudo-survival probability (@sec-car-reduxes-r7) and then treat both representations the same.</span>
<span id="cb1-717"><a href="#cb1-717" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-718"><a href="#cb1-718" aria-hidden="true" tabindex="-1"></a>Let $\tilde{S}_i$ be the predicted multi-label survival probabilities for an observation $i$ such that $\tilde{S}_i(\tau)$ corresponds with $\hat{P}(Y_{i;\tau} = 1)$ for label $\tau \in \mathcal{K}$ where $Y_{i;\tau}$ is defined in @sec-car-reduxes-r7-out and $\mathcal{K} = <span class="sc">\{</span>1,...,K<span class="sc">\}</span>$ is the set of labels for which to make predictions. Then the survival time transformation is defined by</span>
<span id="cb1-719"><a href="#cb1-719" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-720"><a href="#cb1-720" aria-hidden="true" tabindex="-1"></a>T_2(\tilde{S}_i) = \inf <span class="sc">\{</span>\tau \in \mathcal{K} : \tilde{S}_i(\tau) \leq \beta<span class="sc">\}</span></span>
<span id="cb1-721"><a href="#cb1-721" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-722"><a href="#cb1-722" aria-hidden="true" tabindex="-1"></a>for some $\beta \in <span class="co">[</span><span class="ot">0, 1</span><span class="co">]</span>$.</span>
<span id="cb1-723"><a href="#cb1-723" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-724"><a href="#cb1-724" aria-hidden="true" tabindex="-1"></a>This is interpreted as defining the predicted survival time as the first time-point in which the predicted probability of being alive drops below a certain threshold $\beta$. Usually $\beta = 0.5$, though this can be treated as a hyper-parameter for tuning. This composition can be utilised even if predictions are not non-increasing, as only the first time the predicted survival probability drops below the threshold is considered. With this composition the (R8) reduction is now complete.</span>
<span id="cb1-725"><a href="#cb1-725" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-726"><a href="#cb1-726" aria-hidden="true" tabindex="-1"></a><span class="fu">## Conclusions {#sec-car-conc}</span></span>
<span id="cb1-727"><a href="#cb1-727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-728"><a href="#cb1-728" aria-hidden="true" tabindex="-1"></a>This chapter introduced composition and reduction to survival analysis and formalised specific strategies. Formalising these concepts allows for better quality of research and most importantly improved transparency. Clear interface points for hyper-parameters and compositions allow for reproducibility that was previously obfuscated by unclear workflows and imprecise documentation for pipelines.</span>
<span id="cb1-729"><a href="#cb1-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-730"><a href="#cb1-730" aria-hidden="true" tabindex="-1"></a>Additionally, composition and reduction improves accessibility. Reduction workflows vastly increase the number of machine learning models that can be utilised in survival analysis, thus opening the field to those whose experience is limited to regression or classification. Formalisation of workflows allows for precise implementation of model-agnostic pipelines as computational objects, as opposed to functions that are built directly into an algorithm without external interface points.</span>
<span id="cb1-731"><a href="#cb1-731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-732"><a href="#cb1-732" aria-hidden="true" tabindex="-1"></a>Finally, predictive performance is also increased by these methods, which is most prominently the case for the survival model averaging compositor \CAvg (as demonstrated by RSFs).</span>
<span id="cb1-733"><a href="#cb1-733" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-734"><a href="#cb1-734" aria-hidden="true" tabindex="-1"></a>All compositions in this chapter, as well as (R1)-(R6), have been implemented in <span class="in">`r pkg("mlr3proba")`</span> with the <span class="in">`r pkg("mlr3pipelines")`</span>  <span class="co">[</span><span class="ot">@pkgmlr3pipelines</span><span class="co">]</span> interface. The reductions to classification will be implemented in a near-future update. Additionally the <span class="in">`r pkg("discSurv")`</span> package  <span class="co">[</span><span class="ot">@pkgdiscsurv</span><span class="co">]</span> will be interfaced as a <span class="in">`r pkg("mlr3proba")`</span> pipeline to incorporate further discrete-time strategies.</span>
<span id="cb1-735"><a href="#cb1-735" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-736"><a href="#cb1-736" aria-hidden="true" tabindex="-1"></a>The compositions \CDetI and \CProb are included in the benchmark experiment in @Sonabend2021b so that every tested model can make probabilistic survival distribution predictions as well as deterministic survival time predictions. Future research will benchmark all the pipelines in this chapter and will cover algorithm and model selection, tuning, and comparison of performance. Strategies from other papers will also be explored.</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p>All content licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> <br> © Raphael Sonabend, Andreas Bender.</p>
</div>   
    <div class="nav-footer-center">
<p><a href="https://www.mlsabook.com">Website</a> | <a href="https://github.com/mlsa-book/MLSA">GitHub</a></p>
<div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/mlsa-book/MLSA/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li><li><a href="https://github.com/mlsa-book/MLSA/edit/main/book/reductions.qmd" class="toc-action"><i class="bi empty"></i>Edit this page</a></li><li><a href="https://github.com/mlsa-book/MLSA/blob/main/book/reductions.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>


</body></html>