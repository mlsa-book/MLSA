<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.276">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="Raphael Sonabend and Andreas Bender">
<title>Machine Learning in Survival Analysis - 5&nbsp; What are Survival Measures?</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./meas_rank.html" rel="next">
<link href="./survival.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><link rel="stylesheet" href="styles.css">
</head>
<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./evaluation.html">Evaluation</a></li><li class="breadcrumb-item"><a href="./evaluation.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">What are Survival Measures?</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Machine Learning in Survival Analysis</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/RaphaelS1/MLSA/tree/main/book/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./Machine-Learning-in-Survival-Analysis.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./notation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Symbols and Notation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false">
 <span class="menu-text">Survival Analysis and Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">MLSA From Start to Finish</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./machinelearning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Statistical Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./survival.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Survival Analysis</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Evaluation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./evaluation.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">What are Survival Measures?</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./meas_rank.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Evaluating Continuous Rankings</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./meas_calib.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Evaluating Distributions by Calibration Measures</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./meas_rules.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Evaluating Distributions by Scoring Rules</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./meas_time.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Evaluating Survival Time</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eval_choosing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Choosing Measures</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false">
 <span class="menu-text">Models</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./classical.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Classical Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mlmodels.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Machine Learning Survival Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./forests.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Tree-Based Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./boosting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Boosting Methods</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false">
 <span class="menu-text">Reduction Techniques</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./reductions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Reductions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./competing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Competing Risks Pipelines</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li>
<a href="#sec-eval-why" id="toc-sec-eval-why" class="nav-link active" data-scroll-target="#sec-eval-why"><span class="header-section-number">5.1</span> Evaluation Overview</a>
  <ul class="collapse">
<li><a href="#sec-eval-why-what" id="toc-sec-eval-why-what" class="nav-link" data-scroll-target="#sec-eval-why-what"><span class="header-section-number">5.1.1</span> What is Evaluation?</a></li>
  </ul>
</li>
  <li>
<a href="#sec-eval-why-why" id="toc-sec-eval-why-why" class="nav-link" data-scroll-target="#sec-eval-why-why"><span class="header-section-number">5.2</span> Why are Models Evaluated?</a>
  <ul class="collapse">
<li><a href="#how-are-models-evaluated" id="toc-how-are-models-evaluated" class="nav-link" data-scroll-target="#how-are-models-evaluated"><span class="header-section-number">5.2.1</span> How are Models Evaluated?</a></li>
  </ul>
</li>
  <li><a href="#sec-eval-insample" id="toc-sec-eval-insample" class="nav-link" data-scroll-target="#sec-eval-insample"><span class="header-section-number">5.3</span> In-Sample Measures</a></li>
  </ul><div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/RaphaelS1/MLSA/issues/new" class="toc-action">Report an issue</a></p><p><a href="https://github.com/RaphaelS1/MLSA/edit/main/book/evaluation.qmd" class="toc-action">Edit this page</a></p><p><a href="https://github.com/RaphaelS1/MLSA/blob/main/book/evaluation.qmd" class="toc-action">View source</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-eval" class="quarto-section-identifier"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">What are Survival Measures?</span></span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="abstract-title">Abstract</div>
    TODO (150-200 WORDS)
  </div>
</div>

</header><div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Page in progress!
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>This page is a work in progress and will change significantly over time.</strong></p>
</div>
</div>
<p>This chapter studies how to evaluate the predictions arising from the surveyed models in the previous chapter. ‘Model evaluation’ is as vague a phrase as ‘human evaluation’. A human could be evaluated by a series of exams, physical or neurological tests, aesthetics, etc. Likewise a model could be evaluated according to how well it fits to training data, the quality of predictions on new data, the average prediction, and many more methods. This chapter aims to provide a nuanced approach to defining, understanding, and examining model evaluation. Evaluation is defined in further detail in <a href="#sec-eval-why"><span>Section&nbsp;5.1</span></a> and throughout this chapter the definition will continue to be refined and specialised to specific sub-types of evaluation, including discrimination (<a href="meas_rank.html"><span>Chapter&nbsp;6</span></a>), calibration (<a href="meas_calib.html"><span>Chapter&nbsp;7</span></a>), and overall predictive performance (<a href="meas_rules.html"><span>Chapter&nbsp;8</span></a>).</p>
<p>Evaluation is a surprising source of disagreement in the literature with some arguing that the process can often be ignored completely <span class="citation" data-cites="vanderLaan2007 Wolpert1992">(<a href="references.html#ref-vanderLaan2007" role="doc-biblioref">Laan, Polley, and Hubbard 2007</a>; <a href="references.html#ref-Wolpert1992" role="doc-biblioref">Wolpert 1992</a>)</span>. There is a larger divide in survival analysis as many believe that the primary (possibly only) goal is risk prediction <span class="citation" data-cites="Chen2012 Newson1983 Pencina2012">(<a href="references.html#ref-Chen2012" role="doc-biblioref">Chen et al. 2012</a>; <a href="references.html#ref-Newson1983" role="doc-biblioref">Newson 1983</a>; <a href="references.html#ref-Pencina2012" role="doc-biblioref">Pencina, D’Agostino, and Song 2012</a>)</span> and thus other forms of evaluation are not required. These strict views can undermine an integral part of the model building and deployment process, and create more division than necessary. This book advocates for strict implementation of model evaluation as a critical part of the model building process as well as in continuous monitoring of deployed models. Without rigorous evaluation, a model cannot be ‘trusted’ to perform well and could be as useless as making random guesses for all predictions. This is critical in survival analysis, which has important applications in healthcare and finance, in these sectors models that have not been evaluated are potentially dangerous.</p>
<p>An infamous example of evaluation going wrong is the Google Flu Trends (GFT) model, which claimed to accurately predict future flu trends but was in fact deemed by many a complete failure as it significantly overestimated all predictions, in some cases doubling the true figures <span class="citation" data-cites="Lazer2014">(<a href="references.html#ref-Lazer2014" role="doc-biblioref">Lazer et al. 2014</a>)</span>. The GFT model was never utilised (at least openly) in policy and as such no lasting harm was created. However it is not hard to imagine the problems that would be caused by such a model if it was utilised and trusted during the time of COVID-19. On a more individual level, as machine learning is increasingly deployed in public sectors, major decisions for patients could become increasingly automated (or at least machine-assisted). Patients should expect their models to be as trained and tested as their doctors.</p>
<p>This chapter attempts to highlight the purpose and need of evaluation in survival analysis by first giving a high-level overview to evaluation as a concept, then providing a brief review of commonly-used survival measures and finally extensive treatment to scoring rules for evaluation of probabilistic predictions, including novel definitions and proofs for properness of scoring rules. The term <em>measure</em> will be used throughout this chapter to refer to functions or ‘metrics’ that quantify some aspect of model evaluation, this should not be confused with a mathematical measure.</p>
<section id="notation-and-terminology" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="notation-and-terminology">Notation and Terminology</h4>
<p>The notation introduced in <a href="survival.html"><span>Chapter&nbsp;4</span></a> is recapped for use in this chapter. The generative template is given by <span class="math inline">\((X,T,\Delta,Y,C) \ t.v.i. \ \mathcal{X}\times \mathcal{T}\times \{0,1\}\times \mathcal{T}\times \mathcal{T}\)</span> where <span class="math inline">\(\mathcal{X}\subseteq \mathbb{R}^p\)</span> and <span class="math inline">\(\mathcal{T}\subseteq \mathbb{R}_{\geq 0}\)</span>, where <span class="math inline">\(C,Y\)</span> are unobservable, <span class="math inline">\(T := \min\{Y,C\}\)</span>, and <span class="math inline">\(\Delta = \mathbb{I}(Y = T)\)</span>. Specific survival data is given by training data, <span class="math inline">\(\mathcal{D}_{train}= \{(X_1,T_1,\Delta_1),...,(X_n,T_n,\Delta_n)\}\)</span> where <span class="math inline">\((X_i,T_i,\Delta_i) \stackrel{i.i.d.}\sim(X,T,\Delta)\)</span>, and test data, <span class="math inline">\(\mathcal{D}_{test}= \{(X^*_1,T^*_1,\Delta^*_1),...,(X^*_m,T^*_m,\Delta^*_m)\}\)</span> where <span class="math inline">\((X^*_i,T^*_i,\Delta^*_i) \stackrel{i.i.d.}\sim(X,T,\Delta)\)</span>.</p>
</section><section id="sec-eval-why" class="level2 page-columns page-full" data-number="5.1"><h2 data-number="5.1" class="anchored" data-anchor-id="sec-eval-why">
<span class="header-section-number">5.1</span> Evaluation Overview</h2>
<section id="sec-eval-why-what" class="level3 page-columns page-full" data-number="5.1.1"><h3 data-number="5.1.1" class="anchored" data-anchor-id="sec-eval-why-what">
<span class="header-section-number">5.1.1</span> What is Evaluation?</h3>
<p>Evaluation is the process of examining a model’s relationship to data, which may refer to the model’s relationship to training data, i.e.&nbsp;how well the model is ‘fit’ to this data, or the relationship to testing data, i.e.&nbsp;how ‘good’ are the predictions from the model. In this book, only three types of evaluation measure are considered and qualitative definitions of these are given here; more precise definitions appear later in the chapter.</p>
<ul>
<li>Discrimination – A model’s discriminatory power refers to how well it separates observations that are at a higher or lower risk of event. Therefore discrimination is also sometimes referred to as <em>separation</em>. For example, a model with good discrimination will predict that (at a given time) a dead patient has a higher probability of being dead than an alive patient. These measures are the most common in survival and assess relative risk or rank predictions.</li>
<li>Calibration – There is no single agreed upon definition of model calibration, with definitions varying from paper to paper <span class="citation" data-cites="Collins2014 Harrell1996 Rahman2017 VanHouwelingen2000">(<a href="references.html#ref-Collins2014" role="doc-biblioref">Collins et al. 2014</a>; <a href="references.html#ref-Harrell1996" role="doc-biblioref">Harrell, Lee, and Mark 1996</a>; <a href="references.html#ref-Rahman2017" role="doc-biblioref">Rahman et al. 2017</a>; <a href="references.html#ref-VanHouwelingen2000" role="doc-biblioref">Van Houwelingen 2000</a>)</span>. Generally, a model is said to be well-calibrated if the average predicted values from the model are in some ‘agreement’ (which is specified by the chosen measure) with the average true observed values.</li>
<li>Predictive Performance – A model is said to have good predictive performance (or sometimes ‘predictive accuracy’) if its predictions for new data are ‘close to’ the truth.</li>
</ul>
<div class="page-columns page-full"><p>These are referred to as measures of predictive ability as they draw conclusions about the ability of the model to make predictions.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;Measures of predictive ability measure a model’s <em>ability</em> to make any form of prediction. Measures of predictive performance measure the <em>performance</em> of the predictions. In this section a model’s predictive ability refers to all three of discrimination, calibration, and predictive performance.</p></li></div></div>
<p>Using these definitions as a primary taxonomy for survival measures is problematic as without clear definitions there can be significant overlap between model ‘classes’. Instead this book advocates for the same taxonomy as in the previous chapter and categorises measures by the return type that they evaluate: survival time, ranking, or survival distribution.</p>
<p>Goodness-of-fit measures are very briefly discussed in <a href="#sec-eval-insample"><span>Section&nbsp;5.3</span></a> for completeness, however these are generally out of scope in this book as the vast majority (if any) cannot evaluate machine learning models.</p>
</section></section><section id="sec-eval-why-why" class="level2 page-columns page-full" data-number="5.2"><h2 data-number="5.2" class="anchored" data-anchor-id="sec-eval-why-why">
<span class="header-section-number">5.2</span> Why are Models Evaluated?</h2>
<p>A key element of the scientific method is experiments and validation. In the usual workflow of the scientific method:</p>
<ul>
<li>a hypothesis is proposed;</li>
<li>predictions are made; and</li>
<li>experiments are performed to test the hypothesis based on these predictions.</li>
</ul>
<p>For statistical models the same principles are upheld:</p>
<ol type="i">
<li>a model is proposed (by manual or automated selection with possible tuning);</li>
<li>predictions are made either internally (cross-validation) or externally (held-out data); and</li>
<li>validation is performed on these predictions in order to infer something about the model’s performance.</li>
</ol>
<p>The model can then be considered ‘good’ or ‘bad’ and either deployed, adjusted, or discarded. As these are models that are run on a computer (as opposed to experiments in the real-world), the process from fitting to validating is relatively quick and as such multiple proposed models can be evaluated and compared at the same time. This provides two key use-cases for evaluation:</p>
<ol type="i">
<li>demonstrating model performance; and</li>
<li>model comparison/selection.</li>
</ol>
<p>Resistance to model evaluation can be found in the machine learning community. One such example are proponents of inhomogeneous ensemble methods, which combine predictions from multiple different models into a single prediction. The arguments for these models are that:</p>
<ol type="i">
<li>model evaluation can never be precise enough, or strong enough guarantees cannot be given <span class="citation" data-cites="Jiao2016">(<a href="references.html#ref-Jiao2016" role="doc-biblioref">Jiao and Du 2016</a>)</span>; and</li>
<li>ensemble methods can guarantee a better performance than the individual component models and therefore evaluation of the components is not required.</li>
</ol>
<div class="page-columns page-full"><p>For example, ‘super learners’ <span class="citation" data-cites="vanderLaan2007">(<a href="references.html#ref-vanderLaan2007" role="doc-biblioref">Laan, Polley, and Hubbard 2007</a>)</span> are a class of such model and claim<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> to guarantee that a super learner will always perform as well as, if not better, than its component models: ’’…the super learner framework allows a researcher to try many prediction algorithms…knowing that the final combined super learner fit will either be the best fit or near the best fit” <span class="citation" data-cites="Polley2010">(<a href="references.html#ref-Polley2010" role="doc-biblioref">Polley and Van Der Laan 2010</a>)</span>. This has three problems, it:</p><div class="no-row-height column-margin column-container"><li id="fn2"><p><sup>2</sup>&nbsp;Testing this claim is tangential so for now will be assumed true.</p></li></div></div>
<ol type="i">
<li>assumes that researchers will only fit sensible prediction algorithms;</li>
<li>advocates for complex ensemble models instead of transparent and parsimonious ones; and</li>
<li>assumes that a super learner is guaranteed to be the (near) ‘best fit’, which actively discourages simpler models being tested separately.</li>
</ol>
<p>Each of these problems can be resolved by researchers only fitting sensible models and opting for an Occam’s Razor approach where inhomogeneous ensemble methods are used only if they outperform simpler models, thus requiring validation to test this.</p>
<p>By the parsimony principle, if two models have the same predictive performance (within some degree of confidence), then the simpler and more transparent model is preferred. Even a very slight gain in predictive performance could be outweighed by a large increase to complexity. All models, whether simple or complex, should be critically compared to many alternatives. At the very least a model should be compared to a baseline (<a href="meas_rules.html#sec-eval-distr-score-base-base"><span>Section&nbsp;8.0.5.1</span></a>) as many performance measures are uninterpretable without a point of comparison <span class="citation" data-cites="Gressmann2018">(<a href="references.html#ref-Gressmann2018" role="doc-biblioref">Gressmann et al. 2018</a>)</span>.</p>
<section id="how-are-models-evaluated" class="level3" data-number="5.2.1"><h3 data-number="5.2.1" class="anchored" data-anchor-id="how-are-models-evaluated">
<span class="header-section-number">5.2.1</span> How are Models Evaluated?</h3>
<p>The process of evaluation in machine learning is briefly given as a key method in <a href="machinelearning.html#sec-surv-setml"><span>Section&nbsp;3.1</span></a> and relevant parts are repeated here. The evaluation process itself is a simple application of a suitable mathematical function to predictions and true data. Let <span class="math inline">\(L\)</span> be some evaluation measure and for now assume <span class="math inline">\(L\)</span> is a measure evaluating deterministic predictions (the following generalises to other types trivially). A model will either be evaluated on each prediction separately, in which case <span class="math inline">\(L: \mathbb{R}\times \mathbb{R}\rightarrow \bar{\mathbb{R}}\)</span> or the measure is calculated for all predictions simultaneously, in which case <span class="math inline">\(L: \mathbb{R}^m \times \mathbb{R}^m \rightarrow \bar{\mathbb{R}}\)</span>. Specifically the loss parameters are observed (true) outcomes, <span class="math inline">\(Y\)</span>, and predictions of this outcome, <span class="math inline">\(\hat{Y}\)</span>. <span class="math inline">\(L\)</span> is usually referred to as a <em>loss</em> when <span class="math inline">\(L\)</span> should be minimised for optimal prediction, whereas a <em>score</em> is the term given when <span class="math inline">\(L\)</span> should be maximised.</p>
<p>All evaluation measures discussed in this book are out-of-sample measures and therefore evaluation takes place after the model makes predictions on held-out test data.</p>
<p>Specific choices for <span class="math inline">\(L\)</span> are now reviewed.</p>
</section></section><section id="sec-eval-insample" class="level2" data-number="5.3"><h2 data-number="5.3" class="anchored" data-anchor-id="sec-eval-insample">
<span class="header-section-number">5.3</span> In-Sample Measures</h2>
<p>In-sample measures are not examined in this book as no in-sample measures could be found that are applicable to all machine learning methods and therefore are out of scope for this book. Instead, the interested reader is referred to the papers and references listed below:</p>
<section id="residuals" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="residuals">Residuals</h4>
<p>For discussion about model residuals, refer to texts on survival modelling fitting and goodness-of-fit such as:</p>
<ul>
<li><span class="citation" data-cites="Collett2014">Collett (<a href="references.html#ref-Collett2014" role="doc-biblioref">2014</a>)</span></li>
<li><span class="citation" data-cites="dataapplied">Hosmer Jr, Lemeshow, and May (<a href="references.html#ref-dataapplied" role="doc-biblioref">2011</a>)</span></li>
</ul>
<p>Both provide a comprehensive overview to model residuals for semi- and fully-parametric low-complexity survival models.</p>
</section><section id="r2-measures" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="r2-measures">
<span class="math inline">\(R^2\)</span> measures</h4>
<p><span class="math inline">\(R^2\)</span> type measures have been the focus of several reviews and surveys, in particular the following are recommended:</p>
<ul>
<li>
<span class="citation" data-cites="Choodari2012a">Choodari-Oskooei, Royston, and Parmar (<a href="references.html#ref-Choodari2012a" role="doc-biblioref">2012</a>)</span> — For a comprehensive review and simulation study of <span class="math inline">\(R^2\)</span> type measures</li>
<li>
<span class="citation" data-cites="Kent1988">Kent and O’Quigley (<a href="references.html#ref-Kent1988" role="doc-biblioref">1988</a>)</span> — Defines the commonly utilised Kent and O’Quigley <span class="math inline">\(R^2\)</span> measure</li>
<li>
<span class="citation" data-cites="Royston2004">Royston and Sauerbrei (<a href="references.html#ref-Royston2004" role="doc-biblioref">2004</a>)</span> — Defines the commonly utilised Royston and Sauerbrei <span class="math inline">\(R^2\)</span> measure</li>
</ul></section><section id="likelihood-and-information-criteria" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="likelihood-and-information-criteria">Likelihood and Information Criteria</h4>
<p>Measures of likelihood and information criteria (e.g.&nbsp;AIC, BIC) are commonly utilised in in-sample model comparison of low-complexity survival models though in general are harder (if not impossible) to compute on ML alternatives.</p>
<p>These criterion are originally defined in:</p>
<ul>
<li>
<span class="citation" data-cites="Akaike1974">Akaike (<a href="references.html#ref-Akaike1974" role="doc-biblioref">1974</a>)</span> — For the introduction of the AIC</li>
<li>
<span class="citation" data-cites="Schwarz1978">Schwarz (<a href="references.html#ref-Schwarz1978" role="doc-biblioref">1978</a>)</span> — For the introduction of the BIC</li>
</ul>
<p>These are discussed for survival analysis in:</p>
<ul>
<li>
<span class="citation" data-cites="VolinskyRaftery2000">Volinsky and Raftery (<a href="references.html#ref-VolinskyRaftery2000" role="doc-biblioref">2000</a>)</span> — For discussion on the BIC for survival models.</li>
<li>
<span class="citation" data-cites="HURVICH1989">HURVICH and TSAI (<a href="references.html#ref-HURVICH1989" role="doc-biblioref">1989</a>)</span> — Definition of corrected <span class="math inline">\(AIC\)</span> for survival models, <span class="math inline">\(AIC_C\)</span>
</li>
<li>
<span class="citation" data-cites="Liang2008">Liang and Zou (<a href="references.html#ref-Liang2008" role="doc-biblioref">2008</a>)</span> — ‘Improved’ AIC for survival models.</li>
</ul>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-Akaike1974" class="csl-entry" role="listitem">
Akaike, Hirotugu. 1974. <span>“<span class="nocase">A New Look at the Statistical Model Identification</span>.”</span> <em>IEEE Transactions on Automatic Control</em> 19 (6): 716–23. <a href="https://doi.org/10.1093/ietfec/e90-a.12.2762">https://doi.org/10.1093/ietfec/e90-a.12.2762</a>.
</div>
<div id="ref-Chen2012" class="csl-entry" role="listitem">
Chen, Hung Chia, Ralph L. Kodell, Kuang Fu Cheng, and James J. Chen. 2012. <span>“<span class="nocase">Assessment of performance of survival prediction models for cancer prognosis</span>.”</span> <em>BMC Medical Research Methodology</em> 12. <a href="https://doi.org/10.1186/1471-2288-12-102">https://doi.org/10.1186/1471-2288-12-102</a>.
</div>
<div id="ref-Choodari2012a" class="csl-entry" role="listitem">
Choodari-Oskooei, Babak, Patrick Royston, and Mahesh K. B. Parmar. 2012. <span>“<span class="nocase">A simulation study of predictive ability measures in a survival model I: Explained variation measures</span>.”</span> <em>Statistics in Medicine</em> 31 (23): 2627–43. <a href="https://doi.org/10.1002/sim.4242">https://doi.org/10.1002/sim.4242</a>.
</div>
<div id="ref-Collett2014" class="csl-entry" role="listitem">
Collett, David. 2014. <em><span class="nocase">Modelling Survival Data in Medical Research</span></em>. 3rd ed. CRC.
</div>
<div id="ref-Collins2014" class="csl-entry" role="listitem">
Collins, Gary S., Joris A. De Groot, Susan Dutton, Omar Omar, Milensu Shanyinde, Abdelouahid Tajar, Merryn Voysey, et al. 2014. <span>“<span class="nocase">External validation of multivariable prediction models: A systematic review of methodological conduct and reporting</span>.”</span> <em>BMC Medical Research Methodology</em> 14 (1): 1–11. <a href="https://doi.org/10.1186/1471-2288-14-40">https://doi.org/10.1186/1471-2288-14-40</a>.
</div>
<div id="ref-Gressmann2018" class="csl-entry" role="listitem">
Gressmann, Frithjof, Franz J. Király, Bilal Mateen, and Harald Oberhauser. 2018. <span>“<span class="nocase">Probabilistic supervised learning</span>.”</span> <a href="https://doi.org/10.1002/iub.552">https://doi.org/10.1002/iub.552</a>.
</div>
<div id="ref-Harrell1996" class="csl-entry" role="listitem">
Harrell, Frank E., Kerry L. Lee, and Daniel B. Mark. 1996. <span>“<span class="nocase">Multivariable Prognostic Models: Issues in Developing Models, Evaluating Assumptions and Adequacy, and Measuring and Reducing Errors</span>.”</span> <em>Statistics in Medicine</em> 15: 361–87. <a href="https://doi.org/10.1002/0470023678.ch2b(i)">https://doi.org/10.1002/0470023678.ch2b(i)</a>.
</div>
<div id="ref-dataapplied" class="csl-entry" role="listitem">
Hosmer Jr, David W, Stanley Lemeshow, and Susanne May. 2011. <em><span class="nocase">Applied survival analysis: regression modeling of time-to-event data</span></em>. Vol. 618. John Wiley &amp; Sons.
</div>
<div id="ref-HURVICH1989" class="csl-entry" role="listitem">
HURVICH, CLIFFORD M, and CHIH-LING TSAI. 1989. <span>“<span class="nocase">Regression and time series model selection in small samples</span>.”</span> <em>Biometrika</em> 76 (2): 297–307. <a href="https://doi.org/10.1093/biomet/76.2.297">https://doi.org/10.1093/biomet/76.2.297</a>.
</div>
<div id="ref-Jiao2016" class="csl-entry" role="listitem">
Jiao, Yasen, and Pufeng Du. 2016. <span>“<span class="nocase">Performance measures in evaluating machine learning based bioinformatics predictors for classifications</span>.”</span> <em>Quantitative Biology</em> 4 (4): 320–30.
</div>
<div id="ref-Kent1988" class="csl-entry" role="listitem">
Kent, John T., and John O’Quigley. 1988. <span>“<span class="nocase">Measures of dependence for censored survival data</span>.”</span> <em>Biometrika</em> 75 (3): 525–34. <a href="https://doi.org/10.1093/biomet/75.3.525">https://doi.org/10.1093/biomet/75.3.525</a>.
</div>
<div id="ref-vanderLaan2007" class="csl-entry" role="listitem">
Laan, Mark K van der, Eric C Polley, and Alan E Hubbard. 2007. <span>“<span>Super Learner</span>.”</span> <em>Statistical Applications in Genetics and Molecular Biology</em> 6 (1). <a href="https://doi.org/10.2202/1544-6115.1309">https://doi.org/10.2202/1544-6115.1309</a>.
</div>
<div id="ref-Lazer2014" class="csl-entry" role="listitem">
Lazer, David, Ryan Kennedy, Gary King, and Alessandro Vespignani. 2014. <span>“<span class="nocase">The Parable of Google Flu: Traps in Big Data Analysis</span>.”</span> <em>Science</em> 343 (6176): 1203 LP–1205. <a href="https://doi.org/10.1126/science.1248506">https://doi.org/10.1126/science.1248506</a>.
</div>
<div id="ref-Liang2008" class="csl-entry" role="listitem">
Liang, Hua, and Guohua Zou. 2008. <span>“<span class="nocase">Improved AIC Selection Strategy for Survival Analysis</span>.”</span> <em>Computational Statistics &amp; Data Analysis</em> 52 (5): 2538–48. <a href="https://doi.org/10.1016/j.csda.2007.09.003">https://doi.org/10.1016/j.csda.2007.09.003</a>.
</div>
<div id="ref-Newson1983" class="csl-entry" role="listitem">
Newson, Roger B. 1983. <span>“<span class="nocase">Comparing the predictive power of survival models using Harrell’s c or Somers’ D</span>.”</span> <em>The Stata Journal</em>, no. ii: 1–19.
</div>
<div id="ref-Pencina2012" class="csl-entry" role="listitem">
Pencina, Michael J., Ralph B. D’Agostino, and Linye Song. 2012. <span>“<span class="nocase">Quantifying discrimination of Framingham risk functions with different survival C statistics</span>.”</span> <em>Statistics in Medicine</em> 31 (15): 1543–53. <a href="https://doi.org/10.1002/sim.4508">https://doi.org/10.1002/sim.4508</a>.
</div>
<div id="ref-Polley2010" class="csl-entry" role="listitem">
Polley, Eric C, and Mark J Van Der Laan. 2010. <span>“<span class="nocase">Super learner in prediction</span>.”</span>
</div>
<div id="ref-Rahman2017" class="csl-entry" role="listitem">
Rahman, M. Shafiqur, Gareth Ambler, Babak Choodari-Oskooei, and Rumana Z. Omar. 2017. <span>“<span class="nocase">Review and evaluation of performance measures for survival prediction models in external validation settings</span>.”</span> <em>BMC Medical Research Methodology</em> 17 (1): 1–15. <a href="https://doi.org/10.1186/s12874-017-0336-2">https://doi.org/10.1186/s12874-017-0336-2</a>.
</div>
<div id="ref-Royston2004" class="csl-entry" role="listitem">
Royston, Patrick, and Willi Sauerbrei. 2004. <span>“<span class="nocase">A new measure of prognostic separation in survival data</span>.”</span> <em>Statistics in Medicine</em> 23 (5): 723–48. <a href="https://doi.org/10.1002/sim.1621">https://doi.org/10.1002/sim.1621</a>.
</div>
<div id="ref-Schwarz1978" class="csl-entry" role="listitem">
Schwarz, Gideon. 1978. <span>“<span class="nocase">Estimating the Dimension of a Model</span>.”</span> <em>The Annals of Statistics</em> 6 (2): 461–64. <a href="https://doi.org/10.1214/aos/1176344136">https://doi.org/10.1214/aos/1176344136</a>.
</div>
<div id="ref-VanHouwelingen2000" class="csl-entry" role="listitem">
Van Houwelingen, Hans C. 2000. <span>“<span class="nocase">Validation, calibration, revision and combination of prognostic survival models</span>.”</span> <em>Statistics in Medicine</em> 19 (24): 3401–15. <a href="https://doi.org/10.1002/1097-0258(20001230)19:24<3401::AID-SIM554>3.0.CO;2-2">https://doi.org/10.1002/1097-0258(20001230)19:24&lt;3401::AID-SIM554&gt;3.0.CO;2-2</a>.
</div>
<div id="ref-VolinskyRaftery2000" class="csl-entry" role="listitem">
Volinsky, Chris T, and Adrian E Raftery. 2000. <span>“<span class="nocase">Bayesian Information Criterion for Censored Survival Models</span>.”</span> <em>International Biometric Society</em> 56 (1): 256–62.
</div>
<div id="ref-Wolpert1992" class="csl-entry" role="listitem">
Wolpert, David H. 1992. <span>“<span class="nocase">Stacked generalization</span>.”</span> <em>Neural Networks</em> 5 (2): 241–59. https://doi.org/<a href="https://doi.org/10.1016/S0893-6080(05)80023-1">https://doi.org/10.1016/S0893-6080(05)80023-1</a>.
</div>
</div>
</section></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./survival.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Survival Analysis</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./meas_rank.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Evaluating Continuous Rankings</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="an">abstract:</span><span class="co"> TODO (150-200 WORDS)</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>{{&lt; include _setup.qmd &gt;}}</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu"># What are Survival Measures? {#sec-eval}</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>{{&lt; include _wip.qmd &gt;}}</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>This chapter studies how to evaluate the predictions arising from the surveyed models in the previous chapter. 'Model evaluation' is as vague a phrase as 'human evaluation'. A human could be evaluated by a series of exams, physical or neurological tests, aesthetics, etc. Likewise a model could be evaluated according to how well it fits to training data, the quality of predictions on new data, the average prediction, and many more methods. This chapter aims to provide a nuanced approach to defining, understanding, and examining model evaluation. Evaluation is defined in further detail in @sec-eval-why and throughout this chapter the definition will continue to be refined and specialised to specific sub-types of evaluation, including discrimination (@sec-eval-crank), calibration (@sec-eval-distr-calib), and overall predictive performance (@sec-eval-distr).</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>Evaluation is a surprising source of disagreement in the literature with some arguing that the process can often be ignored completely <span class="co">[</span><span class="ot">@vanderLaan2007; @Wolpert1992</span><span class="co">]</span>. There is a larger divide in survival analysis as many believe that the primary (possibly only) goal is risk prediction <span class="co">[</span><span class="ot">@Chen2012; @Newson1983; @Pencina2012</span><span class="co">]</span> and thus other forms of evaluation are not required. These strict views can undermine an integral part of the model building and deployment process, and create more division than necessary. This book advocates for strict implementation of model evaluation as a critical part of the model building process as well as in continuous monitoring of deployed models. Without rigorous evaluation, a model cannot be 'trusted' to perform well and could be as useless as making random guesses for all predictions. This is critical in survival analysis, which has important applications in healthcare and finance, in these sectors models that have not been evaluated are potentially dangerous.</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>An infamous example of evaluation going wrong is the Google Flu Trends (GFT) model, which claimed to accurately predict future flu trends but was in fact deemed by many a complete failure as it significantly overestimated all predictions, in some cases doubling the true figures <span class="co">[</span><span class="ot">@Lazer2014</span><span class="co">]</span>.  The GFT model was never utilised (at least openly) in policy and as such no lasting harm was created. However it is not hard to imagine the problems that would be caused by such a model if it was utilised and trusted during the time of COVID-19. On a more individual level, as machine learning is increasingly deployed in public sectors, major decisions for patients could become increasingly automated (or at least machine-assisted). Patients should expect their models to be as trained and tested as their doctors.</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>This chapter attempts to highlight the purpose and need of evaluation in survival analysis by first giving a high-level overview to evaluation as a concept, then providing a brief review of commonly-used survival measures and finally extensive treatment to scoring rules for evaluation of probabilistic predictions, including novel definitions and proofs for properness of scoring rules. The term *measure* will be used throughout this chapter to refer to functions or 'metrics' that quantify some aspect of model evaluation, this should not be confused with a mathematical measure.</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Notation and Terminology {.unnumbered .unlisted}</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>The notation introduced in @sec-surv is recapped for use in this chapter. The generative template is given by $(X,T,\Delta,Y,C) \ t.v.i. \ \calX \times \calT \times \bset \times \calT \times \calT$ where $\calX \subseteq \Reals^p$ and $\calT \subseteq \NNReals$, where $C,Y$ are unobservable, $T := \min<span class="sc">\{</span>Y,C<span class="sc">\}</span>$, and $\Delta = \II(Y = T)$. Specific survival data is given by training data, $\dtrain = <span class="sc">\{</span>(X_1,T_1,\Delta_1),...,(X_n,T_n,\Delta_n)<span class="sc">\}</span>$ where $(X_i,T_i,\Delta_i) \iid (X,T,\Delta)$, and test data, $\dtest = <span class="sc">\{</span>(X^*_1,T^*_1,\Delta^*_1),...,(X^*_m,T^*_m,\Delta^*_m)\}$ where $(X^*_i,T^*_i,\Delta^*_i) \iid (X,T,\Delta)$.</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="fu">## Evaluation Overview {#sec-eval-why}</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="fu">### What is Evaluation? {#sec-eval-why-what}</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>Evaluation is the process of examining a model's relationship to data, which may refer to the model's relationship to training data, i.e. how well the model is 'fit' to this data, or the relationship to testing data, i.e. how 'good' are the predictions from the model. In this book, only three types of evaluation measure are considered and qualitative definitions of these are given here; more precise definitions appear later in the chapter.</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Discrimination -- A model's discriminatory power refers to how well it separates observations that are at a higher or lower risk of event. Therefore discrimination is also sometimes referred to as *separation*. For example, a model with good discrimination will predict that (at a given time) a dead patient has a higher probability of being dead than an alive patient. These measures are the most common in survival and assess relative risk or rank predictions.</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Calibration -- There is no single agreed upon definition of model calibration, with definitions varying from paper to paper <span class="co">[</span><span class="ot">@Collins2014; @Harrell1996; @Rahman2017; @VanHouwelingen2000</span><span class="co">]</span>. Generally, a model is said to be well-calibrated if the average predicted values from the model are in some 'agreement' (which is specified by the chosen measure) with the average true observed values.</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Predictive Performance -- A model is said to have good predictive performance (or sometimes 'predictive accuracy') if its predictions for new data are 'close to' the truth.</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>These are referred to as measures of predictive ability as they draw conclusions about the ability of the model to make predictions.^<span class="co">[</span><span class="ot">Measures of predictive ability measure a model's *ability* to make any form of prediction. Measures of predictive performance measure the *performance* of the predictions. In this section a model's predictive ability refers to all three of discrimination, calibration, and predictive performance.</span><span class="co">]</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>Using these definitions as a primary taxonomy for survival measures is problematic as without clear definitions there can be significant overlap between model 'classes'. Instead this book advocates for the same taxonomy as in the previous chapter and categorises measures by the return type that they evaluate: survival time, ranking, or survival distribution.</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>Goodness-of-fit measures are very briefly discussed in @sec-eval-insample for completeness, however these are generally out of scope in this book as the vast majority (if any) cannot evaluate machine learning models.</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="fu">## Why are Models Evaluated? {#sec-eval-why-why}</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>A key element of the scientific method is experiments and validation. In the usual workflow of the scientific method:</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>a hypothesis is proposed;</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>predictions are made; and</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>experiments are performed to test the hypothesis based on these predictions.</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>For statistical models the same principles are upheld:</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>i. a model is proposed (by manual or automated selection with possible tuning);</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>i. predictions are made either internally (cross-validation) or externally (held-out data); and</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>i. validation is performed on these predictions in order to infer something about the model's performance.</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>The model can then be considered 'good' or 'bad' and either deployed, adjusted, or discarded. As these are models that are run on a computer (as opposed to experiments in the real-world), the process from fitting to validating is relatively quick and as such multiple proposed models can be evaluated and compared at the same time. This provides two key use-cases for evaluation:</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>i. demonstrating model performance; and</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>i. model comparison/selection.</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>Resistance to model evaluation can be found in the machine learning community. One such example are proponents of inhomogeneous ensemble methods, which combine predictions from multiple different models into a single prediction. The arguments for these models are that:</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>i. model evaluation can never be precise enough, or strong enough guarantees cannot be given <span class="co">[</span><span class="ot">@Jiao2016</span><span class="co">]</span>; and</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>i. ensemble methods can guarantee a better performance than the individual component models and therefore evaluation of the components is not required.</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>For example, 'super learners' <span class="co">[</span><span class="ot">@vanderLaan2007</span><span class="co">]</span> are a class of such model and claim^<span class="co">[</span><span class="ot">Testing this claim is tangential so for now will be assumed true.</span><span class="co">]</span> to guarantee that a super learner will always perform as well as, if not better, than its component models: ''...the super learner framework allows a researcher to try many prediction algorithms...knowing that the final combined super learner fit will either be the best fit or near the best fit" <span class="co">[</span><span class="ot">@Polley2010</span><span class="co">]</span>. This has three problems, it:</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>i. assumes that researchers will only fit sensible prediction algorithms;</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>i. advocates for complex ensemble models instead of transparent and parsimonious ones; and</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>i. assumes that a super learner is guaranteed to be the (near) 'best fit', which actively discourages simpler models being tested separately.</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>Each of these problems can be resolved by researchers only fitting sensible models and opting for an Occam's Razor approach where inhomogeneous ensemble methods are used only if they outperform simpler models, thus requiring validation to test this.</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>By the parsimony principle, if two models have the same predictive performance (within some degree of confidence), then the simpler and more transparent model is preferred. Even a very slight gain in predictive performance could be outweighed by a large increase to complexity. All models, whether simple or complex, should be critically compared to many alternatives. At the very least a model should be compared to a baseline (@sec-eval-distr-score-base-base) as many performance measures are uninterpretable without a point of comparison <span class="co">[</span><span class="ot">@Gressmann2018</span><span class="co">]</span>.</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a><span class="fu">### How are Models Evaluated?</span></span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>The process of evaluation in machine learning is briefly given as a key method in @sec-surv-setml and relevant parts are repeated here. The evaluation process itself is a simple application of a suitable mathematical function to predictions and true data. Let $L$ be some evaluation measure and for now assume $L$ is a measure evaluating deterministic predictions (the following generalises to other types trivially). A model will either be evaluated on each prediction separately, in which case $L: \Reals \times \Reals \rightarrow \ExtReals$ or the measure is calculated for all predictions simultaneously, in which case $L: \Reals^m \times \Reals^m \rightarrow \ExtReals$. Specifically the loss parameters are observed (true) outcomes, $Y$, and predictions of this outcome, $\hatY$. $L$ is usually referred to as a *loss* when $L$ should be minimised for optimal prediction, whereas a *score* is the term given when $L$ should be maximised.</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>All evaluation measures discussed in this book are out-of-sample measures and therefore evaluation takes place after the model makes predictions on held-out test data.</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>Specific choices for $L$ are now reviewed.</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a><span class="fu">## In-Sample Measures {#sec-eval-insample}</span></span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>In-sample measures are not examined in this book as no in-sample measures could be found that are applicable to all machine learning methods and therefore are out of scope for this book. Instead, the interested reader is referred to the papers and references listed below:</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Residuals {.unnumbered .unlisted}</span></span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a>For discussion about model residuals, refer to texts on survival modelling fitting and goodness-of-fit such as:</span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>@Collett2014</span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>@dataapplied</span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a>Both provide a comprehensive overview to model residuals for semi- and fully-parametric low-complexity survival models.</span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a><span class="fu">#### $R^2$ measures {.unnumbered .unlisted}</span></span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a>$R^2$ type measures have been the focus of several reviews and surveys, in particular the following are recommended:</span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>@Choodari2012a --- For a comprehensive review and simulation study of $R^2$ type measures</span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>@Kent1988 --- Defines the commonly utilised Kent and O'Quigley $R^2$ measure</span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>@Royston2004 --- Defines the commonly utilised Royston and Sauerbrei $R^2$ measure</span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Likelihood and Information Criteria {.unnumbered .unlisted}</span></span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a>Measures of likelihood and information criteria (e.g. AIC, BIC) are commonly utilised in in-sample model comparison of low-complexity survival models though in general are harder (if not impossible) to compute on ML alternatives.</span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a>These criterion are originally defined in:</span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>@Akaike1974 --- For the introduction of the AIC</span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>@Schwarz1978 --- For the introduction of the BIC</span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a>These are discussed for survival analysis in:</span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>@VolinskyRaftery2000 --- For discussion on the BIC for survival models.</span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>@HURVICH1989 --- Definition of corrected $AIC$ for survival models, $AIC_C$</span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>@Liang2008 --- 'Improved' AIC for survival models.</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">All content licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> <br> © Raphael Sonabend, Andreas Bender.</div>   
    <div class="nav-footer-center"><a href="https://www.mlsabook.com">Website</a> | <a href="https://github.com/RaphaelS1/MLSA">GitHub</a></div>
    <div class="nav-footer-right">Built with <a href="https://quarto.org/">Quarto</a>.</div>
  </div>
</footer>


</body></html>