<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="Raphael Sonabend and Andreas Bender">
<title>Machine Learning in Survival Analysis - 15&nbsp; Boosting Methods</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./neuralnetworks.html" rel="next">
<link href="./svm.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script><link rel="stylesheet" href="styles.css">
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./classical.html">Models</a></li><li class="breadcrumb-item"><a href="./boosting.html"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Boosting Methods</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Machine Learning in Survival Analysis</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/RaphaelS1/MLSA/tree/main/book/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./Machine-Learning-in-Survival-Analysis.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./notation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Symbols and Notation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false">
 <span class="menu-text">Survival Analysis and Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">MLSA From Start to Finish</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./machinelearning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Statistical Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./survival.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Survival Analysis</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">
 <span class="menu-text">Evaluation</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./meas_what.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">What are Survival Measures?</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./meas_rank.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Discrimination Measures</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./meas_calib.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Calibration Measures</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./meas_rules.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Evaluating Distributions by Scoring Rules</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./meas_time.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Evaluating Survival Time</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./meas_choosing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Choosing Measures</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./classical.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Classical Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mlmodels.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Machine Learning Survival Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./forests.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Tree-Based Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./svm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Support Vector Machines</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./boosting.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Boosting Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./neuralnetworks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./alternatives.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Alternative Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./models_choosing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Choosing Models</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false">
 <span class="menu-text">Reduction Techniques</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./reductions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Reductions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./competing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Competing Risks Pipelines</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./discretetime.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Discrete Time Survival Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./poisson.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Connections to Poisson Regression and Processes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./pseudo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Connections to Regression and Imputation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./advanced.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Advanced Methods</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false">
 <span class="menu-text">Extensions and Outlook</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./common.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Common problems in survival analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./software.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Survival Software</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./next.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">What’s next for MLSA?</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li>
<a href="#sec-surv-ml-models-boost" id="toc-sec-surv-ml-models-boost" class="nav-link active" data-scroll-target="#sec-surv-ml-models-boost"><span class="header-section-number">15.1</span> Gradient Boosting Machines</a>
  <ul class="collapse">
<li><a href="#sec-surv-ml-models-boost-regr" id="toc-sec-surv-ml-models-boost-regr" class="nav-link" data-scroll-target="#sec-surv-ml-models-boost-regr"><span class="header-section-number">15.1.1</span> Gradient Boosting Machines for Regression</a></li>
  <li><a href="#sec-surv-ml-models-boost-surv" id="toc-sec-surv-ml-models-boost-surv" class="nav-link" data-scroll-target="#sec-surv-ml-models-boost-surv"><span class="header-section-number">15.1.2</span> Gradient Boosting Machines for Survival Analysis</a></li>
  <li><a href="#conclusions" id="toc-conclusions" class="nav-link" data-scroll-target="#conclusions"><span class="header-section-number">15.1.3</span> Conclusions</a></li>
  </ul>
</li>
  </ul><div class="toc-actions"><ul><li><a href="https://github.com/RaphaelS1/MLSA/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li><li><a href="https://github.com/RaphaelS1/MLSA/edit/main/book/boosting.qmd" class="toc-action"><i class="bi empty"></i>Edit this page</a></li><li><a href="https://github.com/RaphaelS1/MLSA/blob/main/book/boosting.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./classical.html">Models</a></li><li class="breadcrumb-item"><a href="./boosting.html"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Boosting Methods</span></a></li></ol></nav><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">
<span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Boosting Methods</span>
</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="block-title">Abstract</div>
    TODO (150-200 WORDS)
  </div>
</div>


</header><div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Major changes expected!
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>This page is a work in progress and major changes will be made over time.</strong></p>
</div>
</div>
<section id="sec-surv-ml-models-boost" class="level2" data-number="15.1"><h2 data-number="15.1" class="anchored" data-anchor-id="sec-surv-ml-models-boost">
<span class="header-section-number">15.1</span> Gradient Boosting Machines</h2>
<section id="sec-surv-ml-models-boost-regr" class="level3" data-number="15.1.1"><h3 data-number="15.1.1" class="anchored" data-anchor-id="sec-surv-ml-models-boost-regr">
<span class="header-section-number">15.1.1</span> Gradient Boosting Machines for Regression</h3>
<p>Boosting is a machine learning strategy that can be applied to any model class. Similarly to random forests, boosting is an ‘ensemble’ method that creates a model from a ‘committee’ of learners. The committee is formed of ‘weak’ learners that make poor predictions individually, which creates a ‘slow learning’ approach (as opposed to ‘greedy’) that requires many iterations for a model to be a good fit to the data. Boosting models are similar to random forests in that both make predictions from a large committee of learners. However the two differ in how this committee is combined to a prediction. In random forest algorithms, each decision tree is grown independently and their predictions are combined by a simple mean calculation. In contrast, weak learners in a boosting model are fit sequentially and predictions are made by a linear combination of predictions from each learner. With respect to transparency, it is simpler to inspect 100 trees in a random forest, than it is to inspect 100 weak learners in a boosted model, though both are considered black-box models.</p>
<p>The best known boosting algorithm is likely AdaBoost <span class="citation" data-cites="Freund1996">(<a href="references.html#ref-Freund1996" role="doc-biblioref">Freund and Schapire 1996</a>)</span>, which is more generally a Forward Stagewise Additive Model (FSAM) with an exponential loss <span class="citation" data-cites="Hastie2001">(<a href="references.html#ref-Hastie2001" role="doc-biblioref">Hastie, Tibshirani, and Friedman 2001</a>)</span>. Today, the most widely used boosting model is the Gradient Boosting Machine (GBM) <span class="citation" data-cites="Friedman2001">(<a href="references.html#ref-Friedman2001" role="doc-biblioref">J. H. Friedman 2001</a>)</span>.</p>
<section id="training-a-gbm" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="training-a-gbm">Training a GBM</h4>
<p>Pseudo-code for training a componentwise GBM is presented in (4). The term ‘componentwise’ is explained fully below, only this variation of GBM is presented as it is the most common in implementation <span class="citation" data-cites="pkggbm pkgmboost">(<a href="references.html#ref-pkggbm" role="doc-biblioref">Greenwell et al. 2019</a>; <a href="references.html#ref-pkgmboost" role="doc-biblioref">Hothorn et al. 2020</a>)</span>. Line 1: the initial function is initialized as <span class="math inline">\(g_0 = 0\)</span>; Line 2: iterate over boosting steps <span class="math inline">\(m = 1,...,M\)</span> and; Line 3: randomly sample the training data, <span class="math inline">\(\mathcal{D}_{train}\)</span>, to a smaller sample, <span class="math inline">\(\mathcal{D}_{train}^*\)</span>, this may be ignored if <span class="math inline">\(\phi = 1\)</span>; Line 4: for all training observations in the reduced dataset, <span class="math inline">\(i \in \{i:X_i \in \mathcal{D}_{train}^*\}\)</span>, compute the negative gradient, <span class="math inline">\(r_{im}\)</span>, of the differentiable loss function, <span class="math inline">\(L\)</span>, with respect to predictions from the previous iteration, <span class="math inline">\(g_{m-1}(X_i)\)</span>; Line 5: fit one weak learner for each feature, <span class="math inline">\(j = 1,...,p\)</span>, in the training data, where the feature, <span class="math inline">\(X_{;j}\)</span>, is the single covariate and <span class="math inline">\(r_{im}\)</span> are the labels; Line 6: select the optimal weak learner as the one that minimises the squared error between the prediction and the true gradient; Line 7: update the fitted model by adding the optimal weak learner with a shrinkage penalty, <span class="math inline">\(\nu\)</span>; Line 9: return the model updated in the final iteration as the fitted GBM.</p>
<!-- {#alg-surv-gbm} -->
</section><section id="predicting-with-a-gbm" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="predicting-with-a-gbm">Predicting with a GBM</h4>
<p>In general, predictions from a trained GBM are simple to compute as the fitted model (and all individual weak learners) take the same inputs, which are passed sequentially to each of the weak learners. In (4), the fitted GBM is a single model, which is a linear combination of weak learners. Instead one could think of the returned model as a collection of the optimal weak learners, i.e.&nbsp;let <span class="math inline">\(w_{m;j^*}\)</span> be the optimal weak learner from iteration <span class="math inline">\(m\)</span> and let the fitted GBM (Line 9 (4)) be <span class="math inline">\(\hat{g}:= \{w_{m;j^*}\}^M_{m=1}\)</span>. With this formulation, making predictions from the GBM can be demonstrated simply in (<span class="citation" data-cites="alg-surv-gbm-pred">(<a href="references.html#ref-alg-surv-gbm-pred" role="doc-biblioref"><strong>alg-surv-gbm-pred?</strong></a>)</span>).</p>
<!-- {#alg-surv-gbm-pred} -->
<p>The biggest advantages of boosting are firstly relatively few hyper-parameters, which all have a meaningful and intuitive interpretation, and secondly its modular nature means that, like random forests, relatively few parts need to be updated to derive a novel model. First the model components will be discussed and then the hyper-parameters. Once this has been established, deriving survival variants can be simply presented.</p>
</section><section id="losses-and-learners" class="level4" data-number="15.1.1.1"><h4 data-number="15.1.1.1" class="anchored" data-anchor-id="losses-and-learners">
<span class="header-section-number">15.1.1.1</span> Losses and Learners</h4>
</section><section id="losses" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="losses">Losses</h4>
<p>Building a GBM requires selection of the loss to minimise, <span class="math inline">\(L\)</span>, selection of weak learners, <span class="math inline">\(w_j\)</span>, and a method to compare the weak learners to the loss gradient. The only constraint in selecting a loss, <span class="math inline">\(L\)</span>, is that it must be differentiable with respect to <span class="math inline">\(g(X)\)</span> <span class="citation" data-cites="Hastie2001">(<a href="references.html#ref-Hastie2001" role="doc-biblioref">Hastie, Tibshirani, and Friedman 2001</a>)</span>. Of course a sensible loss should be chosen (a classification loss should not be used for regression) and different choices of losses will optimise different tasks. <span class="math inline">\(L_2\)</span>-losses have been demonstrated to be effective for regression boosting, especially with high-dimensional data <span class="citation" data-cites="Buhlmann2003">(<a href="references.html#ref-Buhlmann2003" role="doc-biblioref">Bühlmann and Yu 2003</a>)</span>; this is referred to as <span class="math inline">\(L_2\)</span>-boosting.</p>
</section><section id="weak-learners" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="weak-learners">Weak Learners</h4>
<ol class="example" type="1">
<li>is specifically a <em>componentwise</em> GBM <span class="citation" data-cites="Buhlmann2003">(<a href="references.html#ref-Buhlmann2003" role="doc-biblioref">Bühlmann and Yu 2003</a>)</span>, which means that each of the <span class="math inline">\(p\)</span> weak learners is fit on a single covariate from the data. This method simplifies selecting the possible choices for the weak learners to selecting the class of weak learner (below). Additionally, componentwise GBMs provide a natural and interpretable feature selection method as selecting the optimal learner ((4), line 6) corresponds to selecting the feature that minimises the chosen loss in iteration <span class="math inline">\(m\)</span>.</li>
</ol>
<p>Only three weak, or ‘base’, learner classes are commonly used in componentwise GBMs <span class="citation" data-cites="pkgmboost Wang2010">(<a href="references.html#ref-pkgmboost" role="doc-biblioref">Hothorn et al. 2020</a>; <a href="references.html#ref-Wang2010" role="doc-biblioref">Wang and Wang 2010</a>)</span>. These are linear least squares <span class="citation" data-cites="Friedman2001">(<a href="references.html#ref-Friedman2001" role="doc-biblioref">J. H. Friedman 2001</a>)</span>, smoothing splines <span class="citation" data-cites="Buhlmann2003">(<a href="references.html#ref-Buhlmann2003" role="doc-biblioref">Bühlmann and Yu 2003</a>)</span>, and decision stumps <span class="citation" data-cites="Buhlmann2003 Friedman2001">(<a href="references.html#ref-Buhlmann2003" role="doc-biblioref">Bühlmann and Yu 2003</a>; <a href="references.html#ref-Friedman2001" role="doc-biblioref">J. H. Friedman 2001</a>)</span>. Let <span class="math inline">\(L\)</span> be a loss with negative gradient for observation <span class="math inline">\(i\)</span> in the <span class="math inline">\(m\)</span>th iteration, <span class="math inline">\(r_{im}\)</span>, and let <span class="math inline">\(\mathcal{D}_{train}\)</span> be the usual training data. For linear least squares, an individual weak learner is fit by <span class="citation" data-cites="Friedman2001 Wang2010">(<a href="references.html#ref-Friedman2001" role="doc-biblioref">J. H. Friedman 2001</a>; <a href="references.html#ref-Wang2010" role="doc-biblioref">Wang and Wang 2010</a>)</span>, <span class="math display">\[
w_j(\mathcal{D}_{train}) = X_{;j}\frac{\sum^n_{i=1} X_{ij}r_{im}}{\sum^n_{i=1} (X_{ij})^2}
\]</span> For smoothing splines, usually cubic splines are implemented, these fit weak learners as the minimisers of the equation <span class="citation" data-cites="Buhlmann2003">(<a href="references.html#ref-Buhlmann2003" role="doc-biblioref">Bühlmann and Yu 2003</a>)</span>, <span class="math display">\[
w_j := \operatornamewithlimits{argmin}_{g \in \mathcal{G}} \frac{1}{n} \sum^{n}_{i = 1} (r_{im} - g(X_{ij}))^2 + \lambda \int (g''(u))^2 du
\]</span> where <span class="math inline">\(g''\)</span> is the second derivative of <span class="math inline">\(g\)</span>, <span class="math inline">\(\mathcal{G}\)</span> is the set of functions, \ <span class="math inline">\(\mathcal{G}:= \{g: g \text{ is twice continuously differentiable and } \int (g''(x))^2 dx &lt; \infty\}\)</span>, and <span class="math inline">\(\lambda\)</span> is a hyper-parameter usually chosen so that the number of degrees of freedom, df, is small, with df <span class="math inline">\(\approx 4\)</span> suggested <span class="citation" data-cites="Buhlmann2003 Schmid2008a Wang2010">(<a href="references.html#ref-Buhlmann2003" role="doc-biblioref">Bühlmann and Yu 2003</a>; <a href="references.html#ref-Schmid2008a" role="doc-biblioref">Schmid and Hothorn 2008a</a>; <a href="references.html#ref-Wang2010" role="doc-biblioref">Wang and Wang 2010</a>)</span>.</p>
<p>Finally for decision stumps ((<span class="quarto-unresolved-ref">?fig-surv-stump</span>)), a decision tree, <span class="math inline">\(w_j\)</span>, is grown (<span class="citation" data-cites="alg-dt-fit">(<a href="references.html#ref-alg-dt-fit" role="doc-biblioref"><strong>alg-dt-fit?</strong></a>)</span>) on <span class="math inline">\((X_{;j}, r_m)\)</span> to depth one (equivalently to two terminal nodes) for each of the <span class="math inline">\(j = 1,...,p\)</span> covariates <span class="citation" data-cites="Friedman2001">(<a href="references.html#ref-Friedman2001" role="doc-biblioref">J. H. Friedman 2001</a>)</span>.</p>
<!-- \begin{figure}[H]
\centering
\begin{tikzpicture}[state/.style={circle, draw, minimum size=15mm}]
\node (t0) [state]  {Root};

\node (t4) [state, draw = none, below=of t0, yshift = 5mm]{};

\node (t1) [state,left=of t4] {Node 1};
\node (t2) [state,right=of t4, label={[label distance=1.0cm]0: - Depth 1}] {Node 2};

\node (t3) [state, draw = none, above=of t2, yshift = -5mm, label={[label distance=1.0cm]0: - Depth 0}]{};

\path[-]
   (t0)  edge (t1)
   (t0)  edge (t2);

\draw [dashed] (-5,1) -- (5,1);
\draw [dashed] (-5,-1) -- (5, -1);
\draw [dashed] (-5,-3) -- (5,-3);
\end{tikzpicture}
\caption[A decision stump]{A decision tree of depth one, known as a decision stump. The root layer is separated at depth 0 from the terminal nodes at depth 1. A decision stump is defined by a decision tree with a single split at the root node.}
 {#fig-surv-stump}
\end{figure} -->
</section><section id="hyper-parameters" class="level4" data-number="15.1.1.2"><h4 data-number="15.1.1.2" class="anchored" data-anchor-id="hyper-parameters">
<span class="header-section-number">15.1.1.2</span> Hyper-Parameters</h4>
<p>The hyper-parameters in (4) are the ‘step-size’, <span class="math inline">\(\nu\)</span>, the sampling fraction, <span class="math inline">\(\phi\)</span>, and the number of iterations, <span class="math inline">\(M\)</span>.</p>
</section><section id="number-of-iterations-m" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="number-of-iterations-m">Number of iterations, <span class="math inline">\(M\)</span>
</h4>
<p>The number of iterations is often claimed to be the most important hyper-parameter in GBMs and it has been demonstrated that as the number of iterations increases, so too does the model performance (with respect to a given loss on test data) up to a certain point of overfitting <span class="citation" data-cites="Buhlmann2006 Hastie2001 Schmid2008a">(<a href="references.html#ref-Buhlmann2006" role="doc-biblioref">Buhlmann 2006</a>; <a href="references.html#ref-Hastie2001" role="doc-biblioref">Hastie, Tibshirani, and Friedman 2001</a>; <a href="references.html#ref-Schmid2008a" role="doc-biblioref">Schmid and Hothorn 2008a</a>)</span>. This is an intuitive result as the foundation of boosting rests on the idea that weak learners can slowly be combined to form a single powerful model. This is especially true in componentwise GBMs as time is required to learn which features are important. Finding the optimal value of <span class="math inline">\(M\)</span> is critical as a value too small will result in poor predictions, whilst a value too large will result in model overfitting. Two primary methods have been suggested for finding the optimal value of <span class="math inline">\(M\)</span>. The first is to find the <span class="math inline">\(M \in \mathbb{N}_{&gt; 0}\)</span> that minimises a given measure based on the AIC <span class="citation" data-cites="Akaike1974">(<a href="references.html#ref-Akaike1974" role="doc-biblioref">Akaike 1974</a>)</span>, the second is the ‘usual’ empirical selection by nested cross-validation. In practice the latter method is usually employed.</p>
</section><section id="step-size-nu" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="step-size-nu">Step-size, <span class="math inline">\(\nu\)</span>
</h4>
<p>The step-size parameter ((4), line 7), <span class="math inline">\(\nu\)</span>, is a shrinkage parameter that controls the contribution of each weak learner at each iteration. Several studies have demonstrated that GBMs perform better when shrinkage is applied and a value of <span class="math inline">\(\nu = 0.1\)</span> is often suggested <span class="citation" data-cites="Buhlmann2007 Hastie2001 Friedman2001 Lee2018 Schmid2008a">(<a href="references.html#ref-Buhlmann2007" role="doc-biblioref">Buhlmann and Hothorn 2007</a>; <a href="references.html#ref-Hastie2001" role="doc-biblioref">Hastie, Tibshirani, and Friedman 2001</a>; <a href="references.html#ref-Friedman2001" role="doc-biblioref">J. H. Friedman 2001</a>; <a href="references.html#ref-Lee2018" role="doc-biblioref">Lee, Chen, and Ishwaran 2019</a>; <a href="references.html#ref-Schmid2008a" role="doc-biblioref">Schmid and Hothorn 2008a</a>)</span>. The optimal values of <span class="math inline">\(\nu\)</span> and <span class="math inline">\(M\)</span> depend on each other, such that smaller values of <span class="math inline">\(\nu\)</span> require larger values of <span class="math inline">\(M\)</span>, and vice versa. This is intuitive as smaller <span class="math inline">\(\nu\)</span> results in a slower learning algorithm and therefore more iterations are required to fit the model. Accurately selecting the <span class="math inline">\(M\)</span> parameter is generally considered to be of more importance, and therefore a value of <span class="math inline">\(\nu\)</span> is often chosen heuristically (e.g.&nbsp;the common value of <span class="math inline">\(0.1\)</span>) and then <span class="math inline">\(M\)</span> is tuned by cross-validation and/or early-stopping.</p>
</section><section id="sampling-fraction-phi" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="sampling-fraction-phi">Sampling Fraction, <span class="math inline">\(\phi\)</span>
</h4>
<p>Motivated by the success of bagging in random forests, stochastic gradient boosting <span class="citation" data-cites="Friedman1999">(<a href="references.html#ref-Friedman1999" role="doc-biblioref">J. Friedman 1999</a>)</span> randomly samples the data in each iteration. It appears that subsampling performs best when also combined with shrinkage <span class="citation" data-cites="Hastie2001">(<a href="references.html#ref-Hastie2001" role="doc-biblioref">Hastie, Tibshirani, and Friedman 2001</a>)</span> and as with the other hyper-parameters, selection of <span class="math inline">\(\phi\)</span> is usually performed by nested cross-validation.</p>
</section></section><section id="sec-surv-ml-models-boost-surv" class="level3" data-number="15.1.2"><h3 data-number="15.1.2" class="anchored" data-anchor-id="sec-surv-ml-models-boost-surv">
<span class="header-section-number">15.1.2</span> Gradient Boosting Machines for Survival Analysis</h3>
<p>In a componentwise GBM framework, adapting boosting to survival analysis requires only selecting a sensible choice of loss function <span class="math inline">\(L\)</span>. Therefore fitting and predicting algorithms for componentwise survival GBMs are not discussed as these are fully described in algorithms (4) and (<span class="citation" data-cites="alg-surv-gbm-pred">(<a href="references.html#ref-alg-surv-gbm-pred" role="doc-biblioref"><strong>alg-surv-gbm-pred?</strong></a>)</span>) respectively. However, some GBMs in this section are not componentwise and therefore require some more detailed consideration. Interestingly, unlike other machine learning algorithms that historically ignored survival analysis, early GBM papers considered boosting in a survival context <span class="citation" data-cites="Ridgeway1999">(<a href="references.html#ref-Ridgeway1999" role="doc-biblioref">Ridgeway 1999</a>)</span>; though there appears to be a decade gap before further considerations were made in the survival setting. After that period, several developments by Binder, Schmid, and Hothorn, adapted componentwise GBMs to a framework suitable for survival analysis. Their developments are covered exhaustively in the R packages <span class="math inline">\(\textbf{gbm}\)</span> <span class="citation" data-cites="pkggbm">(<a href="references.html#ref-pkggbm" role="doc-biblioref">Greenwell et al. 2019</a>)</span> and <span class="math inline">\(\textbf{mboost}\)</span> <span class="citation" data-cites="pkgmboost">(<a href="references.html#ref-pkgmboost" role="doc-biblioref">Hothorn et al. 2020</a>)</span>. This survey continues with the predict type taxonomy.</p>
<section id="cox-survival-models" class="level4" data-number="15.1.2.1"><h4 data-number="15.1.2.1" class="anchored" data-anchor-id="cox-survival-models">
<span class="header-section-number">15.1.2.1</span> Cox Survival Models</h4>
<p>All survival GBMs make ranking predictions and none are able to directly predict survival distributions. However, the GBMs discussed in this section all have natural compositions to distributions as they are modelled in the semi-parametric proportional hazards framework (<a href="reductions.html" class="quarto-xref"><span>Chapter 19</span></a>). The models discussed in the next section can also be composed to distributions though the choice of composition is less clear and therefore they are listed as pure ‘ranking’ models.</p>
<p><strong>GBM-COX</strong> {#mod-gdcox} {#mod-gbmcox}\ The ‘GBM-COX’ aims to predict the distribution of data following the PH assumption by estimating the coefficients of a Cox model in a boosting framework <span class="citation" data-cites="Ridgeway1999">(<a href="references.html#ref-Ridgeway1999" role="doc-biblioref">Ridgeway 1999</a>)</span>. The model attempts to predict <span class="math inline">\(\hat{g}(X^*) = \hat{\eta} := X^*\hat{\beta}\)</span>, by minimising a suitable loss function. As the model assumes a PH specification, the natural loss to optimise is the Cox partial likelihood <span class="citation" data-cites="Cox1972 Cox1975">(<a href="references.html#ref-Cox1972" role="doc-biblioref">Cox 1972</a>, <a href="references.html#ref-Cox1975" role="doc-biblioref">1975</a>)</span>, more specifically to minimise the negative partial log-likelihood, <span class="math inline">\(-l\)</span>, where</p>
<p><span id="eq-surv-logpartial"><span class="math display">\[
l(\beta) = \sum^n_{i=1} \Delta_i \Big[\eta_i \ - \ \log\Big(\sum^n_{j \in \mathcal{R}_{t_i}} \exp(\eta_i)\Big)\Big]
\tag{15.1}\]</span></span> where <span class="math inline">\(\mathcal{R}_{t_i}\)</span> is the set of patients at risk at time <span class="math inline">\(t_i\)</span> and <span class="math inline">\(\eta_i = X_i\beta\)</span>. The gradient of <span class="math inline">\(-l(\beta)\)</span> at iteration <span class="math inline">\(m\)</span> is <span id="eq-surv-partialgrad"><span class="math display">\[
r_{im} := \Delta_i - \sum^n_{j=1} \Delta_j \frac{\mathbb{I}(T_i \geq T_j) \exp(g_{m-1}(X_i))}{\sum_{k \in \mathcal{R}_{t_j}} \exp(g_{m-1}(X_k))}
\tag{15.2}\]</span></span> where <span class="math inline">\(g_{m-1}(X_i) = X_i\beta_{m-1}\)</span>.</p>
<ol start="2" class="example" type="1">
<li>now follows with the loss <span class="math inline">\(L := -l(\beta)\)</span>.</li>
</ol>
<p>The GBM-COX is implemented in <span class="math inline">\(\textbf{mboost}\)</span> <span class="citation" data-cites="pkgmboost">(<a href="references.html#ref-pkgmboost" role="doc-biblioref">Hothorn et al. 2020</a>)</span> and has been demonstrated to perform well even when the data violates the PH assumption <span class="citation" data-cites="Johnson2011">(<a href="references.html#ref-Johnson2011" role="doc-biblioref">Johnson and Long 2011</a>)</span>. Despite being a black-box, GBMs are well-understood and individual weak learners are highly interpretable, thus making GBMs highly transparent. Several well-established software packages implement GBM-COX and those that do not tend to be very flexible with respect to custom implementations.</p>
<p>*CoxBoost** {#mod-coxboost}\ The CoxBoost algorithm boosts the Cox PH by optimising the penalized partial-log likelihood; additionally the algorithm allows for mandatory (or ‘forced’) covariates <span class="citation" data-cites="Binder2008">(<a href="references.html#ref-Binder2008" role="doc-biblioref">Harald Binder and Schumacher 2008</a>)</span>. In medical domains the inclusion of mandatory covariates may be essential, either for model interpretability, or due to prior expert knowledge. This is not a feature usually supported by boosting. CoxBoost deviates from (4) by instead using an offset-based approach for generalized linear models <span class="citation" data-cites="Tutz2007">(<a href="references.html#ref-Tutz2007" role="doc-biblioref">Tutz and Binder 2007</a>)</span>. This model has a non-componentwise and componentwise framework but only the latter is implemented by the authors <span class="citation" data-cites="pkgcoxboost">(<a href="references.html#ref-pkgcoxboost" role="doc-biblioref">Harold Binder 2013</a>)</span> and discussed here. Let <span class="math inline">\(\mathcal{I}_{mand}\)</span> be the indices of the mandatory covariates to be included in all iterations, <span class="math inline">\(m = 1,...,M\)</span>, then for an iteration <span class="math inline">\(m\)</span> the indices to consider for fitting are the set <span class="math display">\[
I_m = \{\{1\} \cup \mathcal{I}_{mand},...,\{p\} \cup \mathcal{I}_{mand}\} / \{\{j\} \cup \mathcal{I}_{mand} : j \in \mathcal{I}_{mand}\}
\]</span> i.e.&nbsp;in each iteration the algorithm fits a weak learner on the mandatory covariates and one additional (non-mandatory) covariate (hence still being componentwise).</p>
<p>In addition, a penalty matrix <span class="math inline">\(\mathbf{P} \in \mathbb{R}^{p \times p}\)</span> is considered such that <span class="math inline">\(P_{ii} &gt; 0\)</span> implies that covariate <span class="math inline">\(i\)</span> is penalized and <span class="math inline">\(P_{ii} = 0\)</span> means no penalization. In practice this is usually a diagonal matrix <span class="citation" data-cites="Binder2008">(<a href="references.html#ref-Binder2008" role="doc-biblioref">Harald Binder and Schumacher 2008</a>)</span> and by setting <span class="math inline">\(P_{ii} = 0, i \in I_{mand}\)</span> and <span class="math inline">\(P_{ii} &gt; 0, i \not\in I_{mand}\)</span>, only optional (non-mandatory) covariates are penalized. The penalty matrix can be allowed to vary with each iteration, which allows for a highly flexible approach, however in implementation a simpler approach is to either select a single penalty to be applied in each iteration step or to have a single penalty matrix <span class="citation" data-cites="pkgcoxboost">(<a href="references.html#ref-pkgcoxboost" role="doc-biblioref">Harold Binder 2013</a>)</span>.</p>
<p>At the <span class="math inline">\(m\)</span>th iteration and the <span class="math inline">\(k\)</span>th set of indices to consider (<span class="math inline">\(k = 1,...,p\)</span>), the loss to optimize is the penalized partial-log likelihood given by <span class="math display">\[
\begin{split}
&amp;l_{pen}(\gamma_{mk}) = \sum^n_{i=1} \Delta_i \Big[\eta_{i,m-1} + X_{i,\mathcal{I}_{mk}}\gamma^T_{mk}\Big] - \\
&amp;\quad\Delta_i\log\Big(\sum^n_{j = 1} \mathbb{I}(T_j \leq T_i) \exp(\eta_{i,{m-1}} + X_{i, \mathcal{I}_{mk}}\gamma^T_{mk}\Big) - \lambda\gamma_{mk}\mathbf{P}_{mk}\gamma^T_{mk}
\end{split}
\]</span></p>
<p>where <span class="math inline">\(\eta_{i,m} = X_i\beta_m\)</span>, <span class="math inline">\(\gamma_{mk}\)</span> are the coefficients corresponding to the covariates in <span class="math inline">\(\mathcal{I}_{mk}\)</span> which is the possible set of candidates for a subset of total candidates <span class="math inline">\(k = 1,...,p\)</span>, <span class="math inline">\(\mathbf{P}_{mk}\)</span> is the penalty matrix, and <span class="math inline">\(\lambda\)</span> is a penalty hyper-parameter to be tuned or selected.</p>
<p>In each iteration, all potential candidate sets (the union of mandatory covariates and one other covariate) are updated by <span class="math display">\[
\hat{\gamma}_{mk} = \mathbf{I}^{-1}_{pen}(0)U(0)
\]</span> where <span class="math inline">\(U(\gamma) = \partial l / \partial \gamma (\gamma)\)</span> and <span class="math inline">\(\mathbf{I}^{-1}_{pen} = \partial^2 l/\partial\gamma\partial\gamma^T (\gamma + \lambda\mathbf{P}_{mk})\)</span> are the first and second derivatives of the unpenalized partial-log-likelihood. The optimal set is then found as <span class="math display">\[
k^* := \operatornamewithlimits{argmax}_k l_{pen}(\gamma_{mk})
\]</span> and the estimated coefficients are updated with <span class="math display">\[
\hat{\beta}_m = \hat{\beta}_{m-1} + \gamma_{mk^*}, \quad k^* \in \mathcal{I}_{mk}
\]</span> The step size, <span class="math inline">\(\nu\)</span>, is then one, but this could potentially be altered.</p>
<p>The algorithm deviates from (4) as <span class="math inline">\(l_{pen}\)</span> is directly optimised and not its gradient, additionally model coefficients are iteratively updated instead of a more general model form. The algorithm is implemented in <span class="math inline">\(\textbf{CoxBoost}\)</span> <span class="citation" data-cites="pkgcoxboost">(<a href="references.html#ref-pkgcoxboost" role="doc-biblioref">Harold Binder 2013</a>)</span>. Experiments suggest that including the ‘correct’ mandatory covariates may increase predictive performance <span class="citation" data-cites="Binder2008">(<a href="references.html#ref-Binder2008" role="doc-biblioref">Harald Binder and Schumacher 2008</a>)</span>. CoxBoost is less accessible than other boosting methods as it requires a unique boosting algorithm, as such only one off-shelf implementation appears to exist and even this implementation has been removed from CRAN as of 2020-11-11. CoxBoost is also less transparent as the underlying algorithm is more complex, though is well-explained by the authors <span class="citation" data-cites="Binder2008">(<a href="references.html#ref-Binder2008" role="doc-biblioref">Harald Binder and Schumacher 2008</a>)</span>. There is good indication that CoxBoost is performant <span class="citation" data-cites="Sonabend2021b">(<a href="references.html#ref-Sonabend2021b" role="doc-biblioref">Sonabend 2021</a>)</span>. In a non-medical domain, where performance may be the most important metric, then perhaps CoxBoost can be recommended as a powerful model. However, when sensitive predictions are required, CoxBoost may not be recommended. Further papers studying the model and more off-shelf implementations could change this in the future.</p>
</section><section id="ranking-survival-models" class="level4" data-number="15.1.2.2"><h4 data-number="15.1.2.2" class="anchored" data-anchor-id="ranking-survival-models">
<span class="header-section-number">15.1.2.2</span> Ranking Survival Models</h4>
<p>The ranking survival models in this section are all unified as they make predictions of the linear predictor, <span class="math inline">\(\hat{g}(X^*) = X^*\hat{\beta}\)</span>.</p>
<p><strong>GBM-AFT</strong> {#mod-gbmaft}\ Schmid and Hothorn (2008) <span class="citation" data-cites="Schmid2008b">(<a href="references.html#ref-Schmid2008b" role="doc-biblioref">Schmid and Hothorn 2008b</a>)</span> published a GBM for accelerated failure time models in response to PH-boosted models that may not be suitable for non-PH data. Their model fits into the GBM framework by assuming a fully-parametric AFT and simultaneously estimating the linear predictor, <span class="math inline">\(\hat{g}(X_i) =\hat{\eta}\)</span>, and the scale parameter, <span class="math inline">\(\hat{\sigma}\)</span>, controlling the amount of noise in the distribution. The (fully-parametric) AFT is defined by <span class="math display">\[
\log Y = \eta + \sigma W
\]</span> where <span class="math inline">\(W\)</span> is a random variable independent of the covariates that follows a given distribution and controls the noise in the model. By assuming a distribution on <span class="math inline">\(W\)</span>, a distribution is assumed for the full parametric model. The full likelihood, <span class="math inline">\(\mathcal{L}\)</span>, is given by <span id="eq-surv-aft-like"><span class="math display">\[
\mathcal{L}(\mathcal{D}_{train}|\mu, \sigma, W) = \prod^n_{i=1} \Big[\frac{1}{\sigma} f_W\Big(\frac{\log(T_i) - \mu}{\sigma}\Big)\Big]^{\Delta_i}\Big[S_W\Big(\frac{\log(T_i) - \mu}{\sigma}\Big)\Big]^{(1-\Delta_i)}
\tag{15.3}\]</span></span> where <span class="math inline">\(f_W, S_W\)</span> is the pdf and survival function of <span class="math inline">\(W\)</span> for a given distribution. By setting <span class="math inline">\(\mu := g(X_i)\)</span>, <span class="math inline">\(\sigma\)</span> is then rescaled according to known results depending on the distribution <span class="citation" data-cites="Klein2003">(<a href="references.html#ref-Klein2003" role="doc-biblioref">Klein and Moeschberger 2003</a>)</span>. The gradient of the negative log-likelihood, <span class="math inline">\(-l\)</span>, is minimised in the <span class="math inline">\(m\)</span>th iteration where <span class="math display">\[
\begin{split}
l(\mathcal{D}_{train}|\hat{g}, \hat{\sigma},W) = \sum^n_{i=1} \Delta_i\Big[- \log\sigma + \log f_W\Big(\frac{\log(T_i) - \hat{g}_{m-1}(X_i)}{\hat{\sigma}_{m-1}}\Big)\Big] + \\
(1-\Delta_i)\Big[\log S_W\Big(\frac{\log(T_i) - \hat{g}_{m-1}(X_i)}{\hat{\sigma}_{m-1}}\Big)\Big]
\end{split}
\]</span> where <span class="math inline">\(\hat{g}_{m-1}, \hat{\sigma}_{m-1}\)</span> are the location-scale parameters estimated in the previous iteration. Note this key difference to other GBM methods in which two estimates are made in each iteration step. In order to allow for this, (4) is run as normal but in addition, after updating <span class="math inline">\(\hat{g}_m\)</span>, one then updates <span class="math inline">\(\hat{\sigma}_m\)</span> as <span class="math display">\[
\hat{\sigma}_m := \operatornamewithlimits{argmin}_\sigma -l(\mathcal{D}_{train}|g_m,\sigma, W)
\]</span> <span class="math inline">\(\sigma_0\)</span> is initialized at the start of the algorithm with <span class="math inline">\(\sigma_0 = 1\)</span> suggested <span class="citation" data-cites="Schmid2008b">(<a href="references.html#ref-Schmid2008b" role="doc-biblioref">Schmid and Hothorn 2008b</a>)</span>.</p>
<p>This algorithm provides a ranking prediction without enforcing an often-unrealistic PH assumption on the data. This model is implemented in <span class="math inline">\(\textbf{mboost}\)</span> and <span class="math inline">\(\textbf{xgboost}\)</span>. Experiments indicate that this may outperform the Cox PH <span class="citation" data-cites="Schmid2008b">(<a href="references.html#ref-Schmid2008b" role="doc-biblioref">Schmid and Hothorn 2008b</a>)</span>. Moreover the model has the same transparency and accessibility as the GBM-COX.</p>
<p><strong>GBM-GEH</strong> {#mod-gbmgeh}\ The concordance index is likely the most popular measure of discrimination, this in part due to the fact that it makes little-to-no assumptions about the data (<a href="meas_rank.html" class="quarto-xref"><span>Chapter 6</span></a>). A less common measure is the Gehan loss, motivated by the semi-parametric AFT. Johnson and Long proposed the GBM with Gehan loss, here termed GBM-GEH, to optimise separation within an AFT framework <span class="citation" data-cites="Johnson2011">(<a href="references.html#ref-Johnson2011" role="doc-biblioref">Johnson and Long 2011</a>)</span>.</p>
<p>The semi-parametric AFT is defined by the linear model, <span class="math display">\[
\log Y = \eta + \epsilon
\]</span> for some error term, <span class="math inline">\(\epsilon\)</span>.</p>
<p>The D-dimensional Gehan loss to minimise is given by, <span class="math display">\[
G_D(\mathcal{D}_{train}, \hat{g}) = -\frac{1}{n^2} \sum^n_{i=1}\sum^n_{j=1} \Delta_i (\hat{e}_i - \hat{e}_j)\mathbb{I}(\hat{e}_i \leq \hat{e}_j)
\]</span> where <span class="math inline">\(\hat{e}_i = \log T_i - \hat{g}(X_i)\)</span>. The negative gradient of the loss is, <span class="math display">\[
r_{im} := \frac{\sum^n_{j=1} \Delta_j \mathbb{I}(\hat{e}_{m-1,i} \geq \hat{e}_{m-1,j}) -\Delta_i\mathbb{I}(\hat{e}_{m-1,i} \leq \hat{e}_{m-1,j})}{n}
\]</span> where <span class="math inline">\(\hat{e}_{m-1,i} = \log T_i - \hat{g}_{m-1}(X_i)\)</span>.</p>
<ol start="3" class="example" type="1">
<li>then follows naturally substituting the loss and gradient above. The algorithm is implemented in <span class="math inline">\(\textbf{mboost}\)</span>. Simulation studies on the performance of the model are inconclusive <span class="citation" data-cites="Johnson2011">(<a href="references.html#ref-Johnson2011" role="doc-biblioref">Johnson and Long 2011</a>)</span> however the results in <span class="citation" data-cites="Sonabend2021b">(<a href="references.html#ref-Sonabend2021b" role="doc-biblioref">Sonabend 2021</a>)</span> indicate strong predictive performance.</li>
</ol>
<p><strong>GBM-BUJAR</strong> {#mod-gbmbujar}\ GBM-BUJAR is another boosted semi-parametric AFT. However the algorithm introduced by Wang and Wang (2010) <span class="citation" data-cites="Wang2010">(<a href="references.html#ref-Wang2010" role="doc-biblioref">Wang and Wang 2010</a>)</span> uses Buckley-James imputation and minimisation. This algorithm is almost identical to a regression GBM (i.e.&nbsp;using squared loss or similar for <span class="math inline">\(L\)</span>), except with one additional step to iteratively impute censored survival times. Assuming a semi-parametric AFT model, the GBM-BUJAR algorithm iteratively updates imputed outcomes with the Buckley-James estimator <span class="citation" data-cites="Buckley1979">(<a href="references.html#ref-Buckley1979" role="doc-biblioref">Buckley and James 1979</a>)</span>, <span class="math display">\[
T^*_{m, i} := \hat{g}_{m-1}(X_i) + e_{m-1, i}\Delta_i + (1-\Delta_i)\Big[\hat{S}_{KM}(e_{m-1, i})^{-1}\sum_{e_{m-1, j} &gt; e_{m-1, i}} e_{m-1, j}\Delta_j \hat{p}_{KM}(e_{m-1, j})\Big]
\]</span> where <span class="math inline">\(\hat{g}_{m-1}(X_i) = \hat{\eta}_{m-1}\)</span>, and <span class="math inline">\(\hat{S}_{KM}, \hat{p}_{KM}\)</span> are Kaplan-Meier estimates of the survival and probability mass functions respectively fit on some training data, and <span class="math inline">\(e_{m-1,i} := \log(T_i) - g_{m-1}(X_i)\)</span>. Once <span class="math inline">\(T^*_{m, i}\)</span> has been updated, (4) continues from with least squares as with any regression model.</p>
<p>GBM-BUJAR is implemented in <span class="math inline">\(\textbf{bujar}\)</span> <span class="citation" data-cites="pkgbujar">(<a href="references.html#ref-pkgbujar" role="doc-biblioref">Wang 2019</a>)</span> though without a separated fit/predict interface, its accessibility is therefore limited. There is no evidence of wide usage of this algorithm nor simulation studies demonstrating its predictive ability. Finally, there are many known problems with semi-parametric AFT models and the Buckey-James procedure <span class="citation" data-cites="Wei1992">(<a href="references.html#ref-Wei1992" role="doc-biblioref">Wei 1992</a>)</span>, hence GBM-BUJAR is also not transparent.</p>
<p><strong>GBM-UNO</strong> {#mod-gbmuno}\ Instead of optimising models based on a given model form, Chen <span class="math inline">\(\textit{et al.}\)</span> <span class="citation" data-cites="Chen2013">(<a href="references.html#ref-Chen2013" role="doc-biblioref">Y. Chen et al. 2013</a>)</span> studied direct optimisation of discrimination by Harrell’s C whereas Mayr and Schmid <span class="citation" data-cites="Mayr2014">(<a href="references.html#ref-Mayr2014" role="doc-biblioref">Mayr and Schmid 2014</a>)</span> focused instead on Uno’s C. Only an implementation of the Uno’s C method could be found, this is therefore discussed here and termed ‘GBM-UNO’.</p>
<p>The GBM-UNO attempts to predict <span class="math inline">\(\hat{g}(X^*) := \hat{\eta}\)</span> by optimising Uno’s C (<a href="meas_rank.html#sec-eval-crank-disc-conc" class="quarto-xref"><span>Section 6.1</span></a>), <span class="math display">\[
C_U(\hat{g}, \mathcal{D}_{train}) = \frac{\sum_{i \neq j}\Delta_i\{\hat{G}_{KM}(T_i)\}^{-2}\mathbb{I}(T_i &lt; T_j)\mathbb{I}(\hat{g}(X_i) &gt;\hat{g}(X_j))}{\sum_{i \neq j}\Delta_i\{\hat{G}_{KM}(T_i)\}^{-2}\mathbb{I}(T_i &lt; T_j)}
\]</span></p>
<p>The GBM algorithm requires that the chosen loss, here <span class="math inline">\(C_U\)</span>, be differentiable with respect to <span class="math inline">\(\hat{g}(X)\)</span>, which is not the case here due to the indicator term, <span class="math inline">\(\mathbb{I}(\hat{g}(X_i) &gt; \hat{g}(X_j))\)</span>. Therefore a smoothed version is instead considered where the indicator is approximated by the sigmoid function <span class="citation" data-cites="Ma2006">(<a href="references.html#ref-Ma2006" role="doc-biblioref">Ma and Huang 2006</a>)</span>,</p>
<p><span class="math display">\[
K(u|\sigma) = (1 + \exp(-u/\sigma))^{-1}
\]</span></p>
<p>where <span class="math inline">\(\sigma\)</span> is a hyper-parameter controlling the smoothness of the approximation. The measure to optimise is then,</p>
<p><span id="eq-surv-gbm-cus"><span class="math display">\[
C_{USmooth}(\mathcal{D}_{train}|\sigma) = \sum_{i \neq j} \frac{k_{ij}}{1 + \exp\big[(\hat{g}(X_j) - \hat{g}(X_i))/\sigma)\big]}
\tag{15.4}\]</span></span></p>
<p>with</p>
<p><span class="math display">\[
k_{ij} = \frac{\Delta_i (\hat{G}_{KM}(T_i))^{-2}\mathbb{I}(T_i &lt; T_j)}{\sum^n_{i \neq j} \Delta_i(\hat{G}_{KM}(T_i))^{-2}\mathbb{I}(T_i &lt; T_j)}
\]</span></p>
<p>The negative gradient at iteration <span class="math inline">\(m\)</span> for observation <span class="math inline">\(i\)</span> can then be found,</p>
<p><span id="eq-surv-gbm-cus-grad"><span class="math display">\[
r_{im} := - \sum^n_{j = 1} k_{ij} \frac{-\exp(\frac{\hat{g}_{m-1}(X_j) - \hat{g}_{m-1}(X_i)}{\sigma})}{\sigma(1 + \exp(\frac{\hat{g}_{m-1}(X_j) - \hat{g}_{m-1}(X_i)}{\sigma}))}
\tag{15.5}\]</span></span></p>
<ol start="4" class="example" type="1">
<li>can then be followed exactly by substituting this loss and gradient; this is implemented in <span class="math inline">\(\textbf{mboost}\)</span>. One disadvantage of GBM-UNO is that C-index boosting is more insensitive to overfitting than other methods <span class="citation" data-cites="Mayr2016">(<a href="references.html#ref-Mayr2016" role="doc-biblioref">Mayr, Hofner, and Schmid 2016</a>)</span>, therefore stability selection <span class="citation" data-cites="Meinshausen2010">(<a href="references.html#ref-Meinshausen2010" role="doc-biblioref">Meinshausen and Bühlmann 2010</a>)</span> can be considered for variable selection; this is possible with <span class="math inline">\(\textbf{mboost}\)</span>. Despite directly optimising discrimination, simulation studies do not indicate that this model has better separation than other boosted or lasso models <span class="citation" data-cites="Mayr2014">(<a href="references.html#ref-Mayr2014" role="doc-biblioref">Mayr and Schmid 2014</a>)</span>. GBM-UNO has the same accessibility, transparency, and performance <span class="citation" data-cites="Sonabend2021b">(<a href="references.html#ref-Sonabend2021b" role="doc-biblioref">Sonabend 2021</a>)</span> as previous boosting models.</li>
</ol></section></section><section id="conclusions" class="level3" data-number="15.1.3"><h3 data-number="15.1.3" class="anchored" data-anchor-id="conclusions">
<span class="header-section-number">15.1.3</span> Conclusions</h3>
<p>Componentwise gradient boosting machines are a highly flexible and powerful machine learning tool. They have proven particularly useful in survival analysis as minimal adjustments are required to make use of off-shelf software. The flexibility of the algorithm allows all the models above to be implemented in very few <span class="math inline">\(\textsf{R}\)</span> (and other programming languages) packages.</p>
<p>Boosting is a method that often relies on intensive computing power and therefore dedicated packages, such as <span class="math inline">\(\textbf{xgboost}\)</span> <span class="citation" data-cites="pkgxgboost">(<a href="references.html#ref-pkgxgboost" role="doc-biblioref">T. Chen et al. 2020</a>)</span>, exist to push CPU/GPUs to their limits in order to optimise predictive performance. This can be viewed as a strong advantage though one should be careful not to focus too much on predictive performance to the detriment of accessibility and transparency.</p>
<p>Boosting, especially with tree learners, is viewed as a black-box model that is increasingly difficult to interpret as the number of iterations increase. However, there are several methods for increasing interpretability, such as variable importance and SHAPs <span class="citation" data-cites="Lundberg2017">(<a href="references.html#ref-Lundberg2017" role="doc-biblioref">Lundberg and Lee 2017</a>)</span>. There is also evidence that boosting models can outperform the Cox PH <span class="citation" data-cites="Schmid2008b">(<a href="references.html#ref-Schmid2008b" role="doc-biblioref">Schmid and Hothorn 2008b</a>)</span> (not something all ML models can claim).</p>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-Akaike1974" class="csl-entry" role="listitem">
Akaike, Hirotugu. 1974. <span>“<span class="nocase">A New Look at the Statistical Model Identification</span>.”</span> <em>IEEE Transactions on Automatic Control</em> 19 (6): 716–23. <a href="https://doi.org/10.1093/ietfec/e90-a.12.2762">https://doi.org/10.1093/ietfec/e90-a.12.2762</a>.
</div>
<div id="ref-Binder2008" class="csl-entry" role="listitem">
Binder, Harald, and Martin Schumacher. 2008. <span>“<span class="nocase">Allowing for mandatory covariates in boosting estimation of sparse high-dimensional survival models</span>.”</span> <em>BMC Bioinformatics</em> 9 (1): 14. <a href="https://doi.org/10.1186/1471-2105-9-14">https://doi.org/10.1186/1471-2105-9-14</a>.
</div>
<div id="ref-pkgcoxboost" class="csl-entry" role="listitem">
Binder, Harold. 2013. <span>“<span class="nocase">CoxBoost: Cox models by likelihood based boosting for a single survival endpoint or competing risks</span>.”</span> CRAN.
</div>
<div id="ref-Buckley1979" class="csl-entry" role="listitem">
Buckley, Jonathan, and Ian James. 1979. <span>“<span class="nocase">Linear Regression with Censored Data</span>.”</span> <em>Biometrika</em> 66 (3): 429–36. <a href="https://doi.org/10.2307/2335161">https://doi.org/10.2307/2335161</a>.
</div>
<div id="ref-Buhlmann2006" class="csl-entry" role="listitem">
Buhlmann, Peter. 2006. <span>“<span class="nocase">Boosting for high-dimensional linear models</span>.”</span> <em>Ann. Statist.</em> 34 (2): 559–83. <a href="https://doi.org/10.1214/009053606000000092">https://doi.org/10.1214/009053606000000092</a>.
</div>
<div id="ref-Buhlmann2007" class="csl-entry" role="listitem">
Buhlmann, Peter, and Torsten Hothorn. 2007. <span>“<span class="nocase">Boosting Algorithms: Regularization, Prediction and Model Fitting</span>.”</span> <em>Statist. Sci.</em> 22 (4): 477–505. <a href="https://doi.org/10.1214/07-STS242">https://doi.org/10.1214/07-STS242</a>.
</div>
<div id="ref-Buhlmann2003" class="csl-entry" role="listitem">
Bühlmann, Peter, and Bin Yu. 2003. <span>“<span class="nocase">Boosting With the L2 Loss</span>.”</span> <em>Journal of the American Statistical Association</em> 98 (462): 324–39. <a href="https://doi.org/10.1198/016214503000125">https://doi.org/10.1198/016214503000125</a>.
</div>
<div id="ref-pkgxgboost" class="csl-entry" role="listitem">
Chen, Tianqi, Tong He, Michael Benesty, Vadim Khotilovich, Yuan Tang, Hyunsu Cho, Kailong Chen, et al. 2020. <span>“<span class="nocase">xgboost: Extreme Gradient Boosting</span>.”</span> CRAN. <a href="https://cran.r-project.org/package=xgboost">https://cran.r-project.org/package=xgboost</a>.
</div>
<div id="ref-Chen2013" class="csl-entry" role="listitem">
Chen, Yifei, Zhenyu Jia, Dan Mercola, and Xiaohui Xie. 2013. <span>“<span class="nocase">A Gradient Boosting Algorithm for Survival Analysis via Direct Optimization of Concordance Index</span>.”</span> Edited by Lev Klebanov. <em>Computational and Mathematical Methods in Medicine</em> 2013: 873595. <a href="https://doi.org/10.1155/2013/873595">https://doi.org/10.1155/2013/873595</a>.
</div>
<div id="ref-Cox1972" class="csl-entry" role="listitem">
Cox, D. R. 1972. <span>“<span class="nocase">Regression Models and Life-Tables</span>.”</span> <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 34 (2): 187–220.
</div>
<div id="ref-Cox1975" class="csl-entry" role="listitem">
———. 1975. <span>“<span>Partial Likelihood</span>.”</span> <em>Biometrika</em> 62 (2): 269–76. <a href="https://doi.org/10.1080/03610910701884021">https://doi.org/10.1080/03610910701884021</a>.
</div>
<div id="ref-Freund1996" class="csl-entry" role="listitem">
Freund, Yoav, and Robert E Schapire. 1996. <span>“<span class="nocase">Experiments with a new boosting algorithm</span>.”</span> In. Citeseer.
</div>
<div id="ref-Friedman1999" class="csl-entry" role="listitem">
Friedman, Jerome. 1999. <span>“<span>Stochastic Gradient Boosting</span>.”</span> <em>Computational Statistics &amp; Data Analysis</em> 38 (March): 367–78. <a href="https://doi.org/10.1016/S0167-9473(01)00065-2">https://doi.org/10.1016/S0167-9473(01)00065-2</a>.
</div>
<div id="ref-Friedman2001" class="csl-entry" role="listitem">
Friedman, Jerome H. 2001. <span>“<span>Greedy Function Approximation: A Gradient Boosting Machine</span>.”</span> <em>The Annals of Statistics</em> 29 (5): 1189–1232. <a href="http://www.jstor.org/stable/2699986">http://www.jstor.org/stable/2699986</a>.
</div>
<div id="ref-pkggbm" class="csl-entry" role="listitem">
Greenwell, Brandon, Bradley Boehmke, Jay Cunningham, and. GBM Developers. 2019. <span>“<span class="nocase">gbm: Generalized Boosted Regression Models</span>.”</span> CRAN. <a href="https://cran.r-project.org/package=gbm">https://cran.r-project.org/package=gbm</a>.
</div>
<div id="ref-Hastie2001" class="csl-entry" role="listitem">
Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2001. <em><span class="nocase">The Elements of Statistical Learning</span></em>. Springer New York Inc.
</div>
<div id="ref-pkgmboost" class="csl-entry" role="listitem">
Hothorn, Torsten, Peter Buehlmann, Thomas Kneib, Matthias Schmid, and Benjamin Hofner. 2020. <span>“<span class="nocase">mboost: Model-Based Boosting</span>.”</span> CRAN. <a href="https://cran.r-project.org/package=mboost">https://cran.r-project.org/package=mboost</a>.
</div>
<div id="ref-Johnson2011" class="csl-entry" role="listitem">
Johnson, Brent A, and Qi Long. 2011. <span>“<span class="nocase">Survival ensembles by the sum of pairwise differences with application to lung cancer microarray studies</span>.”</span> <em>Ann. Appl. Stat.</em> 5 (2A): 1081–101. <a href="https://doi.org/10.1214/10-AOAS426">https://doi.org/10.1214/10-AOAS426</a>.
</div>
<div id="ref-Klein2003" class="csl-entry" role="listitem">
Klein, John P, and Melvin L Moeschberger. 2003. <em><span class="nocase">Survival analysis: techniques for censored and truncated data</span></em>. 2nd ed. Springer Science &amp; Business Media.
</div>
<div id="ref-Lee2018" class="csl-entry" role="listitem">
Lee, Donald K K, Ningyuan Chen, and Hemant Ishwaran. 2019. <span>“<span class="nocase">Boosted nonparametric hazards with time-dependent covariates</span>.”</span> <a href="https://arxiv.org/abs/arXiv:1701.07926v6">https://arxiv.org/abs/arXiv:1701.07926v6</a>.
</div>
<div id="ref-Lundberg2017" class="csl-entry" role="listitem">
Lundberg, Scott M, and Su-In Lee. 2017. <span>“<span class="nocase">A Unified Approach to Interpreting Model Predictions</span>.”</span> <em>Advances in Neural Information Processing Systems</em> 30.
</div>
<div id="ref-Ma2006" class="csl-entry" role="listitem">
Ma, Shuangge, and Jian Huang. 2006. <span>“<span class="nocase">Regularized ROC method for disease classification and biomarker selection with microarray data</span>.”</span> <em>Bioinformatics (Oxford, England)</em> 21 (January): 4356–62. <a href="https://doi.org/10.1093/bioinformatics/bti724">https://doi.org/10.1093/bioinformatics/bti724</a>.
</div>
<div id="ref-Mayr2016" class="csl-entry" role="listitem">
Mayr, Andreas, Benjamin Hofner, and Matthias Schmid. 2016. <span>“<span class="nocase">Boosting the discriminatory power of sparse survival models via optimization of the concordance index and stability selection</span>.”</span> <em>BMC Bioinformatics</em> 17 (1): 288. <a href="https://doi.org/10.1186/s12859-016-1149-8">https://doi.org/10.1186/s12859-016-1149-8</a>.
</div>
<div id="ref-Mayr2014" class="csl-entry" role="listitem">
Mayr, Andreas, and Matthias Schmid. 2014. <span>“<span class="nocase">Boosting the concordance index for survival data–a unified framework to derive and evaluate biomarker combinations</span>.”</span> <em>PloS One</em> 9 (1): e84483–83. <a href="https://doi.org/10.1371/journal.pone.0084483">https://doi.org/10.1371/journal.pone.0084483</a>.
</div>
<div id="ref-Meinshausen2010" class="csl-entry" role="listitem">
Meinshausen, Nicolai, and Peter Bühlmann. 2010. <span>“<span class="nocase">Stability selection</span>.”</span> <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 72 (4): 417–73. <a href="https://doi.org/10.1111/j.1467-9868.2010.00740.x">https://doi.org/10.1111/j.1467-9868.2010.00740.x</a>.
</div>
<div id="ref-Ridgeway1999" class="csl-entry" role="listitem">
Ridgeway, Greg. 1999. <span>“<span class="nocase">The state of boosting</span>.”</span> <em>Computing Science and Statistics</em> 31: 172—–181.
</div>
<div id="ref-Schmid2008a" class="csl-entry" role="listitem">
Schmid, Matthias, and Torsten Hothorn. 2008a. <span>“<span class="nocase">Boosting additive models using component-wise P-splines</span>.”</span> <em>Computational Statistics &amp; Data Analysis</em> 53 (2): 298–311.
</div>
<div id="ref-Schmid2008b" class="csl-entry" role="listitem">
———. 2008b. <span>“<span class="nocase">Flexible boosting of accelerated failure time models</span>.”</span> <em>BMC Bioinformatics</em> 9 (February): 269. <a href="https://doi.org/10.1186/1471-2105-9-269">https://doi.org/10.1186/1471-2105-9-269</a>.
</div>
<div id="ref-Sonabend2021b" class="csl-entry" role="listitem">
Sonabend, Raphael Edward Benjamin. 2021. <span>“<span class="nocase">A Theoretical and Methodological Framework for Machine Learning in Survival Analysis: Enabling Transparent and Accessible Predictive Modelling on Right-Censored Time-to-Event Data</span>.”</span> PhD, University College London (UCL). <a href="https://discovery.ucl.ac.uk/id/eprint/10129352/">https://discovery.ucl.ac.uk/id/eprint/10129352/</a>.
</div>
<div id="ref-Tutz2007" class="csl-entry" role="listitem">
Tutz, Gerhard, and Harald Binder. 2007. <span>“<span>Boosting Ridge Regression</span>.”</span> <em>Computational Statistics &amp; Data Analysis</em> 51 (February): 6044–59. <a href="https://doi.org/10.1016/j.csda.2006.11.041">https://doi.org/10.1016/j.csda.2006.11.041</a>.
</div>
<div id="ref-pkgbujar" class="csl-entry" role="listitem">
Wang, Zhu. 2019. <span>“<span class="nocase">bujar: Buckley-James Regression for Survival Data with High-Dimensional Covariates</span>.”</span> CRAN. <a href="https://cran.r-project.org/package=bujar">https://cran.r-project.org/package=bujar</a>.
</div>
<div id="ref-Wang2010" class="csl-entry" role="listitem">
Wang, Zhu, and C Y Wang. 2010. <span>“<span class="nocase">Buckley-James Boosting for Survival Analysis with High-Dimensional Biomarker Data</span>.”</span> <em>Statistical Applications in Genetics and Molecular Biology</em> 9 (1). https://doi.org/<a href="https://doi.org/10.2202/1544-6115.1550">https://doi.org/10.2202/1544-6115.1550</a>.
</div>
<div id="ref-Wei1992" class="csl-entry" role="listitem">
Wei, L J. 1992. <span>“<span class="nocase">The Accelerated Failure Time Model: A Useful Alternative to the Cox Regression Model in Survival Analysis</span>.”</span> <em>Statistics in Medicine</em> 11: 1871–79.
</div>
</div>
</section></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./svm.html" class="pagination-link  aria-label=" vector="" machines="">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Support Vector Machines</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./neuralnetworks.html" class="pagination-link" aria-label="<span class='chapter-number'>16</span>&nbsp; <span class='chapter-title'>Neural Networks</span>">
        <span class="nav-page-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Neural Networks</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="an">abstract:</span><span class="co"> TODO (150-200 WORDS)</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>{{&lt; include _setup.qmd &gt;}}</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu"># Boosting Methods</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>{{&lt; include _wip.qmd &gt;}}</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="fu">## Gradient Boosting Machines {#sec-surv-ml-models-boost}</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="fu">### Gradient Boosting Machines for Regression {#sec-surv-ml-models-boost-regr}</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>Boosting is a machine learning strategy that can be applied to any model class. Similarly to random forests, boosting is an 'ensemble' method that creates a model from a 'committee' of learners. The committee is formed of 'weak' learners that make poor predictions individually, which creates a 'slow learning' approach (as opposed to 'greedy') that requires many iterations for a model to be a good fit to the data. Boosting models are similar to random forests in that both make predictions from a large committee of learners. However the two differ in how this committee is combined to a prediction. In random forest algorithms, each decision tree is grown independently and their predictions are combined by a simple mean calculation. In contrast, weak learners in a boosting model are fit sequentially and predictions are made by a linear combination of predictions from each learner. With respect to transparency, it is simpler to inspect 100 trees in a random forest, than it is to inspect 100 weak learners in a boosted model, though both are considered black-box models.</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>The best known boosting algorithm is likely AdaBoost  <span class="co">[</span><span class="ot">@Freund1996</span><span class="co">]</span>, which is more generally a Forward Stagewise Additive Model (FSAM) with an exponential loss  <span class="co">[</span><span class="ot">@Hastie2001</span><span class="co">]</span>. Today, the most widely used boosting model is the Gradient Boosting Machine (GBM)  <span class="co">[</span><span class="ot">@Friedman2001</span><span class="co">]</span>.</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Training a GBM {.unnumbered .unlisted}</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>Pseudo-code for training a componentwise GBM is presented in (@alg-surv-gbm). The term 'componentwise' is explained fully below, only this variation of GBM is presented as it is the most common in implementation  <span class="co">[</span><span class="ot">@pkggbm; @pkgmboost</span><span class="co">]</span>. Line 1: the initial function is initialized as $g_0 = 0$;\footnote{Some algorithms may instead initialize $g_0$ by finding the value that minimises the given loss function, however setting $g_0 = 0$ appears to be the most common practice for componentwise GBMs.} Line 2: iterate over boosting steps $m = 1,...,M$ and; Line 3: randomly sample the training data, $\dtrain$, to a smaller sample, $\dtrain^*$, this may be ignored if $\phi = 1$; Line 4: for all training observations in the reduced dataset, $i \in \{i:X_i \in \dtrain^*<span class="sc">\}</span>$, compute the negative gradient, $r_{im}$, of the differentiable loss function, $L$, with respect to predictions from the previous iteration, $g_{m-1}(X_i)$; Line 5: fit one weak learner for each feature, $j = 1,...,p$, in the training data, where the feature, $X_{;j}$, is the single covariate and $r_{im}$ are the labels; Line 6: select the optimal weak learner as the one that minimises the squared error between the prediction and the true gradient; Line 7: update the fitted model by adding the optimal weak learner with a shrinkage penalty, $\nu$; Line 9: return the model updated in the final iteration as the fitted GBM.</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>\begin{algorithm}<span class="co">[</span><span class="ot">H</span><span class="co">]</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>\caption{Training a componentwise Gradient Boosting Machine. <span class="sc">\\</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>**Input** Training data, $\dtrain = <span class="sc">\{</span>(X_1,Y_1),...,(X_n,Y_n)<span class="sc">\}</span>$, where $(X_i,Y_i) \iid (X,Y)$. Differentiable loss, $L$. Hyper-parameters: sampling fraction, $\phi \in (0,1]$; step-size, $\nu \in  (0,1]$; number of iterations, $M \in \PReals$. <span class="sc">\\</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>**Output** Boosted model, $\hatg$.}</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>\begin{algorithmic}<span class="co">[</span><span class="ot">1</span><span class="co">]</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>\State Initialize $g_0 \gets 0$</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>\For{$m = 1,...,M$}</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>\State $\dtrain^* \gets $ Randomly sample $\dtrain$ w.p. $\phi$</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>\State $r_{im} \gets -<span class="co">[</span><span class="ot">\frac{\partial L(y_i, g_{m-1}(X_i))}{\partial g_{m-1}(X_i)}</span><span class="co">]</span>, i \in <span class="sc">\{</span>i: X_i \in \dtrain^*<span class="sc">\}</span>$</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>\State Fit $p$ weak learners, $w_j$ to $(X_i, r_{im}), j = 1,..,p$</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>\State $j^* \gets \argmin_{j = 1,..,p} \sum_{i \in <span class="sc">\{</span>i: X_i \in \dtrain^*<span class="sc">\}</span>}</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>(r_{im} - w_j(X_i))^2$</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>\State $g_m \gets g_{m-1} + \nu w_{j^*}$</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>\EndFor</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>\State $\hatg \gets g_M$</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>\Return $\hatg$</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>\end{algorithmic}</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>\end{algorithm}</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- {#alg-surv-gbm} --&gt;</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Predicting with a GBM {.unnumbered .unlisted}</span></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>In general, predictions from a trained GBM are simple to compute as the fitted model (and all individual weak learners) take the same inputs, which are passed sequentially to each of the weak learners. In (@alg-surv-gbm), the fitted GBM is a single model, which is a linear combination of weak learners. Instead one could think of the returned model as a collection of the optimal weak learners, i.e. let $w_{m;j^*}$ be the optimal weak learner from iteration $m$ and let the fitted GBM (Line 9 (@alg-surv-gbm)) be $\hatg := \{w_{m;j^*}<span class="sc">\}</span>^M_{m=1}$.\footnote{This formulation is computationally and mathematically identical to the formulation in (@alg-surv-gbm) and is practically more convenient for implementation, indeed this is the implementation in $\pkg{mboost}$  <span class="co">[</span><span class="ot">@pkgmboost</span><span class="co">]</span>. Despite this, the formulation in (@alg-surv-gbm) is common in the literature, which often conflates model training and predicting.} With this formulation, making predictions from the GBM can be demonstrated simply in (@alg-surv-gbm-pred).</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>\begin{algorithm}<span class="co">[</span><span class="ot">H</span><span class="co">]</span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>\caption{Predicting from a Gradient Boosting Machine. <span class="sc">\\</span></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>**Input** Fitted GBM, $\hatg := <span class="sc">\{</span>w_{m;j^*}\}^M_{m=1}$, trained with step-size $\nu$. Testing data $X^* \sim \calX$. <span class="sc">\\</span></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>**Output** Prediction, $\hatY \sim \calY$.}</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>\begin{algorithmic}<span class="co">[</span><span class="ot">1</span><span class="co">]</span></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>\State Initialize $\hatY = 0$</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>\For{$m = 1,...,M$}</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>\State $\hatY \gets \hatY + \nu w_{m;j^*}(X^*)$</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>\EndFor</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>\Return $\hatY$</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>\end{algorithmic}</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>\end{algorithm}</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- {#alg-surv-gbm-pred} --&gt;</span></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>The biggest advantages of boosting are firstly relatively few hyper-parameters, which all have a meaningful and intuitive interpretation, and secondly its modular nature means that, like random forests, relatively few parts need to be updated to derive a novel model. First the model components will be discussed and then the hyper-parameters. Once this has been established, deriving survival variants can be simply presented.</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Losses and Learners</span></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Losses {.unnumbered .unlisted}</span></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>Building a GBM requires selection of the loss to minimise, $L$, selection of weak learners, $w_j$, and a method to compare the weak learners to the loss gradient. The only constraint in selecting a loss, $L$, is that it must be differentiable with respect to $g(X)$  <span class="co">[</span><span class="ot">@Hastie2001</span><span class="co">]</span>. Of course a sensible loss should be chosen (a classification loss should not be used for regression) and different choices of losses will optimise different tasks. $L_2$-losses have been demonstrated to be effective for regression boosting, especially with high-dimensional data  <span class="co">[</span><span class="ot">@Buhlmann2003</span><span class="co">]</span>; this is referred to as $L_2$-boosting.</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Weak Learners {.unnumbered .unlisted}</span></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>(@alg-surv-gbm) is specifically a *componentwise* GBM  <span class="co">[</span><span class="ot">@Buhlmann2003</span><span class="co">]</span>, which means that each of the $p$ weak learners is fit on a single covariate from the data. This method simplifies selecting the possible choices for the weak learners to selecting the class of weak learner (below). Additionally, componentwise GBMs provide a natural and interpretable feature selection method as selecting the optimal learner ((@alg-surv-gbm), line 6) corresponds to selecting the feature that minimises the chosen loss in iteration $m$.</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>Only three weak, or 'base', learner classes are commonly used in componentwise GBMs  <span class="co">[</span><span class="ot">@pkgmboost; @Wang2010</span><span class="co">]</span>. These are linear least squares  <span class="co">[</span><span class="ot">@Friedman2001</span><span class="co">]</span>, smoothing splines  <span class="co">[</span><span class="ot">@Buhlmann2003</span><span class="co">]</span>, and decision stumps  <span class="co">[</span><span class="ot">@Buhlmann2003; @Friedman2001</span><span class="co">]</span>. Let $L$ be a loss with negative gradient for observation $i$ in the $m$th iteration, $r_{im}$, and let $\dtrain$ be the usual training data. For linear least squares, an individual weak learner is fit by  <span class="co">[</span><span class="ot">@Friedman2001; @Wang2010</span><span class="co">]</span>,</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>w_j(\dtrain) = X_{;j}\frac{\sum^n_{i=1} X_{ij}r_{im}}{\sum^n_{i=1} (X_{ij})^2}</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>For smoothing splines, usually cubic splines are implemented, these fit weak learners as the minimisers of the equation  <span class="co">[</span><span class="ot">@Buhlmann2003</span><span class="co">]</span>,</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>w_j := \argmin_{g \in \calG} \mean{(r_{im} - g(X_{ij}))^2} + \lambda \int (g''(u))^2 du</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>where $g''$ is the second derivative of $g$, $\calG$ is the set of functions, <span class="sc">\\</span> $\calG := <span class="sc">\{</span>g: g \text{ is twice continuously differentiable and } \int (g''(x))^2 dx &lt; \infty<span class="sc">\}</span>$, and $\lambda$ is a hyper-parameter usually chosen so that the number of degrees of freedom, df, is small, with df $\approx 4$ suggested  <span class="co">[</span><span class="ot">@Buhlmann2003; @Schmid2008a; @Wang2010</span><span class="co">]</span>.</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>Finally for decision stumps ((@fig-surv-stump)), a decision tree, $w_j$, is grown (@alg-dt-fit) on $(X_{;j}, r_m)$ to depth one (equivalently to two terminal nodes) for each of the $j = 1,...,p$ covariates  <span class="co">[</span><span class="ot">@Friedman2001</span><span class="co">]</span>.</span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{figure}[H]</span></span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a><span class="co">\centering</span></span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a><span class="co">\begin{tikzpicture}[state/.style={circle, draw, minimum size=15mm}]</span></span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t0) [state]  {Root};</span></span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t4) [state, draw = none, below=of t0, yshift = 5mm]{};</span></span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t1) [state,left=of t4] {Node 1};</span></span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t2) [state,right=of t4, label={[label distance=1.0cm]0: - Depth 1}] {Node 2};</span></span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a><span class="co">\node (t3) [state, draw = none, above=of t2, yshift = -5mm, label={[label distance=1.0cm]0: - Depth 0}]{};</span></span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a><span class="co">\path[-]</span></span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a><span class="co">   (t0)  edge (t1)</span></span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a><span class="co">   (t0)  edge (t2);</span></span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a><span class="co">\draw [dashed] (-5,1) -- (5,1);</span></span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a><span class="co">\draw [dashed] (-5,-1) -- (5, -1);</span></span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a><span class="co">\draw [dashed] (-5,-3) -- (5,-3);</span></span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a><span class="co">\end{tikzpicture}</span></span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a><span class="co">\caption[A decision stump]{A decision tree of depth one, known as a decision stump. The root layer is separated at depth 0 from the terminal nodes at depth 1. A decision stump is defined by a decision tree with a single split at the root node.}</span></span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a><span class="co"> {#fig-surv-stump}</span></span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a><span class="co">\end{figure} --&gt;</span></span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Hyper-Parameters</span></span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a>The hyper-parameters in (@alg-surv-gbm) are the 'step-size', $\nu$, the sampling fraction, $\phi$, and the number of iterations, $M$.</span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Number of iterations, $M$ {.unnumbered .unlisted}</span></span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a>The number of iterations is often claimed to be the most important hyper-parameter in GBMs and it has been demonstrated that as the number of iterations increases, so too does the model performance (with respect to a given loss on test data) up to a certain point of overfitting  <span class="co">[</span><span class="ot">@Buhlmann2006; @Hastie2001; @Schmid2008a</span><span class="co">]</span>. This is an intuitive result as the foundation of boosting rests on the idea that weak learners can slowly be combined to form a single powerful model. This is especially true in componentwise GBMs as time is required to learn which features are important. Finding the optimal value of $M$ is critical as a value too small will result in poor predictions, whilst a value too large will result in model overfitting. Two primary methods have been suggested for finding the optimal value of $M$. The first is to find the $M \in \PNaturals$ that minimises a given measure based on the AIC  <span class="co">[</span><span class="ot">@Akaike1974</span><span class="co">]</span>, the second is the 'usual' empirical selection by nested cross-validation. In practice the latter method is usually employed.</span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Step-size, $\nu$ {.unnumbered .unlisted}</span></span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a>The step-size parameter ((@alg-surv-gbm), line 7), $\nu$, is a shrinkage parameter that controls the contribution of each weak learner at each iteration. Several studies have demonstrated that GBMs perform better when shrinkage is applied and a value of $\nu = 0.1$ is often suggested  <span class="co">[</span><span class="ot">@Buhlmann2007; @Hastie2001; @Friedman2001; @Lee2018; @Schmid2008a</span><span class="co">]</span>. The optimal values of $\nu$ and $M$ depend on each other, such that smaller values of $\nu$ require larger values of $M$, and vice versa. This is intuitive as smaller $\nu$ results in a slower learning algorithm and therefore more iterations are required to fit the model. Accurately selecting the $M$ parameter is generally considered to be of more importance, and therefore a value of $\nu$ is often chosen heuristically (e.g. the common value of $0.1$) and then $M$ is tuned by cross-validation and/or early-stopping.</span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Sampling Fraction, $\phi$ {.unnumbered .unlisted}</span></span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a>Motivated by the success of bagging in random forests, stochastic gradient boosting  <span class="co">[</span><span class="ot">@Friedman1999</span><span class="co">]</span> randomly samples the data in each iteration. It appears that subsampling performs best when also combined with shrinkage  <span class="co">[</span><span class="ot">@Hastie2001</span><span class="co">]</span> and as with the other hyper-parameters, selection of $\phi$ is usually performed by nested cross-validation.</span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a><span class="fu">### Gradient Boosting Machines for Survival Analysis {#sec-surv-ml-models-boost-surv}</span></span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a>In a componentwise GBM framework, adapting boosting to survival analysis requires only selecting a sensible choice of loss function $L$. Therefore fitting and predicting algorithms for componentwise survival GBMs are not discussed as these are fully described in algorithms (@alg-surv-gbm) and (@alg-surv-gbm-pred) respectively. However, some GBMs in this section are not componentwise and therefore require some more detailed consideration. Interestingly, unlike other machine learning algorithms that historically ignored survival analysis, early GBM papers considered boosting in a survival context  <span class="co">[</span><span class="ot">@Ridgeway1999</span><span class="co">]</span>; though there appears to be a decade gap before further considerations were made in the survival setting. After that period, several developments by Binder, Schmid, and Hothorn, adapted componentwise GBMs to a framework suitable for survival analysis. Their developments are covered exhaustively in the R packages $\pkg{gbm}$  <span class="co">[</span><span class="ot">@pkggbm</span><span class="co">]</span> and $\pkg{mboost}$  <span class="co">[</span><span class="ot">@pkgmboost</span><span class="co">]</span>. This survey continues with the predict type taxonomy.</span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Cox Survival Models</span></span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a>All survival GBMs make ranking predictions and none are able to directly predict survival distributions. However, the GBMs discussed in this section all have natural compositions to distributions as they are modelled in the semi-parametric proportional hazards framework (@sec-car). The models discussed in the next section can also be composed to distributions though the choice of composition is less clear and therefore they are listed as pure 'ranking' models.</span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a>**GBM-COX** {#mod-gdcox} {#mod-gbmcox}<span class="sc">\\</span></span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a>The 'GBM-COX' aims to predict the distribution of data following the PH assumption by estimating the coefficients of a Cox model in a boosting framework  <span class="co">[</span><span class="ot">@Ridgeway1999</span><span class="co">]</span>. The model attempts to predict $\hatg(X^*) = \hat{\eta} := X^*\hat{\beta}$, by minimising a suitable loss function. As the model assumes a PH specification, the natural loss to optimise is the Cox partial likelihood  <span class="co">[</span><span class="ot">@Cox1972; @Cox1975</span><span class="co">]</span>, more specifically to minimise the negative partial log-likelihood, $-l$, where</span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a>l(\beta) = \sum^n_{i=1} \Delta_i \Big<span class="co">[</span><span class="ot">\eta_i \ - \ \log\Big(\sum^n_{j \in \calR_{t_i}} \exp(\eta_i)\Big)\Big</span><span class="co">]</span></span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a>$$ {#eq-surv-logpartial}</span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a>where $\calR_{t_i}$ is the set of patients at risk at time $t_i$ and $\eta_i = X_i\beta$. The gradient of $-l(\beta)$ at iteration $m$ is</span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a>r_{im} := \Delta_i - \sum^n_{j=1} \Delta_j \frac{\II(T_i \geq T_j) \exp(g_{m-1}(X_i))}{\sum_{k \in \calR_{t_j}} \exp(g_{m-1}(X_k))}</span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a>$$ {#eq-surv-partialgrad}</span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a>where $g_{m-1}(X_i) = X_i\beta_{m-1}$.</span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a>(@alg-surv-gbm) now follows with the loss $L := -l(\beta)$.\footnote{Early implementations and publications of the GBM algorithm  <span class="co">[</span><span class="ot">@Friedman1999; @Friedman2001</span><span class="co">]</span> included an additional step to the algorithm in which a step size is estimated by line search. More recent research has determined that this additional step is unneccesary  <span class="co">[</span><span class="ot">@Buhlmann2007</span><span class="co">]</span> and the line search method does not appear to be used in practice.}</span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a>The GBM-COX is implemented in $\pkg{mboost}$  <span class="co">[</span><span class="ot">@pkgmboost</span><span class="co">]</span> and has been demonstrated to perform well even when the data violates the PH assumption  <span class="co">[</span><span class="ot">@Johnson2011</span><span class="co">]</span>. Despite being a black-box, GBMs are well-understood and individual weak learners are highly interpretable, thus making GBMs highly transparent. Several well-established software packages implement GBM-COX and those that do not tend to be very flexible with respect to custom implementations.</span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a>\noindent **CoxBoost** {#mod-coxboost}<span class="sc">\\</span></span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a>The CoxBoost algorithm boosts the Cox PH by optimising the penalized partial-log likelihood; additionally the algorithm allows for mandatory (or 'forced') covariates  <span class="co">[</span><span class="ot">@Binder2008</span><span class="co">]</span>. In medical domains the inclusion of mandatory covariates may be essential, either for model interpretability, or due to prior expert knowledge. This is not a feature usually supported by boosting. CoxBoost deviates from (@alg-surv-gbm) by instead using an offset-based approach for generalized linear models  <span class="co">[</span><span class="ot">@Tutz2007</span><span class="co">]</span>. This model has a non-componentwise and componentwise framework but only the latter is implemented by the authors  <span class="co">[</span><span class="ot">@pkgcoxboost</span><span class="co">]</span> and discussed here. Let $\calI_{mand}$ be the indices of the mandatory covariates to be included in all iterations, $m = 1,...,M$, then for an iteration $m$ the indices to consider for fitting are the set</span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a> I_m = <span class="sc">\{\{</span>1<span class="sc">\}</span> \cup \calI_{mand},...,<span class="sc">\{</span>p<span class="sc">\}</span> \cup \calI_{mand}<span class="sc">\}</span> / <span class="sc">\{\{</span>j<span class="sc">\}</span> \cup \calI_{mand} : j \in \calI_{mand}<span class="sc">\}</span></span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a>i.e. in each iteration the algorithm fits a weak learner on the mandatory covariates and one additional (non-mandatory) covariate (hence still being componentwise).</span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a>In addition, a penalty matrix $\mathbf{P} \in \Reals^{p \times p}$ is considered such that $P_{ii} &gt; 0$ implies that covariate $i$ is penalized and $P_{ii} = 0$ means no penalization. In practice this is usually a diagonal matrix  <span class="co">[</span><span class="ot">@Binder2008</span><span class="co">]</span> and by setting $P_{ii} = 0, i \in I_{mand}$ and $P_{ii} &gt; 0, i \not\in I_{mand}$, only optional (non-mandatory) covariates are penalized. The penalty matrix can be allowed to vary with each iteration, which allows for a highly flexible approach, however in implementation a simpler approach is to either select a single penalty to be applied in each iteration step or to have a single penalty matrix  <span class="co">[</span><span class="ot">@pkgcoxboost</span><span class="co">]</span>.</span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a>At the $m$th iteration and the $k$th set of indices to consider ($k = 1,...,p$), the loss to optimize is the penalized partial-log likelihood given by</span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a>&amp;l_{pen}(\gamma_{mk}) = \sum^n_{i=1} \Delta_i \Big<span class="co">[</span><span class="ot">\eta_{i,m-1} + X_{i,\calI_{mk}}\gamma^T_{mk}\Big</span><span class="co">]</span> - <span class="sc">\\</span></span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a>&amp;\quad\Delta_i\log\Big(\sum^n_{j = 1} \II(T_j \leq T_i) \exp(\eta_{i,{m-1}} + X_{i, \calI_{mk}}\gamma^T_{mk}\Big) - \lambda\gamma_{mk}\mathbf{P}_{mk}\gamma^T_{mk}</span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a>where $\eta_{i,m} = X_i\beta_m$, $\gamma_{mk}$ are the coefficients corresponding to the covariates in $\calI_{mk}$ which is the possible set of candidates for a subset of total candidates $k = 1,...,p$, $\mathbf{P}_{mk}$ is the penalty matrix, and $\lambda$ is a penalty hyper-parameter to be tuned or selected.\footnote{On notation, note that $\mathbf{P}_{ij}$ refers to the penalty matrix in the $i$th iteration for the $j$th set of indices, whereas $P_{ij}$ is the $(i,j)$th element in the matrix $\mathbf{P}$.}</span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a>In each iteration, all potential candidate sets (the union of mandatory covariates and one other covariate) are updated by</span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a>\hat{\gamma}_{mk} = \mathbf{I}^{-1}_{pen}(0)U(0)</span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a>where $U(\gamma) = \partial l / \partial \gamma (\gamma)$ and $\mathbf{I}^{-1}_{pen} = \partial^2 l/\partial\gamma\partial\gamma^T (\gamma + \lambda\mathbf{P}_{mk})$ are the first and second derivatives of the unpenalized partial-log-likelihood. The optimal set is then found as</span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a>k^* := \argmax_k l_{pen}(\gamma_{mk})</span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a>and the estimated coefficients are updated with</span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a>\hat{\beta}_m = \hat{\beta}_{m-1} + \gamma_{mk^*}, \quad k^* \in \calI_{mk}</span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a>The step size, $\nu$, is then one, but this could potentially be altered.</span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a>The algorithm deviates from (@alg-surv-gbm) as $l_{pen}$ is directly optimised and not its gradient, additionally model coefficients are iteratively updated instead of a more general model form. The algorithm is implemented in $\pkg{CoxBoost}$  <span class="co">[</span><span class="ot">@pkgcoxboost</span><span class="co">]</span>. Experiments suggest that including the 'correct' mandatory covariates may increase predictive performance  <span class="co">[</span><span class="ot">@Binder2008</span><span class="co">]</span>. CoxBoost is less accessible than other boosting methods as it requires a unique boosting algorithm, as such only one off-shelf implementation appears to exist and even this implementation has been removed from CRAN as of 2020-11-11. CoxBoost is also less transparent as the underlying algorithm is more complex, though is well-explained by the authors  <span class="co">[</span><span class="ot">@Binder2008</span><span class="co">]</span>. There is good indication that CoxBoost is performant <span class="co">[</span><span class="ot">@Sonabend2021b</span><span class="co">]</span>. In a non-medical domain, where performance may be the most important metric, then perhaps CoxBoost can be recommended as a powerful model. However, when sensitive predictions are required, CoxBoost may not be recommended. Further papers studying the model and more off-shelf implementations could change this in the future.</span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Ranking Survival Models</span></span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a>The ranking survival models in this section are all unified as they make predictions of the linear predictor, $\hat{g}(X^*) = X^*\hat{\beta}$.\footnote{This is commonly referred to as a 'linear predictor' as it directly relates to the boosted linear model (e.g. Cox PH), however it is more accurately a 'prognostic index' as the final prediction is not the true linear predictor.}</span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a>**GBM-AFT** {#mod-gbmaft}<span class="sc">\\</span></span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a>Schmid and Hothorn (2008)  <span class="co">[</span><span class="ot">@Schmid2008b</span><span class="co">]</span> published a GBM for accelerated failure time models in response to PH-boosted models that may not be suitable for non-PH data. Their model fits into the GBM framework by assuming a fully-parametric AFT and simultaneously estimating the linear predictor, $\hatg(X_i) =\hat{\eta}$, and the scale parameter, $\hat{\sigma}$, controlling the amount of noise in the distribution. The (fully-parametric) AFT is defined by</span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a>\log Y = \eta + \sigma W</span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a>where $W$ is a random variable independent of the covariates that follows a given distribution and controls the noise in the model. By assuming a distribution on $W$, a distribution is assumed for the full parametric model. The full likelihood, $\calL$, is given by</span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a>\calL(\dtrain|\mu, \sigma, W) = \prod^n_{i=1} \Big<span class="co">[</span><span class="ot">\frac{1}{\sigma} f_W\Big(\frac{\log(T_i) - \mu}{\sigma}\Big)\Big</span><span class="co">]</span>^{\Delta_i}\Big<span class="co">[</span><span class="ot">S_W\Big(\frac{\log(T_i) - \mu}{\sigma}\Big)\Big</span><span class="co">]</span>^{(1-\Delta_i)}</span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a>$$ {#eq-surv-aft-like}</span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a>where $f_W, S_W$ is the pdf and survival function of $W$ for a given distribution. By setting $\mu := g(X_i)$, $\sigma$ is then rescaled according to known results depending on the distribution  <span class="co">[</span><span class="ot">@Klein2003</span><span class="co">]</span>. The gradient of the negative log-likelihood, $-l$, is minimised in the $m$th iteration where</span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a>l(\dtrain|\hat{g}, \hat{\sigma},W) = \sum^n_{i=1} \Delta_i\Big<span class="co">[</span><span class="ot">- \log\sigma + \log f_W\Big(\frac{\log(T_i) - \hat{g}_{m-1}(X_i)}{\hat{\sigma}_{m-1}}\Big)\Big</span><span class="co">]</span> + <span class="sc">\\</span></span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a>(1-\Delta_i)\Big<span class="co">[</span><span class="ot">\log S_W\Big(\frac{\log(T_i) - \hat{g}_{m-1}(X_i)}{\hat{\sigma}_{m-1}}\Big)\Big</span><span class="co">]</span></span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a>where $\hatg_{m-1}, \hat{\sigma}_{m-1}$ are the location-scale parameters estimated in the previous iteration. Note this key difference to other GBM methods in which two estimates are made in each iteration step. In order to allow for this, (@alg-surv-gbm) is run as normal but in addition, after updating $\hatg_m$, one then updates $\hat{\sigma}_m$ as</span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a>\hat{\sigma}_m := \argmin_\sigma -l(\dtrain|g_m,\sigma, W)</span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a>$\sigma_0$ is initialized at the start of the algorithm with $\sigma_0 = 1$ suggested  <span class="co">[</span><span class="ot">@Schmid2008b</span><span class="co">]</span>.</span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a>This algorithm provides a ranking prediction without enforcing an often-unrealistic PH assumption on the data. This model is implemented in $\pkg{mboost}$ and $\pkg{xgboost}$. Experiments indicate that this may outperform the Cox PH  <span class="co">[</span><span class="ot">@Schmid2008b</span><span class="co">]</span>. Moreover the model has the same transparency and accessibility as the GBM-COX.</span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a>**GBM-GEH** {#mod-gbmgeh}<span class="sc">\\</span></span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a>The concordance index is likely the most popular measure of discrimination, this in part due to the fact that it makes little-to-no assumptions about the data (@sec-eval-crank). A less common measure is the Gehan loss, motivated by the semi-parametric AFT. Johnson and Long proposed the GBM with Gehan loss, here termed GBM-GEH, to optimise separation within an AFT framework  <span class="co">[</span><span class="ot">@Johnson2011</span><span class="co">]</span>.</span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a>The semi-parametric AFT is defined by the linear model,</span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a>\log Y = \eta + \epsilon</span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a>for some error term, $\epsilon$.</span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a>The D-dimensional Gehan loss to minimise is given by,</span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a>G_D(\dtrain, \hatg) = -\frac{1}{n^2} \sum^n_{i=1}\sum^n_{j=1} \Delta_i (\hat{e}_i - \hat{e}_j)\II(\hat{e}_i \leq \hat{e}_j)</span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a>where $\hat{e}_i = \log T_i - \hat{g}(X_i)$. The negative gradient of the loss is,</span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a>r_{im} := \frac{\sum^n_{j=1} \Delta_j \II(\hat{e}_{m-1,i} \geq \hat{e}_{m-1,j}) -\Delta_i\II(\hat{e}_{m-1,i} \leq \hat{e}_{m-1,j})}{n}</span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a>where $\hat{e}_{m-1,i} = \log T_i - \hatg_{m-1}(X_i)$.</span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a>(@alg-surv-gbm) then follows naturally substituting the loss and gradient above. The algorithm is implemented in $\pkg{mboost}$. Simulation studies on the performance of the model are inconclusive  <span class="co">[</span><span class="ot">@Johnson2011</span><span class="co">]</span> however the results in <span class="co">[</span><span class="ot">@Sonabend2021b</span><span class="co">]</span> indicate strong predictive performance.</span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a>**GBM-BUJAR** {#mod-gbmbujar}<span class="sc">\\</span></span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a>GBM-BUJAR is another boosted semi-parametric AFT. However the algorithm introduced by Wang and Wang (2010)  <span class="co">[</span><span class="ot">@Wang2010</span><span class="co">]</span> uses Buckley-James imputation and minimisation. This algorithm is almost identical to a regression GBM (i.e. using squared loss or similar for $L$), except with one additional step to iteratively impute censored survival times. Assuming a semi-parametric AFT model, the GBM-BUJAR algorithm iteratively updates imputed outcomes with the Buckley-James estimator  <span class="co">[</span><span class="ot">@Buckley1979</span><span class="co">]</span>,</span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a>T^*_{m, i} := \hatg_{m-1}(X_i) + e_{m-1, i}\Delta_i + (1-\Delta_i)\Big[\KMS(e_{m-1, i})^{-1}\sum_{e_{m-1, j} &gt; e_{m-1, i}} e_{m-1, j}\Delta_j \hatp_{KM}(e_{m-1, j})\Big]</span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a>where $\hatg_{m-1}(X_i) = \hat{\eta}_{m-1}$, and $\KMS, \hatp_{KM}$ are Kaplan-Meier estimates of the survival and probability mass functions respectively fit on some training data, and $e_{m-1,i} := \log(T_i) - g_{m-1}(X_i)$. Once $T^*_{m, i}$ has been updated, (@alg-surv-gbm) continues from with least squares as with any regression model.</span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a>GBM-BUJAR is implemented in $\pkg{bujar}$  <span class="co">[</span><span class="ot">@pkgbujar</span><span class="co">]</span> though without a separated fit/predict interface, its accessibility is therefore limited. There is no evidence of wide usage of this algorithm nor simulation studies demonstrating its predictive ability. Finally, there are many known problems with semi-parametric AFT models and the Buckey-James procedure  <span class="co">[</span><span class="ot">@Wei1992</span><span class="co">]</span>, hence GBM-BUJAR is also not transparent.</span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a>**GBM-UNO** {#mod-gbmuno}<span class="sc">\\</span></span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a>Instead of optimising models based on a given model form, Chen $\etal$ <span class="co">[</span><span class="ot">@Chen2013</span><span class="co">]</span> studied direct optimisation of discrimination by Harrell's C whereas Mayr and Schmid  <span class="co">[</span><span class="ot">@Mayr2014</span><span class="co">]</span> focused instead on Uno's C. Only an implementation of the Uno's C method could be found, this is therefore discussed here and termed 'GBM-UNO'.</span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a>The GBM-UNO attempts to predict $\hatg(X^*) := \hat{\eta}$ by optimising Uno's C (@sec-eval-crank-disc-conc),</span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a>C_U(\hat{g}, \dtrain) = \frac{\sum_{i \neq j}\Delta_i<span class="sc">\{</span>\KMG(T_i)<span class="sc">\}</span>^{-2}\II(T_i &lt; T_j)\II(\hatg(X_i) &gt;\hatg(X_j))}{\sum_{i \neq j}\Delta_i<span class="sc">\{</span>\KMG(T_i)<span class="sc">\}</span>^{-2}\II(T_i &lt; T_j)}</span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a>The GBM algorithm requires that the chosen loss, here $C_U$, be differentiable with respect to $\hatg(X)$, which is not the case here due to the indicator term, $\II(\hatg(X_i) &gt; \hatg(X_j))$. Therefore a smoothed version is instead considered where the indicator is approximated by the sigmoid function  <span class="co">[</span><span class="ot">@Ma2006</span><span class="co">]</span>,</span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a>K(u|\sigma) = (1 + \exp(-u/\sigma))^{-1}</span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a>where $\sigma$ is a hyper-parameter controlling the smoothness of the approximation. The measure to optimise is then,</span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a>C_{USmooth}(\dtrain|\sigma) = \sum_{i \neq j} \frac{k_{ij}}{1 + \exp\big<span class="co">[</span><span class="ot">(\hatg(X_j) - \hatg(X_i))/\sigma)\big</span><span class="co">]</span>}</span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a>$$ {#eq-surv-gbm-cus}</span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a>with</span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a>k_{ij} = \frac{\Delta_i (\KMG(T_i))^{-2}\II(T_i &lt; T_j)}{\sum^n_{i \neq j} \Delta_i(\KMG(T_i))^{-2}\II(T_i &lt; T_j)}</span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a>The negative gradient at iteration $m$ for observation $i$ can then be found,</span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a>r_{im} := - \sum^n_{j = 1} k_{ij} \frac{-\exp(\frac{\hatg_{m-1}(X_j) - \hatg_{m-1}(X_i)}{\sigma})}{\sigma(1 + \exp(\frac{\hatg_{m-1}(X_j) - \hatg_{m-1}(X_i)}{\sigma}))}</span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a>$$ {#eq-surv-gbm-cus-grad}</span>
<span id="cb1-274"><a href="#cb1-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-275"><a href="#cb1-275" aria-hidden="true" tabindex="-1"></a>(@alg-surv-gbm) can then be followed exactly by substituting this loss and gradient; this is implemented in $\pkg{mboost}$. One disadvantage of GBM-UNO is that C-index boosting is more insensitive to overfitting than other methods  <span class="co">[</span><span class="ot">@Mayr2016</span><span class="co">]</span>, therefore stability selection  <span class="co">[</span><span class="ot">@Meinshausen2010</span><span class="co">]</span> can be considered for variable selection; this is possible with $\pkg{mboost}$. Despite directly optimising discrimination, simulation studies do not indicate that this model has better separation than other boosted or lasso models  <span class="co">[</span><span class="ot">@Mayr2014</span><span class="co">]</span>. GBM-UNO has the same accessibility, transparency, and performance <span class="co">[</span><span class="ot">@Sonabend2021b</span><span class="co">]</span> as previous boosting models.</span>
<span id="cb1-276"><a href="#cb1-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-277"><a href="#cb1-277" aria-hidden="true" tabindex="-1"></a><span class="fu">### Conclusions</span></span>
<span id="cb1-278"><a href="#cb1-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-279"><a href="#cb1-279" aria-hidden="true" tabindex="-1"></a>Componentwise gradient boosting machines are a highly flexible and powerful machine learning tool. They have proven particularly useful in survival analysis as minimal adjustments are required to make use of off-shelf software. The flexibility of the algorithm allows all the models above to be implemented in very few $\Rstats$ (and other programming languages) packages.</span>
<span id="cb1-280"><a href="#cb1-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-281"><a href="#cb1-281" aria-hidden="true" tabindex="-1"></a>Boosting is a method that often relies on intensive computing power and therefore dedicated packages, such as $\pkg{xgboost}$  <span class="co">[</span><span class="ot">@pkgxgboost</span><span class="co">]</span>, exist to push CPU/GPUs to their limits in order to optimise predictive performance. This can be viewed as a strong advantage though one should be careful not to focus too much on predictive performance to the detriment of accessibility and transparency.</span>
<span id="cb1-282"><a href="#cb1-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-283"><a href="#cb1-283" aria-hidden="true" tabindex="-1"></a>Boosting, especially with tree learners, is viewed as a black-box model that is increasingly difficult to interpret as the number of iterations increase. However, there are several methods for increasing interpretability, such as variable importance and SHAPs  <span class="co">[</span><span class="ot">@Lundberg2017</span><span class="co">]</span>. There is also evidence that boosting models can outperform the Cox PH  <span class="co">[</span><span class="ot">@Schmid2008b</span><span class="co">]</span> (not something all ML models can claim).</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p>All content licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> <br> © Raphael Sonabend, Andreas Bender.</p>
</div>   
    <div class="nav-footer-center">
<p><a href="https://www.mlsabook.com">Website</a> | <a href="https://github.com/RaphaelS1/MLSA">GitHub</a></p>
<div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/RaphaelS1/MLSA/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li><li><a href="https://github.com/RaphaelS1/MLSA/edit/main/book/boosting.qmd" class="toc-action"><i class="bi empty"></i>Edit this page</a></li><li><a href="https://github.com/RaphaelS1/MLSA/blob/main/book/boosting.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>


</body></html>