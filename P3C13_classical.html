<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Raphael Sonabend and Andreas Bender">

<title>10&nbsp; Traditional Survival Models – Machine Learning in Survival Analysis</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./P3C14_forests.html" rel="next">
<link href="./P2C11_time.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-be0bf478834dcd5fa1d207f31fcfa0a3.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-1008a5a8f5e3c2ed0fd245401abc5d00.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./P3C13_classical.html">Models</a></li><li class="breadcrumb-item"><a href="./P3C13_classical.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Traditional Survival Models</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Machine Learning in Survival Analysis</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/mlsa-book/MLSA/tree/main/book/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./Machine-Learning-in-Survival-Analysis.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P0C0_notation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Symbols and Notation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P0C1_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Survival Analysis and Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P1C3_machinelearning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Machine Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P1C4_survival.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Survival Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P1C5_eha.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Event-history Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P1C6_survtsk.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Survival Task</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Evaluation</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P2C8_rank.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Discrimination</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P2C9_calib.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Calibration</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P2C10_rules.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Scoring Rules</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P2C11_time.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Survival Time Measures</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P3C13_classical.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Traditional Survival Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P3C14_forests.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Random Forests</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P3C15_svm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Support Vector Machines</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P3C16_boosting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Boosting Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P3C17_neural.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Neural Networks</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">Reduction Techniques</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P4C19_reductions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Reductions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P4C20_competing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Competing Risks Pipelines</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P4C21_discrete.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Discrete Time Survival Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P4C22_poisson.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Connections to Poisson Regression and Processes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P4C23_pseudo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Connections to Regression and Imputation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P5C24_conclusions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">FAQs and Outlook</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P5C25_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P5C26_references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-classical-nonpar" id="toc-sec-classical-nonpar" class="nav-link active" data-scroll-target="#sec-classical-nonpar"><span class="header-section-number">10.1</span> Non-Parametric Estimators</a>
  <ul class="collapse">
  <li><a href="#unconditional-estimators" id="toc-unconditional-estimators" class="nav-link" data-scroll-target="#unconditional-estimators"><span class="header-section-number">10.1.1</span> Unconditional estimators</a></li>
  <li><a href="#conditional-estimators" id="toc-conditional-estimators" class="nav-link" data-scroll-target="#conditional-estimators"><span class="header-section-number">10.1.2</span> Conditional estimators</a></li>
  </ul></li>
  <li><a href="#sec-classical-cox" id="toc-sec-classical-cox" class="nav-link" data-scroll-target="#sec-classical-cox"><span class="header-section-number">10.2</span> Proportional Hazards</a>
  <ul class="collapse">
  <li><a href="#sec-ph-semi-parametric" id="toc-sec-ph-semi-parametric" class="nav-link" data-scroll-target="#sec-ph-semi-parametric"><span class="header-section-number">10.2.1</span> Semi-Parametric PH</a></li>
  <li><a href="#sec-ph-parametric" id="toc-sec-ph-parametric" class="nav-link" data-scroll-target="#sec-ph-parametric"><span class="header-section-number">10.2.2</span> Parametric PH</a></li>
  <li><a href="#competing-risks" id="toc-competing-risks" class="nav-link" data-scroll-target="#competing-risks"><span class="header-section-number">10.2.3</span> Competing risks</a></li>
  </ul></li>
  <li><a href="#sec-surv-models-param" id="toc-sec-surv-models-param" class="nav-link" data-scroll-target="#sec-surv-models-param"><span class="header-section-number">10.3</span> Accelerated Failure Time</a>
  <ul class="collapse">
  <li><a href="#understanding-acceleration" id="toc-understanding-acceleration" class="nav-link" data-scroll-target="#understanding-acceleration"><span class="header-section-number">10.3.1</span> Understanding acceleration</a></li>
  <li><a href="#parametric-afts" id="toc-parametric-afts" class="nav-link" data-scroll-target="#parametric-afts"><span class="header-section-number">10.3.2</span> Parametric AFTs</a></li>
  </ul></li>
  <li><a href="#proportional-odds" id="toc-proportional-odds" class="nav-link" data-scroll-target="#proportional-odds"><span class="header-section-number">10.4</span> Proportional Odds</a></li>
  <li><a href="#sec-flexible" id="toc-sec-flexible" class="nav-link" data-scroll-target="#sec-flexible"><span class="header-section-number">10.5</span> Flexible Parametric Models</a></li>
  <li><a href="#sec-classical-improving" id="toc-sec-classical-improving" class="nav-link" data-scroll-target="#sec-classical-improving"><span class="header-section-number">10.6</span> Improving traditional models</a>
  <ul class="collapse">
  <li><a href="#non-linear-effects" id="toc-non-linear-effects" class="nav-link" data-scroll-target="#non-linear-effects"><span class="header-section-number">10.6.1</span> Non-linear effects</a></li>
  <li><a href="#dimension-reduction-and-feature-selection" id="toc-dimension-reduction-and-feature-selection" class="nav-link" data-scroll-target="#dimension-reduction-and-feature-selection"><span class="header-section-number">10.6.2</span> Dimension reduction and feature selection</a></li>
  <li><a href="#ensemble-methods" id="toc-ensemble-methods" class="nav-link" data-scroll-target="#ensemble-methods"><span class="header-section-number">10.6.3</span> Ensemble methods</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">10.7</span> Conclusion</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/mlsa-book/MLSA/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li><li><a href="https://github.com/mlsa-book/MLSA/edit/main/book/P3C13_classical.qmd" class="toc-action"><i class="bi empty"></i>Edit this page</a></li><li><a href="https://github.com/mlsa-book/MLSA/blob/main/book/P3C13_classical.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./P3C13_classical.html">Models</a></li><li class="breadcrumb-item"><a href="./P3C13_classical.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Traditional Survival Models</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-models-classical" class="quarto-section-identifier"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Traditional Survival Models</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="block-title">Abstract</div>
    TODO (150-200 WORDS)
  </div>
</div>


</header>


<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Minor changes expected!
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>This page is a work in progress and minor changes will be made over time.</strong></p>
</div>
</div>
<p>In a predictive setting it can be easy to dismiss ‘traditional models’ and favour testing of more modern ‘machine learning’ tools; this would be a mistake. Firstly, on low dimensional data (small number of variables), traditional methods often outperform machine learning models <span class="citation" data-cites="Burk2025 Beaulac2020">(<a href="P5C26_references.html#ref-Burk2025" role="doc-biblioref">Burk et al. 2024</a>; <a href="P5C26_references.html#ref-Beaulac2020" role="doc-biblioref">Beaulac et al. 2020</a>)</span>. Secondly, even on high-dimensional data, several papers have demonstrated that augmenting traditional models (<a href="#sec-classical-improving" class="quarto-xref"><span>Section 10.6</span></a>) can yield models that outperform machine learning alternatives <span class="citation" data-cites="Zhang2021 Spooner2020">(<a href="P5C26_references.html#ref-Zhang2021" role="doc-biblioref">Zhang et al. 2021</a>; <a href="P5C26_references.html#ref-Spooner2020" role="doc-biblioref">Spooner et al. 2020</a>)</span>. Finally, the majority of machine learning survival algorithms make use of these traditional models, for example by using non-parametric estimators (<a href="#sec-classical-nonpar" class="quarto-xref"><span>Section 10.1</span></a>) and/or assuming a proportional hazards form (<a href="#sec-classical-cox" class="quarto-xref"><span>Section 10.2</span></a>), as a central component to construct an algorithm around. Therefore, a robust understanding of these models is imperative to fairly construct and evaluate machine learning survival models. This chapter begins with demonstrating non-parametric estimators as predictive tools, including a recap of some estimators in <a href="P1C4_survival.html" class="quarto-xref"><span>Chapter 3</span></a>. Semi- and fully-parametric models are then introduced, most notably the Cox proportional hazards model and the accelerated failure time model. Finally, methods to improve traditional models through machine learning methodology is presented.</p>
<section id="sec-classical-nonpar" class="level2" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="sec-classical-nonpar"><span class="header-section-number">10.1</span> Non-Parametric Estimators</h2>
<p>Non-parametric estimators have already been introduced in <a href="P1C4_survival.html#sec-surv-estimation-non-param" class="quarto-xref"><span>Section 3.5.2</span></a>, therefore this section is brief and focuses only on how these estimators can be used as predictive models.</p>
<section id="unconditional-estimators" class="level3" data-number="10.1.1">
<h3 data-number="10.1.1" class="anchored" data-anchor-id="unconditional-estimators"><span class="header-section-number">10.1.1</span> Unconditional estimators</h3>
<p>Recall from <a href="P1C4_survival.html#sec-surv-estimation-non-param" class="quarto-xref"><span>Section 3.5.2</span></a> the Kaplan-Meier and Nelson-Aalen estimators respectively defined by</p>
<p><span id="eq-km-ml-two"><span class="math display">\[
S_{KM}(\tau) = \prod_{k:t_{(k)} \leq \tau}\left(1-\frac{d_{t_{(k)}}}{t_{(k)}}\right)
\tag{10.1}\]</span></span></p>
<p>and</p>
<p><span class="math display">\[
H_{NA}(\tau) = \sum_{k:t_{(k)}\leq \tau} \frac{d_{t_{(k)}}}{n_{t_{(k)}}}.
\]</span></p>
<p>where <span class="math inline">\(d_{t_{(k)}}\)</span> and <span class="math inline">\(n_{t_{(k)}}\)</span> are the number of events and observations at risk at the <span class="math inline">\(k\)</span>th ordered event time, <span class="math inline">\(t_{(k)}\)</span> respectively.</p>
<p>For example, <a href="#fig-km-rats" class="quarto-xref">Figure&nbsp;<span>10.1</span></a> shows the Kaplan-Meier estimator fit on the <code>rats</code> <span class="citation" data-cites="datarats">(<a href="P5C26_references.html#ref-datarats" role="doc-biblioref">Mantel, Bohidar, and Ciminera 1977</a>)</span> dataset. The top image displays how the estimator is a step function with steps occurring at event times (some examples in green dashed lines). At censoring times, the estimator stays constant (examples in blue dotted lines). The bottom image displays how to use the estimator as a predictive tool. To predict the survival probability of a new rat, one can find the estimated survival probability at a given time from the trained estimator, without needing any more details about the rat in question (as covariates are ignored). This provides a quick tool that tends to be well-calibrated to the average observation.</p>
<p>As predictive models, these can also be extended to other censoring and truncation types as well as event history analysis more generally from using the estimators defined in <a href="P1C4_survival.html#sec-surv-estimation-non-param" class="quarto-xref"><span>Section 3.5.2</span></a>, <a href="P1C5_eha.html#sec-aalen-johanson" class="quarto-xref"><span>Section 4.2.2</span></a>, and <a href="P1C5_eha.html#sec-ms-aalen-johanson" class="quarto-xref"><span>Section 4.3.4</span></a>.</p>
<div id="fig-km-rats" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Two graphs both with time on the x-axis and survival probability on the y-axis. Both graphs show the same step function decreasing from S(t)=1 at t=0 to around S(t)=0.8 at around t=100. In the top graph, three dashed lines mark three steps in the function, two blue lines mark horizontal lines without steps. In the bottom graph, an arrow from t=60 points to the survival probability of around S(t)=0.98.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-km-rats-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/classical/km_test.png" class="img-fluid figure-img" alt="Two graphs both with time on the x-axis and survival probability on the y-axis. Both graphs show the same step function decreasing from S(t)=1 at t=0 to around S(t)=0.8 at around t=100. In the top graph, three dashed lines mark three steps in the function, two blue lines mark horizontal lines without steps. In the bottom graph, an arrow from t=60 points to the survival probability of around S(t)=0.98.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-km-rats-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.1: Using the Kaplan-Meier estimator as a predictive tool. The top image shows the estimator fit to data, the green dashed lines so steps in the function at event times and the blue dotted lines are censoring times in the training data and no steps occur. The bottom image demonstrates using the estimator as a predictive tool by reading off the survival probability at given times.
</figcaption>
</figure>
</div>
</section>
<section id="conditional-estimators" class="level3" data-number="10.1.2">
<h3 data-number="10.1.2" class="anchored" data-anchor-id="conditional-estimators"><span class="header-section-number">10.1.2</span> Conditional estimators</h3>
<p>As well as unconditional estimators, which do not account for covariates, an alternative is the conditional Akritas estimator <span class="citation" data-cites="Akritas1994">(<a href="P5C26_references.html#ref-Akritas1994" role="doc-biblioref">Akritas 1994</a>)</span> usually defined by <span class="citation" data-cites="Blanche2013">(<a href="P5C26_references.html#ref-Blanche2013" role="doc-biblioref">Blanche, Dartigues, and Jacqmin-Gadda 2013</a>)</span>:</p>
<p><span id="eq-akritas"><span class="math display">\[
S(\tau|\mathbf{x}^*, \lambda) = \prod_{k:t_{(k)}\leq \tau} \Big(1 - \frac{\sum^n_{i=1} K(\mathbf{x}^*,\mathbf{x}_i|\lambda)\mathbb{I}(t_i = t_{(k)}, \delta_i = 1)}{\sum^n_{i=1} K(\mathbf{x}^*,\mathbf{x}_i|\lambda)\mathbb{I}(t_i \geq t_{(k)})}\Big)
\tag{10.2}\]</span></span> where <span class="math inline">\(K\)</span> is a kernel function, usually <span class="math inline">\(K(x,y|\lambda) = \mathbb{I}(\lvert \hat{F}_X(x) - \hat{F}_X(y)\rvert &lt; \lambda), \lambda \in (0, 1]\)</span>, <span class="math inline">\(\hat{F}_X\)</span> is the empirical distribution function of the data, and <span class="math inline">\(\lambda\)</span> is a hyper-parameter. The estimator can be interpreted as a conditional Kaplan-Meier estimator which is computed on a neighbourhood of subjects closest to <span class="math inline">\(\mathbf{x}^*\)</span>. In fact, if <span class="math inline">\(\lambda = 1\)</span> then <span class="math inline">\(K(\cdot|\lambda) = 1\)</span> and (<a href="#eq-akritas" class="quarto-xref"><span>10.2</span></a>) is identical to (<a href="#eq-km-ml-two" class="quarto-xref"><span>10.1</span></a>).</p>
<p>The formulation in (<a href="#eq-akritas" class="quarto-xref"><span>10.2</span></a>) includes fitting and predicting in one step as the usual application of the model is as a non-parametric estimator. By first estimating <span class="math inline">\(\hat{F}_X\)</span> on separate training data, the estimator can be used as a baseline predictive model.</p>
</section>
</section>
<section id="sec-classical-cox" class="level2" data-number="10.2">
<h2 data-number="10.2" class="anchored" data-anchor-id="sec-classical-cox"><span class="header-section-number">10.2</span> Proportional Hazards</h2>
<p>This section begins with an introduction to the proportional hazards concept, introduces estimation with the Cox PH model, and then moves to fully parametric proportional hazards models, with the Weibull model as a motivating example.</p>
<p>Let <span class="math inline">\(\eta_i = \mathbf{x}_i^\top\boldsymbol{\beta}\)</span> be the linear predictor for some observation <span class="math inline">\(i\)</span> with covariates <span class="math inline">\(\mathbf{x}_i\)</span> and model coefficients <span class="math inline">\(\boldsymbol{\beta}\in \mathbb{R}^p\)</span>, then proportional hazards (PH) models assume that the hazard function for <span class="math inline">\(i\)</span> follows the form <span id="eq-ph"><span class="math display">\[
h_{PH}(\tau|\mathbf{x}_i)= h_0(\tau)\exp(\eta_i)
\tag{10.3}\]</span></span></p>
<p>or equivalently:</p>
<p><span id="eq-ph-cum"><span class="math display">\[
H_{PH}(\tau|\mathbf{x}_i)= H_0(\tau)\exp(\eta_i)
\tag{10.4}\]</span></span></p>
<p>and</p>
<p><span id="eq-ph-surv"><span class="math display">\[
S_{PH}(\tau|\mathbf{x}_i)= S_0(\tau)^{\exp(\eta_i)}
\tag{10.5}\]</span></span></p>
<p><span class="math inline">\(h_0,H_0,S_0\)</span> are referred to as the baseline hazard, cumulative hazard, and survival function respectively. Instead of modelling a separate intercept, the baseline hazard represents the hazard when the linear predictor is zero, hence the term ‘baseline’. Note that the baseline hazard may not have a meaningful interpretation, unless the covariates are all centered around zero or reference coded in case of categorical covariates (similar to the intercept <span class="math inline">\(\beta_0\)</span> in linear regression).</p>
<p>It can be seen from (<a href="#eq-ph" class="quarto-xref"><span>10.3</span></a>) that time is only incorporated via the baseline hazard (ignoring adaptations to time-varying models). Therefore, PH models estimate the baseline risk of an event at a given time, and modulate this risk according to the specification of covariates. This represents the eponymous ‘proportional hazards’ assumption as the individual’s hazard at time <span class="math inline">\(\tau\)</span> is directly proportional to a multiplicative function of their own covariates: <span class="math inline">\(h(\tau|\mathbf{x}_i) \propto \exp(\eta_i)\)</span>. In other words, a unit change in a covariate acts multiplicatively on the estimated hazard. Further, the hazard ratio, which is a measure of the difference in risk, between two different subjects, depends solely on the value of their (linear) predictors and not on time. For a single covariate <span class="math inline">\(x\)</span>:</p>
<p><span class="math display">\[
\frac{h_{PH}(\tau|x_i)}{h_{PH}(\tau|x_j)} = \frac{h_0(\tau)\exp(x_i\beta)}{h_0(\tau)\exp(x_j\beta)} = \exp(\beta(x_i -x_j))
\]</span></p>
<p>Equivalently:</p>
<p><span id="eq-hazratio-diff"><span class="math display">\[
h_{PH}(\tau|x_i) = \exp(\beta(x_i - x_j))h_{PH}(\tau|x_j)
\tag{10.6}\]</span></span></p>
<p>So in the case where the covariate differs between subjects by <span class="math inline">\(1\)</span>, the hazard ratio increases multiplicatively by <span class="math inline">\(\exp(\beta)\)</span>. This yields an interpretable model, in which hazard ratios are constant over time and don’t depend on <span class="math inline">\(\tau\)</span>. That is, the covariates effect on the hazard is independent of time. Note that this doesn’t imply that the effect of covariates on the survival function is constant over time (a constant difference in hazards at each time point will accumulate over time and the difference between the survival functions will increase).</p>
<p>We next consider how to fit the <span class="math inline">\(\beta\)</span> parameters semi-parametrically (<a href="#sec-ph-semi-parametric" class="quarto-xref"><span>Section 10.2.1</span></a>) and fully parametrically (<a href="#sec-ph-parametric" class="quarto-xref"><span>Section 10.2.2</span></a>).</p>
<section id="sec-ph-semi-parametric" class="level3" data-number="10.2.1">
<h3 data-number="10.2.1" class="anchored" data-anchor-id="sec-ph-semi-parametric"><span class="header-section-number">10.2.1</span> Semi-Parametric PH</h3>
<p>The Cox Proportional Hazards (Cox PH) <span class="citation" data-cites="Cox1972">(<a href="P5C26_references.html#ref-Cox1972" role="doc-biblioref">Cox 1972</a>)</span>, or Cox model, is likely the most widely known semi-parametric model and the most studied survival model <span class="citation" data-cites="Reid1994 Wang2017">(<a href="P5C26_references.html#ref-Reid1994" role="doc-biblioref">Reid 1994</a>; <a href="P5C26_references.html#ref-Wang2017" role="doc-biblioref">Wang, Li, and Reddy 2019</a>)</span>. Often, it is considered synonymous with proportional hazards and the functional form of the hazard given in (<a href="#eq-ph" class="quarto-xref"><span>10.3</span></a>). However, the main contribution of Cox’s work was to develop a method to estimate <span class="math inline">\(\boldsymbol{\beta}\)</span> without making any assumptions about the baseline hazard. We derive the estimation of the parameters in some detail as the objective function of the Cox model is also used by many machine learning methods like boosting (<a href="P3C16_boosting.html" class="quarto-xref"><span>Chapter 13</span></a>) and neural networks (<a href="P3C17_neural.html" class="quarto-xref"><span>Chapter 14</span></a>).</p>
<p>Recall from <a href="P1C4_survival.html#sec-surv-estimation" class="quarto-xref"><span>Section 3.5</span></a>, to estimate the distribution of event times one either needs to make distributional assumptions and accordingly define the likelihood of observing the data (given model parameters), or to use non-parametric estimators, which usually do not incorporate covariate information. Let <span class="math inline">\(i_{(k)}\)</span> denote the subject who experienced the event at ordered event time <span class="math inline">\(t_{(k)}\)</span>. Cox noted the contribution of an individual could be defined as the probability of a particular subject <span class="math inline">\(i_{(k)}\)</span> experiencing the event at <span class="math inline">\(t_{(k)}\)</span> <em>given</em> that <em>someone</em> in the risk set experienced the event at that time. The likelihood contribution of this <span class="math inline">\(k\)</span>th event is given by</p>
<p><span class="math display">\[
\ell^{Cox}_{i_{(k)}}
=\frac{h_0\left(t_{(k)}\right)\exp\left(\eta_{i_{(k)}}\right)}
{\sum_{j\in \mathcal{R}_{t_{(k)}}} h_0\left(t_{(k)}\right)\exp\left(\eta_j\right)}
=\frac{\exp\left(\eta_{i_{(k)}}\right)}
{\sum_{j\in \mathcal{R}_{t_{(k)}}}\exp\left(\eta_j\right)},
\]</span></p>
<p>which depends on <span class="math inline">\(\boldsymbol{\beta}\)</span> via <span class="math inline">\(\eta=\mathbf{x}^\top\boldsymbol{\beta}\)</span>. Note how the baseline hazard <span class="math inline">\(h_0\)</span> cancels out in the likelihood contribution and thus doesn’t depend on time anymore. Thus, for the estimation of <span class="math inline">\(\boldsymbol{\beta}\)</span>, the baseline hazard can be considered a ‘nuissance parameter’ and the likelihood for the entire data set can be defined as:</p>
<p><span id="eq-partial"><span class="math display">\[
\mathcal{L}_{PL}(\boldsymbol{\beta}) = \prod_{k=1}^m \ell^{Cox}_{i_{(k)}} = \prod_{k=1}^m \left(\frac{\exp(\eta_{i_{(k)}})}{\sum_{j \in \mathcal{R}_{t_{(k)}}} \exp(\eta_j)}\right).
\tag{10.7}\]</span></span></p>
<p>Information about the event times only contributes to (1) through the index of the product and sum, thus preserving rankings, i.e., the product is taken from first to last observed event time. The baseline hazard, and thus information about the exact event time is absent from the function. Moreover, censored observations only contribute in the denominator of the calculation. (1) is thereforer eferred to as a <em>partial likelihood</em> <span class="citation" data-cites="Cox1975">(<a href="P5C26_references.html#ref-Cox1975" role="doc-biblioref">Cox 1975</a>)</span> function, as it does not make use of all the observed data.</p>
<ol class="example" type="1">
<li>also assumes that there are no ties in the event time, that is, no two subjects have an event at the same time. In practice, ties can be common and several methods have been proposed to handle them, namely an exact method <span class="citation" data-cites="KalbfleischPrentice1973">(<a href="P5C26_references.html#ref-KalbfleischPrentice1973" role="doc-biblioref">J. D. Kalbfleisch and Prentice 1973</a>)</span> (which is computationally expensive), the Breslow approximation <span class="citation" data-cites="breslowCovarianceAnalysisCensored1974">(<a href="P5C26_references.html#ref-breslowCovarianceAnalysisCensored1974" role="doc-biblioref">Breslow 1974</a>)</span>, and the Efron approximation <span class="citation" data-cites="Efron1977">(<a href="P5C26_references.html#ref-Efron1977" role="doc-biblioref">Efron 1977</a>)</span>; further details are not discussed here but all three methods are readily available in openly available software.</li>
</ol>
<p>The log-partial likelihood, usually prefered for optimization, is given by <!--  --> <span id="eq-lpartial"><span class="math display">\[
\mathcal{l}_{PL}(\boldsymbol{\beta}) = \sum_{k=1}^m \left(\eta_{i_{(k)}} - \log \left(\sum_{j \in \mathcal{R}_{t_{(k)}}} \exp(\eta_j)\right)\right),
\tag{10.8}\]</span></span> <!--  --> such that <!--  --> <span id="eq-estimate-beta"><span class="math display">\[
\hat{\boldsymbol{\beta}} = \mathop{\mathrm{arg\,max}}_{\boldsymbol{\beta}}\ \mathcal{l}_{PL}(\boldsymbol{\beta}).
\tag{10.9}\]</span></span></p>
<p>Traditionally, <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> is obtained using numerical optimization methods, such as Newton-Raphson or Fisher-Scoring, which require derivation the first and second deriviatives of <a href="#eq-lpartial" class="quarto-xref"><span>10.8</span></a>.</p>
<p>Importantly, the partial likelihood allows us to estimate covariate effects (and interpret them in terms of hazard ratios) without making any assumptions about the underlying distribution of event times. Obtaining <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> also gives us enough information to make predictions in the form of relative risks (<a href="P1C6_survtsk.html" class="quarto-xref"><span>Chapter 5</span></a>).</p>
<p>At this point, however, we don’t have an estimate of the baseline hazard <span class="math inline">\(h_0\)</span> and thus cannot make survival distribution predictions. The Breslow estimator <span class="citation" data-cites="Breslow1972 linBreslowEstimator2007">(<a href="P5C26_references.html#ref-Breslow1972" role="doc-biblioref">Breslow 1972</a>; <a href="P5C26_references.html#ref-linBreslowEstimator2007" role="doc-biblioref">Lin 2007</a>)</span> provides a way to obtain an estimate of the cumulative baseline hazard, <span class="math inline">\(H_0\)</span>, using the parameters from the Cox model: <!--  --> <span id="eq-breslow"><span class="math display">\[
H_{Bres}(\tau) = H_0(\tau) = \sum_{k:t_{(k)}\leq \tau} \frac{d_{t_{(k)}}}{\sum_{j \in \mathcal{R}_{t_{(k)}}} \exp(\eta_j)}.
\tag{10.10}\]</span></span> <!--  --> Note that if the value for all covariates or their effects was zero, or if there were no covariates, then the Breslow estimator is identical to the Nelson-Aalen estimator (<a href="P1C4_survival.html#sec-surv-na" class="quarto-xref"><span>Section 3.5.2.2</span></a>):</p>
<p><span class="math display">\[
H_{Bres}(\tau) = \sum_{k:t_{(k)}\leq \tau} \frac{d_{t_{(k)}}}{\sum_{j \in \mathcal{R}_{t_{(k)}}} 1} = \sum_{t_{(k)}\leq \tau} \frac{d_{t_{(k)}}}{n_{t_{(k)}}} = H_{NA}(\tau).
\]</span></p>
<p>With these formulae, the Cox PH model can be used as a predictive model by using training data to estimate <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> via (<a href="#eq-estimate-beta" class="quarto-xref"><span>10.9</span></a>). These fitted coefficients are used to predict <span class="math inline">\(\hat{\boldsymbol{\eta}}\)</span> for new observations and finally the cumulative baseline hazard is computed with (<a href="#eq-breslow" class="quarto-xref"><span>10.10</span></a>) to return a predicted distribution, for example the survival probability (<a href="#eq-ph-surv" class="quarto-xref"><span>10.5</span></a>).</p>
<!-- FIXME -->
<p>The Cox model is is highly interpretable and has a long history of usage in clinical prediction modelling and analysis. However, the proportional hazards assumption is often violated in real life, leaving the model to be a questionable choice when used for data analysis or inference. Over the years, extensions to the Cox model have been developed <span class="citation" data-cites="therneau2001modelingsurvival">(<a href="P5C26_references.html#ref-therneau2001modelingsurvival" role="doc-biblioref">Therneau and Grambsch 2001</a>)</span> to incorporate stratified baseline hazards (the PH assumption only has to hold within strata), time-varying effects (the effects of time-constant covariates change over time) and time-varying covariates (the values of covariates change over time). However, especially in case of time-varying covariates, it is difficult to make meaningful and interpretable predictions (as the values of covariates might not be known at the time of prediction). Whilst violation of the PH assumption can be problematic, especially for interpretation of covariate effects, it doesn’t appear to cause problems in terms of prediction accuracy. In fact, the Cox model often outperforms machine learning alternatives, including those that relax the PH assumption <span class="citation" data-cites="Burk2025 Gensheimer2018 Luxhoj1997 VanBelle2011b">(<a href="P5C26_references.html#ref-Burk2025" role="doc-biblioref">Burk et al. 2024</a>; <a href="P5C26_references.html#ref-Gensheimer2018" role="doc-biblioref">Gensheimer and Narasimhan 2018</a>; <a href="P5C26_references.html#ref-Luxhoj1997" role="doc-biblioref">Luxhoj and Shyur 1997</a>; <a href="P5C26_references.html#ref-VanBelle2011b" role="doc-biblioref">Van Belle et al. 2011</a>)</span>.</p>
</section>
<section id="sec-ph-parametric" class="level3" data-number="10.2.2">
<h3 data-number="10.2.2" class="anchored" data-anchor-id="sec-ph-parametric"><span class="header-section-number">10.2.2</span> Parametric PH</h3>
<p>Semi-parametric approaches (like the Cox model) are popular because they don’t make an assumption about the underlying distribution of event times, leaving the baseline hazard unspecified. However, there are some cases where modelling a particular distribution may make sense. On these occasions, a particular probability distribution of the event times is assumed, with three common choices <span class="citation" data-cites="Kalbfleisch2011 Wang2017">(<a href="P5C26_references.html#ref-Kalbfleisch2011" role="doc-biblioref">John D. Kalbfleisch and Prentice 2011</a>; <a href="P5C26_references.html#ref-Wang2017" role="doc-biblioref">Wang, Li, and Reddy 2019</a>)</span> being the Exponential, Gompertz, and Weibull distributions. The Weibull distribution is particularly important as it reduces to the Exponential distribution when the shape parameter equals <span class="math inline">\(1\)</span>. <!-- FIXME: AFT not introduced yet? --> Moreover, it is unique (and Exponential as a special case) in that it has both the PH and AFT (<span class="quarto-unresolved-ref">?sec-aft</span>) property (technically a less known representation of Gompertz also has this property).</p>
<p>Assuming a PH model one can plug in the hazard and survival functions from the Weibull distribution into (<a href="#eq-ph" class="quarto-xref"><span>10.3</span></a>) and (<a href="#eq-ph-surv" class="quarto-xref"><span>10.5</span></a>) respectively. First recall for a <span class="math inline">\(\operatorname{Weibull}(\gamma, \lambda)\)</span> distribution with shape parameter <span class="math inline">\(\gamma\)</span> and scale parameter <span class="math inline">\(\lambda\)</span>, the relevant functions can be given by <span class="citation" data-cites="KalbfleischPrentice1973">(<a href="P5C26_references.html#ref-KalbfleischPrentice1973" role="doc-biblioref">J. D. Kalbfleisch and Prentice 1973</a>)</span>:</p>
<p><span class="math display">\[
h(\tau) = \lambda\gamma \tau^{\gamma-1}
\]</span></p>
<p>and</p>
<p><span class="math display">\[
S(\tau) = \exp(-\lambda \tau^\gamma)
\]</span></p>
<p>Taking these to be the baseline hazard and survival functions respectively, they can be substituted into the Cox model as follows: <!--  --> <span id="eq-ph-weibull"><span class="math display">\[
h_{WeibullPH}(\tau|\mathbf{x}_i)= (\lambda\gamma \tau^{\gamma-1}) \exp(\eta_i)
\tag{10.11}\]</span></span> <!--  --> or equivalently <!--  --> <span class="math display">\[
S_{WeibullPH}(\tau|\mathbf{x}_i)= (\exp(-\lambda \tau^\gamma))^{\exp(\eta_i)}
\]</span> <!--  --> Finally, these formulae can be used to define the full likelihood (<a href="P1C4_survival.html#sec-surv-estimation-param" class="quarto-xref"><span>Section 3.5.1</span></a>) for the WeibullPH model (here for right-censored data):</p>
<p><span class="math display">\[
\begin{aligned}
\mathcal{L}(\boldsymbol{\theta}) &amp;= \prod_{i=1}^n h_Y(t_i|\mathbf{x}_i, \boldsymbol{\theta})^{\delta_i}S_Y(t_i|\mathbf{x}_i, \boldsymbol{\theta}) \\
&amp;= \prod_{i=1}^n \Big((\lambda\gamma t_i^{\gamma-1} \exp(\eta_i))^{\delta_i}\Big)\Big(\exp(-\lambda t_i^\gamma\exp(\eta_i))\Big)
\end{aligned}
\]</span></p>
<p>with log-likelihood</p>
<p><span class="math display">\[
\begin{aligned}
\mathcal{l}(\boldsymbol{\theta}) &amp;= \sum_{i=1}^n \delta_i[\log(\lambda\gamma) + (\gamma-1)\log(t_i) + \eta_i] - \lambda t_i^\gamma\exp(\eta_i) \\
&amp;\propto \sum_{i=1}^n \delta_i[\log(\lambda\gamma) + \gamma\log(t_i) + \eta_i] - \lambda t_i^\gamma \exp(\eta_i)
\end{aligned}
\]</span></p>
<p>Parameters can then be fit using maximum likelihood estimation (MLE) with respect to all unknown parameters <span class="math inline">\(\boldsymbol{\theta}= \{\boldsymbol{\beta}, \gamma, \lambda\}\)</span>. Expansion to other censoring types and truncation follows by using other likelihood forms presented in <a href="P1C4_survival.html#sec-surv-estimation" class="quarto-xref"><span>Section 3.5</span></a>.</p>
<p>When considering which probability distributions to model in predictive experiments, Weibull is a common starting choice <span class="citation" data-cites="Hielscher2010 CoxSnell1968 Rahman2017">(<a href="P5C26_references.html#ref-Hielscher2010" role="doc-biblioref">Hielscher et al. 2010</a>; <a href="P5C26_references.html#ref-CoxSnell1968" role="doc-biblioref">R. and J. 1968</a>; <a href="P5C26_references.html#ref-Rahman2017" role="doc-biblioref">Rahman et al. 2017</a>)</span>, its two parameters make it a flexible fit to data but on the other hand it can be easily reduced to Exponential when <span class="math inline">\(\gamma=1\)</span>. Gompertz <span class="citation" data-cites="Gompertz1825">(<a href="P5C26_references.html#ref-Gompertz1825" role="doc-biblioref">Gompertz 1825</a>)</span> is commonly used in medical domains, especially when describing adult lifespans. In a machine learning context, one can select the optimal distribution for future predictive performance by running a benchmark experiment. In contrast to the semi-parametric Cox model, fully parametric PH models can predict absolutely continuous survival distributions, they do not treat the baseline hazard as a nuisance, and in general will result in more precise and interpretable predictions if the distribution is correctly specified <span class="citation" data-cites="Reid1994 Royston2002">(<a href="P5C26_references.html#ref-Reid1994" role="doc-biblioref">Reid 1994</a>; <a href="P5C26_references.html#ref-Royston2002" role="doc-biblioref">Royston and Parmar 2002</a>)</span>.</p>
</section>
<section id="competing-risks" class="level3" data-number="10.2.3">
<h3 data-number="10.2.3" class="anchored" data-anchor-id="competing-risks"><span class="header-section-number">10.2.3</span> Competing risks</h3>
<p>There are two common methods to extend the Cox model to the competing risks setting. The first makes use of the cause-specific hazard to fit a cause-specific Cox model, the second fits a ‘subdistribution’ hazard.</p>
<section id="cause-specific-ph-models" class="level4 unlisted unnumbered">
<h4 class="unlisted unnumbered anchored" data-anchor-id="cause-specific-ph-models">Cause-specific PH models</h4>
<p>In cause-specific models we define the hazard for cause <span class="math inline">\(e\)</span> as:</p>
<p><span id="eq-cause-specific-hazard-ph"><span class="math display">\[
h_{e}(\tau|\mathbf{x}_{e;i})= h_{e;0}(\tau)\exp(\eta_{e;i}),
\tag{10.12}\]</span></span></p>
<p>where <span class="math inline">\(h_{e;0}\)</span> is a cause-specific baseline hazard and <span class="math inline">\(\mathbf{x}_{e;i}\)</span> is a set of cause-specific covariates (although in practice often the same covariates are used for all causes), and <span class="math inline">\(\eta_{e;i}\)</span> is the cause-specific linear predictor: <!--  --> <span class="math display">\[
\eta_{e;i} = \mathbf{x}_{e;i}^T\boldsymbol{\beta}_e.
\]</span> <!--  --> In order to estimate <span class="math inline">\(\boldsymbol{\beta}_e\)</span>, let <span class="math inline">\(t_{e;(k)}, k=1,\ldots,m(e)\)</span> be the unique, ordered event times at which events of cause <span class="math inline">\(e\)</span> occur and let <span class="math inline">\(i_{e;(k)}\)</span> be the index of the observation that experiences the <span class="math inline">\(k\)</span>th event of cause <span class="math inline">\(e\)</span>. Then the cause-specific partial likelihood is given by: <!--  --> <span id="eq-partial-cr"><span class="math display">\[
\mathcal{L}_{PL}(\boldsymbol{\beta}_e) = \prod_{k=1}^{m(e)} \Bigg(\frac{\exp(\eta_{e;i_{e;(k)}})}{\sum_{j \in \mathcal{R}_{t_{e;(k)}}} \exp(\eta_{e;j})}\Bigg),
\tag{10.13}\]</span></span></p>
<p>This is identical to the single-event partial likelihood in (1), with the only difference being that the product and sum are over the unique, ordered event times for cause <span class="math inline">\(e\)</span>. The risk-set definition is unaltered such that <span class="math inline">\(\mathcal{R}_{t_{e;(k)}}\)</span> is the set of observations that have not experienced and event of <em>any</em> cause or censoring by <span class="math inline">\(t_{e;(k)}\)</span>.</p>
<p>Using the same logic, the Breslow estimator follows from (<a href="#eq-breslow" class="quarto-xref"><span>10.10</span></a>): <!--  --> <span id="eq-breslow-cr"><span class="math display">\[
H_{Bres;e}(\tau) = \sum_{k:t_{e;(k)}\leq \tau} \frac{d_{t_{e;(k)}}}{\sum_{j \in \mathcal{R}_{t_{e;(k)}}} \exp(\eta_{e;j})},
\tag{10.14}\]</span></span> <!--  --> and the feature-dependent, cause-specific cumulative hazard (<a href="#eq-ph-cum" class="quarto-xref"><span>10.4</span></a>) as</p>
<p><span id="eq-cause-specific-cumu-hazard-cox"><span class="math display">\[
H_{e}(\tau|\mathbf{x}) = H_{Bres;e}(\tau)\exp(\mathbf{x}^T\boldsymbol{\beta}_e)
\tag{10.15}\]</span></span></p>
<p>Finally, in order to obtain an estimate of the cumulative incidence function <span class="math inline">\(F_e(\tau)\)</span> (<a href="P1C5_eha.html#eq-cif" class="quarto-xref"><span>4.9</span></a>), we need an estimate of the all cause survival probability and an estimate of the cause-specific hazard (which is not directly available in the Cox modelas the Breslow estimator only provides an estimate of the cause-specific <em>cumulative</em> baseline hazard). The all cause survival probability is obtained using <a href="#eq-cause-specific-cumu-hazard-cox" class="quarto-xref"><span>10.15</span></a> and the usual relationships (<a href="P1C5_eha.html#eq-all-cause-cumu-hazard" class="quarto-xref"><span>4.7</span></a>, <a href="P1C4_survival.html#eq-surv-haz" class="quarto-xref"><span>3.4</span></a>) as <!--  --> <span id="eq-all-cause-surv-prob-cox"><span class="math display">\[
S(\tau|\mathbf{x}) = \exp\left(-\sum_{e=1}^q H_{e}(\tau|\mathbf{x})\right)
\tag{10.16}\]</span></span> <!--  --> and an estimate of the cause-specific hazard is obtained via <!--  --> <span id="eq-cause-specific-hazard-cox"><span class="math display">\[
\begin{aligned}
h_{e}(\tau|\mathbf{x}) = \Delta H_{e}(\tau|\mathbf{x}) &amp; = \Delta H_{Bres;e}(\tau)\exp(\mathbf{x}^T\boldsymbol{\beta}_e)\\
&amp; = \frac{d_{t_{e;(k)}}}{\sum_{j \in \mathcal{R}_{t_{e;(k)}}} \exp(\eta_{e;j})}\exp(\mathbf{x}^T\boldsymbol{\beta}_e),
\end{aligned}
\tag{10.17}\]</span></span> <!--  --> where <span class="math inline">\(\Delta H_{Bres;e}(\tau)\)</span> is the increment of the cause-specific cumulative baseline hazard between successive time points (note the missing sum over different time points compared to <a href="#eq-breslow-cr" class="quarto-xref"><span>10.14</span></a>). With <a href="#eq-all-cause-surv-prob-cox" class="quarto-xref"><span>10.16</span></a> and <a href="#eq-cause-specific-hazard-cox" class="quarto-xref"><span>10.17</span></a>, the CIF is approximated by <!--  --> <span id="eq-cif-cox"><span class="math display">\[
F_e(\tau|\mathbf{x}) = \sum_{k:t_{(k)}\leq \tau} S(\tau|\mathbf{x}) h_{e}(\tau|\mathbf{x}).
\tag{10.18}\]</span></span> <!--  --></p>
</section>
<section id="subdistribution-ph-models" class="level4 unlisted unnumbered">
<h4 class="unlisted unnumbered anchored" data-anchor-id="subdistribution-ph-models">Subdistribution PH models</h4>
<p>The methods discussed thus far estimate cause-specific hazards (<a href="P1C5_eha.html#eq-cause-specific-hazard" class="quarto-xref"><span>4.4</span></a>), which represent the instantaneous risk of an individual experiencing the cause of interest, given that they have not yet experienced <em>any</em> event. An alternative approach is to model subdistribution hazards, which model the risk of an individual experiencing the cause of interest, given they have not yet experienced the event of interest, but may have experienced a competing event. As will be shown below, the benefit of the subdistribution model is the ability to directly predict the cumulative incidence function (CIF) under a PH model, rather than using the indirect calculation in Equation (<a href="#eq-cif-cox" class="quarto-xref"><span>10.18</span></a>). The subdistribution hazard approach also provides a direct relationship between covariates and the CIF for an event of interest <span class="citation" data-cites="Austin2016">(<a href="P5C26_references.html#ref-Austin2016" role="doc-biblioref">Austin, Lee, and Fine 2016</a>)</span>.</p>
<p>Mathematically, the difference between cause-specific and subdistribution hazards comes from the definition of the risk set. The subdistribution risk set is defined as: <!--  --> <span id="eq-riskset-sd"><span class="math display">\[
\mathcal{R}_{e;\tau} := \{i: t_i \geq \tau \vee [t_i &lt; \tau \wedge e_i \neq e \wedge \delta_i = 1]\}
\tag{10.19}\]</span></span> <!--  --> Observe that in this definition the left-hand side is the same as the standard risk set definition (<a href="P1C4_survival.html#eq-risk-set" class="quarto-xref"><span>3.10</span></a>) and the right-hand side additionally includes those that have experienced a different event already. Anyone that has been censored (<span class="math inline">\(e = e_0\)</span>) before <span class="math inline">\(\tau\)</span> is removed from the risk set.</p>
<p>The definition of the subdistribution risk (<a href="#eq-riskset-sd" class="quarto-xref"><span>10.19</span></a>) is equivalent to defining the subdistribution hazard for cause <span class="math inline">\(e\)</span> as: <!--  --> <span id="eq-hazard-sd"><span class="math display">\[
h^{SD}_{e}(\tau) = \lim_{\mathrm{d}\tau\to 0} \frac{P(\tau \leq Y \leq \tau + \mathrm{d}\tau, E = e\ |\ Y \geq \tau \vee (E \neq e \wedge \Delta=1))}{\mathrm{d}\tau}.
\tag{10.20}\]</span></span> <!--  --> Fine and Gray <span class="citation" data-cites="Fine1999">(<a href="P5C26_references.html#ref-Fine1999" role="doc-biblioref">Fine and Gray 1999</a>)</span> proposed a proportional hazards formulation of the subdistribution hazard (<a href="#eq-hazard-sd" class="quarto-xref"><span>10.20</span></a>) as <!--  --> <span id="eq-cox-sd"><span class="math display">\[
h_{FG;e}(\tau|\mathbf{x}_i)= h^{SD}_{e;0}(\tau)\exp(\eta_i),
\tag{10.21}\]</span></span> <!--  --> with subdistribution baseline hazard <span class="math inline">\(h^{SD}_{e;0}(\tau)\)</span> (we add the superscript here in order to make explicit that this baseline hazard will differ from the one obtained from the Cox model (<a href="#eq-ph-cum" class="quarto-xref"><span>10.4</span></a>) due to differences in risk set definition).</p>
<p>While the subdistribution hazards model is different from the proportional hazards Cox model, <span class="citation" data-cites="Fine1999">Fine and Gray (<a href="P5C26_references.html#ref-Fine1999" role="doc-biblioref">1999</a>)</span> showed that it’s parameters could be estimated using a weighted partial likelihood, which is otherwise identical to the cause-specific partial likelihood (<a href="#eq-partial-cr" class="quarto-xref"><span>10.13</span></a>): <!--  --> <span id="eq-fg-likelihood"><span class="math display">\[
\mathcal{L}_{PL}^{SD}(\boldsymbol{\beta}) = \prod_{k=1}^m \left(\frac{\exp(\eta_{e;i_{e;(k)}})}{\sum_{j \in \mathcal{R}_{e;t_{e;(k)}}} w_{kj}\exp(\eta_{e;j})}\right),
\tag{10.22}\]</span></span> <!--  --> In (<a href="#eq-fg-likelihood" class="quarto-xref"><span>10.22</span></a>), <span class="math inline">\(t_{e;(k)}\)</span> is the same as in the cause-specific case and weights <span class="math inline">\(w_{kj}\)</span> account for the fact that the subdistribution risk set is different from the cause-specific risk set. The weights are defined as <!--  --> <span class="math display">\[
w_{kj} := \frac{G_{KM}(t_{e;(k)})}{G_{KM}(\min\{t_{e;(k)}, t_j\})},
\]</span> <!--  --> where <span class="math inline">\(G_{KM}\)</span> is the Kaplan-Meier estimator fit on the censoring distribution (<a href="P1C4_survival.html#sec-surv-km" class="quarto-xref"><span>Section 3.5.2.1</span></a>). Because of the way the subdistribution risk set is defined in (<a href="#eq-riskset-sd" class="quarto-xref"><span>10.19</span></a>), the denominator of (<a href="#eq-fg-likelihood" class="quarto-xref"><span>10.22</span></a>) is a weighted sum over individuals, <span class="math inline">\(j \in \mathcal{R}_{e;t_{e;(k)}}\)</span>, at time <span class="math inline">\(t_{e;(k)}\)</span> who have either yet to experience an event (<span class="math inline">\(t_j \geq t_{e;(k)}\)</span>) or experienced a different event (<span class="math inline">\(t_j &lt; t_{e;(k)}\wedge e_i \ne e \wedge \delta_i=1\)</span>). The weighting function handles these cases as follows:</p>
<ol type="1">
<li>If <span class="math inline">\(t_j \geq t_{e;(k)}\)</span> then <span class="math inline">\(w_{kj} = 1\)</span> and thus observations that have not experienced any event contribute fully to the denominator.</li>
<li>If <span class="math inline">\(t_j &lt; t_{e;(k)}\)</span> then <span class="math inline">\(w_{kj} &lt; 1\)</span> as <span class="math inline">\(G_{KM}\)</span> is a monotonically decreasing function and <span class="math inline">\(w_{kj}\)</span> continues to decrease as the distance between <span class="math inline">\(t_j\)</span> and <span class="math inline">\(t_{e;(k)}\)</span> increases. Thus the contribution from observations that have experienced competing events reduces over time.</li>
</ol>
<p>Whilst modelling the subdistribution can seem unintuitive, note that if there is only one event of interest then <span class="math inline">\(w_{kj} = 1\)</span> for all <span class="math inline">\(k\)</span> and <span class="math inline">\(j\)</span> and further <span class="math inline">\(e_i \neq e\)</span> must always be false, meaning (<a href="#eq-riskset-sd" class="quarto-xref"><span>10.19</span></a>) reduces to the standard risk set definition (<a href="P1C4_survival.html#eq-risk-set" class="quarto-xref"><span>3.10</span></a>) as only the left condition can ever be true and by the same logic the subdistribution hazard reduces to the usual hazard definition. Therefore the standard Cox PH for single events is perfectly recovered.</p>
<p>Instead of interpreting the subdistribution hazards directly, <span class="citation" data-cites="Austin2017b">Austin and Fine (<a href="P5C26_references.html#ref-Austin2017b" role="doc-biblioref">2017</a>)</span> recommend interpreting the fitted coefficients via the cause-specific CIF and cumulative hazard forms of (<a href="#eq-cox-sd" class="quarto-xref"><span>10.21</span></a>), which can be obtained in the ‘usual’ way by first integrating to obtain the cumulative hazard form:</p>
<p><span id="eq-fg-cum"><span class="math display">\[
H_{FG;e}(\tau|\mathbf{x}_i)= H^{SD}_{e;0}(\tau)\exp(\eta_i)
\tag{10.23}\]</span></span></p>
<p>where <span class="math inline">\(H^{SD}_{e;0}\)</span> is the cause-specific baseline cumulative hazard for cause <span class="math inline">\(e\)</span>. Then using (<a href="P1C4_survival.html#eq-surv-haz" class="quarto-xref"><span>3.4</span></a>) to relate the survival and hazard functions and representing this in terms of the CIF:</p>
<p><span id="eq-fg-cif-long"><span class="math display">\[
F_{FG;e}(\tau|\mathbf{x}_i) = 1 - \exp(-H^{SD}_{e;0}(\tau))^{\exp(\eta_i)}
\tag{10.24}\]</span></span></p>
<p>Or more simply:</p>
<p><span id="eq-fg-cif"><span class="math display">\[
F_{FG;e}(\tau|\mathbf{x}_i) = 1 - (1 - F^{SD}_{e;0}(\tau))^{\exp(\eta_i)}
\tag{10.25}\]</span></span></p>
<p>where <span class="math inline">\(F^{SD}_{e;0}\)</span> is the cause-specific baseline cumulative incidence function for cause <span class="math inline">\(e\)</span>. The model in (<a href="#eq-fg-cif" class="quarto-xref"><span>10.25</span></a>) is fit by estimating the baseline cumulative hazard function and substituting into (<a href="#eq-fg-cif-long" class="quarto-xref"><span>10.24</span></a>). Similarly to how the subdistribution hazard was created, estimation of <span class="math inline">\(\hat{H}^{SD}\)</span> follows by updating (<a href="#eq-breslow" class="quarto-xref"><span>10.10</span></a>) to use the subdistribution risk set definition and applying the same weighting to compensate for multiple events:</p>
<p><span id="eq-fg-breslow"><span class="math display">\[
\hat{H}^{SD}_{Bres;e}(\tau) = \sum_{k:t_{e;(k)}\leq \tau} \frac{d_{t_{e;(k)}}}{\sum_{j \in \mathcal{R}_{e;t_{e;(k)}}} w_{kj}\exp(\hat{\eta}_j)}
\tag{10.26}\]</span></span></p>
<p>Use of the Fine-Gray model has to be carefully considered before model fitting. The subdistribution risk set definition, which includes competing events, treats all causes as non-terminal (even if realistically impossible), which means an observation could be considered at risk of the event of interest even after experiencing a terminal event (like death). Moreover, combining subdistribution CIF estimates across causes can result in probabilities that exceed <span class="math inline">\(1\)</span>, which should be impossible as events are mutually exclusive and exhaustive <span class="citation" data-cites="Austin2022b">(<a href="P5C26_references.html#ref-Austin2022b" role="doc-biblioref">Austin et al. 2022</a>)</span>. The cause-specific hazards approach for the estimation of the CIF (<a href="P1C5_eha.html#sec-cr-notation" class="quarto-xref"><span>Section 4.2.1</span></a> and Equations <a href="#eq-all-cause-surv-prob-cox" class="quarto-xref"><span>10.16</span></a>, <a href="#eq-cif-cox" class="quarto-xref"><span>10.18</span></a>) is often preferred <span class="citation" data-cites="Austin2022b">(<a href="P5C26_references.html#ref-Austin2022b" role="doc-biblioref">Austin et al. 2022</a>)</span> as fitting subdistribution models requires model assumptions to hold for all causes simultaneously, which is not possible (<span class="citation" data-cites="bonnevilleWhyYouShould2024">Bonneville, de Wreede, and Putter (<a href="P5C26_references.html#ref-bonnevilleWhyYouShould2024" role="doc-biblioref">2024</a>)</span>).</p>
<p>The Fine-Gray model is most appropriate when one is only interested in analyzing one of the causes. In this case, interpretation of coefficients from a subdistribution model can be more intuitive as they represent the magnitude of the effect on the incidence, rather than the hazard, which is often of more interest, for example in clinical settings <span class="citation" data-cites="Austin2017b">(<a href="P5C26_references.html#ref-Austin2017b" role="doc-biblioref">Austin and Fine 2017</a>)</span>.</p>
</section>
</section>
</section>
<section id="sec-surv-models-param" class="level2" data-number="10.3">
<h2 data-number="10.3" class="anchored" data-anchor-id="sec-surv-models-param"><span class="header-section-number">10.3</span> Accelerated Failure Time</h2>
<p>Whilst the proportional hazards models is a powerful model, it often does not represent real-world phenomena well. The accelerated failure time (AFT) model is a popular alternative which models the effect of covariates as ‘acceleration factors’ that act multiplicatively on time. In contrast to the PH model, AFT models are all fully-parametric. A semi-parametric model has been suggested <span class="citation" data-cites="Buckley1979">(<a href="P5C26_references.html#ref-Buckley1979" role="doc-biblioref">Buckley and James 1979</a>)</span> however this is not widely used as it lacks ‘theoretical justification’ and is ‘not reliable’ <span class="citation" data-cites="Wei1992">(<a href="P5C26_references.html#ref-Wei1992" role="doc-biblioref">Wei 1992</a>)</span>. Similarly, whilst its theoretically possible to fit cause-specific AFT models for the competing risks setting, this does not appear common in practice.</p>
<section id="understanding-acceleration" class="level3" data-number="10.3.1">
<h3 data-number="10.3.1" class="anchored" data-anchor-id="understanding-acceleration"><span class="header-section-number">10.3.1</span> Understanding acceleration</h3>
<p>Moving from a PH to AFT framework can be confusing, so to elucidate this, take the following example adapted from <span class="citation" data-cites="Kleinbaum1996">Kleinbaum and Klein (<a href="P5C26_references.html#ref-Kleinbaum1996" role="doc-biblioref">1996</a>)</span>. Consider the lifespans of humans and small dogs. In this example we are taking species to be a modifier and we’re looking at what survival would look like under AFT (time scaling) versus PH (hazard scaling).</p>
<p>Suppose small dogs age five times faster than humans. Under AFT (time-scaling modifier), a dog’s survival at age <span class="math inline">\(\tau\)</span> matches a human’s at <span class="math inline">\(5\tau\)</span>:</p>
<p><span class="math display">\[
S_{dog}(\tau) = S_{human}(5\tau)
\]</span></p>
<p>For example, at age 10, a small dog has the same probability of being alive as a human at age 50. The dog’s survival curve is <em>accelerated</em> by a factor of 5, as shown in the bottom, red curve in <a href="#fig-dogs" class="quarto-xref">Figure&nbsp;<span>10.2</span></a>.</p>
<p>If instead, one assumes a constant hazard ratio then at age <span class="math inline">\(\tau\)</span>, the dog’s risk is five times the humans (<a href="#eq-ph-surv" class="quarto-xref"><span>10.5</span></a>):</p>
<p><span class="math display">\[
S_{dog}(\tau) = S_{human}(\tau)^5
\]</span></p>
<p>the middle, blue curve in <a href="#fig-dogs" class="quarto-xref">Figure&nbsp;<span>10.2</span></a>.</p>
<p>These illustrative curves demonstrate how the same modifier yields different behaviour under PH and AFT assumptions.</p>
<div id="fig-dogs" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Survival time is on the x-axis and survival probability on the y-axis. The top, black curve models a human life span smoothly decreasing from S(T)=1 to S(T)=0.5 between T=0 and T=80. The middle, blue curve represents a dog's lifespan under the PH assumption. The survival probability drops close to S(T)=0 by T=0 but is positive and is even above 0.8 at T=30. The bottom, red line represents a dog's lifespan under the AFT assumption. The curve drops to 0 by T=20 but with low survival probability from around T=16.">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-dogs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/classical/dogs.png" class="img-fluid figure-img" alt="Survival time is on the x-axis and survival probability on the y-axis. The top, black curve models a human life span smoothly decreasing from S(T)=1 to S(T)=0.5 between T=0 and T=80. The middle, blue curve represents a dog's lifespan under the PH assumption. The survival probability drops close to S(T)=0 by T=0 but is positive and is even above 0.8 at T=30. The bottom, red line represents a dog's lifespan under the AFT assumption. The curve drops to 0 by T=20 but with low survival probability from around T=16.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-dogs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.2: Comparing human (black) and dog lifespans where the latter is modelled using an AFT model (red) versus a PH model (blue). Clearly the AFT model is (sadly) a better reflection of reality. Human lifespan modelled with Gompertz(0.09, 0.00005).
</figcaption>
</figure>
</div>
<p>More generally, the accelerated failure time model estimates survival functions as</p>
<p><span id="eq-aft-surv"><span class="math display">\[
S_{AFT}(\tau|\mathbf{x}_i) = S_0(\tau e^{-\eta_i})
\tag{10.27}\]</span></span></p>
<p>with respective hazard function</p>
<p><span id="eq-aft-haz"><span class="math display">\[
h_{AFT}(\tau|\mathbf{x}_i) = e^{-\eta_i} h_0(\tau e^{-\eta_i})
\tag{10.28}\]</span></span></p>
<p>Note three key differences compared to the PH model. Firstly, <span class="math inline">\(\exp(-\eta_i)\)</span> is modelled instead of <span class="math inline">\(\exp(\eta_i)\)</span>, hence in a PH model <span class="math inline">\(h_{PH}(\eta_i+1) &gt; h_{PH}(\eta_i)\)</span> whereas in an AFT model <span class="math inline">\(h_{AFT}(\eta_i+1) &lt; h_{AFT}(\eta_i)\)</span>. Secondly, the baseline risk now clearly depends on both time and the linear predictor. Thirdly, an increase in a covariate results in a multiplicative increase over <em>time</em> compared to the PH model in which the hazard is increased – this is often seen as more intuitive to understand than hazard ratio, especially to clinicians who may be more interested in survival times and not abstract relative risks.</p>
<p>This third point is visualised in <a href="#fig-phaft" class="quarto-xref">Figure&nbsp;<span>10.3</span></a> in which a covariate is increased by <span class="math inline">\(\log(2)\)</span>. The left panel shows that the estimated hazard function from a PH model is double the baseline at all time points – the multiplicative effect is seen on the y-axis (risk). In contrast, the right panel shows how the survival function from an AFT model decreases at double the speed to the baseline – the multiplicative effects is now on the x-axis (time). Another way to demonstrate this effect is through the log-linear form of the accelerated failure time model:</p>
<p><span id="eq-aft-log"><span class="math display">\[
\log(t_i) = \mu + \eta_i + \sigma\epsilon_i
\tag{10.29}\]</span></span></p>
<p>where <span class="math inline">\(\sigma\)</span> is a scale parameter, <span class="math inline">\(\epsilon_i\)</span> is an error term, and <span class="math inline">\(\mu\)</span> is an intercept. Now consider the difference in <span class="math inline">\(t_i\)</span> when <span class="math inline">\(\eta_i\)</span> is increased by one (assuming just one covariate):</p>
<p><span class="math display">\[
\log(t_i|x_i + 1) - \log(t_i|x_i) = (\mu + \beta (x_i + 1) + \sigma\epsilon_i) - (\mu + \beta x_i + \sigma\epsilon_i) = \beta
\]</span></p>
<p>Taking exponentials</p>
<p><span class="math display">\[
\frac{t_i|x_i + 1}{t_i|x_i} = \exp(\beta)
\]</span></p>
<p>Hence increasing a covariate effectively multiplies the survival time by <span class="math inline">\(\exp(\beta)\)</span>:</p>
<p><span class="math display">\[
t_i|x_i + 1 = e^{\beta}t_i | x_i
\]</span></p>
<div id="fig-phaft" class="quarto-float quarto-figure quarto-figure-center anchored" alt="TODO">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-phaft-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/classical/compare.png" class="img-fluid figure-img" alt="TODO">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-phaft-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.3: Comparing increasing a covariate <span class="math inline">\(x_i\)</span> between PH (left) and AFT (right) models. An increase of <span class="math inline">\(x_i + \log(2)\)</span> multiplies <span class="math inline">\(h(t)\)</span> by <span class="math inline">\(\exp(\log(2)) = 2\)</span> in a PH model. Whereas the result in the AFT is to multiply time <span class="math inline">\(t\)</span> by <span class="math inline">\(2\)</span>, hence for any <span class="math inline">\(t\)</span>, the AFT model reaches <span class="math inline">\(S(t)\)</span> in half the time as the baseline.
</figcaption>
</figure>
</div>
</section>
<section id="parametric-afts" class="level3" data-number="10.3.2">
<h3 data-number="10.3.2" class="anchored" data-anchor-id="parametric-afts"><span class="header-section-number">10.3.2</span> Parametric AFTs</h3>
<p>As stated, AFTs are usually fully parametric, which means <span class="math inline">\(S_0\)</span> and <span class="math inline">\(h_0\)</span> are chosen according to some specific distribution. Common distribution choices include Weibull, Exponential, Log-logistic, and Log-Normal <span class="citation" data-cites="Kalbfleisch2011 Wang2017">(<a href="P5C26_references.html#ref-Kalbfleisch2011" role="doc-biblioref">John D. Kalbfleisch and Prentice 2011</a>; <a href="P5C26_references.html#ref-Wang2017" role="doc-biblioref">Wang, Li, and Reddy 2019</a>)</span>. The hazard function of the log-logistic distribution is plotted in <a href="#fig-logloghaz" class="quarto-xref">Figure&nbsp;<span>10.4</span></a>, note the hazard is non-monotonic, allowing non-PH representations to be modelled where the risk of an event may increase before decreasing, or vice versa. When distributions are well-specified and the PH assumption is violated, AFTs can outperform PH alternatives <span class="citation" data-cites="Patel2006 Qi2009 Zare2015">(<a href="P5C26_references.html#ref-Patel2006" role="doc-biblioref">Patel, Kay, and Rowell 2006</a>; <a href="P5C26_references.html#ref-Qi2009" role="doc-biblioref">Qi 2009</a>; <a href="P5C26_references.html#ref-Zare2015" role="doc-biblioref">Zare et al. 2015</a>)</span>.</p>
<div id="fig-logloghaz" class="quarto-float quarto-figure quarto-figure-center anchored" alt="TODO">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-logloghaz-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/classical/llog_hazard.png" class="img-fluid figure-img" alt="TODO">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-logloghaz-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.4: Log-logistic hazard curves with a fixed scale parameter of 1 and a changing shape parameter. x-axis is time and y-axis is the log-logistic hazard as a function of time.
</figcaption>
</figure>
</div>
<p>As with the PH model, AFT models can be fit using maximum likelihood estimation of the full-likelihood by plugging in distribution defining functions into (<a href="#eq-aft-surv" class="quarto-xref"><span>10.27</span></a>) and (<a href="#eq-aft-surv" class="quarto-xref"><span>10.27</span></a>) and likelihoods defined in (<a href="P1C4_survival.html#sec-surv-estimation-param" class="quarto-xref"><span>Section 3.5.1</span></a>). Using Exponential this time as an example (the maths is a bit more friendly), first recall that if <span class="math inline">\(X \sim \operatorname{Exp}(\lambda)\)</span> then <span class="math inline">\(h_X(\tau) = \lambda\)</span> and <span class="math inline">\(S_X(\tau) = \exp(-\lambda\tau)\)</span>. Then:</p>
<p><span class="math display">\[
h_{ExpAFT}(\tau|\mathbf{x}_i)= \lambda e^{-\eta_i}
\]</span></p>
<p>and</p>
<p><span class="math display">\[
S_{ExpAFT}(\tau|\mathbf{x}_i)= \exp(-\lambda\tau e^{-\eta_i})
\]</span></p>
<p>Giving the ExpAFT likelihood (<a href="P1C4_survival.html#sec-surv-estimation-param" class="quarto-xref"><span>Section 3.5.1</span></a>):</p>
<p><span class="math display">\[
\begin{aligned}
\mathcal{L}(\boldsymbol{\theta}) &amp;= \prod_{i=1}^n h_Y(t_i|\boldsymbol{\theta})^{\delta_i}S_Y(t_i|\boldsymbol{\theta}) \\
&amp;= \prod_{i=1}^n \Big(\lambda e^{-\eta_i})^{\delta_i}\Big(\exp(-\lambda t_i e^{-\eta_i})\Big) \\
&amp;= \prod_{i=1}^n \lambda^{\delta_i} \exp(-\lambda t_i e^{-\eta_i} - \delta_i\eta_i) \\
\end{aligned}
\]</span></p>
<p>with log-likelihood</p>
<p><span class="math display">\[
\begin{aligned}
\mathcal{l}(\boldsymbol{\theta}) &amp;= \sum_{i=1}^n \log(\lambda^{\delta_i} \exp(-\lambda t_i e^{-\eta_i} - \delta_i\eta_i)) \\
&amp;= \sum_{i=1}^n \delta_i\log(\lambda) - \lambda t_i e^{-\eta_i} - \delta_i\eta_i \\
\end{aligned}
\]</span></p>
<p>Likelihoods can also be derived using the log-linear form in (<a href="#eq-aft-log" class="quarto-xref"><span>10.29</span></a>) however these are beyond the scope of this book. As before, extensions to other censoring types and truncation follows by specifying the correct likelihood form from <a href="P1C4_survival.html#sec-surv-estimation-param" class="quarto-xref"><span>Section 3.5.1</span></a>.</p>
</section>
</section>
<section id="proportional-odds" class="level2" data-number="10.4">
<h2 data-number="10.4" class="anchored" data-anchor-id="proportional-odds"><span class="header-section-number">10.4</span> Proportional Odds</h2>
<p>Proportional odds models <span class="citation" data-cites="Bennett1983">(<a href="P5C26_references.html#ref-Bennett1983" role="doc-biblioref">Bennett 1983</a>)</span> are the final of the three major linear model classes in survival analysis. In contrast to the PH and AFT models just discussed, proportional models are rarely, if ever, used on their own to make inferences about underlying data or as predictive models. Instead they are more commonly found as components within neural networks (<a href="P3C17_neural.html" class="quarto-xref"><span>Chapter 14</span></a>) or in flexible parametric models (discussed next). Therefore this section very briefly describes the motivation for the model and its key properties.</p>
<p>As the name may suggest, the proportional odds model is analogous to the proportional hazards model except with the goal of modelling odds instead of hazards. For a given time <span class="math inline">\(\tau\)</span>, the odds of an event happening at <strong>at</strong> <span class="math inline">\(\tau\)</span> are</p>
<p><span class="math display">\[
O(\tau) = \frac{p(\tau)}{1 - p(\tau)}
\]</span></p>
<p>Where <span class="math inline">\(p(\tau)\)</span> is the probability of the event happening at <span class="math inline">\(\tau\)</span>. Of course as has been seen throughout this book the general interest is centered around the survival probability and therefore a more relevant quantity is the odds of the event not happening <strong>before</strong> <span class="math inline">\(\tau\)</span>:</p>
<p><span class="math display">\[
O(\tau) = \frac{S(\tau)}{1-S(\tau)} = \frac{S(\tau)}{F(\tau)}
\]</span></p>
<p>By considering the same functional form as in the proportional hazards model, the proportional odds model follows analogously, subsituting odds in place of the hazards:</p>
<p><span class="math display">\[
O_{PO}(\tau|\mathbf{x}_i) =  O_0(\tau)\exp(\eta_i)
\]</span></p>
<p>where <span class="math inline">\(O_0\)</span> is the baseline odds.</p>
<p>By the same logic as the proportional hazards model, this model assumes <span class="math inline">\(O(\tau|\mathbf{x}_i) \propto \exp(\eta_i)\)</span> and that a unit increase in a covariate multiplies the odds of surviving past <span class="math inline">\(t\)</span> by <span class="math inline">\(\exp(\eta_i)\)</span>. A useful implication is the convergence of hazard functions, which states <span class="math inline">\(h_i(\tau)/h_0(\tau) \rightarrow 1\)</span> as <span class="math inline">\(\tau \rightarrow \infty\)</span> <span class="citation" data-cites="Kirmani2001">(<a href="P5C26_references.html#ref-Kirmani2001" role="doc-biblioref">Kirmani and Gupta 2001</a>)</span>. To see this note that the PO model can be represented in terms of the hazard function via <span class="citation" data-cites="Collett2014">(<a href="P5C26_references.html#ref-Collett2014" role="doc-biblioref">Collett 2014</a>)</span></p>
<p><span id="eq-po"><span class="math display">\[
h_{PO}(\tau|\mathbf{x}_i) =  h_0(\tau)\Bigg(1 - \frac{S_0(\tau)}{(\exp(\eta_i) - 1)^{-1} + S_0(\tau)} \Bigg)
\tag{10.30}\]</span></span></p>
<p>Dividing by the baseline hazard yields</p>
<p><span class="math display">\[
\frac{h_{PO}(\tau|\mathbf{x}_i)}{h_0(\tau)} =  \Bigg(1 - \frac{S_0(\tau)}{(\exp(\eta_i) - 1)^{-1} + S_0(\tau)} \Bigg) =  \frac{(\exp(\eta_i) - 1)^{-1} }{(\exp(\eta_i) - 1)^{-1} + S_0(\tau)}
\]</span></p>
<p>Simplifying gives <span class="math inline">\((1 + S_0(\tau)(\exp(\eta_i) - 1))^{-1}\)</span>. As <span class="math inline">\(S_0(\tau) \rightarrow 0\)</span> when <span class="math inline">\(\tau \rightarrow \infty\)</span>, it follows that the hazard ratio tends to <span class="math inline">\(1\)</span> as <span class="math inline">\(\tau\)</span> increases.</p>
<p>This means that for any individual, their individual hazard approaches the baseline hazard over a long period of time. This assumption holds in several contexts, commonly in medical domains in which death is the event of interest. For example, take two patients with a disease, patient <span class="math inline">\(i\)</span> receives treatment and patient <span class="math inline">\(j\)</span> does not. Let <span class="math inline">\(\exp(\eta_i) = 4\)</span>, <span class="math inline">\(\exp(\eta_j) = 1\)</span>, <span class="math inline">\(S_0(0) = 1\)</span>, and <span class="math inline">\(S_0(5) = 0.01\)</span>. Following (<a href="#eq-po" class="quarto-xref"><span>10.30</span></a>), we have for patient <span class="math inline">\(i\)</span></p>
<p><span class="math display">\[
h_{PO}(0|\mathbf{x}_i) =  0.25h_0(0); \quad\quad h_{PO}(\tau|\mathbf{x}_i) =  0.97h_0(5)
\]</span></p>
<p>and for patient <span class="math inline">\(j\)</span></p>
<p><span class="math display">\[
h_{PO}(0|\mathbf{x}_j) = h_0(0); \quad\quad h_{PO}(5|\mathbf{x}_j) = h_0(5)
\]</span></p>
<p>The treatment effect reduces the hazard for observation <span class="math inline">\(i\)</span> at early time-points. However, at the later time-point, the hazard is very similar for both observations.</p>
<p>There is no simple closed form expression for the partial likelihood of a semi-parametric proportional odds model and hence in practice a Log-logistic distribution is usually assumed for the baseline odds and the model is fit by maximum likelihood estimation on the full likelihood <span class="citation" data-cites="Bennett1983">(<a href="P5C26_references.html#ref-Bennett1983" role="doc-biblioref">Bennett 1983</a>)</span>, discussed further in the next section.</p>
</section>
<section id="sec-flexible" class="level2" data-number="10.5">
<h2 data-number="10.5" class="anchored" data-anchor-id="sec-flexible"><span class="header-section-number">10.5</span> Flexible Parametric Models</h2>
<p>Royston-Parmar flexible parametric models <span class="citation" data-cites="Royston2002">(<a href="P5C26_references.html#ref-Royston2002" role="doc-biblioref">Royston and Parmar 2002</a>)</span> extend PH and PO models by estimating the baseline hazard with natural cubic splines. The model was designed to keep the form of the PH or PO methods but without being forced to estimate a misleading baseline hazard (for semi-parametric models) or missspecifying the survival distribution (for fully-parametric models). This is achieved by fitting natural cubic splines in place of the baseline hazard.</p>
<p>The crux of the method is to use splines to model time on a log-scale and to either estimate the log cumulative Hazard for PH models,or the log Odds for PO models. For the flexible PH model, a Weibull distribution is the basis for the baseline distribution, whereas a Log-logistic distribution is assumed for the baseline odds in the flexible PO model. The exact derivation of the model requires a lot of mathematical exposition which is not included here, a very good summary of the model is given in <span class="citation" data-cites="Collett2014">Collett (<a href="P5C26_references.html#ref-Collett2014" role="doc-biblioref">2014</a>)</span>. Instead, below is the model in its full form with an explanation of the variables and figures that demonstrate cubic splines.</p>
<p>The flexible parametric Royston-Parmar (RP) proportional hazards and proportional odds model are respectively defined by</p>
<p><span id="eq-rp-hazard"><span class="math display">\[
\log{H}_{RP}(\tau|\mathbf{x}_i) = s(\tau|\boldsymbol{\gamma},\boldsymbol{k}) + \eta_i
\tag{10.31}\]</span></span></p>
<p><span id="eq-rp-odds"><span class="math display">\[
\log{O}_{RP}(\tau|\mathbf{x}_i) = s(\tau|\boldsymbol{\gamma},\boldsymbol{k}) + \eta_i
\tag{10.32}\]</span></span></p>
<p>where <span class="math inline">\(\boldsymbol{\gamma}\)</span> are spline coefficients to be estimated by maximum likelihood estimation, <span class="math inline">\(\boldsymbol{k}\)</span> are the positions of <span class="math inline">\(K\)</span> knots, and <span class="math inline">\(s\)</span> is the restricted cubic spline function in log time defined by</p>
<p><span class="math display">\[
s(\tau|\boldsymbol{\gamma},\boldsymbol{k}) = \gamma_0 + \gamma_1\log(\tau) + \gamma_2\nu_1(\log(\tau)) + ... + \gamma_{K}\nu_K(\log(\tau))
\]</span></p>
<p><span class="math inline">\(\nu_j\)</span> is the basis function at knot <span class="math inline">\(k_j\)</span> defined by</p>
<p><span class="math display">\[
\nu_j(x) = (x - k_j)^3_+ - \lambda_j(x - k_{min})^3_+ - (1 - \lambda_j)(x - k_{max})^3_+
\]</span></p>
<p>where <span class="math display">\[
\lambda_j = \frac{k_{max} - k_j}{k_{max} - k_{min}}
\]</span></p>
<p>and <span class="math inline">\((x - y)_+ = \max\{0, (x - y)\}\)</span> for any <span class="math inline">\(x, y\)</span>, and where <span class="math inline">\(k_{min}\)</span> and <span class="math inline">\(k_{max}\)</span> are the boundaries of the cubic spline, meaning the curve is linear when <span class="math inline">\(\log(t) &lt; k_{min}\)</span> or <span class="math inline">\(\log(t) &gt; k_{max}\)</span>.</p>
<p>To see how the proportional hazards RP model relates to the Weibull distribution, first we integrate and take logs of the Weibull-PH hazard function from equation (<a href="#eq-ph-weibull" class="quarto-xref"><span>10.11</span></a>):</p>
<p><span class="math display">\[
\log(H_{WeibullPH}(\tau|\mathbf{x}_i)) = \log\big((\lambda \tau^\gamma) \exp(\eta_i)\big) = \log(\lambda) + \gamma\log(\tau) + \eta_i
\]</span></p>
<p>Setting <span class="math inline">\(\gamma_0 = \log(\lambda)\)</span> and <span class="math inline">\(\gamma_1 = \gamma\)</span> yields (<a href="#eq-rp-hazard" class="quarto-xref"><span>10.31</span></a>) when there are no knots. Analogous results can be shown between (<a href="#eq-rp-odds" class="quarto-xref"><span>10.32</span></a>) and the Log-logistic distribution.</p>
<p>To fit the model, the number and position of knots are theoretically tunable, although Royston and Parmar advised against tuning and suggest often only one internal knot is required and the placement of the knot does not make a significant difference to performance <span class="citation" data-cites="Royston2002">(<a href="P5C26_references.html#ref-Royston2002" role="doc-biblioref">Royston and Parmar 2002</a>)</span>. Increasing knots can increase model overfitting however <span class="citation" data-cites="Bower2019">Bower et al. (<a href="P5C26_references.html#ref-Bower2019" role="doc-biblioref">2019</a>)</span> showed up to seven knots does not significantly increase model bias. The model’s primary advantage is it’s flexibility to model non-linear effects and can also be extended to time-dependent covariates. Moreover, the model can be fit via maximum likelihood estimation and thus many standard off-shelf routines for estimating a smooth survival time function. Despite advantages, the model appears to be limited in common use which makes it difficult to verify the model’s utility across different contexts <span class="citation" data-cites="Ng2018">(<a href="P5C26_references.html#ref-Ng2018" role="doc-biblioref">Ng et al. 2018</a>)</span>.</p>
<p>In the same manner as other proportional hazards models, the Royston-Parmar model can be extended to competing risks by modelling cause-specific hazards, considering only one event at a time and censoring competing events <span class="citation" data-cites="Hinchliffe2013">(<a href="P5C26_references.html#ref-Hinchliffe2013" role="doc-biblioref">Hinchliffe and Lambert 2013</a>)</span>.</p>
</section>
<section id="sec-classical-improving" class="level2" data-number="10.6">
<h2 data-number="10.6" class="anchored" data-anchor-id="sec-classical-improving"><span class="header-section-number">10.6</span> Improving traditional models</h2>
<p>A number of model-agnostic algorithms have been created to improve a model’s predictive ability. When applied to traditional algorithms, these methods can be used to create powerful models that outperform other machine learning. As each could be the subject of a whole book, this section remains brief and just covers the general overview. These are split into methods for:</p>
<ol type="1">
<li>modelling non-linear data effects;</li>
<li>reducing the number of variables in a dataset; and</li>
<li>combining predictions from multiple models.</li>
</ol>
<section id="non-linear-effects" class="level3" data-number="10.6.1">
<h3 data-number="10.6.1" class="anchored" data-anchor-id="non-linear-effects"><span class="header-section-number">10.6.1</span> Non-linear effects</h3>
<p>One of the major limitations of the models discussed so far is the assumption of a linear relationship between covariates and outcomes (on the scale of the predictor). At first one might view the Cox model as non-linear due to the presence of the exponential function. However, the linearity becomes clear when the model is equivalently expressed as:</p>
<p><span class="math display">\[
\log\left(\frac{h(\tau|\mathbf{x}_i)}{h_0(\tau)}\right) = x_1\beta_1 + ... x_p\beta_p
\]</span></p>
<p>Consider modelling the time until disease progression with covariates age (continuous) and treatment (binary):</p>
<p><span class="math display">\[
\log\left(\frac{h(\tau|\mathbf{x}_i)}{h_0(\tau)}\right) = x_{age_i}\beta_{age} + x_{trt_i}\beta_{trt}
\]</span></p>
<p>In this form, increasing age from <span class="math inline">\(1\)</span> to <span class="math inline">\(21\)</span> or <span class="math inline">\(81\)</span> to <span class="math inline">\(101\)</span> has the same effect on the log hazard ratio; this is clearly not realistic. There are many approaches to relaxing linearity; these are discussed extensively elsewhere and not repeated here, we recommend <span class="citation" data-cites="Hastie2013">(<a href="P5C26_references.html#ref-Hastie2013" role="doc-biblioref">James et al. 2013</a>)</span> which covers non-linear modelling in detail.</p>
<p>In brief, PH and AFT can be extended to <em>generalised additive models</em> (GAM) in the ‘usual’ way. For example for the Cox model,</p>
<p><span class="math display">\[
\log\left(\frac{h_i(\tau|\mathbf{x}_i)}{h_0(\tau)}\right) = f_1(x_1) + ... + f_p(x_p)
\]</span></p>
<p>where each <span class="math inline">\(f_j\)</span> is a smooth, possibly non-linear function of its covariate. If all <span class="math inline">\(f_j\)</span> are the identity function then this reduces to the standard Cox model. The functions <span class="math inline">\(f_j\)</span> are often chosen to be natural splines, but step functions, polynomial bases, or any other transformation can also be used. The Royston-Parmar model (<a href="#sec-flexible" class="quarto-xref"><span>Section 10.5</span></a>) is a special case of a GAM where splines are used to model the baseline hazard.</p>
</section>
<section id="dimension-reduction-and-feature-selection" class="level3" data-number="10.6.2">
<h3 data-number="10.6.2" class="anchored" data-anchor-id="dimension-reduction-and-feature-selection"><span class="header-section-number">10.6.2</span> Dimension reduction and feature selection</h3>
<p>In a predictive modelling problem, only a small subset of variables in datasets tend to be relevant for correctly predicting the outcome. Other variables are either redundant – they provide no more information than their counterparts – or irrelevant – they do not influence the outcome. In these cases, using all variables for modelling results in worse interpretability, increased computational complexity, and often inferior model performance as model’s tend to overfit the training data and generalise poorly to new data.</p>
<p>To improve model performance, one can therefore ‘help’ models by applying feature selection methods to reduce the number of variables in the dataset. Feature selection is often grouped into three categories: 1) filters; 2) wrappers; and 3) embedded methods. Wrappers fit multiple models on subsets of variables and select the best performing subsets, this is often computationally infeasible in the context of very large datasets, and as such have less relevance in survival analysis which often tackles very high-dimensional datasets such as genomic datasets and detailed time-series economic data. This section only looks at methods specific to survival analysis and does not consider general algorithms such as PCA, see further reading below for suggested additional material that covers these areas.</p>
<section id="embedded-methods" class="level4 unlisted unnumbered">
<h4 class="unlisted unnumbered anchored" data-anchor-id="embedded-methods">Embedded methods</h4>
<p>Embedded methods refers to those that are incorporated during model fitting. The vast majority of machine learning models incorporate embedded methods and thus reduce a dataset’s size as part of the training process. In contrast, models that do not apply any form of feature selection will perform poorly when there is a large number of variables in a dataset. One model that straddles the line of ‘traditional’ and ‘machine learning’ methodology is the elastic Cox model, which incorporates the ‘lasso’ and ‘ridge’ regularization methods. Given a generic learning algorithm, lasso and ridge regularization constrain the model coefficients subject to the <span class="math inline">\(\cal{l}^1\)</span>-norm and <span class="math inline">\(\cal{l}^2\)</span>-norm respectively. The Lasso-Cox <span class="citation" data-cites="Tibshirani1997">(<a href="P5C26_references.html#ref-Tibshirani1997" role="doc-biblioref">Tibshirani 1997</a>)</span> model fits the Cox model by estimating <span class="math inline">\(\boldsymbol{\beta}\)</span> as</p>
<p><span class="math display">\[
\hat{\boldsymbol{\beta}} = \mathop{\mathrm{arg\,max}}\mathcal{L}(\boldsymbol{\beta}); \text{ subject to } \sum |\beta_j| \leq \gamma
\]</span></p>
<p>where <span class="math inline">\(\mathcal{L}\)</span> is the likelihood defined in (1) and <span class="math inline">\(\gamma &gt; 0\)</span> is a hyper-parameter.</p>
<p>In contrast, the Ridge-Cox model estimates <span class="math inline">\(\boldsymbol{\beta}\)</span> as</p>
<p><span class="math display">\[
\hat{\boldsymbol{\beta}} = \mathop{\mathrm{arg\,max}}\ \mathcal{L}(\boldsymbol{\beta}); \text{ subject to } \sum \beta_j^2 \leq \gamma
\]</span></p>
<p>Ridge and lasso are both shrinkage methods, which are used to reduce model variance and overfitting, especially in the context of multi-collinearity. However, the <span class="math inline">\(\mathcal{l}^1\)</span> norm in Lasso regression can also shrink coefficients to zero and thus performs variable selection as well. It is therefore possible to incorporate a feature selection method first and then pass the results to a Ridge-Cox model – though experiments have shown Ridge-Cox on its own is already a powerful tool <span class="citation" data-cites="Spooner2020">(<a href="P5C26_references.html#ref-Spooner2020" role="doc-biblioref">Spooner et al. 2020</a>)</span>. Alternatively, as with many machine learning algorithms, deciding between lasso and ridge can be performed in empirical benchmark experiments by using elastic net <span class="citation" data-cites="Simon2011 Zou2005">(<a href="P5C26_references.html#ref-Simon2011" role="doc-biblioref">Simon et al. 2011</a>; <a href="P5C26_references.html#ref-Zou2005" role="doc-biblioref">Zou and Hastie 2005</a>)</span>, which is a convex combination of <span class="math inline">\(\mathcal{l}^1\)</span> and <span class="math inline">\(\mathcal{l}^2\)</span> penalties such that <span class="math inline">\(\boldsymbol{\beta}\)</span> is estimated as</p>
<p><span class="math display">\[
\hat{\boldsymbol{\beta}} = \mathop{\mathrm{arg\,max}}\mathcal{L}(\boldsymbol{\beta}); \text{ subject to } \alpha \sum |\beta_j| + (1-\alpha) \sum \beta_j^2 \leq \gamma
\]</span></p>
<p>where <span class="math inline">\(\alpha\)</span> is a hyper-parameter to be tuned.</p>
</section>
<section id="filter-methods" class="level4 unlisted unnumbered">
<h4 class="unlisted unnumbered anchored" data-anchor-id="filter-methods">Filter methods</h4>
<p>Filter methods are a two-step process that score features according to some metric and then select either a given number of top-performing features (i.e., have the best score) or those where the score exceeds some threshold. Once again determining the number of features to select, or the threshold to exceed, can be performed via hyperparameter optimisation. <span class="citation" data-cites="Bommert2021">Bommert et al. (<a href="P5C26_references.html#ref-Bommert2021" role="doc-biblioref">2021</a>)</span> compared 14 filter methods for high-dimensional survival data by extending existing methods, making use of tools seen throughout this book including non-parametric estimators, martingale residuals, and inverse probability of censoring weighting. However, the authors found that the method that outperformed all others was a simple variance filter:</p>
<p><span class="math display">\[
V(\mathbf{x}_{;j}) = \text{Var}(\mathbf{x}_{;j})
\]</span></p>
<p>where <span class="math inline">\(\mathbf{x}_{;j}\)</span> is the <span class="math inline">\(j\)</span>th variable in the data and <span class="math inline">\(V\)</span> is the resulting score. The filter measures the amount of variance in the feature and removes features that have little variation.</p>
<p>Another common filter method is to train another model and make use of its embedded feature selection and pass these results to a simpler model. This allows a traditional model to be trained on relevant features without loss to interpretability or performance. Common choices for models to use in the first step of the pipeline include random forests (<a href="P3C14_forests.html" class="quarto-xref"><span>Chapter 11</span></a>) and gradient boosting machines (<a href="P3C16_boosting.html" class="quarto-xref"><span>Chapter 13</span></a>).</p>
</section>
</section>
<section id="ensemble-methods" class="level3" data-number="10.6.3">
<h3 data-number="10.6.3" class="anchored" data-anchor-id="ensemble-methods"><span class="header-section-number">10.6.3</span> Ensemble methods</h3>
<p>Ensemble methods fit multiple models and combine the result into a single prediction. Common ensemble methods include boosting, bagging, and stacking. These are briefly explained below and can be applied to any model, whether machine learning or a simple linear model. Note that nested cross-validation should be used when fitting any of the models below in order to ensure no data is ‘leaked’ between training and predictions (<a href="P1C3_machinelearning.html#sec-ml-opt" class="quarto-xref"><span>Section 2.5</span></a>).</p>
<section id="bagging-and-averaging" class="level4 unlisted unnumbered">
<h4 class="unlisted unnumbered anchored" data-anchor-id="bagging-and-averaging">Bagging and averaging</h4>
<p>The simplest ensemble method is to fit multiple models on the same data and make predictions by taking an average over the individual model predictions. The average over predictions could be uniform, weighted with weights selected through expert knowledge, or weighted with weights optimised as hyper-parameters. Ensemble methods perform best when there is high variance between models as each then captures unique information about the underlying data. Therefore ensemble averaging is more common after first subsetting the training data and training each model on a different subset.</p>
<p>Whilst increasing variance is beneficial, too much variance may result in worse predictions. Hence, bagging (Bootstrap AGGregatING) is a common approach to increase variance without losing predictive accuracy. Bootstrapping is the process of sampling data with replacement, meaning the rows may be duplicated in each subset – this is discussed further in <a href="P3C14_forests.html" class="quarto-xref"><span>Chapter 11</span></a>. After sampling the process is the same with predictions made and averaged.</p>
</section>
<section id="model-based-boosting" class="level4 unlisted unnumbered">
<h4 class="unlisted unnumbered anchored" data-anchor-id="model-based-boosting">Model-based boosting</h4>
<p>Model-based boosting fits a sequence of models that iteratively improve model performance by correcting the previous model’s mistakes. The initial model is trained as usual on a testing dataset, and subsequent models are fit on the same features but using ‘pseudo-residuals’ as targets (a regression problem). These pseudo-residuals are the negative gradient of a chosen loss from the previous iteration – this is discussed in detail in <a href="P3C16_boosting.html" class="quarto-xref"><span>Chapter 13</span></a>. The result is a gradual increase in improvement as each model captures patterns missed previously. In a survival analysis context, many of the losses discussed in Part II can be used in this pipeline, with the choice of loss dependent on the task of interest. Model-based boosting is a generic pipeline which may underperform the purpose-built algorithms discussed in <a href="P3C16_boosting.html" class="quarto-xref"><span>Chapter 13</span></a>.</p>
</section>
<section id="stacking" class="level4 unlisted unnumbered">
<h4 class="unlisted unnumbered anchored" data-anchor-id="stacking">Stacking</h4>
<p>Stacking can improve model performance by fitting multiple models and aggregating the predictions using a meta-model. Fitting a meta-model, often a simple linear model, results in fitted coefficients that weight the input models according to how close or far they were from the truth.</p>
<p>Training data is partitioned (once or several times) and the first partition is used to train several independent models, a meta-model is fit using the outputs (predictions) from the base models as features and the targets <span class="math inline">\((t_i,\delta_i)\)</span> from the second partition as targets.</p>
<p>As an example, take stacking three Cox models with a Cox meta-model. Let <span class="math inline">\(\mathcal{D}= \{(\mathbf{x}_i, t_i, \delta_i)\}\)</span> be a dataset. Partition <span class="math inline">\(\mathcal{D}\)</span> into two disjoint datasets <span class="math inline">\(\mathcal{D}_1\)</span> of size <span class="math inline">\(n\)</span> and <span class="math inline">\(\mathcal{D}_2\)</span> of size <span class="math inline">\(m\)</span>. Three Cox base models are fit on <span class="math inline">\(\mathcal{D}_1\)</span> and linear predictors are obtained (predicted) for all <span class="math inline">\(m\)</span> observations in <span class="math inline">\(\mathcal{D}_2\)</span>:</p>
<p><span class="math display">\[
Z =
\begin{bmatrix}
\hat{\eta}^{(1)}_{1} &amp; \cdots &amp; \hat{\eta}^{(3)}_{1} \\
\vdots &amp; \ddots &amp; \vdots \\
\hat{\eta}^{(1)}_{m} &amp; \cdots &amp; \hat{\eta}^{(3)}_{m} \\
\end{bmatrix}
\]</span></p>
<p>where <span class="math inline">\(\hat{\eta}^{(j)}_{i}\)</span> is the linear predictor for the <span class="math inline">\(i\)</span>th observation in the validation set from the <span class="math inline">\(j\)</span>th base model.</p>
<p>Fit the meta-Cox model on <span class="math inline">\((Z, (t_i, \delta_i)_{i \in \mathcal{D}_2})\)</span>:</p>
<p><span class="math display">\[
h_M(\tau|\hat{\boldsymbol{\eta}}_i) = h^{(M)}_{0}(\tau)\exp(\beta^{(M)}_1\hat{\eta}^{(1)}_{i} + \beta^{(M)}_2\hat{\eta}^{(2)}_{i} + \beta^{(M)}_3\hat{\eta}^{(3)}_{i}), \quad i \in \mathcal{D}_2
\]</span></p>
<p>Finally, the base learners are refit on all <span class="math inline">\(\mathcal{D}\)</span> but keeping <span class="math inline">\(\hat{\boldsymbol{\beta}}^{(M)}\)</span> and <span class="math inline">\(\hat{h}^{(M)}_0\)</span> from the meta-model fixed.</p>
<p>Predictions for a new observation, <span class="math inline">\(\mathbf{x}^*\)</span> are made by first predicting <span class="math inline">\((\hat{\eta}_*^{(1)},\hat{\eta}_*^{(2)},\hat{\eta}_*^{(3)})\)</span> from the trained base models and passing those to <span class="math inline">\(h_M\)</span> using the fitted <span class="math inline">\(\hat{\boldsymbol{\beta}}^{(M)}\)</span> coefficients and <span class="math inline">\(\hat{h}^{(M)}_0\)</span>.</p>
<p>In the above example, Cox models are used throughout. However, any machine learning models with the same prediction types can be stacked, including combinations of models.</p>
</section>
</section>
</section>
<section id="conclusion" class="level2" data-number="10.7">
<h2 data-number="10.7" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">10.7</span> Conclusion</h2>
<div class="callout callout-style-default callout-warning no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Key takeaways
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Traditional statistical models broadly fall into three categories: non-parametric estimators, semi-parametric models that include a baseline estimate, and fully-parametric estimates. Each has its own advantages and disadvantages.</li>
<li>Non-parametric estimators are used throughout survival analysis, often as components in more complex machine learning models.</li>
<li>Proportional hazards and accelerated failure time models encode different assumptions but both are powerful tools for learning patterns from data and even in prediction problems.</li>
<li>The boundary between machine learning and statistical models is fuzzy, and simpler survival models can outperform more complex machine learning alternatives.</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Limitations
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Several models can be extended to time-dependent covariates however these are not well-developed for predictive problems.</li>
<li>Simpler (linear) models encode assumptions that are rarely met in practice, for example the proportional hazards assumption. However, even if assumptions are violated, these could still generalise well to new data and are therefore worth including in benchmark experiments.</li>
<li>Unregularized models perform badly on high-dimensional data without some form of pre-processing, however this is relatively simple with modern off-shelf software such as <span class="math inline">\(\textbf{sklearn}\)</span> and <span class="math inline">\(\textbf{mlr3}\)</span>.</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Further reading
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>To learn more about hazard ratios from Cox models and complexities in interpretation, we recommend <span class="citation" data-cites="Sashegyi2017">Sashegyi and Ferry (<a href="P5C26_references.html#ref-Sashegyi2017" role="doc-biblioref">2017</a>)</span> and <span class="citation" data-cites="Spruance2004">Spruance et al. (<a href="P5C26_references.html#ref-Spruance2004" role="doc-biblioref">2004</a>)</span>.</li>
<li><span class="citation" data-cites="Collett2014">Collett (<a href="P5C26_references.html#ref-Collett2014" role="doc-biblioref">2014</a>)</span> and <span class="citation" data-cites="KalbfleischPrentice1973">J. D. Kalbfleisch and Prentice (<a href="P5C26_references.html#ref-KalbfleischPrentice1973" role="doc-biblioref">1973</a>)</span> both provide comprehensive reading for traditional statistical models. The former is slightly less technical and covers extensions to multiple settings.</li>
<li>For more abstract feature selection algorithms that can be applied to any data (survival or otherwise), see <span class="citation" data-cites="Chandrashekar2014">Chandrashekar and Sahin (<a href="P5C26_references.html#ref-Chandrashekar2014" role="doc-biblioref">2014</a>)</span> and <span class="citation" data-cites="Guyon2003">Guyon and Elisseeff (<a href="P5C26_references.html#ref-Guyon2003" role="doc-biblioref">2003</a>)</span>.</li>
<li>Kernel-based approaches have been suggested for smooth non-parametric estimates of the baseline hazard, these do not appear commonly used in practice but details can be found in <span class="citation" data-cites="Gefeller1992">Gefeller and Dette (<a href="P5C26_references.html#ref-Gefeller1992" role="doc-biblioref">1992</a>)</span> and <span class="citation" data-cites="Muller1994">Müller and Wang (<a href="P5C26_references.html#ref-Muller1994" role="doc-biblioref">1994</a>)</span>.</li>
</ul>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-Akritas1994" class="csl-entry" role="listitem">
Akritas, Michael G. 1994. <span>“<span class="nocase">Nearest Neighbor Estimation of a Bivariate Distribution Under Random Censoring</span>.”</span> <em>Ann. Statist.</em> 22 (3): 1299–1327. <a href="https://doi.org/10.1214/aos/1176325630">https://doi.org/10.1214/aos/1176325630</a>.
</div>
<div id="ref-Austin2017b" class="csl-entry" role="listitem">
Austin, Peter C., and Jason P. Fine. 2017. <span>“Practical Recommendations for Reporting Fine-Gray Model Analyses for Competing Risk Data.”</span> <em>Statistics in Medicine</em> 36 (27): 4391–4400. https://doi.org/<a href="https://doi.org/10.1002/sim.7501">https://doi.org/10.1002/sim.7501</a>.
</div>
<div id="ref-Austin2016" class="csl-entry" role="listitem">
Austin, Peter C., Douglas S. Lee, and Jason P. Fine. 2016. <span>“Introduction to the Analysis of Survival Data in the Presence of Competing Risks.”</span> <em>Circulation</em> 133 (6): 601–9. <a href="https://doi.org/10.1161/CIRCULATIONAHA.115.017719">https://doi.org/10.1161/CIRCULATIONAHA.115.017719</a>.
</div>
<div id="ref-Austin2022b" class="csl-entry" role="listitem">
Austin, Peter C., Hein Putter, Douglas S. Lee, and Ewout W. Steyerberg. 2022. <span>“Estimation of the Absolute Risk of Cardiovascular Disease and Other Events: Issues with the Use of Multiple Fine-Gray Subdistribution Hazard Models.”</span> <em>Circulation: Cardiovascular Quality and Outcomes</em> 15 (2): e008368. <a href="https://doi.org/10.1161/CIRCOUTCOMES.121.008368">https://doi.org/10.1161/CIRCOUTCOMES.121.008368</a>.
</div>
<div id="ref-Beaulac2020" class="csl-entry" role="listitem">
Beaulac, Cédric, Jeffrey S. Rosenthal, Qinglin Pei, Debra Friedman, Suzanne Wolden, and David Hodgson. 2020. <span>“An Evaluation of Machine Learning Techniques to Predict the Outcome of Children Treated for Hodgkin-Lymphoma on the AHOD0031 Trial.”</span> <em>Applied Artificial Intelligence</em> 34 (14): 1100–1114. <a href="https://doi.org/10.1080/08839514.2020.1815151">https://doi.org/10.1080/08839514.2020.1815151</a>.
</div>
<div id="ref-Bennett1983" class="csl-entry" role="listitem">
Bennett, Steve. 1983. <span>“<span class="nocase">Analysis of survival data by the proportional odds model</span>.”</span> <em>Statistics in Medicine</em> 2 (2): 273–77. https://doi.org/<a href="https://doi.org/10.1002/sim.4780020223">https://doi.org/10.1002/sim.4780020223</a>.
</div>
<div id="ref-Blanche2013" class="csl-entry" role="listitem">
Blanche, Paul, Jean-François Dartigues, and Hélène Jacqmin-Gadda. 2013. <span>“<span class="nocase">Review and comparison of ROC curve estimators for a time-dependent outcome with marker-dependent censoring</span>.”</span> <em>Biometrical Journal</em> 55 (5): 687–704. <a href="https://doi.org/10.1002/bimj.201200045">https://doi.org/10.1002/bimj.201200045</a>.
</div>
<div id="ref-Bommert2021" class="csl-entry" role="listitem">
Bommert, Andrea, Thomas Welchowski, Matthias Schmid, and Jörg Rahnenführer. 2021. <span>“Benchmark of Filter Methods for Feature Selection in High-Dimensional Gene Expression Survival Data.”</span> <em>Briefings in Bioinformatics</em> 23 (1): bbab354. <a href="https://doi.org/10.1093/bib/bbab354">https://doi.org/10.1093/bib/bbab354</a>.
</div>
<div id="ref-bonnevilleWhyYouShould2024" class="csl-entry" role="listitem">
Bonneville, Edouard F, Liesbeth C de Wreede, and Hein Putter. 2024. <span>“Why You Should Avoid Using Multiple <span>Fine</span>–<span>Gray</span> Models: Insights from (Attempts at) Simulating Proportional Subdistribution Hazards Data.”</span> <em>Journal of the Royal Statistical Society Series A: Statistics in Society</em> 187 (3): 580–93. <a href="https://doi.org/10.1093/jrsssa/qnae056">https://doi.org/10.1093/jrsssa/qnae056</a>.
</div>
<div id="ref-Bower2019" class="csl-entry" role="listitem">
Bower, Hannah, Michael J Crowther, Mark J Rutherford, Therese M.-L. Andersson, Mark Clements, Xing-Rong Liu, Paul W Dickman, and Paul C Lambert. 2019. <span>“<span class="nocase">Capturing simple and complex time-dependent effects using flexible parametric survival models: A simulation study</span>.”</span> <em>Communications in Statistics - Simulation and Computation</em>, July, 1–17. <a href="https://doi.org/10.1080/03610918.2019.1634201">https://doi.org/10.1080/03610918.2019.1634201</a>.
</div>
<div id="ref-Breslow1972" class="csl-entry" role="listitem">
Breslow, N. 1972. <span>“<span class="nocase">Discussion following <span>‘Regression models and life tables’</span> by D. R. Cox</span>.”</span> <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 34 (2): 187–220.
</div>
<div id="ref-breslowCovarianceAnalysisCensored1974" class="csl-entry" role="listitem">
———. 1974. <span>“Covariance <span>Analysis</span> of <span>Censored Survival Data</span>.”</span> <em>Biometrics</em> 30 (1): 89–99. <a href="https://doi.org/10.2307/2529620">https://doi.org/10.2307/2529620</a>.
</div>
<div id="ref-Buckley1979" class="csl-entry" role="listitem">
Buckley, Jonathan, and Ian James. 1979. <span>“<span class="nocase">Linear Regression with Censored Data</span>.”</span> <em>Biometrika</em> 66 (3): 429–36. <a href="https://doi.org/10.2307/2335161">https://doi.org/10.2307/2335161</a>.
</div>
<div id="ref-Burk2025" class="csl-entry" role="listitem">
Burk, Lukas, John Zobolas, Bernd Bischl, Andreas Bender, Marvin N. Wright, and Raphael Sonabend. 2024. <span>“<span class="nocase">A Large-Scale Neutral Comparison Study of Survival Models on Low-Dimensional Data</span>,”</span> June. <a href="http://arxiv.org/abs/2406.04098">http://arxiv.org/abs/2406.04098</a>.
</div>
<div id="ref-Chandrashekar2014" class="csl-entry" role="listitem">
Chandrashekar, Girish, and Ferat Sahin. 2014. <span>“A Survey on Feature Selection Methods.”</span> <em>Computers &amp; Electrical Engineering</em> 40 (1): 16–28. https://doi.org/<a href="https://doi.org/10.1016/j.compeleceng.2013.11.024">https://doi.org/10.1016/j.compeleceng.2013.11.024</a>.
</div>
<div id="ref-Collett2014" class="csl-entry" role="listitem">
Collett, David. 2014. <em><span class="nocase">Modelling Survival Data in Medical Research</span></em>. 3rd ed. CRC.
</div>
<div id="ref-Cox1972" class="csl-entry" role="listitem">
Cox, D. R. 1972. <span>“<span class="nocase">Regression Models and Life-Tables</span>.”</span> <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 34 (2): 187–220.
</div>
<div id="ref-Cox1975" class="csl-entry" role="listitem">
———. 1975. <span>“<span>Partial Likelihood</span>.”</span> <em>Biometrika</em> 62 (2): 269–76. <a href="https://doi.org/10.1080/03610910701884021">https://doi.org/10.1080/03610910701884021</a>.
</div>
<div id="ref-Efron1977" class="csl-entry" role="listitem">
Efron, Bradley. 1977. <span>“<span class="nocase">The Efficiency of Cox’s Likelihood Function for Censored Data</span>.”</span> <em>Journal of the American Statistical Association</em> 72 (359): 557–65. <a href="https://doi.org/10.1080/01621459.1977.10480613">https://doi.org/10.1080/01621459.1977.10480613</a>.
</div>
<div id="ref-Fine1999" class="csl-entry" role="listitem">
Fine, Jason P., and Robert J. Gray. 1999. <span>“A Proportional Hazards Model for the Subdistribution of a Competing Risk.”</span> <em>Journal of the American Statistical Association</em> 94 (446): 496–509. <a href="http://www.jstor.org/stable/2670170">http://www.jstor.org/stable/2670170</a>.
</div>
<div id="ref-Gefeller1992" class="csl-entry" role="listitem">
Gefeller, Olaf, and Holger Dette. 1992. <span>“Nearest Neighbour Kernel Estimation of the Hazard Function from Censored Data.”</span> <em>Journal of Statistical Computation and Simulation</em> 43 (1-2): 93–101. <a href="https://doi.org/10.1080/00949659208811430">https://doi.org/10.1080/00949659208811430</a>.
</div>
<div id="ref-Gensheimer2018" class="csl-entry" role="listitem">
Gensheimer, Michael F., and Balasubramanian Narasimhan. 2018. <span>“<span class="nocase">A Simple Discrete-Time Survival Model for Neural Networks</span>,”</span> 1–17. <a href="https://doi.org/arXiv:1805.00917v3">https://doi.org/arXiv:1805.00917v3</a>.
</div>
<div id="ref-Gompertz1825" class="csl-entry" role="listitem">
Gompertz, Benjamin. 1825. <span>“<span class="nocase">On the Nature of the Function Expressive of the Law of Human Mortality, and on a New Mode of Determining the Value of Life Contingencies</span>.”</span> <em>Philosophical Transactions of the Royal Society of London</em> 115: 513–83.
</div>
<div id="ref-Guyon2003" class="csl-entry" role="listitem">
Guyon, Isabelle, and André Elisseeff. 2003. <span>“An Introduction to Variable and Feature Selection.”</span> <em>The Journal of Machine Learning Research</em> 3 (March): 1157–82.
</div>
<div id="ref-Hielscher2010" class="csl-entry" role="listitem">
Hielscher, Thomas, Manuela Zucknick, Wiebke Werft, and Axel Benner. 2010. <span>“<span class="nocase">On the Prognostic Value of Gene Expression Signatures for Censored Data BT - Advances in Data Analysis, Data Handling and Business Intelligence</span>.”</span> In, edited by Andreas Fink, Berthold Lausen, Wilfried Seidel, and Alfred Ultsch, 663–73. Berlin, Heidelberg: Springer Berlin Heidelberg.
</div>
<div id="ref-Hinchliffe2013" class="csl-entry" role="listitem">
Hinchliffe, Sally R, and Paul C Lambert. 2013. <span>“Flexible Parametric Modelling of Cause-Specific Hazards to Estimate Cumulative Incidence Functions.”</span> <em>BMC Medical Research Methodology</em> 13: 13. <a href="https://doi.org/10.1186/1471-2288-13-13">https://doi.org/10.1186/1471-2288-13-13</a>.
</div>
<div id="ref-Hastie2013" class="csl-entry" role="listitem">
James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. <em><span class="nocase">An introduction to statistical learning</span></em>. Vol. 112. New York: Springer.
</div>
<div id="ref-KalbfleischPrentice1973" class="csl-entry" role="listitem">
Kalbfleisch, J. D., and R. L. Prentice. 1973. <span>“<span class="nocase">Marginal likelihoods based on Cox’s regression and life model</span>.”</span> <em>Biometrika</em> 60 (2): 267–78. <a href="https://doi.org/10.1093/biomet/60.2.267">https://doi.org/10.1093/biomet/60.2.267</a>.
</div>
<div id="ref-Kalbfleisch2011" class="csl-entry" role="listitem">
Kalbfleisch, John D, and Ross L Prentice. 2011. <em><span class="nocase">The statistical analysis of failure time data</span></em>. Vol. 360. John Wiley &amp; Sons.
</div>
<div id="ref-Kirmani2001" class="csl-entry" role="listitem">
Kirmani, S N U A, and Ramesh C Gupta. 2001. <span>“<span class="nocase">On the Proportional Odds Model in Survival Analysis</span>.”</span> <em>Annals of the Institute of Statistical Mathematics</em> 53 (2): 203–16. <a href="https://doi.org/10.1023/A:1012458303498">https://doi.org/10.1023/A:1012458303498</a>.
</div>
<div id="ref-Kleinbaum1996" class="csl-entry" role="listitem">
Kleinbaum, David G, and Mitchel Klein. 1996. <em>Survival Analysis a Self-Learning Text</em>. Springer.
</div>
<div id="ref-linBreslowEstimator2007" class="csl-entry" role="listitem">
Lin, D. Y. 2007. <span>“On the <span>Breslow</span> Estimator.”</span> <em>Lifetime Data Analysis</em> 13 (4): 471–80. <a href="https://doi.org/10.1007/s10985-007-9048-y">https://doi.org/10.1007/s10985-007-9048-y</a>.
</div>
<div id="ref-Luxhoj1997" class="csl-entry" role="listitem">
Luxhoj, James T., and Huan Jyh Shyur. 1997. <span>“<span class="nocase">Comparison of proportional hazards models and neural networks for reliability estimation</span>.”</span> <em>Journal of Intelligent Manufacturing</em> 8 (3): 227–34. <a href="https://doi.org/10.1023/A:1018525308809">https://doi.org/10.1023/A:1018525308809</a>.
</div>
<div id="ref-datarats" class="csl-entry" role="listitem">
Mantel, N., N. R. Bohidar, and J. L. Ciminera. 1977. <span>“<span class="nocase">Mantel-Haenszel analyses of litter-matched time to response data, with modifications for recovery of interlitter information.</span>”</span> <em>Cancer Research</em> 37: 3863–68.
</div>
<div id="ref-Muller1994" class="csl-entry" role="listitem">
Müller, Hans-Georg, and Jane-Ling Wang. 1994. <span>“Hazard Rate Estimation Under Random Censoring with Varying Kernels and Bandwidths.”</span> <em>Biometrics</em> 50 (1): 61–76. <a href="http://www.jstor.org/stable/2533197">http://www.jstor.org/stable/2533197</a>.
</div>
<div id="ref-Ng2018" class="csl-entry" role="listitem">
Ng, Ryan, Kathy Kornas, Rinku Sutradhar, Walter P. Wodchis, and Laura C. Rosella. 2018. <span>“<span class="nocase">The current application of the Royston-Parmar model for prognostic modeling in health research: a scoping review</span>.”</span> <em>Diagnostic and Prognostic Research</em> 2 (1): 4. <a href="https://doi.org/10.1186/s41512-018-0026-5">https://doi.org/10.1186/s41512-018-0026-5</a>.
</div>
<div id="ref-Patel2006" class="csl-entry" role="listitem">
Patel, Katie, Richard Kay, and Lucy Rowell. 2006. <span>“<span class="nocase">Comparing proportional hazards and accelerated failure time models: An application in influenza</span>.”</span> <em>Pharmaceutical Statistics</em> 5 (3): 213–24. <a href="https://doi.org/10.1002/pst.213">https://doi.org/10.1002/pst.213</a>.
</div>
<div id="ref-Qi2009" class="csl-entry" role="listitem">
Qi, Jiezhi. 2009. <span>“<span class="nocase">Comparison of Proportional Hazards and Accelerated Failure Time Models</span>.”</span> PhD thesis.
</div>
<div id="ref-CoxSnell1968" class="csl-entry" role="listitem">
R., Cox, and Snell J. 1968. <span>“<span class="nocase">A General Definition of Residuals</span>.”</span> <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 30 (2): 248–75.
</div>
<div id="ref-Rahman2017" class="csl-entry" role="listitem">
Rahman, M. Shafiqur, Gareth Ambler, Babak Choodari-Oskooei, and Rumana Z. Omar. 2017. <span>“<span class="nocase">Review and evaluation of performance measures for survival prediction models in external validation settings</span>.”</span> <em>BMC Medical Research Methodology</em> 17 (1): 1–15. <a href="https://doi.org/10.1186/s12874-017-0336-2">https://doi.org/10.1186/s12874-017-0336-2</a>.
</div>
<div id="ref-Reid1994" class="csl-entry" role="listitem">
Reid, Nancy. 1994. <span>“A <span>Conversation</span> with <span>Sir David Cox</span>.”</span> <em>Statistical Science</em> 9 (3): 439–55. <a href="https://doi.org/10.1214/ss/1177010394">https://doi.org/10.1214/ss/1177010394</a>.
</div>
<div id="ref-Royston2002" class="csl-entry" role="listitem">
Royston, Patrick, and Mahesh K. B. Parmar. 2002. <span>“<span class="nocase">Flexible parametric proportional-hazards and proportional-odds models for censored survival data, with application to prognostic modelling and estimation of treatment effects</span>.”</span> <em>Statistics in Medicine</em> 21 (15): 2175–97. <a href="https://doi.org/10.1002/sim.1203">https://doi.org/10.1002/sim.1203</a>.
</div>
<div id="ref-Sashegyi2017" class="csl-entry" role="listitem">
Sashegyi, Andreas, and David Ferry. 2017. <span>“<span class="nocase">On the Interpretation of the Hazard Ratio and Communication of Survival Benefit</span>.”</span> <em>The Oncologist</em> 22 (4): 484–86. <a href="https://doi.org/10.1634/theoncologist.2016-0198">https://doi.org/10.1634/theoncologist.2016-0198</a>.
</div>
<div id="ref-Simon2011" class="csl-entry" role="listitem">
Simon, Noah, Jerome H. Friedman, Trevor Hastie, and Rob Tibshirani. 2011. <span>“Regularization Paths for Cox’s Proportional Hazards Model via Coordinate Descent.”</span> <em>Journal of Statistical Software</em> 39 (5): 1–13. <a href="https://doi.org/10.18637/jss.v039.i05">https://doi.org/10.18637/jss.v039.i05</a>.
</div>
<div id="ref-Spooner2020" class="csl-entry" role="listitem">
Spooner, Annette, Emily Chen, Arcot Sowmya, Perminder Sachdev, Nicole A Kochan, Julian Trollor, and Henry Brodaty. 2020. <span>“<span class="nocase">A comparison of machine learning methods for survival analysis of high-dimensional clinical data for dementia prediction</span>.”</span> <em>Scientific Reports</em> 10 (1): 20410. <a href="https://doi.org/10.1038/s41598-020-77220-w">https://doi.org/10.1038/s41598-020-77220-w</a>.
</div>
<div id="ref-Spruance2004" class="csl-entry" role="listitem">
Spruance, Spotswood L, Julia E Reid, Michael Grace, and Matthew Samore. 2004. <span>“<span class="nocase">Hazard ratio in clinical trials</span>.”</span> <em>Antimicrobial Agents and Chemotherapy</em> 48 (8): 2787–92. <a href="https://doi.org/10.1128/AAC.48.8.2787-2792.2004">https://doi.org/10.1128/AAC.48.8.2787-2792.2004</a>.
</div>
<div id="ref-therneau2001modelingsurvival" class="csl-entry" role="listitem">
Therneau, Terry M., and Patricia M. Grambsch. 2001. <em><span>Modeling Survival Data: Extending the Cox Model</span></em>. 1st ed. 2000. Corr. 2nd printing 2001. New York: Springer.
</div>
<div id="ref-Tibshirani1997" class="csl-entry" role="listitem">
Tibshirani, Robert. 1997. <span>“The Lasso Method for Variable Selection in the Cox Model.”</span> <em>Statistics in Medicine</em> 16 (4): 385–95. https://doi.org/<a href="https://doi.org/10.1002/(SICI)1097-0258(19970228)16:4<385::AID-SIM380>3.0.CO;2-3">https://doi.org/10.1002/(SICI)1097-0258(19970228)16:4&lt;385::AID-SIM380&gt;3.0.CO;2-3</a>.
</div>
<div id="ref-VanBelle2011b" class="csl-entry" role="listitem">
Van Belle, Vanya, Kristiaan Pelckmans, Sabine Van Huffel, and Johan A. K. Suykens. 2011. <span>“<span class="nocase">Support vector methods for survival analysis: A comparison between ranking and regression approaches</span>.”</span> <em>Artificial Intelligence in Medicine</em> 53 (2): 107–18. <a href="https://doi.org/10.1016/j.artmed.2011.06.006">https://doi.org/10.1016/j.artmed.2011.06.006</a>.
</div>
<div id="ref-Wang2017" class="csl-entry" role="listitem">
Wang, Ping, Yan Li, and Chandan K. Reddy. 2019. <span>“<span class="nocase">Machine Learning for Survival Analysis</span>.”</span> <em>ACM Computing Surveys</em> 51 (6): 1–36. <a href="https://doi.org/10.1145/3214306">https://doi.org/10.1145/3214306</a>.
</div>
<div id="ref-Wei1992" class="csl-entry" role="listitem">
Wei, L J. 1992. <span>“<span class="nocase">The Accelerated Failure Time Model: A Useful Alternative to the Cox Regression Model in Survival Analysis</span>.”</span> <em>Statistics in Medicine</em> 11: 1871–79.
</div>
<div id="ref-Zare2015" class="csl-entry" role="listitem">
Zare, Ali, Mostafa Hosseini, Mahmood Mahmoodi, Kazem Mohammad, Hojjat Zeraati, and Kourosh Holakouie Naieni. 2015. <span>“<span class="nocase">A Comparison between Accelerated Failure-time and Cox Proportional Hazard Models in Analyzing the Survival of Gastric Cancer Patients.</span>”</span> <em>Iranian Journal of Public Health</em> 44 (8): 1095–1102. <a href="https://doi.org/10.1007/s00606-006-0435-8">https://doi.org/10.1007/s00606-006-0435-8</a>.
</div>
<div id="ref-Zhang2021" class="csl-entry" role="listitem">
Zhang, Yunwei, Germaine Wong, Graham Mann, Samuel Muller, and Jean Y H Yang. 2021. <span>“<span class="nocase">SurvBenchmark: comprehensive benchmarking study of survival analysis methods using both omics data and clinical data</span>.”</span> <em>bioRxiv</em>, January, 2021.07.11.451967. <a href="https://doi.org/10.1101/2021.07.11.451967">https://doi.org/10.1101/2021.07.11.451967</a>.
</div>
<div id="ref-Zou2005" class="csl-entry" role="listitem">
Zou, Hui, and Trevor Hastie. 2005. <span>“Regularization and Variable Selection via the Elastic Net.”</span> <em>Journal of the Royal Statistical Society Series B: Statistical Methodology</em> 67 (2): 301–20. <a href="https://doi.org/10.1111/j.1467-9868.2005.00503.x">https://doi.org/10.1111/j.1467-9868.2005.00503.x</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./P2C11_time.html" class="pagination-link" aria-label="Survival Time Measures">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Survival Time Measures</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./P3C14_forests.html" class="pagination-link" aria-label="Random Forests">
        <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Random Forests</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>All content licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> <br> © Raphael Sonabend, Andreas Bender.</p>
</div>   
    <div class="nav-footer-center">
<p><a href="https://www.mlsabook.com">Website</a> | <a href="https://github.com/mlsa-book/MLSA">GitHub</a></p>
<div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/mlsa-book/MLSA/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li><li><a href="https://github.com/mlsa-book/MLSA/edit/main/book/P3C13_classical.qmd" class="toc-action"><i class="bi empty"></i>Edit this page</a></li><li><a href="https://github.com/mlsa-book/MLSA/blob/main/book/P3C13_classical.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>