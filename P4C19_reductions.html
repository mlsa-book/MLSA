<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Raphael Sonabend and Andreas Bender">

<title>16&nbsp; Reductions – Machine Learning in Survival Analysis</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./P4C20_competing.html" rel="next">
<link href="./P3C17_neural.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-0d45b1ff1595a53868627e64e30aef28.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-b6db0a1bf8162d09ed5006fd111a6427.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./P4C19_reductions.html">Reduction Techniques</a></li><li class="breadcrumb-item"><a href="./P4C19_reductions.html"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Reductions</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Machine Learning in Survival Analysis</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/mlsa-book/MLSA/tree/main/book/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./Machine-Learning-in-Survival-Analysis.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P0C0_notation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Symbols and Notation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P0C1_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Survival Analysis and Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P1C2_preview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">MLSA From Start to Finish</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P1C3_machinelearning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Machine Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P1C4_survival.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Survival Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P1C5_eha.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Event-history Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P1C6_survtsk.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Survival Task</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Evaluation</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P2C8_rank.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Discrimination</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P2C9_calib.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Calibration</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P2C10_rules.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Scoring Rules</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P2C11_time.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Survival Time Measures</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">Models</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P3C13_classical.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Classical Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P3C14_forests.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Random Forests</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P3C15_svm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Support Vector Machines</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P3C16_boosting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Boosting Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P3C17_neural.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Neural Networks</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Reduction Techniques</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P4C19_reductions.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Reductions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P4C20_competing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Competing Risks Pipelines</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P4C21_discrete.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Discrete Time Survival Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P4C22_poisson.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Connections to Poisson Regression and Processes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P4C23_pseudo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Connections to Regression and Imputation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P5C24_conclusions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">FAQs and Outlook</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P5C25_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P5C26_references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-car-pipes" id="toc-sec-car-pipes" class="nav-link active" data-scroll-target="#sec-car-pipes"><span class="header-section-number">16.1</span> Representing Pipelines</a></li>
  <li><a href="#sec-car-comp" id="toc-sec-car-comp" class="nav-link" data-scroll-target="#sec-car-comp"><span class="header-section-number">16.2</span> Introduction to Composition</a>
  <ul class="collapse">
  <li><a href="#sec-car-comp-tax" id="toc-sec-car-comp-tax" class="nav-link" data-scroll-target="#sec-car-comp-tax"><span class="header-section-number">16.2.1</span> Taxonomy of Compositors</a></li>
  <li><a href="#sec-car-comp-mot" id="toc-sec-car-comp-mot" class="nav-link" data-scroll-target="#sec-car-comp-mot"><span class="header-section-number">16.2.2</span> Motivation for Composition</a></li>
  </ul></li>
  <li><a href="#sec-car-redux" id="toc-sec-car-redux" class="nav-link" data-scroll-target="#sec-car-redux"><span class="header-section-number">16.3</span> Introduction to Reduction</a>
  <ul class="collapse">
  <li><a href="#sec-car-redux-mot" id="toc-sec-car-redux-mot" class="nav-link" data-scroll-target="#sec-car-redux-mot"><span class="header-section-number">16.3.1</span> Reduction Motivation</a></li>
  <li><a href="#sec-car-redux-task" id="toc-sec-car-redux-task" class="nav-link" data-scroll-target="#sec-car-redux-task"><span class="header-section-number">16.3.2</span> Task, Loss, and Data Reduction</a></li>
  <li><a href="#sec-car-reduxstrats-mistakes" id="toc-sec-car-reduxstrats-mistakes" class="nav-link" data-scroll-target="#sec-car-reduxstrats-mistakes"><span class="header-section-number">16.3.3</span> Common Mistakes in Implementation of Reduction</a></li>
  </ul></li>
  <li><a href="#sec-car-pipelines" id="toc-sec-car-pipelines" class="nav-link" data-scroll-target="#sec-car-pipelines"><span class="header-section-number">16.4</span> Composition Strategies for Survival Analysis</a>
  <ul class="collapse">
  <li><a href="#sec-car-pipelines-distr" id="toc-sec-car-pipelines-distr" class="nav-link" data-scroll-target="#sec-car-pipelines-distr"><span class="header-section-number">16.4.1</span> C1) Linear Predictor <span class="math inline">\(\rightarrow\)</span> Distribution</a></li>
  <li><a href="#sec-car-pipelines-time" id="toc-sec-car-pipelines-time" class="nav-link" data-scroll-target="#sec-car-pipelines-time"><span class="header-section-number">16.4.2</span> C2) Survival Time <span class="math inline">\(\rightarrow\)</span> Distribution</a></li>
  <li><a href="#sec-car-pipelines-crank" id="toc-sec-car-pipelines-crank" class="nav-link" data-scroll-target="#sec-car-pipelines-crank"><span class="header-section-number">16.4.3</span> C3) Distribution <span class="math inline">\(\rightarrow\)</span> Survival Time Composition</a></li>
  <li><a href="#sec-car-pipelines-avg" id="toc-sec-car-pipelines-avg" class="nav-link" data-scroll-target="#sec-car-pipelines-avg"><span class="header-section-number">16.4.4</span> C4) Survival Model Averaging</a></li>
  </ul></li>
  <li><a href="#sec-car-reduxes" id="toc-sec-car-reduxes" class="nav-link" data-scroll-target="#sec-car-reduxes"><span class="header-section-number">16.5</span> Novel Survival Reductions</a>
  <ul class="collapse">
  <li><a href="#sec-car-reduxes-r7r8" id="toc-sec-car-reduxes-r7r8" class="nav-link" data-scroll-target="#sec-car-reduxes-r7r8"><span class="header-section-number">16.5.1</span> R7-R8) Survival <span class="math inline">\(\rightarrow\)</span> Probabilistic Classification</a></li>
  </ul></li>
  <li><a href="#sec-car-conc" id="toc-sec-car-conc" class="nav-link" data-scroll-target="#sec-car-conc"><span class="header-section-number">16.6</span> Conclusions</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/mlsa-book/MLSA/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li><li><a href="https://github.com/mlsa-book/MLSA/edit/main/book/P4C19_reductions.qmd" class="toc-action"><i class="bi empty"></i>Edit this page</a></li><li><a href="https://github.com/mlsa-book/MLSA/blob/main/book/P4C19_reductions.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./P4C19_reductions.html">Reduction Techniques</a></li><li class="breadcrumb-item"><a href="./P4C19_reductions.html"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Reductions</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-car" class="quarto-section-identifier"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Reductions</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="block-title">Abstract</div>
    TODO (150-200 WORDS)
  </div>
</div>


</header>


<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Major changes expected!
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>This page is a work in progress and major changes will be made over time.</strong></p>
</div>
</div>
<p>In this chapter, composition and reduction are formally introduced, defined and demonstrated within survival analysis. Neither of these are novel concepts in general or in survival, with several applications already seen earlier when reviewing models (particularly in neural networks), however a lack of formalisation has led to much repeated work and at times questionable applications (<a href="P3C17_neural.html#sec-surv-ml-models-nn" class="quarto-xref"><span>Section 15.1</span></a>). The primary purpose of this chapter is to formalise composition and reduction for survival and to unify references and strategies for future use. These strategies are introduced in the context of minimal ‘workflows’ and graphical ‘pipelines’ in order to maximise their generalisability. <!-- %The compositions discussed in this chapter are important for understanding how classical and machine learning models are routinely discussed and implemented in survival analysis. Whereas the reductions in this chapter are more conceptual and relate specifically to solving machine learning tasks algorithmically. --></p>
<p>A <em>workflow</em> is a generic term given to a series of sequential operations. For example a standard ML workflow is fit/predict/evaluate, which means a model is fit, predictions are made, and these are evaluated. In this book, a <em>pipeline</em> is the name given to a concrete workflow. <a href="#sec-car-pipes" class="quarto-xref"><span>Section 16.1</span></a> demonstrates how pipelines are represented in this book.</p>
<p>Composition (<a href="#sec-car-comp" class="quarto-xref"><span>Section 16.2</span></a>) is a general process in which an object is built (or composed) from other objects and parameters. Reduction (<a href="#sec-car-redux" class="quarto-xref"><span>Section 16.3</span></a>) is a closely related concept that utilises composition in order to transform one problem into another. Concrete strategies for composition and reduction are detailed in sections <a href="#sec-car-pipelines" class="quarto-xref"><span>Section 16.4</span></a> and <a href="#sec-car-reduxes" class="quarto-xref"><span>Section 16.5</span></a>.</p>
<section id="notation-and-terminology" class="level4 unnumbered unlisted">
<h4 class="unnumbered unlisted anchored" data-anchor-id="notation-and-terminology">Notation and Terminology</h4>
<p>The notation introduced in <a href="P1C4_survival.html" class="quarto-xref"><span>Chapter 4</span></a> is recapped for use in this chapter: the generative survival template for the survival setting is given by <span class="math inline">\((X,T,\Delta,Y,C) \ t.v.i. \ \mathcal{X}\times \mathcal{T}\times \{0,1\}\times \mathcal{T}\times \mathcal{T}\)</span> where <span class="math inline">\(\mathcal{X}\subseteq \mathbb{R}^p\)</span> and <span class="math inline">\(\mathcal{T}\subseteq \mathbb{R}_{\geq 0}\)</span>, where <span class="math inline">\(C,Y\)</span> are unobservable, <span class="math inline">\(T := \min\{Y,C\}\)</span>, and <span class="math inline">\(\Delta = \mathbb{I}(Y = T)\)</span>. Random survival data is given by <span class="math inline">\((X_i,T_i,\Delta_i,Y_i,C_i) \stackrel{i.i.d.}\sim(X,T,\Delta,Y,C)\)</span>. Usually data will instead be presented as a training dataset, <span class="math inline">\(\mathcal{D}_{train}= \{(X_1,T_1,\Delta_1),...,(X_n,T_n,\Delta_n)\}\)</span> where <span class="math inline">\((X_i,T_i,\Delta_i) \stackrel{i.i.d.}\sim(X,T,\Delta)\)</span>, and some test data <span class="math inline">\(\mathcal{D}_{test}= (X^*,T^*,\Delta^*) \sim (X,T,\Delta)\)</span>.</p>
<p>For regression models the generative template is given by <span class="math inline">\((X,Y)\)</span> t.v.i. <span class="math inline">\(\mathcal{X}\subseteq \mathbb{R}^p\)</span> and <span class="math inline">\(Y \subseteq \mathbb{R}\)</span>. As with the survival setting, a regression training set is given by <span class="math inline">\(\{(X_1,Y_1),...,(X_n,Y_n)\}\)</span> where <span class="math inline">\((X_i,Y_i) \stackrel{i.i.d.}\sim(X,Y)\)</span> and some test data <span class="math inline">\((X^*,Y^*) \sim (X,Y)\)</span>.</p>
</section>
<section id="sec-car-pipes" class="level2" data-number="16.1">
<h2 data-number="16.1" class="anchored" data-anchor-id="sec-car-pipes"><span class="header-section-number">16.1</span> Representing Pipelines</h2>
<p>Before introducing concrete composition and reduction algorithms, this section briefly demonstrates how these pipelines will be represented in this book.</p>
<p>Pipelines are represented by graphs designed in the following way: all are drawn with operations progressing sequentially from left to right; graphs are comprised of nodes (or ‘vertices’) and arrows (or ‘directed edges’); a rounded rectangular node represents a process such as a function or model fitting/predicting; a (regular) rectangular node represents objects such as data or hyper-parameters. Output from rounded nodes are sometimes explicitly drawn but when omitted the output from the node is the input to the next.</p>
<p>These features are demonstrated in <span class="quarto-unresolved-ref">?fig-car-example</span>. Say <span class="math inline">\(y = 2\)</span> and <span class="math inline">\(a = 2\)</span>, then: data is provided (<span class="math inline">\(y = 2\)</span>) and passed to the shift function (<span class="math inline">\(f(x)=x + 2)\)</span>, the output of this function (<span class="math inline">\(y=4\)</span>) is passed directly to the next <span class="math inline">\((h(x|a)=x^a)\)</span>, this function requires a parameter which is also input (<span class="math inline">\(a = 2\)</span>), finally the resulting output is returned (<span class="math inline">\(y^*=16\)</span>). Programmatically, <span class="math inline">\(a = 2\)</span> would be a hyper-parameter that is stored and passed to the required function when the function is called.</p>
<p>This pipeline is represented as a pseudo-algorithm in <span class="citation" data-cites="alg-car-ex">(<a href="P5C26_references.html#ref-alg-car-ex" role="doc-biblioref"><strong>alg-car-ex?</strong></a>)</span>, though of course is overly complicated and in practice one would just code <span class="math inline">\((y+2)^\wedge a\)</span>.</p>
<!-- \begin{figure}[H]
\centering
\begin{tikzpicture}[framed]
\node (t0)[objnode] {$y$};
\node (t1)[funnode, right=of t0]{$f(x) = x+2$};
\node (t2)[funnode,right=of t1]{$h(x|a) = x^a$};
\node (t3)[objnode, right=of t2]{$y^*$};
\node (t4)[objnode, above=of t2]{$a$};

\path[->]
   (t0)  edge  (t1)
   (t1)  edge  (t2)
   (t2)  edge  (t3)
   (t4)  edge  (t2);
\end{tikzpicture}
\caption[Example of a pipeline]{Example of a pipeline.}\label{fig:car_example}
\end{figure} -->
<!-- \begin{algorithm}[H]
\caption{Example pipeline. \\
**Input** Data, $y \in \Reals$. Parameter, $a \in \Reals$. \\
**Output** Transformed data, $x \in \Reals$.}
\begin{algorithmic}
\State $x \gets y$
\State $x \gets x + 2$
\State $x \gets x^\wedge a$
\Return $x$
\end{algorithmic}
\end{algorithm} -->
<!-- {#alg-car-ex} -->
</section>
<section id="sec-car-comp" class="level2" data-number="16.2">
<h2 data-number="16.2" class="anchored" data-anchor-id="sec-car-comp"><span class="header-section-number">16.2</span> Introduction to Composition</h2>
<p>This section introduces composition, defines a taxonomy for describing compositors (<a href="#sec-car-comp-tax" class="quarto-xref"><span>Section 16.2.1</span></a>), and provides some motivating examples of composition in survival analysis (<a href="#sec-car-comp-mot" class="quarto-xref"><span>Section 16.2.2</span></a>).</p>
<p>In the simplest definition, a model (be it mathematical, computational, machine learning, etc.) is called a <em>composite model</em> if it is built of two or more constituent parts. This can be simplest defined in terms of objects. Just as objects in the real-world can be combined in some way, so can mathematical objects. The exact ‘combining’ process (or ‘compositor’) depends on the specific composition, so too do the inputs and outputs. By example, a wooden table can be thought of as a composite object (<a href="#fig-car-comp-ex" class="quarto-xref">Figure&nbsp;<span>16.1</span></a>). The inputs are wood and nails, the combining process is hammering (assuming the wood is pre-chopped), and the output is a surface for eating. In mathematics, this process is mirrored. Take the example of a shifted linear regression model. This is defined by a linear regression model, <span class="math inline">\(f(x) = \beta_0 + x\beta_1\)</span>, a shifting parameter, <span class="math inline">\(\alpha\)</span>, and a compositor <span class="math inline">\(g(x|\alpha) = f(x) + \alpha\)</span>. Mathematically this example is overly trivial as this could be directly modelled with <span class="math inline">\(f(x) = \alpha + \beta_0 + x\beta_1\)</span>, but algorithmically there is a difference. The composite model <span class="math inline">\(g\)</span>, is defined by first fitting the linear regression model, <span class="math inline">\(f\)</span>, and then applying a shift, <span class="math inline">\(\alpha\)</span>; as opposed to fitting a directly shifted model.</p>
<div id="fig-car-comp-ex" class="quarto-float quarto-figure quarto-figure-center anchored" alt="TODO">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-car-comp-ex-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/car/comp.png" class="img-fluid figure-img" alt="TODO">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-car-comp-ex-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;16.1: Visualising composition in the real-world. A table is a composite object built from nails and wood, which are combined with a hammer ‘compositor’. Figure not to scale.
</figcaption>
</figure>
</div>
<section id="why-composition" class="level4 unnumbered unlisted">
<h4 class="unnumbered unlisted anchored" data-anchor-id="why-composition">Why Composition?</h4>
<p>Tables tend to be better surfaces for eating your dinner than bundles of wood. Or in modelling terms, it is well-known that ensemble methods (e.g.&nbsp;random forests) will generally outperform their components (e.g.&nbsp;decision trees). All ensemble methods are composite models and this demonstrates one of the key use-cases of composition: improved predictive performance. The second key use-case is reduction, which is fully discussed in <a href="#sec-car-redux" class="quarto-xref"><span>Section 16.3</span></a>. <a href="#sec-car-comp-mot" class="quarto-xref"><span>Section 16.2.2</span></a> motivates composition in survival analysis by demonstrating how it is already prevalent but requires formalisation to make compositions more transparent and accessible.</p>
</section>
<section id="composite-model-vs.-sub-models" class="level4 unnumbered unlisted">
<h4 class="unnumbered unlisted anchored" data-anchor-id="composite-model-vs.-sub-models">Composite Model vs.&nbsp;Sub-models</h4>
<p>A bundle of wood and nails is not a table and <span class="math inline">\(1,000\)</span> decision trees are not a random forest, both require a compositor. The compositor in a composite model combines the components into a single model. Considering a composite model as a single model enables the hyper-parameters of the compositor and the component model(s) to be efficiently tuned whilst being evaluated as a single model. This further allows the composite to be compared to other models, including its own components, which is required to justify complexity instead of parsimony in model building (<span class="quarto-unresolved-ref">?sec-eval-why-why</span>).</p>
</section>
<section id="sec-car-comp-tax" class="level3" data-number="16.2.1">
<h3 data-number="16.2.1" class="anchored" data-anchor-id="sec-car-comp-tax"><span class="header-section-number">16.2.1</span> Taxonomy of Compositors</h3>
<p>Just as there are an infinite number of ways to make a table, composition can come in infinite forms. However there are relatively few categories that these can be grouped into. Two primary taxonomies are identified here. The first is the ‘composition type’ and relates to the number of objects composed:</p>
<p>[i)] i. Single-Object Composition (SOC) – This form of composition either makes use of parameters or a transformation to alter a single object. The shifted linear regression model above is one example of this, another is given in <a href="#sec-car-pipelines-crank" class="quarto-xref"><span>Section 16.4.3</span></a>. i. Multi-Object Composition (MOC) – In contrast, this form of composition combines multiple objects into a single one. Both examples in <a href="#sec-car-comp-mot" class="quarto-xref"><span>Section 16.2.2</span></a> are multi-object compositions.</p>
<p>The second grouping is the ‘composition level’ and determines at what ‘level’ the composition takes place:</p>
<p>[i)] i. Prediction Composition – This applies at the level of predictions; the component models could be forgotten at this point. Predictions may be combined from multiple models (MOC) or transformed from a single model (SOC). Both examples in <a href="#sec-car-comp-mot" class="quarto-xref"><span>Section 16.2.2</span></a> are prediction compositions. i. Task Composition – This occurs when one task (e.g.&nbsp;regression) is transformed to one or more others (e.g.&nbsp;classification), therefore always SOC. This is seen mainly in the context of reduction (<a href="#sec-car-redux" class="quarto-xref"><span>Section 16.3</span></a>). i. Model Composition – This is commonly seen in the context of wrappers (<a href="#sec-car-reduxes-r7-mlc" class="quarto-xref"><span>Section 16.5.1.4</span></a>), in which one model is contained within another. i. Data Composition – This is transformation of training/testing data types, which occurs at the first stage of every pipeline.</p>
</section>
<section id="sec-car-comp-mot" class="level3" data-number="16.2.2">
<h3 data-number="16.2.2" class="anchored" data-anchor-id="sec-car-comp-mot"><span class="header-section-number">16.2.2</span> Motivation for Composition</h3>
<p>Two examples are provided below to demonstrate common uses of composition in survival analysis and to motivate the compositions introduced in <a href="#sec-car-pipelines" class="quarto-xref"><span>Section 16.4</span></a>.</p>
<section id="example-1-cox-proportional-hazards" class="level4 unnumbered unlisted">
<h4 class="unnumbered unlisted anchored" data-anchor-id="example-1-cox-proportional-hazards">Example 1: Cox Proportional Hazards</h4>
<p>Common implementations of well-known models can themselves be viewed as composite models, the Cox PH is the most prominent example in survival analysis. Recall the model defined by</p>
<p><span class="math display">\[
h(\tau|X_i) = h_0(\tau)\exp(\beta X_i)
\]</span> where <span class="math inline">\(h_0\)</span> is the baseline hazard and <span class="math inline">\(\beta\)</span> are the model coefficients.</p>
<p>This can be seen as a composite model as Cox defines the model in two stages <span class="citation" data-cites="Cox1972">(<a href="P5C26_references.html#ref-Cox1972" role="doc-biblioref">Cox 1972</a>)</span>: first fitting the <span class="math inline">\(\beta\)</span>-coefficients using the partial likelihood and then by suggesting an estimate for the baseline distribution. This first stage produces a linear predictor return type (<a href="P1C6_survtsk.html" class="quarto-xref"><span>Chapter 6</span></a>) and the second stage returns a survival distribution prediction. Therefore the Cox model for linear predictions is a single (non-composite) model, however when used to make distribution predictions then it is a composite. Cox implicitly describes the model as a composite by writing ‘’alternative simpler procedures would be worth having’’ <span class="citation" data-cites="Cox1972">(<a href="P5C26_references.html#ref-Cox1972" role="doc-biblioref">Cox 1972</a>)</span>, which implies a decision in fitting (a key feature of composition). This composition is formalised in <a href="#sec-car-pipelines-distr" class="quarto-xref"><span>Section 16.4.1</span></a> as a general pipelins. The Cox model utilises the pipeline with a PH form and Kaplan-Meier baseline.</p>
</section>
<section id="example-2-random-survival-forests" class="level4 unnumbered unlisted">
<h4 class="unnumbered unlisted anchored" data-anchor-id="example-2-random-survival-forests">Example 2: Random Survival Forests</h4>
<p>Fully discussed in <a href="P3C14_forests.html" class="quarto-xref"><span>Chapter 12</span></a>, random survival forests are composed from many individual decision trees via a prediction composition algorithm (<span class="citation" data-cites="alg-rsf-pred">(<a href="P5C26_references.html#ref-alg-rsf-pred" role="doc-biblioref"><strong>alg-rsf-pred?</strong></a>)</span>). In general, random forests perform better than their component decision trees, which tends to be true of all ensemble methods. Aggregation of predictions in survival analysis requires slightly more care than other fields due to the multiple prediction types, however this is still possible and is formalised in <a href="#sec-car-pipelines-avg" class="quarto-xref"><span>Section 16.4.4</span></a>.</p>
</section>
</section>
</section>
<section id="sec-car-redux" class="level2" data-number="16.3">
<h2 data-number="16.3" class="anchored" data-anchor-id="sec-car-redux"><span class="header-section-number">16.3</span> Introduction to Reduction</h2>
<p>This section introduces reduction, motivates its use in survival analysis (<a href="#sec-car-redux-mot" class="quarto-xref"><span>Section 16.3.1</span></a>), details an abstract reduction pipeline and defines the difference between a complete/incomplete reduction (<a href="#sec-car-redux-task" class="quarto-xref"><span>Section 16.3.2</span></a>), and outlines some common mistakes that have been observed in the literature when applying reduction (<a href="#sec-car-reduxstrats-mistakes" class="quarto-xref"><span>Section 16.3.3</span></a>).</p>
<p>Reduction is a concept found across disciplines with varying definitions. This report uses the Langford definition: reduction is ‘’a complex problem decomposed into simpler subproblems so that a solution to the subproblems gives a solution to the complex problem’’ <span class="citation" data-cites="Langford2016">(<a href="P5C26_references.html#ref-Langford2016" role="doc-biblioref">Langford et al. 2016</a>)</span>. Generalisation (or induction) is a common real-world use of reduction, for example sampling a subset of a population in order to estimate population-level results. The true answer (population-level values) may not always be found in this way but very good approximations can be made with simpler sub-problems (sub-sampling).</p>
<p>Reductions are workflows that utilise composition. By including hyper-parameters, even complex reduction strategies can remain relatively flexible. To illustrate reduction by example, recall the table-building example (<a href="#sec-car-comp" class="quarto-xref"><span>Section 16.2</span></a>) in which the task of interest is to acquire a table. The most direct but complex solution is to fell a tree and directly saw it into a table (<a href="#fig-car-redux" class="quarto-xref">Figure&nbsp;<span>16.2</span></a>, top), clearly this is not a sensible process. Instead the problem can be reduced into simpler sub-problems: saw the tree into bundles of wood, acquire nails, and then use the ‘hammer compositor’ (<a href="#fig-car-comp-ex" class="quarto-xref">Figure&nbsp;<span>16.1</span></a>) to create a table (<a href="#fig-car-redux" class="quarto-xref">Figure&nbsp;<span>16.2</span></a>, bottom).</p>
<div id="fig-car-redux" class="quarto-float quarto-figure quarto-figure-center anchored" alt="TODO">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-car-redux-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/car/redux.png" class="img-fluid figure-img" alt="TODO">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-car-redux-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;16.2: Visualising reduction in the real-world. The complex process (top) of directly sawing a tree into a table is inefficient and unnecessarily complex. The reduction (bottom) that involves first creating bundles of wood is simpler, more efficient, and yields the same result, though technically requiring more steps.
</figcaption>
</figure>
</div>
<p>In a modelling example, predicting a survival distribution with the Cox model can be viewed as a reduction in which two sub-problems are solved and composed:</p>
<ol type="i">
<li>predict continuous ranking;</li>
<li>estimate baseline hazard; and</li>
<li>compose with (<a href="#sec-car-pipelines-distr" class="quarto-xref"><span>Section 16.4.1</span></a>).</li>
</ol>
<p>This is visualised as a reduction strategy in <span class="quarto-unresolved-ref">?fig-car-cargraph</span>. The entire process from defining the original problem, to combining the simpler sub-solutions (in green), is the reduction (in red).</p>
<!-- \begin{figure}[h]
\centering
\begin{tikzpicture}
\node (t0) [objnode, minimum width = 6.2cm]  {Task: Predict Distribution};
\node (t1) [objnode, above=of t0, minimum width = 6.2cm] {Sub-Task: Predict Ranking};
\node (t2) [objnode, below=of t0, minimum width = 6.2cm] {Sub-Task: Estimate Baseline};
\node (t3) [objnode, right=of t1,xshift=1.5cm] {$\hat{\eta}$};
\node (t6) [funnode, below=of t3, fill = orange!30] {$C$};
\node (t4) [objnode, below=of t6] {$\hatS_0$};
\node (t5) [objnode, left=of t6] {$S$};
\node (t7) [objnode, right=of t6] {$\zeta$};
\node (t8) [below=of t7, minimum width=10mm, minimum height = 5mm] {};

\path[->]
   (t0)  edge (t1)
   (t0)  edge (t2)
   (t1)  edge (t3)
   (t2)  edge (t4)
   (t3)  edge (t6)
   (t4)  edge (t6)
   (t5)  edge (t6)
   (t6)  edge (t7);

\begin{pgfonlayer}{background}
  \draw[fill=red!30,fill opacity = 0.5,rounded corners]
($(t1.north west)+(-0.1,0.2)$) rectangle ($(t8.south east)+(0.1,-0.4)$);
  \draw[fill=green!30,fill opacity = 0.5,rounded corners]
($(t3.north west)+(-2,0.1)$) rectangle ($(t4.south east) +(0.1,-0.1)$);
 \end{pgfonlayer}
\end{tikzpicture}
\caption[Probabilistic survival task reduction]{Solving a survival distribution task by utilising reduction and (C1) (@sec-car-pipelines-distr). $S$, $\hat{\eta}$, $C$, $\hatS_0$ are fully described in @fig-car-comp-distr. The nodes in the green area are part of the composite model, all nodes combined form the reduction.}\label{fig:car_cargraph}
\end{figure} -->
<section id="sec-car-redux-mot" class="level3" data-number="16.3.1">
<h3 data-number="16.3.1" class="anchored" data-anchor-id="sec-car-redux-mot"><span class="header-section-number">16.3.1</span> Reduction Motivation</h3>
<p>Formalisation of reduction positively impacts upon accessibility, transparency, and predictive performance. Improvements to predictive performance have already been demonstrated when comparing random forests to decision trees. In addition, a reduction with multiple stages and many hyper-parameters allows for fine tuning for improved transparency and model performance (usual overfitting caveat applies, as does the trade-off described in <span class="quarto-unresolved-ref">?sec-car-pipelines-trade</span>).</p>
<p>The survey of ANNs (<a href="P3C17_neural.html#sec-surv-ml-models-nn" class="quarto-xref"><span>Section 15.1</span></a>) demonstrated how reduction is currently utilised without transparency. Many of these ANNs are implicitly reductions to probabilistic classification (<a href="#sec-car-reduxes-r7" class="quarto-xref"><span>Section 16.5.1.6</span></a>) however none include details about how the reduction is performed. Furthermore in implementation, none provide interface points to the reduction hyper-parameters. Formalisation encourages consistent terminology, methodology and transparent implementation, which can only improve model performance by exposing further hyper-parameters.</p>
<p>Accessibility is improved by formalising specific reduction workflows that previously demanded expert knowledge in deriving, building, and running these pipelines.</p>
<p>Finally there is an economic and efficiency advantage to reduction. A reduction model is relatively ‘cheap’ to explore as they utilise pre-established models and components to solve a new problem. Therefore if a certain degree of predictive ability can be demonstrated from reduction models, it may not be worth the expense of pursuing more novel ideas and hence reduction can help direct future research.</p>
</section>
<section id="sec-car-redux-task" class="level3" data-number="16.3.2">
<h3 data-number="16.3.2" class="anchored" data-anchor-id="sec-car-redux-task"><span class="header-section-number">16.3.2</span> Task, Loss, and Data Reduction</h3>
<p>Reduction can be categorised into task, loss, and data reduction, often these must be used in conjunction with each other. The direction of the reductions may be one- or two-way; this is visualised in <span class="quarto-unresolved-ref">?fig-car-reduxdiag</span>. This diagram should not be viewed as a strict fit/predict/evaluation workflow but instead as a guidance for which tasks, <span class="math inline">\(T\)</span>, data, <span class="math inline">\(D\)</span>, models, <span class="math inline">\(M\)</span>, and losses, <span class="math inline">\(L\)</span>, are required for each other. The subscript <span class="math inline">\(O\)</span> refers to the original object ‘level’ before reduction, whereas the subscript <span class="math inline">\(R\)</span> is in reference to the reduced object.</p>
<!-- \begin{figure}[H]
\centering
\begin{tikzpicture}
\node (t0) {$L_O$};

\node (t2)  [below=0.3cm of t0] {$D_O$};
\node (t3)  [below=0.3cm of t2] {$D_R$};

\node (t4)  [right=2cm of t0] {$M_O$};
\node (t5)  [right=2cm of t3] {$M_R$};

\node (t6)  [right=2cm of t4] {$T_O$};
\node (t7)  [right=2cm of t5] {$T_R$};

\path[->]
   (t2) edge (t0)
   (t2) edge (t3)

   (t3) edge (t5)

   (t4) edge (t0)
   (t4) edge (t6)

   (t5) edge (t4)

   (t6) edge (t7)

   (t7) edge (t5);
\end{tikzpicture}
\caption[Task, loss, and data reduction]{Task, loss, and data reduction to and from the original complex problem to sub-problems.}
\label{fig:car_reduxdiag}
\end{figure} -->
<p>The individual task, model, and data compositions in the diagram are listed below, the reduction from survival to classification (<a href="#sec-car-reduxes-r7r8" class="quarto-xref"><span>Section 16.5.1</span></a>) is utilised as a running example to help exposition.</p>
<ul>
<li><span class="math inline">\(T_O \rightarrow T_R\)</span>: By definition of a machine learning reduction, task reduction will always be one way. A more complex task, <span class="math inline">\(T_O\)</span>, is reduced to a simpler one, <span class="math inline">\(T_R\)</span>, for solving. <span class="math inline">\(T_R\)</span> could also be multiple simpler tasks. For example, solving a survival task, <span class="math inline">\(T_O\)</span>, by classification, <span class="math inline">\(T_R\)</span> (<a href="#sec-car-reduxes-r7r8" class="quarto-xref"><span>Section 16.5.1</span></a>).</li>
<li><span class="math inline">\(T_R \rightarrow M_R\)</span>: All machine learning tasks have models that are designed to solve them. For example logistic regression, <span class="math inline">\(M_R\)</span>, for classification tasks, <span class="math inline">\(T_R\)</span>.</li>
<li><span class="math inline">\(M_R \rightarrow M_O\)</span>: The simpler models, <span class="math inline">\(M_R\)</span>, are used for the express purpose to solve the original task, <span class="math inline">\(T_O\)</span>, via solving the simpler ones. To solve <span class="math inline">\(T_O\)</span>, a compositor must be applied, which may transform one (SOC) or multiple models (MOC) at a model- or prediction-level, thus creating <span class="math inline">\(M_O\)</span>. For example predicting survival probabilities with logistic regression, <span class="math inline">\(M_R\)</span>, at times <span class="math inline">\(1,...,\tau^*\)</span> for some <span class="math inline">\(\tau^* \in \mathbb{N}_{&gt; 0}\)</span> (<a href="#sec-car-reduxes-r7-mlc" class="quarto-xref"><span>Section 16.5.1.4</span></a>).</li>
<li><span class="math inline">\(M_O \rightarrow T_O\)</span>: The original task should be solvable by the composite model. For example predicting a discrete survival distribution by concatenating probabilistic predictions at the times <span class="math inline">\(1,...,\tau^*\)</span> (<a href="#sec-car-reduxes-r7" class="quarto-xref"><span>Section 16.5.1.6</span></a>).</li>
<li><span class="math inline">\(D_O \rightarrow D_R\)</span>: Just as the tasks and models are reduced, the data required to fit these must likewise be reduced. Similarly to task reduction, data reduction can usually only take place in one direction, to see why this is the case take an example of data reduction by summaries. If presented with 10 data-points <span class="math inline">\(\{1,1,1,5,7,3,5,4,3,3\}\)</span> then these could be reduced to a single point by calculating the sample mean, <span class="math inline">\(3.3\)</span>. Clearly given only the number <span class="math inline">\(3.3\)</span> there is no strategy to recover the original data. There are very few (if any) data reduction strategies that allow recovery of the original data. Continuing the running example, survival data, <span class="math inline">\(D_O\)</span>, can be binned (<a href="#sec-car-reduxes-r7-binning" class="quarto-xref"><span>Section 16.5.1.1</span></a>) to classification data, <span class="math inline">\(D_R\)</span>.</li>
</ul>
<p>There is no arrow between <span class="math inline">\(D_O\)</span> and <span class="math inline">\(M_O\)</span> as the composite model is never fit directly, only via composition from <span class="math inline">\(M_R \rightarrow M_O\)</span>. However, the original data, <span class="math inline">\(D_O\)</span>, is required when evaluating the composite model against the respective loss, <span class="math inline">\(L_O\)</span>. Reduction should be directly comparable to non-reduction models, hence this diagram does not include loss reduction and instead insists that all models are compared against the same loss <span class="math inline">\(L_O\)</span>.</p>
<p>A reduction is said to be <em>complete</em> if there is a full pipeline from <span class="math inline">\(T_O \rightarrow M_O\)</span> and the original task is solved, otherwise it is <em>incomplete</em>. The simplest complete reduction is comprised of the pipeline <span class="math inline">\(T_O \rightarrow T_R \rightarrow M_R \rightarrow M_O\)</span>. Usually this is not sufficient on its own as the reduced models are fit on the reduced data, <span class="math inline">\(D_R \rightarrow M_R\)</span>.</p>
<p>A complete reduction can be specified by detailing:</p>
<ol type="i">
<li>the original task and the sub-task(s) to be solved, <span class="math inline">\(T_O \rightarrow T_R\)</span>;</li>
<li>the original dataset and the transformation to the reduced one, <span class="math inline">\(D_O \rightarrow D_R\)</span> (if required); and</li>
<li>the composition from the simpler model to the complex one, <span class="math inline">\(M_R \rightarrow M_O\)</span>.</li>
</ol>
</section>
<section id="sec-car-reduxstrats-mistakes" class="level3" data-number="16.3.3">
<h3 data-number="16.3.3" class="anchored" data-anchor-id="sec-car-reduxstrats-mistakes"><span class="header-section-number">16.3.3</span> Common Mistakes in Implementation of Reduction</h3>
<p>In surveying models and measures, several common mistakes in the implementation of reduction and composition were found to be particularly prevalent and problematic throughout the literature. It is assumed that these are indeed mistakes (not deliberate) and result from a lack of prior formalisation. These mistakes were even identified 20 years ago <span class="citation" data-cites="Schwarzer2000">(<a href="P5C26_references.html#ref-Schwarzer2000" role="doc-biblioref">Schwarzer, Vach, and Schumacher 2000</a>)</span> but are provided in more detail in order to highlight their current prevalence and why they cannot be ignored.</p>
<p>RM1. Incomplete reduction. This occurs when a reduction workflow is presented as if it solves the original task but fails to do so and only the reduction strategy is solved. A common example is claiming to solve the survival task by using binary classification, e.g.&nbsp;erroneously claiming that a model predicts survival probabilities (which implies distribution) when it actually predicts a five year probability of death (<span class="citation" data-cites="box-task-classif">(<a href="P5C26_references.html#ref-box-task-classif" role="doc-biblioref"><strong>box-task-classif?</strong></a>)</span>). This is a mistake as it misleads readers into believing that the model solves a survival task (<span class="citation" data-cites="box-task-surv">(<a href="P5C26_references.html#ref-box-task-surv" role="doc-biblioref"><strong>box-task-surv?</strong></a>)</span>) when it does not. This is usually a semantic not mathematical error and results from misuse of terminology. It is important to be clear about model predict types (<a href="P1C6_survtsk.html" class="quarto-xref"><span>Chapter 6</span></a>) and general terms such as ‘survival predictions’ should be avoided unless they refer to one of the three prediction tasks. RM2. Inappropriate comparisons. This is a direct consequence of (RM1) and the two are often seen together. (RM2) occurs when an incomplete reduction is directly compared to a survival model (or complete reduction model) using a measure appropriate for the reduction. This may lead to a reduction model appearing erroneously superior. For example, comparing a logistic regression to a random survival forest (RSF) (<a href="P3C14_forests.html" class="quarto-xref"><span>Chapter 12</span></a>) for predicting survival probabilities at a single time using the accuracy measure is an unfair comparison as the RSF is optimised for distribution predictions. This would be non-problematic if a suitable composition is clearly utilised. For example a regression SSVM predicting survival time cannot be directly compared to a Cox PH. However the SSVM can be compared to a CPH composed with the probabilistic to deterministic compositor, then conclusions can be drawn about comparison to the composite survival time Cox model (and not simply a Cox PH). RM3. Na"ive censoring deletion. This common mistake occurs when trying to reduce survival to regression or classification by simply deleting all censored observations, even if censoring is informative. This is a mistake as it creates bias in the dataset, which can be substantial if the proportion of censoring is high and informative. More robust deletion methods are described in <a href="P4C23_pseudo.html" class="quarto-xref"><span>Chapter 20</span></a>. RM4. Oversampling uncensored observations. This is often seen when trying to reduce survival to regression or classification, and often alongside (RM3). Oversampling is the process of replicating observations to artificially inflate the sample size of the data. Whilst this process does not create any new information, it can help a model detect important features in the data. However, by only oversampling uncensored observations, this creates a source of bias in the data and ignores the potentially informative information provided by the proportion of censoring.</p>
</section>
</section>
<section id="sec-car-pipelines" class="level2" data-number="16.4">
<h2 data-number="16.4" class="anchored" data-anchor-id="sec-car-pipelines"><span class="header-section-number">16.4</span> Composition Strategies for Survival Analysis</h2>
<p>Though composition is common practice in survival analysis, with the Cox model being a prominent example, a lack of formalisation means a lack of consensus in simple operations. For example, it is often asked in survival analysis how a model predicting a survival distribution can be used to return a survival time prediction. A common strategy is to define the survival time prediction as the median of the predicted survival curve however there is no clear reason why this should be more sensible than returning the distribution mean, mode, or some random quantile. Formalisation allow these choices to be analytically compared both theoretically and practically as hyper-parameters in a workflow. Four prediction compositions are discussed in this section (<span class="citation" data-cites="tab-car-taxredcar">(<a href="P5C26_references.html#ref-tab-car-taxredcar" role="doc-biblioref"><strong>tab-car-taxredcar?</strong></a>)</span>), three are utilised to convert prediction types between one another, the fourth is for aggregating multiple predictions. One data composition is discussed for converting survival to regression data. Each is first graphically represented and then the components are discussed in detail. As with losses in the previous chapter, compositions are discussed at an individual observation level but extend trivially to multiple observations.</p>
<table class="caption-top table">
<caption>Compositions formalised in <a href="#sec-car-pipelines" class="quarto-xref"><span>Section 16.4</span></a>.</caption>
<thead>
<tr class="header">
<th>ID<span class="math inline">\(^1\)</span></th>
<th>Composition</th>
<th>Type<span class="math inline">\(^2\)</span></th>
<th>Level<span class="math inline">\(^3\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>C1)</td>
<td>Linear predictor to distribution</td>
<td>MOC</td>
<td>Prediction</td>
</tr>
<tr class="even">
<td>C2)</td>
<td>Survival time to distribution</td>
<td>MOC</td>
<td>Prediction</td>
</tr>
<tr class="odd">
<td>C3)</td>
<td>Distribution to survival time</td>
<td>SOC</td>
<td>Prediction</td>
</tr>
<tr class="even">
<td>C4)</td>
<td>Survival model averaging</td>
<td>MOC</td>
<td>Prediction</td>
</tr>
<tr class="odd">
<td>C5)</td>
<td>Survival to regression</td>
<td>SOC</td>
<td>Data</td>
</tr>
</tbody>
</table>
<p><sup> 1. ID for reference throughout this book. 2. Composition type. Multi-object composition (MOC) or single-object composition (SOC). 3. Composition level. </sup></p>
<section id="sec-car-pipelines-distr" class="level3" data-number="16.4.1">
<h3 data-number="16.4.1" class="anchored" data-anchor-id="sec-car-pipelines-distr"><span class="header-section-number">16.4.1</span> C1) Linear Predictor <span class="math inline">\(\rightarrow\)</span> Distribution</h3>
<!-- \begin{figure}[H]
\centering
\begin{tikzpicture}[framed]
\node (t0)[objnode] {$\hat{\eta}$};
\node (t3)[funnode,right=of t0,fill=orange!30]{$C$};
\node (t1)[objnode,above=of t3]{$M$};
\node (t2)[objnode,below=of t3]{$\hatS_0$};
\node (t4)[objnode, right=of t3]{$\zeta$};

\path[->]
   (t0) edge  (t3)
   (t1) edge  (t3)
   (t2) edge  (t3)
   (t3) edge  (t4);
\end{tikzpicture}
\caption[Linear predictor to distribution composition]{Linear predictor ($\hat{\eta}$) to survival distribution ($\zeta$) composition. Parameters: $M$ -- Model form; $\hatS_0$ -- Estimated baseline survival function.}
\label{fig:car_comp_distr}
\end{figure} -->
<p>This is a prediction-level MOC that composes a survival distribution from a predicted linear predictor and estimated baseline survival distribution. The composition (<span class="quarto-unresolved-ref">?fig-car-comp-distr</span>) requires:</p>
<ul>
<li><p><span class="math inline">\(\hat{\eta}\)</span>: Predicted linear predictor. <span class="math inline">\(\hat{\eta}\)</span> can be tuned by including this composition multiple times in a benchmark experiment with different models predicting <span class="math inline">\(\hat{\eta}\)</span>. In theory any continuous ranking could be utilised instead of a linear predictor though results may be less sensible (<span class="quarto-unresolved-ref">?sec-car-pipelines-trade</span>).</p></li>
<li><p><span class="math inline">\(\hat{S}_0\)</span>: Estimated baseline survival function. This is usually estimated by the Kaplan-Meier estimator fit on training data, <span class="math inline">\(\hat{S}_{KM}\)</span>. However any model that can predict a survival distribution can estimate the baseline distribution (caveat: see <span class="quarto-unresolved-ref">?sec-car-pipelines-trade</span>) by taking a uniform mixture of the predicted individual distributions: say <span class="math inline">\(\xi_1,...,\xi_m\)</span> are m predicted distributions, then <span class="math inline">\(\hat{S}_0(\tau) = \frac{1}{m} \sum^{m}_{i = 1} \xi_i.S(\tau)\)</span>. The mixture is required as the baseline must be the same for all observations. Alternatively, parametric distributions can be assumed for the baseline, e.g.&nbsp;<span class="math inline">\(\xi = \operatorname{Exp}(2)\)</span> and <span class="math inline">\(\xi.S(t) = \exp(-2t)\)</span>. As with <span class="math inline">\(\hat{\eta}\)</span>, this parameter is also tunable.</p></li>
<li><p><span class="math inline">\(M\)</span>: Chosen model form, which theoretically can be any non-increasing right-continuous function but is usually one of:</p></li>
<li><p>Proportional Hazards (PH): <span class="math inline">\(S_{PH}(\tau|\eta, S_0) = S_0(\tau)^{\exp(\eta)}\)</span></p></li>
<li><p>Accelerated Failure Time (AFT): <span class="math inline">\(S_{AFT}(\tau|\eta, S_0) = S_0(\frac{\tau}{\exp(\eta)})\)</span></p></li>
<li><p>Proportional Odds (PO): <span class="math inline">\(S_{PO}(\tau|\eta, S_0) = \frac{S_0(\tau)}{\exp(-\eta) + (1-\exp(-\eta)) S_0(\tau)}\)</span></p></li>
</ul>
<p>Models that predict linear predictors will make assumptions about the model form and therefore dictate sensible choices of <span class="math inline">\(M\)</span>, for example the Cox model assumes a PH form. This does not mean other choices of <span class="math inline">\(M\)</span> cannot be specified but that interpretation may be more difficult (<span class="quarto-unresolved-ref">?sec-car-pipelines-trade</span>). The model form can be treated as a hyper-parameter to tune. * <span class="math inline">\(C\)</span>: Compositor returning the composed distribution, <span class="math inline">\(\zeta := C(M, \hat{\eta}, \hat{S}_0)\)</span> where <span class="math inline">\(\zeta\)</span> has survival function <span class="math inline">\(\zeta.S(\tau) = M(\tau|\hat{\eta}, \hat{S}_0)\)</span>.</p>
<p>Pseudo-code for training (<span class="citation" data-cites="alg-car-comp-distr-fit">(<a href="P5C26_references.html#ref-alg-car-comp-distr-fit" role="doc-biblioref"><strong>alg-car-comp-distr-fit?</strong></a>)</span>) and predicting (<span class="citation" data-cites="alg-car-comp-distr-pred">(<a href="P5C26_references.html#ref-alg-car-comp-distr-pred" role="doc-biblioref"><strong>alg-car-comp-distr-pred?</strong></a>)</span>) this composition as a model ‘wrapper’ with sensible parameter choices (<span class="quarto-unresolved-ref">?sec-car-pipelines-trade</span>) is provided in appendix <span class="citation" data-cites="app-car">(<a href="P5C26_references.html#ref-app-car" role="doc-biblioref"><strong>app-car?</strong></a>)</span>.</p>
</section>
<section id="sec-car-pipelines-time" class="level3" data-number="16.4.2">
<h3 data-number="16.4.2" class="anchored" data-anchor-id="sec-car-pipelines-time"><span class="header-section-number">16.4.2</span> C2) Survival Time <span class="math inline">\(\rightarrow\)</span> Distribution</h3>
<!-- \begin{figure}[H]
\centering
\begin{tikzpicture}[framed]
\node (t4)[objnode]{$\hatT$};
\node (t3)[funnode,right=of t4,fill=orange!30]{$C$};
\node (t1)[objnode,above=of t3]{$\xi$};
\node (t6)[objnode, below=of t3]{$\hat{\sigma}$};
\node (t5)[objnode, right=of t3]{$\zeta$};

\path[->]
   (t1) edge  (t3)
   (t6) edge (t3)
   (t4) edge  (t3)
   (t3) edge  (t5);
\end{tikzpicture}
\caption[Survival time to distribution composition]{Survival time ($\hatT$) to distribution ($\zeta$) composition. Parameters: $\hat{\sigma}$ -- Estimated scale parameter; $\xi$ -- Assumed survival distribution.}
\label{fig:car_comp_response}
\end{figure} -->
<p>This is a prediction-level MOC that composes a distribution from a predicted survival time and assumed location-scale distribution. The composition (<span class="quarto-unresolved-ref">?fig-car-comp-response</span>) requires:</p>
<ul>
<li><span class="math inline">\(\hat{T}\)</span>: A predicted survival time. As with the previous composition, this is tunable. In theory any continuous ranking could replace <span class="math inline">\(\hat{T}\)</span>, though the resulting distribution may not be sensible (<span class="quarto-unresolved-ref">?sec-car-pipelines-trade</span>).</li>
<li><span class="math inline">\(\xi\)</span>: A specified location-scale distribution, <span class="math inline">\(\xi(\mu, \sigma)\)</span>, e.g.&nbsp;Normal distribution.</li>
<li><span class="math inline">\(\hat{\sigma}\)</span>: Estimated scale parameter for the distribution. This can be treated as a hyper-parameter or predicted by another model.</li>
<li><span class="math inline">\(C\)</span>: Compositor returning the composed distribution <span class="math inline">\(\zeta := C(\xi, \hat{T}, \hat{\sigma}) = \xi(\hat{T}, \hat{\sigma})\)</span>.</li>
</ul>
<p>Pseudo-code for training (<span class="citation" data-cites="alg-car-comp-response-fit">(<a href="P5C26_references.html#ref-alg-car-comp-response-fit" role="doc-biblioref"><strong>alg-car-comp-response-fit?</strong></a>)</span>) and predicting (<span class="citation" data-cites="alg-car-comp-response-pred">(<a href="P5C26_references.html#ref-alg-car-comp-response-pred" role="doc-biblioref"><strong>alg-car-comp-response-pred?</strong></a>)</span>) this composition as a model ‘wrapper’ with sensible parameter choices (<span class="quarto-unresolved-ref">?sec-car-pipelines-trade</span>) is provided in appendix <span class="citation" data-cites="app-car">(<a href="P5C26_references.html#ref-app-car" role="doc-biblioref"><strong>app-car?</strong></a>)</span>.</p>
</section>
<section id="sec-car-pipelines-crank" class="level3" data-number="16.4.3">
<h3 data-number="16.4.3" class="anchored" data-anchor-id="sec-car-pipelines-crank"><span class="header-section-number">16.4.3</span> C3) Distribution <span class="math inline">\(\rightarrow\)</span> Survival Time Composition</h3>
<!-- \begin{figure}[H]
\centering
\begin{tikzpicture}[framed]
\node (t1)[funnode, right=of t0]{$\zeta$};
\node (t2)[funnode, right=of t1, fill = orange!30]{$C$};
\node (t4)[objnode, above=of t2]{$\phi$};
\node (t3)[objnode, right=of t2]{$\hatT$};

\path[->]
   (t1) edge  (t2)
   (t4) edge  (t2)
   (t2) edge  (t3);
\end{tikzpicture}
\caption[Distribution to survival time composition]{Distribution ($\zeta$) to survival time ($\hatT$) composition. Parameters: $\phi$ -- Summary method.}
\label{fig:car_comp_crank}
\end{figure} -->
<p>This is a prediction-level SOC that composes a survival time from a predicted distribution. Any paper that evaluates a distribution on concordance is implicitly using this composition in some manner. Not acknowledging the composition leads to unfair model comparison (<a href="#sec-car-reduxstrats-mistakes" class="quarto-xref"><span>Section 16.3.3</span></a>). The composition (<span class="quarto-unresolved-ref">?fig-car-comp-crank</span>) requires:</p>
<ul>
<li><span class="math inline">\(\zeta\)</span>: A predicted survival distribution, which again is ‘tunable’.</li>
<li><span class="math inline">\(\phi\)</span>: A distribution summary method. Common examples include the mean, median and mode. Other alternatives include distribution quantiles, <span class="math inline">\(\zeta.F^{-1}(\alpha)\)</span>,\<span class="math inline">\(\alpha \in [0,1]\)</span>; <span class="math inline">\(\alpha\)</span> could be tuned as a hyper-parameter.</li>
<li><span class="math inline">\(C\)</span>: Compositor returning composed survival time predictions, <span class="math inline">\(\hat{T}:= C(\phi, \zeta) = \phi(\zeta)\)</span>.</li>
</ul>
<p>Pseudo-code for training (<span class="citation" data-cites="alg-car-comp-crank-fit">(<a href="P5C26_references.html#ref-alg-car-comp-crank-fit" role="doc-biblioref"><strong>alg-car-comp-crank-fit?</strong></a>)</span>) and predicting (<span class="citation" data-cites="alg-car-comp-crank-pred">(<a href="P5C26_references.html#ref-alg-car-comp-crank-pred" role="doc-biblioref"><strong>alg-car-comp-crank-pred?</strong></a>)</span>) this composition as a model ‘wrapper’ with sensible parameter choices (<span class="quarto-unresolved-ref">?sec-car-pipelines-trade</span>) is provided in appendix <span class="citation" data-cites="app-car">(<a href="P5C26_references.html#ref-app-car" role="doc-biblioref"><strong>app-car?</strong></a>)</span>.</p>
</section>
<section id="sec-car-pipelines-avg" class="level3" data-number="16.4.4">
<h3 data-number="16.4.4" class="anchored" data-anchor-id="sec-car-pipelines-avg"><span class="header-section-number">16.4.4</span> C4) Survival Model Averaging</h3>
<!-- \begin{figure}[H]
\centering
\begin{tikzpicture}[framed]
\node (t2)[funnode, above right=of t0,yshift=-10mm]{$\rho_2$};
\node (t1)[funnode, above=of t2, yshift=-5mm]{$\rho_1$};
\node (t3)[funnode, below right=of t0,yshift=10mm]{...};
\node (t4)[funnode, below=of t3,yshift=5mm]{$\rho_B$};
\node (t5)[funnode, right=of t0, fill=orange!30,xshift=20mm]{$C$};
\node (t6)[objnode, right=of t5]{$\hat{\rho}$};
\node (t7)[objnode, below=of t5, yshift = 0.2cm]{$w$};

\path[->]
   (t1) edge  (t5)
   (t2) edge  (t5)
   (t3) edge  (t5)
   (t4) edge  (t5)
   (t5) edge  (t6)
   (t7) edge (t5);

\end{tikzpicture}
\caption[Survival model averaging composition]{Survival model averaging composition. $\rho_1,...,\rho_B$ are $B$ predictions of the same return type (time, ranking, distribution) and $\hat{\rho}$ is the averaged prediction. Parameters: $w = w_1,...,w_B$ -- Weights summing to one.}
\label{fig:car_comp_avg}
\end{figure} -->
<p>Ensembling is likely the most common composition in machine learning. In survival it is complicated slightly as multiple prediction types means one of two possible compositions is utilised to average predictions. The (<span class="quarto-unresolved-ref">?fig-car-comp-avg</span>) composition requires:</p>
<ul>
<li><span class="math inline">\(\rho = \rho_1,...,\rho_B\)</span>: <span class="math inline">\(B\)</span> predictions (not necessarily from the same model) of the same type: ranking, survival time or distribution; again ‘tunable’.</li>
<li><span class="math inline">\(w = w_1,...,w_B\)</span>: Weights that sum to one.</li>
<li><span class="math inline">\(C\)</span>: Compositor returning combined predictions, <span class="math inline">\(\hat{\rho} := C(\rho, w)\)</span> where <span class="math inline">\(C(\rho, w) = \frac{1}{B} \sum^{B}_{i = 1} w_i \rho_i\)</span>, if <span class="math inline">\(\rho\)</span> are ranking of survival time predictions; or <span class="math inline">\(C(\rho, w) = \zeta\)</span> where <span class="math inline">\(\zeta\)</span> is the distribution defined by the survival function <span class="math inline">\(\zeta.S(\tau) = \frac{1}{B} \sum^{B}_{i = 1} w_i \rho_i.S(\tau)\)</span>, if <span class="math inline">\(\rho\)</span> are distribution predictions.</li>
</ul>
<p>Pseudo-code for training (<span class="citation" data-cites="alg-car-comp-avg-fit">(<a href="P5C26_references.html#ref-alg-car-comp-avg-fit" role="doc-biblioref"><strong>alg-car-comp-avg-fit?</strong></a>)</span>) and predicting (<span class="citation" data-cites="alg-car-comp-avg-pred">(<a href="P5C26_references.html#ref-alg-car-comp-avg-pred" role="doc-biblioref"><strong>alg-car-comp-avg-pred?</strong></a>)</span>) this composition as a model ‘wrapper’ with sensible parameter choices (<span class="quarto-unresolved-ref">?sec-car-pipelines-trade</span>) is provided in appendix <span class="citation" data-cites="app-car">(<a href="P5C26_references.html#ref-app-car" role="doc-biblioref"><strong>app-car?</strong></a>)</span>.</p>
</section>
</section>
<section id="sec-car-reduxes" class="level2" data-number="16.5">
<h2 data-number="16.5" class="anchored" data-anchor-id="sec-car-reduxes"><span class="header-section-number">16.5</span> Novel Survival Reductions</h2>
<p>This section collects the various strategies and settings discussed previously into complete reduction workflows. <span class="citation" data-cites="tab-car-reduxes">(<a href="P5C26_references.html#ref-tab-car-reduxes" role="doc-biblioref"><strong>tab-car-reduxes?</strong></a>)</span> lists the reductions discussed in this section with IDs for future reference. All strategies are described by visualising a graphical pipeline and then listing the composition steps required in fitting and predicting.</p>
<p>This section only includes novel reduction strategies and does not provide a survey of pre-existing strategies. This limitation is primarily due to time (and page) constraints as every method has very distinct workflows that require complex exposition. Well-established strategies are briefly mentioned below and future research is planned to survey and compare all strategies with respect to empirical performance (i.e.&nbsp;in benchmark experiments).</p>
<p>Two prominent reductions are ‘landmarking’ <span class="citation" data-cites="VanHouwelingen2007">(<a href="P5C26_references.html#ref-VanHouwelingen2007" role="doc-biblioref">Van Houwelingen 2007</a>)</span> and piecewise exponential models <span class="citation" data-cites="Friedman1982">(<a href="P5C26_references.html#ref-Friedman1982" role="doc-biblioref">Friedman 1982</a>)</span>. Both are reductions for time-varying covariates and hence outside the scope of this book. Relevant to this book scope is a large class of strategies that utilise ‘discrete time survival analysis’ <span class="citation" data-cites="Tutz2016">(<a href="P5C26_references.html#ref-Tutz2016" role="doc-biblioref">Tutz and Schmid 2016</a>)</span>; these strategies include reductions (R7) and (R8). Methodology for discrete time survival analysis has been seen in the literature for the past three decades <span class="citation" data-cites="Liestol1994">(<a href="P5C26_references.html#ref-Liestol1994" role="doc-biblioref">Liestol, Andersen, and Andersen 1994</a>)</span>. The primary reduction strategy for discrete time survival analysis is implemented in the <span class="math inline">\(\textsf{R}\)</span> package <strong>discSurv</strong>. <span class="citation" data-cites="pkgdiscsurv">(<a href="P5C26_references.html#ref-pkgdiscsurv" role="doc-biblioref">Welchowski and Schmid 2019</a>)</span>; this is very similar to (R7) except that it enforces stricter constraints in the composition procedures and forces a ‘discrete-hazard’ instead of ‘discrete-survival’ representation (<a href="#sec-car-reduxes-r7-out" class="quarto-xref"><span>Section 16.5.1.2</span></a>).</p>
<section id="sec-car-reduxes-r7r8" class="level3" data-number="16.5.1">
<h3 data-number="16.5.1" class="anchored" data-anchor-id="sec-car-reduxes-r7r8"><span class="header-section-number">16.5.1</span> R7-R8) Survival <span class="math inline">\(\rightarrow\)</span> Probabilistic Classification</h3>
<!-- \begin{figure}[H]
\centering
\begin{tikzpicture}[framed]
\node (t0) [objnode]  {$\dtrain$};
\node (t1) [funnode,right=of t0] {$B(\dtrain|w)$};
\node (t2) [objnode,right=of t1] {$D_B$};
\node (t3) [funnode, below=of t2] {$C_C$};
\node (t4) [funnode, right=of t3] {$g_C(D_B|\phi)$};
\node (t5) [funnode, above=of t2] {$C_B$};
\node (t6) [funnode, right=of t5] {$g_B(D_B|\varphi)$};
\node (t7) [funnode,right=of t2] {$g_L(D_B|\theta)$};
\node (t8) [objnode,right=of t7] {$\hatg$};

\node (t9) [objnode, below=of t0, yshift = -15mm] {$\dtest$};
\node (t10) [funnode, right=of t9] {$\hat{g}(\dtest|\Theta)$};
\node (t11) [objnode, right=of t10] {$\tilde{S}$};
\node (t12) [funnode, right=of t11] {$T_1(\tilde{S})$};
\node (t13) [funnode, below=of t12] {$T_2(\tilde{S})$};
\node (t14) [objnode, right=of t12] {$\zeta$};
\node (t15) [objnode, right=of t13] {$\hatT$};

\path[->]
   (t0)  edge (t1)
   (t1)  edge (t2)
   (t2)  edge[dashed] (t3)
   (t2)  edge[dashed] (t5)
   (t2)  edge[dashed] (t7)
   (t3)  edge (t4)
   (t4)  edge (t8)
   (t6)  edge (t8)
   (t7)  edge (t8)
   (t5)  edge (t6)

   (t9) edge (t10)
   (t10) edge (t11)
   (t11) edge[dotted,color=red] (t12)
   (t11) edge[dash dot,color=blue] (t13)
   (t12) edge[dotted,color=red] (t14)
   (t13) edge[dash dot,color=blue] (t15);

\draw[dashed, line width=0.1mm] (-1,-2.5) -- (11,-2.5);
\end{tikzpicture}
\caption[Survival to classification reduction]{Survival to classification reduction. Top row is fitting and bottom row is predicting. Dashed lines represent a choice in the reduction (alternative compositions). Red dotted lines complete the probabilistic survival reduction (R7) and the blue dash-dotted lines complete the deterministic survival reduction (R8). Key: training data, $\dtrain$; binning function, $B$, with weights, $w$; binned data, $D_B$; composition to binary-class classification, $C_B$; composition to multi-class classification, $C_C$; binary-class classifier, $g_B$, with parameters, $\varphi$; multi-label classifier, $g_L$, with parameters, $\theta$; multi-class classifier, $g_C$, with parameters $\phi$; trained classifier, $\hat{g}$ with parameters $\Theta$; testing data, $\dtest$; pseudo-survival probabilities, $\tilde{S}$; composition, $T_1$, to distribution, $\zeta$; composition, $T_2$, to survival time, $\hatT$.}
\label{fig:car_R7R8}
\end{figure} -->
<p>Two separate reductions are presented in <span class="quarto-unresolved-ref">?fig-car-R7R8</span> however as both are reductions to probabilistic classification and are only different in the very last step, both are presented in this section. Steps and compositions of the reduction (<span class="quarto-unresolved-ref">?fig-car-R7R8</span>):</p>
<p><strong>Fit</strong> F1) A survival dataset, <span class="math inline">\(\mathcal{D}_{train}\)</span>, is binned, <span class="math inline">\(B\)</span>, with a continuous to discrete data composition (<a href="#sec-car-reduxes-r7-binning" class="quarto-xref"><span>Section 16.5.1.1</span></a>). F2) A multi-label classification model, with adaptations for censoring, <span class="math inline">\(g_L(D_B|\theta)\)</span>, is fit on the transformed dataset, <span class="math inline">\(D_B\)</span>. Optionally, <span class="math inline">\(g_L\)</span> could be further reduced to binary, <span class="math inline">\(g_B\)</span>, or multi-class classification, <span class="math inline">\(g_c\)</span>, (<a href="#sec-car-reduxes-r7-mlc" class="quarto-xref"><span>Section 16.5.1.4</span></a>). <strong>Predict</strong> P1) Testing survival data, <span class="math inline">\(\mathcal{D}_{test}\)</span>, is passed to the trained classification model, <span class="math inline">\(\hat{g}\)</span>, to predict pseudo-survival probabilities <span class="math inline">\(\tilde{S}\)</span> (or optionally hazards (<a href="#sec-car-reduxes-r7-out" class="quarto-xref"><span>Section 16.5.1.2</span></a>)). P2a) Predictions can be composed, <span class="math inline">\(T_1\)</span>, into a survival distribution prediction, <span class="math inline">\(\zeta = \zeta_1,...,\zeta_m\)</span> (<a href="#sec-car-reduxes-r7" class="quarto-xref"><span>Section 16.5.1.6</span></a>); or, P2b) Predictions can be composed, <span class="math inline">\(T_2\)</span>, to survival time predictions, <span class="math inline">\(\hat{T}= \hat{T}_1,...,\hat{T}_m\)</span> (<a href="#sec-car-reduxes-r8" class="quarto-xref"><span>Section 16.5.1.7</span></a>).</p>
<p>Further details for binning, multi-label classification, and transformation of pseudo-survival probabilities are now provided.</p>
<section id="sec-car-reduxes-r7-binning" class="level4" data-number="16.5.1.1">
<h4 data-number="16.5.1.1" class="anchored" data-anchor-id="sec-car-reduxes-r7-binning"><span class="header-section-number">16.5.1.1</span> Composition: Binning Survival Times</h4>
<p>An essential part of the reduction is the transformation from a survival dataset to a classification dataset, which requires two separate compositions. The first (discussed here) is to discretise the survival times (<span class="math inline">\(B(\mathcal{D}_{train}|w)\)</span> in <span class="quarto-unresolved-ref">?fig-car-R7R8</span>) and the second is to merge the survival time and censoring indicator into a single outcome (<a href="#sec-car-reduxes-r7-out" class="quarto-xref"><span>Section 16.5.1.2</span></a>).</p>
<p>Discretising survival times is achieved by the common ‘binning’ composition, in which a continuous outcome is discretised into ‘bins’ according to specified thresholds. These thresholds are usually determined by specifying the width of the bins as a hyper-parameter <span class="math inline">\(w\)</span>. This is a common transformation and therefore further discussion is not provided here. An example is given below with the original survival data on the left and the binned data on the right (<span class="math inline">\(w = 1\)</span>).</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>X</th>
<th>Time (Cont.)</th>
<th>Died</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>1.56</td>
<td>0</td>
</tr>
<tr class="even">
<td>2</td>
<td>2</td>
<td>1</td>
</tr>
<tr class="odd">
<td>3</td>
<td>3.3</td>
<td>1</td>
</tr>
<tr class="even">
<td>4</td>
<td>3.6</td>
<td>0</td>
</tr>
<tr class="odd">
<td>5</td>
<td>4</td>
<td>0</td>
</tr>
</tbody>
</table>
<table class="caption-top table">
<thead>
<tr class="header">
<th>X</th>
<th>Time (Disc.)</th>
<th>Died</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>[1, 2)</td>
<td>0</td>
</tr>
<tr class="even">
<td>2</td>
<td>[2, 3)</td>
<td>1</td>
</tr>
<tr class="odd">
<td>3</td>
<td>[3, 4)</td>
<td>1</td>
</tr>
<tr class="even">
<td>4</td>
<td>[3, 4)</td>
<td>0</td>
</tr>
<tr class="odd">
<td>5</td>
<td>[4, 5)</td>
<td>0</td>
</tr>
</tbody>
</table>
</section>
<section id="sec-car-reduxes-r7-out" class="level4" data-number="16.5.1.2">
<h4 data-number="16.5.1.2" class="anchored" data-anchor-id="sec-car-reduxes-r7-out"><span class="header-section-number">16.5.1.2</span> Composition: Survival to Classification Outcome</h4>
<p>The binned dataset still has the unique survival data format of utilising two outcomes for training (time and status) but only making a prediction for one outcome (distribution). In order for this to be compatible with classification, the two outcome variables are composed into a single variable. This is achieved by casting the survival times into a ‘wide’ format and creating a new outcome indicator. Two outcome transformations are possible, the first represents a discrete survival function and the second represents a discrete hazard function.</p>
</section>
<section id="discrete-survival-function-composition" class="level4 unnumbered unlisted">
<h4 class="unnumbered unlisted anchored" data-anchor-id="discrete-survival-function-composition">Discrete Survival Function Composition</h4>
<p>In this composition, the data in the transformed dataset represents the discrete survival function. The new indicator is defined as follows, <span class="math display">\[
Y_{i;\tau} :=
\begin{cases}
1, &amp; T_i &gt; \tau \\
0, &amp; T_i \leq \tau \cap \Delta_i = 1 \\
-1, &amp; T_i \leq \tau \cap \Delta_i = 0
\end{cases}
\]</span> At a given discrete time <span class="math inline">\(\tau\)</span>, an observation, <span class="math inline">\(i\)</span>, is either alive (<span class="math inline">\(Y_{i;\tau} = 1\)</span>), dead (<span class="math inline">\(Y_{i;\tau} = 0\)</span>), or censored (<span class="math inline">\(Y_{i;\tau} = -1\)</span>). Therefore <span class="math inline">\(\hat{P}(Y_{i;\tau} = 1) = \hat{S}_i(\tau)\)</span>, motivating this particular choice of representation.</p>
<p>This composition is demonstrated below with the binned data (left) and the composed classification data (right).</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>X</th>
<th>Time (Disc.)</th>
<th>Died</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>[1, 2)</td>
<td>0</td>
</tr>
<tr class="even">
<td>2</td>
<td>[2, 3)</td>
<td>1</td>
</tr>
<tr class="odd">
<td>3</td>
<td>[3, 4)</td>
<td>1</td>
</tr>
<tr class="even">
<td>4</td>
<td>[3, 4)</td>
<td>0</td>
</tr>
<tr class="odd">
<td>5</td>
<td>[4, 5)</td>
<td>0</td>
</tr>
</tbody>
</table>
<table class="caption-top table">
<thead>
<tr class="header">
<th>X</th>
<th>[1,2)</th>
<th>[2,3)</th>
<th>[3,4)</th>
<th>[4,5)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>-1</td>
<td>-1</td>
<td>-1</td>
<td>-1</td>
</tr>
<tr class="even">
<td>2</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td>3</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>4</td>
<td>1</td>
<td>1</td>
<td>-1</td>
<td>-1</td>
</tr>
<tr class="odd">
<td>5</td>
<td>1</td>
<td>1</td>
<td>-1</td>
<td>-1</td>
</tr>
</tbody>
</table>
</section>
<section id="discrete-hazard-function-composition" class="level4 unnumbered unlisted">
<h4 class="unnumbered unlisted anchored" data-anchor-id="discrete-hazard-function-composition">Discrete Hazard Function Composition</h4>
<p>In this composition, the data in the transformed dataset represents the discrete hazard function. The new indicator is defined as follows, <span class="math display">\[
Y^*_{i;\tau} :=
\begin{cases}
1, &amp; T_i = \tau \cap \Delta_i = 1 \\
-1, &amp; T_i = \tau \cap \Delta_i = 0 \\
0, &amp; \text{otherwise}
\end{cases}
\]</span> At a given discrete time <span class="math inline">\(\tau\)</span>, an observation, <span class="math inline">\(i\)</span>, either experiences the event (<span class="math inline">\(Y^*_{i;\tau} = 1\)</span>), experiences censoring (<span class="math inline">\(Y_{i;\tau} = -1\)</span>), or neither (<span class="math inline">\(Y_{i;\tau} = 0\)</span>). Utilising sequential multi-label classification problem transformation methods (<a href="#sec-car-reduxes-r7-mlc" class="quarto-xref"><span>Section 16.5.1.4</span></a>) results in <span class="math inline">\(\hat{P}(Y^*_{i;\tau} = 1) = \hat{h}_i(\tau)\)</span>. If methods are utilised that do not ‘look back’ at predictions then <span class="math inline">\(\hat{P}(Y^*_{i;\tau} = 1) = \hat{p}_i(\tau)\)</span> (<a href="#sec-car-reduxes-r7-mlc" class="quarto-xref"><span>Section 16.5.1.4</span></a>).</p>
<p>This composition is demonstrated below with the binned data (left) and the composed classification data (right).</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>X</th>
<th>Time (Disc.)</th>
<th>Died</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>[1, 2)</td>
<td>0</td>
</tr>
<tr class="even">
<td>2</td>
<td>[2, 3)</td>
<td>1</td>
</tr>
<tr class="odd">
<td>3</td>
<td>[3, 4)</td>
<td>1</td>
</tr>
<tr class="even">
<td>4</td>
<td>[3, 4)</td>
<td>0</td>
</tr>
<tr class="odd">
<td>5</td>
<td>[4, 5)</td>
<td>0</td>
</tr>
</tbody>
</table>
<table class="caption-top table">
<thead>
<tr class="header">
<th>X</th>
<th>[1,2)</th>
<th>[2,3)</th>
<th>[3,4)</th>
<th>[4,5)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>-1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>2</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td>3</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="even">
<td>4</td>
<td>0</td>
<td>0</td>
<td>-1</td>
<td>0</td>
</tr>
<tr class="odd">
<td>5</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>-1</td>
</tr>
</tbody>
</table>
</section>
<section id="multi-label-classification-data" class="level4 unnumbered unlisted">
<h4 class="unnumbered unlisted anchored" data-anchor-id="multi-label-classification-data">Multi-Label Classification Data</h4>
<p>In both compositions, survival data t.v.i. <span class="math inline">\(\mathbb{R}^p \times \mathbb{R}_{\geq 0}\times \{0,1\}\)</span> is transformed to multi-label classification data t.v.i. <span class="math inline">\(\mathbb{R}^p \times \{-1,0,1\}^K\)</span> for <span class="math inline">\(K\)</span> binned time-intervals. The multi-label classification task is defined in <a href="#sec-car-reduxes-r7-mlc" class="quarto-xref"><span>Section 16.5.1.4</span></a> with possible algorithms.</p>
<p>The discrete survival representation has a slightly more natural interpretation and is ‘easier’ for classifiers to use for training as there are more positive events (i.e.&nbsp;more observations alive) to train on, whereas the discrete hazard representation will have relatively few events in each time-point. However the hazard representation leads to more natural predictions (<a href="#sec-car-reduxes-r7" class="quarto-xref"><span>Section 16.5.1.6</span></a>).</p>
<p>A particular bias that may easily result from the composition of survival to classification data is now discussed.</p>
</section>
<section id="reduction-to-classification-bias" class="level4" data-number="16.5.1.3">
<h4 data-number="16.5.1.3" class="anchored" data-anchor-id="reduction-to-classification-bias"><span class="header-section-number">16.5.1.3</span> Reduction to Classification Bias</h4>
<p>The reduction to classification bias is commonly known <span class="citation" data-cites="Zhou2005">(<a href="P5C26_references.html#ref-Zhou2005" role="doc-biblioref">Zhou et al. 2005</a>)</span> but is reiterated briefly here as it must be accounted for in any automated reduction to classification workflow. This bias occurs when making classification predictions about survival at a given time and incorrectly censoring patients who have not been observed long enough, instead of removing them.</p>
<p>By example, say the prediction of interest is five-year survival probabilities after a particular diagnosis, clearly a patient who has only been diagnosed for three years cannot inform this prediction. The bias is introduced if this patient is censored at five-years instead of being removed from the dataset. The result of this bias is to artificially inflate the probability of survival at each time-point as an unknown outcome is treated as censored and therefore alive.</p>
<p>This bias is simply dealt with by removing patients who have not been alive ‘long enough’. Paradoxically, even if a patient is observed to die before the time-point of interest, they should still be removed if they have not been in the dataset ‘long enough’ as failing to do so will result in a bias in the opposite direction, thus over-inflating the proportion of dead observations.</p>
<p>Accounting for this bias is particularly important in the multi-label reduction as the number of observable patients will decrease over time due to censoring.</p>
</section>
<section id="sec-car-reduxes-r7-mlc" class="level4" data-number="16.5.1.4">
<h4 data-number="16.5.1.4" class="anchored" data-anchor-id="sec-car-reduxes-r7-mlc"><span class="header-section-number">16.5.1.4</span> Multi-Label Classification Algorithms</h4>
<p>As the work in this section is completely out of the book scope, the full text is in appendix <span class="citation" data-cites="app-mlc">(<a href="P5C26_references.html#ref-app-mlc" role="doc-biblioref"><strong>app-mlc?</strong></a>)</span>. The most important contributions from this section are:</p>
<ul>
<li>Reviewing problem transformation methods <span class="citation" data-cites="Tsoumakas2007">(<a href="P5C26_references.html#ref-Tsoumakas2007" role="doc-biblioref">Tsoumakas and Katakis 2007</a>)</span> for multi-label classification;</li>
<li>Identifying that only binary relevance, nested stacking, and classifier chains are appropriate in this reduction; and</li>
<li>Generalising these methods into a single wrapper for any binary classifier, the ‘LWrapper’.</li>
</ul>
</section>
<section id="censoring-in-classification" class="level4" data-number="16.5.1.5">
<h4 data-number="16.5.1.5" class="anchored" data-anchor-id="censoring-in-classification"><span class="header-section-number">16.5.1.5</span> Censoring in Classification</h4>
<p>Classification algorithms cannot natively handle the censoring that is included in the survival reduction, but this can be incorporated using one of two approaches.</p>
</section>
<section id="multi-class-classification" class="level4 unnumbered unlisted">
<h4 class="unnumbered unlisted anchored" data-anchor-id="multi-class-classification">Multi-Class Classification</h4>
<p>All multi-label datasets can also handle multi-class data, hence the simplest way in which to handle censoring is to make multi-class predictions in each label for the outcome <span class="math inline">\(Y_\tau \ t.v.i. \{-1, 0, 1\}\)</span>. Many off-shelf classification learners can make multi-class predictions natively and simple reductions exist for those that cannot. As a disadvantage to this method, classifiers would then predict if an individual is dead or alive or censored (each mutually exclusive), and not simply alive or dead. Though this could be perceived as an advantage when censoring is informative as this will accurately reflect a real-world competing-risks set-up.</p>
</section>
<section id="subsettinghurdle-models" class="level4 unnumbered unlisted">
<h4 class="unnumbered unlisted anchored" data-anchor-id="subsettinghurdle-models">Subsetting/Hurdle Models</h4>
<p>For this approach, the multi-class task is reduced to two binary class tasks: first predict if a subject is censored or not (dead or alive) and only if the prediction for censoring is below some threshold, <span class="math inline">\(\alpha \in [0, 1]\)</span>, then predict if the subject is alive or not (dead or censored). If the probability of censoring is high in the first task then the probability of being alive is automatically set to zero in the final prediction, otherwise the prediction from the second task is used. Any classifier can utilise this approach and it has a meaningful interpretation, additionally <span class="math inline">\(\alpha\)</span> is a tunable hyper-parameter. The main disadvantage is increases to storage and run-time requirements as double the number of models may be fit.</p>
<p>Once the datasets have been composed to classification datasets and censoring is suitably incorporated by either approach, then any probabilistic classification model can be fit on the data. Predictions from these models can either be composed to a distribution prediction (R7) or a survival time prediction (R8).</p>
</section>
<section id="sec-car-reduxes-r7" class="level4" data-number="16.5.1.6">
<h4 data-number="16.5.1.6" class="anchored" data-anchor-id="sec-car-reduxes-r7"><span class="header-section-number">16.5.1.6</span> R7) Probabilistic Survival <span class="math inline">\(\rightarrow\)</span> Probabilistic Classification</h4>
<!-- \begin{figure}[H]
\centering
\begin{tikzpicture}[framed]
\node (t0) [objnode]  {$\dtrain$};
\node (t1) [funnode,right=of t0] {$B(\dtrain|w)$};
\node (t2) [objnode,right=of t1] {$D_B$};
\node (t3) [funnode, below=of t2] {$C_C$};
\node (t4) [funnode, right=of t3] {$g_C(D_B|\phi)$};
\node (t5) [funnode, above=of t2] {$C_B$};
\node (t6) [funnode, right=of t5] {$g_B(D_B|\varphi)$};
\node (t7) [funnode,right=of t2] {$g_L(D_B|\theta)$};
\node (t8) [objnode,right=of t7] {$\hatg$};

\node (t9) [objnode, below=of t0, yshift = -15mm] {$\dtest$};
\node (t10) [funnode, right=of t9] {$\hat{g}(\dtest|\Theta)$};
\node (t11) [objnode, right=of t10] {$\tilde{S}$};
\node (t12) [funnode, right=of t11] {$T_1(\tilde{S})$};
\node (t14) [objnode, right=of t12] {$\zeta$};

\path[->]
   (t0)  edge (t1)
   (t1)  edge (t2)
   (t2)  edge[dashed] (t3)
   (t2)  edge[dashed] (t5)
   (t2)  edge[dashed] (t7)
   (t3)  edge (t4)
   (t4)  edge (t8)
   (t6)  edge (t8)
   (t7)  edge (t8)
   (t5)  edge (t6)

   (t9) edge (t10)
   (t10) edge (t11)
   (t11) edge (t12)
   (t12) edge (t14);

\draw[dashed, line width=0.1mm] (-1,-2.5) -- (11,-2.5);
\end{tikzpicture}
\caption[Probabilistic survival to probabilistic classification reduction]{Probabilistic survival to probabilistic reduction. See @fig-car-R7R8 for key.}
\label{fig:car_R7}
\end{figure} -->
<p>This final part of the (R7) reduction is described separately for discrete hazard and survival representations of the data (<a href="#sec-car-reduxes-r7-out" class="quarto-xref"><span>Section 16.5.1.2</span></a>).</p>
</section>
<section id="discrete-hazard-representation" class="level4 unnumbered unlisted">
<h4 class="unnumbered unlisted anchored" data-anchor-id="discrete-hazard-representation">Discrete Hazard Representation</h4>
<p>In this representation recall that predictions of the positive class, <span class="math inline">\(P(Y_\tau = 1)\)</span>, are estimating the quantity <span class="math inline">\(h(\tau)\)</span>. These predictions provide a natural and efficient transformation from predicted hazards to survival probabilities. Let <span class="math inline">\(\hat{h}_i\)</span> be a predicted hazard function for some observation <span class="math inline">\(i\)</span>, then the survival function for that observation can be found with a Kaplan-Meier type estimator, <span class="math display">\[
\tilde{S}_i(\tau^*) = \prod_\tau 1 - \hat{h}_i(\tau)
\]</span> Now predictions are for a pseudo-survival function, which is ‘pseudo’ as it is not right-continuous. Resolving this is discussed below.</p>
</section>
<section id="discrete-survival-representation" class="level4 unnumbered unlisted">
<h4 class="unnumbered unlisted anchored" data-anchor-id="discrete-survival-representation">Discrete Survival Representation</h4>
<p>In this representation, <span class="math inline">\(P(Y_\tau = 1)\)</span> is estimating <span class="math inline">\(S(\tau)\)</span>, which means that predictions from a classification model result in discrete point predictions and not a right-continuous function. More importantly, there is no guarantee that a non-increasing function will be predicted, i.e.&nbsp;there is no guarantee that <span class="math inline">\(P(Y_j = 1) &lt; P(Y_i = 1)\)</span>, for time-points <span class="math inline">\(j &gt; i\)</span>.</p>
<p>Unfortunately there is no optimal way of dealing with predictions of this sort and ‘mistakes’ of this kind have been observed in some software implementation. One point to note is that in practice these are quite rare as the probability of survival will always decrease over time. Therefore the ‘usual’ approach is quite ‘hacky’ and involves imputing increasing predictions with the previous prediction, formally, <span class="math display">\[
\tilde{S}({i+1}) := \min\{P(Y_{i+1} = 1), P(Y_i = 1)\}, \forall i = \mathbb{R}_{\geq 0}
\]</span> assuming <span class="math inline">\(\tilde{S}(0) = 1\)</span>. Future research should seek more robust alternatives.</p>
</section>
<section id="right-continuous-survival-function" class="level4 unnumbered unlisted">
<h4 class="unnumbered unlisted anchored" data-anchor-id="right-continuous-survival-function">Right-Continuous Survival Function</h4>
<p>From either representation, a \ non-increasing but non-continuous pseudo-survival function, <span class="math inline">\(\tilde{S}\)</span>, is now predicted. Creating a right-continuous function (‘<span class="math inline">\(T_1(\tilde{S})\)</span>’ in <span class="quarto-unresolved-ref">?fig-car-R7</span>) from these point predictions (<a href="#fig-car-survclass" class="quarto-xref">Figure&nbsp;<span>16.3</span></a> (a)) is relatively simple and well-known with accessible off-shelf software. At the very least, one can assume a constant hazard rate between predictions and cast them into a step function (<a href="#fig-car-survclass" class="quarto-xref">Figure&nbsp;<span>16.3</span></a> (b)). This is a fairly common assumption and is usually valid as bin-width decreases. Alternatively, the point predictions can be smoothed into a continuous function with off-shelf software, for example with polynomial local regression smoothing (<a href="#fig-car-survclass" class="quarto-xref">Figure&nbsp;<span>16.3</span></a> (c)) or generalised linear smoothing (<a href="#fig-car-survclass" class="quarto-xref">Figure&nbsp;<span>16.3</span></a> (d)). Whichever method is chosen, the survival function is now non-increasing right-continuous and the (R7) reduction is complete.</p>
<div id="fig-car-survclass" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-car-survclass-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-car-survclass" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-car-survclass-a" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-car-survclass-a-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/car/surv_points.png" class="img-fluid figure-img" data-ref-parent="fig-car-survclass">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-car-survclass-a-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Point Predictions
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-car-survclass" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-car-survclass-b" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-car-survclass-b-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/car/surv_step.png" class="img-fluid figure-img" data-ref-parent="fig-car-survclass">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-car-survclass-b-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Survival Step Function
</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-car-survclass" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-car-survclass-c" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-car-survclass-c-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/car/surv_loess.png" class="img-fluid figure-img" data-ref-parent="fig-car-survclass">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-car-survclass-c-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(c) Local polynomial regression smoothing
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-car-survclass" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-car-survclass-d" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-car-survclass-d-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Figures/car/surv_glm.png" class="img-fluid figure-img" data-ref-parent="fig-car-survclass">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-car-survclass-d-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(d) Generalised linear smoothing
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-car-survclass-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;16.3: Survival function as a: point prediction (a), step function assuming constant risk (b), local polynomial regression smoothing (c), and generalised linear smoothing (d). (c) and (d) computed with <strong>ggplot2</strong> <span class="citation" data-cites="pkgggplot2">(<a href="P5C26_references.html#ref-pkgggplot2" role="doc-biblioref">Wickham 2016</a>)</span>.
</figcaption>
</figure>
</div>
</section>
<section id="sec-car-reduxes-r8" class="level4" data-number="16.5.1.7">
<h4 data-number="16.5.1.7" class="anchored" data-anchor-id="sec-car-reduxes-r8"><span class="header-section-number">16.5.1.7</span> R8) Deterministic Survival <span class="math inline">\(\rightarrow\)</span> Probabilistic Classification</h4>
<!-- \begin{figure}[H]
\centering
\begin{tikzpicture}[framed]
\node (t0) [objnode]  {$\dtrain$};
\node (t1) [funnode,right=of t0] {$B(\dtrain|w)$};
\node (t2) [objnode,right=of t1] {$D_B$};
\node (t3) [funnode, below=of t2] {$C_C$};
\node (t4) [funnode, right=of t3] {$g_C(D_B|\phi)$};
\node (t5) [funnode, above=of t2] {$C_B$};
\node (t6) [funnode, right=of t5] {$g_B(D_B|\varphi)$};
\node (t7) [funnode,right=of t2] {$g_L(D_B|\theta)$};
\node (t8) [objnode,right=of t7] {$\hatg$};

\node (t9) [objnode, below=of t0, yshift = -15mm] {$\dtest$};
\node (t10) [funnode, right=of t9] {$\hat{g}(\dtest|\Theta)$};
\node (t11) [objnode, right=of t10] {$\tilde{S}$};
\node (t13) [funnode, right=of t11] {$T_2(\tilde{S})$};
\node (t15) [objnode, right=of t13] {$\hatT$};

\path[->]
   (t0)  edge (t1)
   (t1)  edge (t2)
   (t2)  edge[dashed] (t3)
   (t2)  edge[dashed] (t5)
   (t2)  edge[dashed] (t7)
   (t3)  edge (t4)
   (t4)  edge (t8)
   (t6)  edge (t8)
   (t7)  edge (t8)
   (t5)  edge (t6)

   (t9) edge (t10)
   (t10) edge (t11)
   (t11) edge (t13)
   (t13) edge (t15);

\draw[dashed, line width=0.1mm] (-1,-2.5) -- (11,-2.5);
\end{tikzpicture}
\caption[Deterministic survival to probabilistic classification reduction]{Deterministic survival to probabilistic reduction. See @fig-car-R7R8 for key.}
\label{fig:car_R8}
\end{figure} -->
<p>Predicting a deterministic survival time from the multi-label classification predictions is relatively straightforward and can be viewed as a discrete analogue to (C3) (<a href="#sec-car-pipelines-crank" class="quarto-xref"><span>Section 16.4.3</span></a>). For the discrete hazard representation, one can simply take the predicted time-point for an individual to be time at which the predicted hazard probability is highest however this could easily be problematic as there may be multiple time-points at which the predicted hazard equals <span class="math inline">\(1\)</span>. Instead it is cleaner to first cast the hazard to a pseudo-survival probability (<a href="#sec-car-reduxes-r7" class="quarto-xref"><span>Section 16.5.1.6</span></a>) and then treat both representations the same.</p>
<p>Let <span class="math inline">\(\tilde{S}_i\)</span> be the predicted multi-label survival probabilities for an observation <span class="math inline">\(i\)</span> such that <span class="math inline">\(\tilde{S}_i(\tau)\)</span> corresponds with <span class="math inline">\(\hat{P}(Y_{i;\tau} = 1)\)</span> for label <span class="math inline">\(\tau \in \mathcal{K}\)</span> where <span class="math inline">\(Y_{i;\tau}\)</span> is defined in <a href="#sec-car-reduxes-r7-out" class="quarto-xref"><span>Section 16.5.1.2</span></a> and <span class="math inline">\(\mathcal{K} = \{1,...,K\}\)</span> is the set of labels for which to make predictions. Then the survival time transformation is defined by <span class="math display">\[
T_2(\tilde{S}_i) = \inf \{\tau \in \mathcal{K} : \tilde{S}_i(\tau) \leq \beta\}
\]</span> for some <span class="math inline">\(\beta \in [0, 1]\)</span>.</p>
<p>This is interpreted as defining the predicted survival time as the first time-point in which the predicted probability of being alive drops below a certain threshold <span class="math inline">\(\beta\)</span>. Usually <span class="math inline">\(\beta = 0.5\)</span>, though this can be treated as a hyper-parameter for tuning. This composition can be utilised even if predictions are not non-increasing, as only the first time the predicted survival probability drops below the threshold is considered. With this composition the (R8) reduction is now complete.</p>
</section>
</section>
</section>
<section id="sec-car-conc" class="level2" data-number="16.6">
<h2 data-number="16.6" class="anchored" data-anchor-id="sec-car-conc"><span class="header-section-number">16.6</span> Conclusions</h2>
<p>This chapter introduced composition and reduction to survival analysis and formalised specific strategies. Formalising these concepts allows for better quality of research and most importantly improved transparency. Clear interface points for hyper-parameters and compositions allow for reproducibility that was previously obfuscated by unclear workflows and imprecise documentation for pipelines.</p>
<p>Additionally, composition and reduction improves accessibility. Reduction workflows vastly increase the number of machine learning models that can be utilised in survival analysis, thus opening the field to those whose experience is limited to regression or classification. Formalisation of workflows allows for precise implementation of model-agnostic pipelines as computational objects, as opposed to functions that are built directly into an algorithm without external interface points.</p>
<p>Finally, predictive performance is also increased by these methods, which is most prominently the case for the survival model averaging compositor (as demonstrated by RSFs).</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-Cox1972" class="csl-entry" role="listitem">
Cox, D. R. 1972. <span>“<span class="nocase">Regression Models and Life-Tables</span>.”</span> <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 34 (2): 187–220.
</div>
<div id="ref-Friedman1982" class="csl-entry" role="listitem">
Friedman, Michael. 1982. <span>“<span class="nocase">Piecewise exponential models for survival data with covariates</span>.”</span> <em>The Annals of Statistics</em> 10 (1): 101–13.
</div>
<div id="ref-Langford2016" class="csl-entry" role="listitem">
Langford, John, Paul Mineiro, Alina Beygelzimer, and Hal Daume. 2016. <span>“<span class="nocase">Learning Reductions that Really Work</span>.”</span> <em>Proceedings of the IEEE</em> 104 (1).
</div>
<div id="ref-Liestol1994" class="csl-entry" role="listitem">
Liestol, Knut, Per Kragh Andersen, and Ulrich Andersen. 1994. <span>“<span class="nocase">Survival analysis and neural nets</span>.”</span> <em>Statistics in Medicine</em> 13 (12): 1189–1200. <a href="https://doi.org/10.1002/sim.4780131202">https://doi.org/10.1002/sim.4780131202</a>.
</div>
<div id="ref-Schwarzer2000" class="csl-entry" role="listitem">
Schwarzer, Guido, Werner Vach, and Martin Schumacher. 2000. <span>“<span class="nocase">On the misuses of artificial neural networks for prognostic and diagnostic classification in oncology</span>.”</span> <em>Statistics in Medicine</em> 19 (4): 541–61. <a href="https://doi.org/10.1002/(SICI)1097-0258(20000229)19:4<541::AID-SIM355>3.0.CO;2-V">https://doi.org/10.1002/(SICI)1097-0258(20000229)19:4&lt;541::AID-SIM355&gt;3.0.CO;2-V</a>.
</div>
<div id="ref-Tsoumakas2007" class="csl-entry" role="listitem">
Tsoumakas, Grigorios, and Ioannis Katakis. 2007. <span>“<span>Multi-Label Classification: An Overview</span>.”</span> <em>International Journal of Data Warehousing and Mining</em> 3 (3): 1–13. <a href="https://doi.org/10.4018/jdwm.2007070101">https://doi.org/10.4018/jdwm.2007070101</a>.
</div>
<div id="ref-Tutz2016" class="csl-entry" role="listitem">
Tutz, Gerhard, and Matthias Schmid. 2016. <em><span class="nocase">Modeling Discrete Time-to-Event Data</span></em>. Springer Series in Statistics. Cham: Springer International Publishing. <a href="https://doi.org/10.1007/978-3-319-28158-2">https://doi.org/10.1007/978-3-319-28158-2</a>.
</div>
<div id="ref-VanHouwelingen2007" class="csl-entry" role="listitem">
Van Houwelingen, Hans C. 2007. <span>“<span class="nocase">Dynamic prediction by landmarking in event history analysis</span>.”</span> <em>Scandinavian Journal of Statistics</em> 34 (1): 70–85. <a href="https://doi.org/10.1111/j.1467-9469.2006.00529.x">https://doi.org/10.1111/j.1467-9469.2006.00529.x</a>.
</div>
<div id="ref-pkgdiscsurv" class="csl-entry" role="listitem">
Welchowski, Thomas, and Matthias Schmid. 2019. <span>“<span class="nocase">discSurv: Discrete Time Survival Analysis</span>.”</span> CRAN. <a href="https://cran.r-project.org/package=discSurv">https://cran.r-project.org/package=discSurv</a>.
</div>
<div id="ref-pkgggplot2" class="csl-entry" role="listitem">
Wickham, Hadley. 2016. <em><span class="nocase">ggplot2: Elegant Graphics for Data Analysis</span></em>. Springer-Verlag New York. <a href="https://ggplot2.tidyverse.org">https://ggplot2.tidyverse.org</a>.
</div>
<div id="ref-Zhou2005" class="csl-entry" role="listitem">
Zhou, Zheng, Elham Rahme, Michal Abrahamowicz, and Louise Pilote. 2005. <span>“<span class="nocase">Survival Bias Associated with Time-to-Treatment Initiation in Drug Effectiveness Evaluation: A Comparison of Methods</span>.”</span> <em>American Journal of Epidemiology</em> 162 (10): 1016–23. <a href="https://doi.org/10.1093/aje/kwi307">https://doi.org/10.1093/aje/kwi307</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./P3C17_neural.html" class="pagination-link" aria-label="Neural Networks">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Neural Networks</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./P4C20_competing.html" class="pagination-link" aria-label="Competing Risks Pipelines">
        <span class="nav-page-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Competing Risks Pipelines</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>All content licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> <br> © Raphael Sonabend, Andreas Bender.</p>
</div>   
    <div class="nav-footer-center">
<p><a href="https://www.mlsabook.com">Website</a> | <a href="https://github.com/mlsa-book/MLSA">GitHub</a></p>
<div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/mlsa-book/MLSA/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li><li><a href="https://github.com/mlsa-book/MLSA/edit/main/book/P4C19_reductions.qmd" class="toc-action"><i class="bi empty"></i>Edit this page</a></li><li><a href="https://github.com/mlsa-book/MLSA/blob/main/book/P4C19_reductions.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>