[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning in Survival Analysis",
    "section": "",
    "text": "Getting Started",
    "crumbs": [
      " "
    ]
  },
  {
    "objectID": "index.html#licensing",
    "href": "index.html#licensing",
    "title": "Machine Learning in Survival Analysis",
    "section": "Licensing",
    "text": "Licensing\nThis book is licensed under CC BY-NC-SA 4.0, so you can adapt and redistribute the contents however you like as long as you: i) do cite this book (information below); ii) do not use any material for commercial purposes; and iii) do use a CC BY-NC-SA 4.0 compatible license if you adapt the material.\nIf you have any questions about licensing just open an issue and we will help you out.",
    "crumbs": [
      " "
    ]
  },
  {
    "objectID": "index.html#citation-information",
    "href": "index.html#citation-information",
    "title": "Machine Learning in Survival Analysis",
    "section": "Citation Information",
    "text": "Citation Information\nWhilst this book remains a work in progress you can cite it as\nSonabend. R, Bender. A. (2025). Machine Learning in Survival Analysis.\nhttps://www.mlsabook.com.\n\n@book{MLSA2025\n    title = Machine Learning in Survival Analysis,\n    editor = {Raphael Sonabend, Andreas Bender},\n    url = {https://www.mlsabook.com},\n    year = {2025}\n}",
    "crumbs": [
      " "
    ]
  },
  {
    "objectID": "index.html#contributing-to-this-book",
    "href": "index.html#contributing-to-this-book",
    "title": "Machine Learning in Survival Analysis",
    "section": "Contributing to this book",
    "text": "Contributing to this book\nWe welcome contributions to the electronic copy of the book, whether they’re issues picking up on typos, requests for additional content, or pull requests with contributions from any size. All contributions will be acknowledged in the preface of the book.\nBefore you contribute please make sure you have read our code of conduct.",
    "crumbs": [
      " "
    ]
  },
  {
    "objectID": "index.html#biographies",
    "href": "index.html#biographies",
    "title": "Machine Learning in Survival Analysis",
    "section": "Biographies",
    "text": "Biographies\nRaphael Sonabend is the CEO and Co-Founder of OSPO Now, a company providing virtual open-source program offices as a service. They are also a Visiting Researcher at Imperial College London. Raphael holds a PhD in statistics, specializing in machine learning applications for survival analysis. They created the R packages mlr3proba, survivalmodels, and the Julia package SurvivalAnalysis.jl. Raphael co-edited and co-authored Applied Machine Learning Using mlr3 in R (Bischl et al. 2024).\nAndreas Bender is FIXME.",
    "crumbs": [
      " "
    ]
  },
  {
    "objectID": "index.html#overview-to-the-book",
    "href": "index.html#overview-to-the-book",
    "title": "Machine Learning in Survival Analysis",
    "section": "Overview to the book",
    "text": "Overview to the book\nThis textbook is intended to fill a gap in the literature by providing a comprehensive introduction to machine learning in the survival setting. If you are interested in machine learning or survival analysis separately then you might consider James et al. (2013), Hastie, Tibshirani, and Friedman (2001), Bishop (2006) for machine learning and Collett (2014), Kalbfleisch and Prentice (1973) for survival analysis. This book serves as a complement to the above examples and introduces common machine learning terminology from simpler settings such as regression and classification, but without diving into the detail found in other sources, instead focusing on extension to the survival analysis setting.\nThis book may be useful for Masters or PhD students who are specialising in machine learning in survival analysis, machine learning practitioners looking to work in the survival setting, or statisticians who are familiar with survival analysis but less so with machine learning. The book could be read cover-to-cover, but this is not advised. Instead it may be preferable to dip into sections of the book as required and use the ‘signposts’ that direct the reader to sections of the book that are relevant to each other.\nThe book is split into five parts:\nPart I: Survival Analysis and Machine Learning The book begins by introducing the basics of survival analysis and machine learning and unifying terminology between the two to enable meaningful description of ‘machine learning in survival analysis’ (MLSA). In particular, the survival analysis ‘task’ and survival ‘prediction types’ are defined.\nPart II: Evaluation The second part of the book discusses measures for evaluating survival models. These are presented in different classes that reflect the prediction types identified in Part I. In each chapter, the measure class is introduced, particular metrics are listed, and commentary is provided on how and when to use the measures. The final chapter of Part II briefly discusses when to use a given measure class and provides recommendations for model comparison.\nPart III: Models Part III is a deep dive into machine learning models for solving survival analysis problems. This begins with ‘classical’ models that may not be considered ‘machine learning’ and then continues by exploring different classes of machine learning models including random forests, support vector machines, gradient boosting machines, neural networks, and other less common classes. Each model class is introduced in the simpler regression setting and then extensions to survival analysis are discussed. Differences between model implementations are not discussed, instead the focus is on understanding how these models are built for survival analysis - in this way readers are well-equipped to independently follow individual papers introducing specific implementations.\nPart IV: Reduction Techniques The next part of the book introduces reduction techniques in survival analysis, which is the process of solving the survival analysis task by using methods from other fields. In particular, chapters focus on demonstrating how any survival model can be used in the competing risks setting, discrete time modelling, Poisson methods, pseudovalues (reduction to regression), and other advanced modelling methods.\nPart V: Extensions and Outlook The final part of the book provides some miscellaneous chapters that may be of use to readers. The first chapter lists common practical problems that occur when running survival analysis experiments and solutions that we have found useful. The next lists open-source software at the time of writing for running machine learning survival analysis experiments. The final chapter is our outlook on survival analysis and where the field may be heading.\nExercises are provided at the end of the book so you can test yourself as you go along.",
    "crumbs": [
      " "
    ]
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "Machine Learning in Survival Analysis",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nWe would like to gratefully acknowledge our colleagues that reviewed the content of this book, including: Lukas Burk, Cesaire Fouodo.\n\n\n\n\nBischl, Bernd, Raphael Sonabend, Lars Kotthoff, and Michel Lang, eds. 2024. Applied Machine Learning Using mlr3 in R. CRC Press. https://mlr3book.mlr-org.com.\n\n\nBishop, Christopher M. 2006. Pattern recognition and machine learning. springer.\n\n\nCollett, David. 2014. Modelling Survival Data in Medical Research. 3rd ed. CRC.\n\n\nHastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2001. The Elements of Statistical Learning. Springer New York Inc.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. An introduction to statistical learning. Vol. 112. New York: Springer.\n\n\nKalbfleisch, J. D., and R. L. Prentice. 1973. “Marginal likelihoods based on Cox’s regression and life model.” Biometrika 60 (2): 267–78. https://doi.org/10.1093/biomet/60.2.267.",
    "crumbs": [
      " "
    ]
  },
  {
    "objectID": "P0C0_notation.html",
    "href": "P0C0_notation.html",
    "title": "Symbols and Notation",
    "section": "",
    "text": "Fonts, matrices, vectors\nThe most common symbols and notation used throughout this book are presented below; in rare cases where different meanings are intended within the book, this will be made clear.\nA lower-case letter in normal font, \\(x\\), refers to a single, fixed observation. When in bold font, a lower-case letter, \\(\\mathbf{x}\\), refers to a vector of fixed observations, and an upper-case letter, \\(\\mathbf{X}\\), represents a matrix. Calligraphic letters, \\(\\mathcal{X}\\), are used to denote sets.\nA matrix will always be defined with its dimensions using the notation, \\(\\mathbf{X}\\in \\mathcal{X}^{n \\times p}\\), or if for example \\(\\mathcal{X}\\) is the set of Reals, it may be written as “\\(\\mathbf{X}\\) is a \\(n \\times p\\) Real-valued matrix”, analogously for integer-valued matrices etc. By default, a ‘vector’ will refer to a column vector, which may be thought of as a matrix with \\(n\\) rows and one column, and may be represented as:\n\\[\n\\mathbf{x}= \\begin{pmatrix}\n        x_1 \\\\\n        x_2 \\\\\n        \\vdots \\\\\n        x_n\n      \\end{pmatrix}\n\\]\nVectors are usually defined using transpose notation, for example the vector above may instead be written as \\(\\mathbf{x}^\\top= (x_1 \\ x_2 \\cdots x_n)\\) or \\(\\mathbf{x}= (x_1 \\ x_2 \\cdots x_n)^\\top\\). Vectors may also be defined in a shortened format as \\(\\mathbf{x}\\in \\mathcal{X}^{n \\times 1}\\) or more simply \\(\\mathbf{x}\\in \\mathcal{X}^n\\), which implies a column vector of length \\(n\\) with elements as represented above.\nA letter in normal font with one subscript refers to a single element from a vector. For example, given \\(\\mathbf{x}\\in \\mathcal{X}^n\\), the \\(i\\)th element is denoted \\(x_i\\). Given a matrix \\(\\mathbf{X}\\in \\mathcal{X}^{n \\times p}\\), a bold-face lower-case letter with a single subscript refers to the row of a matrix, for example the \\(i\\)th row would be \\(\\mathbf{x}_i = (x_{i;1} \\ x_{i;2} \\cdots x_{i;p})^\\top\\). Whereas a column is referenced with a semi-colon before the subscript, for example the \\(j\\)th column would be \\(\\mathbf{x}_{;j} = (x_{1;j} \\ x_{2;j} \\cdots x_{n;j})^\\top\\). Two subscripts can be used to reference a single element of a matrix, for example \\(x_{i;j} \\in \\mathcal{X}\\) would be the element in the \\(i\\)th row and \\(j\\)th column of \\(\\mathbf{X}\\).",
    "crumbs": [
      "Symbols and Notation"
    ]
  },
  {
    "objectID": "P0C0_notation.html#functions",
    "href": "P0C0_notation.html#functions",
    "title": "Symbols and Notation",
    "section": "Functions",
    "text": "Functions\nTypically, a ‘hat’, \\(\\hat{x}\\), will refer to the prediction or estimation of a variable, \\(x\\), with bold-face used again to represent vectors. A ‘bar’, \\(\\bar{x}\\), refers to the sample mean of \\(\\mathbf{x}\\). Capital letters in normal font, \\(X\\), refer to scalar or vector random variables, which will be made clear from context. \\(\\mathbb{E}(X)\\) is the expectation of the random variable \\(X\\). We write \\(A \\perp \\!\\!\\! \\perp B\\), to denote that \\(A\\) and \\(B\\) are independent, i.e., that \\(P(A \\cap B) = P(A)P(B)\\).\nA function \\(f\\), will either be written as a formal map of domain to codomain, \\(f: \\mathcal{X}\\rightarrow \\mathcal{Y}; (x, y) \\mapsto f(x, y)\\) (which is most useful for understanding inputs and outputs), or more simply and commonly as \\(f(x, y)\\). Given a random variable, \\(X\\), following distribution \\(\\zeta\\) (mathematically written \\(X \\sim \\zeta\\)), then \\(f_X\\) denotes the probability density function, and analogously for other distribution defining functions such as the cumulative distribution function, survival function, etc. In the survival analysis context (4  Survival Analysis), a subscript “\\(0\\)” refers to a “baseline” function, for example, \\(S_0\\) is the baseline survival function.\nFinally, \\(\\exp\\), refers to the exponential function, \\(f(x) = e^x\\), and \\(\\log\\) refers to the natural logarithm \\(\\ln(x) = \\log_e(x)\\).",
    "crumbs": [
      "Symbols and Notation"
    ]
  },
  {
    "objectID": "P0C0_notation.html#variables-and-acronyms",
    "href": "P0C0_notation.html#variables-and-acronyms",
    "title": "Symbols and Notation",
    "section": "Variables and acronyms",
    "text": "Variables and acronyms\nCommon variables and acronyms used in the book are given in Table 1 and Table 2 respectively.\n\n\n\nTable 1: Common variables used throughout the book.\n\n\n\n\n\n\n\n\n\nVariable\nDefinition\n\n\n\n\n\\(\\mathbb{R}, \\mathbb{R}_{&gt;0}, \\mathbb{R}_{\\geq 0}, \\bar{\\mathbb{R}}\\)\nSet of Reals, positive Reals (excl. zero), non-negative Reals (incl. zero), and Reals including \\(\\pm\\infty\\).\n\n\n\\(\\mathbb{N}_{&gt; 0}\\)\nSet of Naturals excluding zero.\n\n\n\\((\\mathbf{X}, \\mathbf{t}, \\boldsymbol{\\delta})\\)\nSurvival data where \\(\\mathbf{X}\\in \\mathbb{R}^{n \\times p}\\) is a real-valued matrix of \\(n\\) observations (rows) and \\(p\\) features (columns), \\(\\mathbf{t}\\in \\mathbb{R}^n\\) is a vector of observed outcome times, and \\(\\boldsymbol{\\delta}\\in \\mathbb{R}^n\\) is a vector of observed outcome indicators.\n\n\n\\(\\boldsymbol{\\beta}\\)\nVector of model coefficients/weights, \\(\\boldsymbol{\\beta}\\in \\mathbb{R}^p\\).\n\n\n\\(\\boldsymbol{\\eta}\\)\nVector of linear predictors, \\(\\boldsymbol{\\eta} = ({\\eta}_1 \\ {\\eta}_2 \\cdots {\\eta}_{n})^\\top\\), where \\(\\boldsymbol{\\eta}= \\mathbf{X}\\boldsymbol{\\beta}\\) and \\(\\eta_i = \\mathbf{x}_{i}^\\top\\boldsymbol{\\beta}\\).\n\n\n\\(\\mathcal{D}, \\mathcal{D}_{train}, \\mathcal{D}_{test}\\)\nDataset, training data, and testing data.\n\n\n\n\n\n\n\n\n\nTable 2: Common acronyms used throughout the book.\n\n\n\n\n\nAcronym\nDefinition\n\n\n\n\nAFT\nAccelerated Failure Time\n\n\ncdf\nCumulative Distribution Function\n\n\nchf\nCumulative Hazard Function\n\n\nCPH\nCox Proportional Hazards\n\n\nGBM\nGradient Boosting Machine\n\n\nGLM\nGeneralised Linear Model\n\n\nIPC(W)\nInverse Probability of Censoring (Weighted)\n\n\nML\nMachine Learning\n\n\npdf\nProbability Density Function\n\n\nPH\nProportional Hazards\n\n\n(S)SVM\n(Survival) Support Vector Machine\n\n\nt.v.i.\nTaking Values In",
    "crumbs": [
      "Symbols and Notation"
    ]
  },
  {
    "objectID": "P0C1_intro.html",
    "href": "P0C1_intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Why is this book needed?\nTODO\nWriting after a global pandemic, applications of survival analysis are more relevant than ever. Predicting the time from onset of COVID-19 symptoms to hospitalisation, or the time from hospitalisation to intubation, or intubation to death, are all time-to-event predictions that are at the centre of survival analysis. As well as morbid applications, survival analysis predictions may be concerned with predicting the time until a customer cancels their gym membership, or the lifetime of a lightbulb; any event that is guaranteed (or at least very likely) to occur can be modelled by a survival analysis prediction. As these predictions can be so sensitive, for example a model predicting when a child should be taken off breathing support (Data Study Group Team 2020), the best possible predictions, evaluated to the highest standard, are a necessity. In other fields of predictive modelling, machine learning has made incredible breakthroughs (such as AlphaFold), therefore applying machine learning to survival analysis is a natural step in the evolution of an important field.\nSurvival analysis is the field of Statistics focusing on modelling the distribution of an event, which may mean the time until the event takes place, the risk of the event happening, the probability of the event occurring at a single time, or the event’s underlying probability distribution. Survival analysis (‘survival’) is a unique field of study in Statistics as it includes the added difficulty of ‘censoring’. Censoring is best described through example: a study is conducted to determine the mortality rate of a group of patients after diagnoses with a particular disease. If a patient dies during this study then their outcome is ‘death’ and their time of death can be recorded. However if a patient drops-out of the study before they die, then their time of death (though guaranteed to occur) is unknown and the only available information is the time at which they left the study. This patient is now said to be censored at the time they drop out. The censoring mechanism allows as much outcome information (time and event) to be captured as possible for all patients (observations).\nMachine learning (ML) is the field of Statistics primarily concerned with building models to either predict outputs from inputs or to learn relationships from data (Hastie, Tibshirani, and Friedman 2001; James et al. 2013). This book is limited to the former case, or more specifically supervised learning, as this is the field in which the vast majority of survival problems live. Relative to other areas of supervised learning, development in survival analysis has been slow – the majority of developments in machine learning for survival analysis have only been in the past decade (see chapters (?sec-review)-(Chapter 7)). This appears to have resulted in less interest in the development of machine learning survival models (?sec-review), less rigour in the evaluation of such models (Chapter 7), and fewer off-shelf/open-source implementations (Sonabend et al. 2021). This book seeks to set the foundations for clear workflows, good practice, and precise results for ‘machine learning survival analysis’.\nFirstly, whilst there are many books dedicated to regression and classification as machine learning problems (the ‘bibles’ of machine learning focus entirely on regression and classification only (Bishop 2006; Hastie, Tibshirani, and Friedman 2001; James et al. 2013)), there is a deficit of books covering the survival analysis setting. By writing this book we hope to fill this gap and enable more practitioners to use cutting-edge methods in survival analysis. Survival analysis has important applications in healthcare, finance, engineering and more, all fields that directly impact upon individual lives on a day-to-day basis, and should perhaps be considered as important as classification and regression. The result of this gap in interest, is the erroneous assumption that one field can be directly applied to another. For example there is evidence of researchers treating censoring as a nuisance to be ignored and using regression models instead (Schwarzer, Vach, and Schumacher 2000). Censoring is indeed a challenge and may contribute to making survival analysis less accessible than other fields, but this need not be the case; a clear unification of terminology and presentation of methods may help make ‘machine learning survival analysis’ more accessible. Added accessibility could lead to more academics (and non-academics) engaging with the field and promoting good standards of practice, as well as developing more novel models and measures.\nWhere survival models have been developed, these have skewed towards ‘ranking models’, which predict the relative risk of an event occurring (?sec-surv-set-types). In many applications these predictions are sufficient, for example in randomised control trials if assessing the increased/decreased risk of an event after treatment. However, there are many use-cases where predicting an individual’s survival probability distribution is required. Take, for example, an engineer calculating the lifetime of a plane’s engine.1 There are three important reasons to replace a jet engine at the optimal time:\nNow consider examples for the three possible ‘prediction types’ the engineer can make:\nThe first prediction type is not useful as the underlying relative risk may be unknown and the engineer is concerned with the individual lifetime. The second prediction type provides a useful quantity for the engineer to work with however there is no uncertainty captured in this prediction. The third prediction type can capture the uncertainty of failure over the entirety of the positive Reals (though usually only a small subset is possible and useful). With this final prediction type, the engineer can create safe decisions: ‘replace the engine at time \\(\\tau\\), where \\(\\tau\\) is the time when the predicted probability of survival drops below 60%, \\(S(\\tau) = 0.6\\)’. There are ethical, economic, and environmental reasons for a good survival distribution prediction and this book considers a distribution prediction to be the most important prediction type.\nEvaluating predictions from survival models is of the utmost importance. This is especially important as survival models are often deployed in the public domain, particularly in healthcare. Physical products in healthcare, such as new vaccines, undergo rigorous testing and research in randomised control trials before being publically deployed; the same level of rigour should be expected for the evaluation of survival models that are used in life-and-death situations. Evaluation measures for regression and classification are well-understood with important properties, however survival measures have not undergone the same treatment. For example many survival models are still being evaluated solely with concordance indices that have been repeatedly criticised (Gönen and Heller 2005; Rahman et al. 2017; Schmid and Potapov 2012).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "P0C1_intro.html#sec-intro-motobj",
    "href": "P0C1_intro.html#sec-intro-motobj",
    "title": "1  Introduction",
    "section": "",
    "text": "1 In this engineering context, survival analysis is usually referred to as reliability analysis.\nfinancial: jet engines are very expensive and replacing one sooner than required is a waste of money;\nenvironmental: an engine being replaced too early is a waste of potential usage;\nsafety: if the engine is replaced too late then there is a risk to passengers.\n\n\n\nA ‘relative risk prediction’: This engine is twice as likely to fail as another.\nA ‘survival time prediction’: The engine is expected to fail in 30 days.\nA ‘survival distribution prediction’: The lifetime of the engine is distributed according to the probability distribution \\(\\zeta\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "P0C1_intro.html#reproducibility",
    "href": "P0C1_intro.html#reproducibility",
    "title": "1  Introduction",
    "section": "1.2 Reproducibility",
    "text": "1.2 Reproducibility\nThis book includes simulations and figures generated in \\(\\textsf{R}\\), the code for any figures or experiments in this book are freely available at https://github.com/mlsa-book/MLSA under an MIT licence and all content on this website is available under CC BY 4.0.\n\n\n\n\n\n\nFurther reading\n\n\n\n\n(Wang, Li, and Reddy 2019) provides a light-touch but comprehensive survey of machine learning models for survival analysis.\n\n\n\n\n\n\n\nBishop, Christopher M. 2006. Pattern recognition and machine learning. springer.\n\n\nData Study Group Team. 2020. “Data Study Group Final Report: Great Ormond Street Hospital.” https://doi.org/10.5281/zenodo.3670726.\n\n\nGönen, Mithat, and Glenn Heller. 2005. “Concordance Probability and Discriminatory Power in Proportional Hazards Regression.” Biometrika 92 (4): 965–70.\n\n\nHastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2001. The Elements of Statistical Learning. Springer New York Inc.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. An introduction to statistical learning. Vol. 112. New York: Springer.\n\n\nRahman, M. Shafiqur, Gareth Ambler, Babak Choodari-Oskooei, and Rumana Z. Omar. 2017. “Review and evaluation of performance measures for survival prediction models in external validation settings.” BMC Medical Research Methodology 17 (1): 1–15. https://doi.org/10.1186/s12874-017-0336-2.\n\n\nSchmid, Matthias, and Sergej Potapov. 2012. “A comparison of estimators to evaluate the discriminatory power of time-to-event models.” Statistics in Medicine 31 (23): 2588–2609. https://doi.org/10.1002/sim.5464.\n\n\nSchwarzer, Guido, Werner Vach, and Martin Schumacher. 2000. “On the misuses of artificial neural networks for prognostic and diagnostic classification in oncology.” Statistics in Medicine 19 (4): 541–61. https://doi.org/10.1002/(SICI)1097-0258(20000229)19:4&lt;541::AID-SIM355&gt;3.0.CO;2-V.\n\n\nSonabend, Raphael, Franz J Király, Andreas Bender, Bernd Bischl, and Michel Lang. 2021. “mlr3proba: an R package for machine learning in survival analysis.” Edited by Jonathan Wren. Bioinformatics 37 (17): 2789–91. https://doi.org/10.1093/bioinformatics/btab039.\n\n\nWang, Ping, Yan Li, and Chandan K. Reddy. 2019. “Machine Learning for Survival Analysis.” ACM Computing Surveys 51 (6): 1–36. https://doi.org/10.1145/3214306.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "P1C2_preview.html",
    "href": "P1C2_preview.html",
    "title": "2  MLSA From Start to Finish",
    "section": "",
    "text": "Page coming soon!\n\n\n\nWe are working on this page and it will be available soon!",
    "crumbs": [
      "Survival Analysis and Machine Learning",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>MLSA From Start to Finish</span>"
    ]
  },
  {
    "objectID": "P1C3_machinelearning.html",
    "href": "P1C3_machinelearning.html",
    "title": "3  Machine Learning",
    "section": "",
    "text": "3.1 Basic workflow\nThis chapter covers core concepts in machine learning. This is not intended as a comprehensive introduction and does not cover mathematical theory nor how to run machine learning models using software. Instead, the focus is on introducing important concepts and to provide basic intuition for a general machine learning workflow. This includes the concept of a machine learning task, data splitting (resampling), model training and prediction, evaluation, and model comparison. Recommendations for more comprehensive introductions are given at the end of this chapter, including books that cover practical implementation in different programming languages.\nThis book focuses on supervised learning, in which predictions are made for outcomes based on data with observed dependent and independent variables. For example, predicting someone’s height is a supervised learning problem as data can be collected for features (independent variables) such as age and sex, and an observable outcome (dependent variable), which is height. Alternatives to supervised learning include unsupervised learning, semi-supervised learning, and reinforcement learning. This book is primarily concerned with predictive survival analysis, i.e., making future predictions based on (partially) observed survival outcomes, which falls naturally within the supervised learning domain.\nThe basic machine learning workflow is represented in Figure 3.1. Data is split into training and test datasets. A learner is selected and is trained on the training data, inducing a fitted model. The features from the test data are passed to the model which makes predictions for the unseen outcomes (Box 1). The outcomes from the test data are passed to a chosen measure with the predictions, which evaluates the performance of the model (Box 2). The process of repeating this procedure to test different training and test data is called resampling and running multiple resampling experiments with different models is called benchmarking. All these concepts will be explained in this chapter.",
    "crumbs": [
      "Survival Analysis and Machine Learning",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Machine Learning</span>"
    ]
  },
  {
    "objectID": "P1C3_machinelearning.html#sec-ml-basics",
    "href": "P1C3_machinelearning.html#sec-ml-basics",
    "title": "3  Machine Learning",
    "section": "",
    "text": "Figure 3.1: Basic machine learning workflow with data splitting, model training, predicting, and evaluating. Image from Foss and Kotthoff (2024) (CC BY-NC-SA 4.0).",
    "crumbs": [
      "Survival Analysis and Machine Learning",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Machine Learning</span>"
    ]
  },
  {
    "objectID": "P1C3_machinelearning.html#sec-ml-tasks",
    "href": "P1C3_machinelearning.html#sec-ml-tasks",
    "title": "3  Machine Learning",
    "section": "3.2 Tasks",
    "text": "3.2 Tasks\nA machine learning task is the specification of the mathematical problem that is to be solved by a given algorithm. For example, “predict the height of a male, 13 year old child”, is a machine learning task. Tasks are derived from datasets and one dataset can give rise to many tasks across any machine learning domain. The dataset described by columns: ‘age’, ‘weight’, ‘height’, ‘sex’, ‘diagnosis’, ‘time of death’, ‘clinician notes’, could give rise to any of the following tasks (and more):\n\nPredict age from weight, height, and sex - supervised regression task\nPredict sex from age and diagnosis - supervised classification task\nPredict time of death from all other features - supervised survival task\nCategorise observations into clusters - unsupervised clustering\nLearn to speak like a clinician depending on client diagnosis - natural language processing, likely with reinforcement learning\n\nAs this book is focused on supervised learning, only the first three of these is covered in this chapter and beyond. The specification of a task is vital for interpreting predictions from a model and its subsequent performance. This is particularly true when separating between determinisitc and probabilistic predictions, as discussed later in the chapter.\nFormally, let \\(\\mathbf{x}\\in \\mathcal{X}\\subseteq \\mathbb{R}^{n \\times p}\\) be a matrix with \\(p\\) features for \\(n\\) observations and let \\(y \\in \\mathcal{Y}\\) be a vector of labels (or outcomes or targets) for all observations. A dataset is then given by \\(\\mathcal{D}= ((\\mathbf{x}_1, y_1) , . . . , (\\mathbf{x}_n, y_n))\\) where it is assumed \\(\\mathcal{D}\\stackrel{i.i.d.}\\sim(\\mathbb{P}_{xy})^n\\) for some unknown distribution \\(\\mathbb{P}\\).\nA machine learning task is the problem of learning the unknown function \\(f : \\mathcal{X}\\rightarrow \\mathcal{Y}\\) where \\(\\mathcal{Y}\\) specifies the nature of the task, for example classification, regression, or survival.\n\n3.2.1 Regression\nRegression tasks make continuous predictions, for example someone’s height. Regression may be deterministic, in which case a single continuous value is predicted, or probabilistic, where a probability distribution over the Reals is predicted. For example, predicting an individual’s height as 165cm would be a deterministic regression prediction, whereas predicting their height follows a \\(\\mathcal{N}(165, 2)\\) distribution would be probabilistic.\nFormally, a deterministic regression task is specified by \\(f_{Rd} : \\mathcal{X}\\rightarrow \\mathcal{Y}\\subseteq \\mathbb{R}^n\\), and a probabilistic regression task by \\(f_{Rp} : \\mathcal{X}\\rightarrow \\mathcal{S}\\) where \\(\\mathcal{S}\\subset \\operatorname{Distr}(\\mathcal{Y})\\) and \\(\\operatorname{Distr}(\\mathcal{Y})\\) is the space of distributions over \\(\\mathcal{Y}\\).\nIn machine learning, deterministic regression is much more common than probabilistic and hence the shorthand ‘regression’ is used to refer to deterministic regression (in contrast to statistical modeling, where regression usually implies probabilistic regression).\n\n\n3.2.2 Classification\nClassification tasks make discrete predictions, for example whether it will rain, snow, or be sunny tomorrow. Similarly to regression, predictions may be deterministic or probabilistic. Deterministic classification predicts which category an observation falls into, whereas probabilistic classification predicts the probability of an observation falling into each category. Predicting it will rain tomorrow is a deterministic prediction whereas predicting \\(\\hat{p}(rain) = 0.6; \\hat{p}(snow) = 0.1; \\hat{p}(sunny) = 0.3\\) is probabilistic.\nFormally, a deterministic classification task is given by \\(f_{Cd} : \\mathcal{X}\\rightarrow \\mathcal{Y}\\subseteq \\mathbb{N}_0\\), and a probabilistic classification task as \\(f_{Cp} : \\mathcal{X}\\rightarrow \\mathcal{Y}\\subseteq [0,1]^k\\) where \\(k\\) is the number of categories an observation may fall into. Practically this latter prediction is estimation of the probability mass function \\(\\hat{p}_Y(y) = P(Y = y)\\). If only two categories are possible, these reduce to the binary classification tasks: \\(f_{Bd}: \\mathcal{X}\\rightarrow \\{0, 1\\}\\) and \\(f_{Bp}: \\mathcal{X}\\rightarrow [0, 1]\\) for deterministic and probabilistic binary classification respectively.\nNote that in the probabilistic binary case it is common to write the task as predicting \\([0,1]\\) not \\([0,1]^2\\) as the classes are mutually exclusive. The class for which probabilities are predicted is referred to as the positive class, and the other as the negative class.",
    "crumbs": [
      "Survival Analysis and Machine Learning",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Machine Learning</span>"
    ]
  },
  {
    "objectID": "P1C3_machinelearning.html#sec-ml-models",
    "href": "P1C3_machinelearning.html#sec-ml-models",
    "title": "3  Machine Learning",
    "section": "3.3 Training and predicting",
    "text": "3.3 Training and predicting\nThe terms algorithm, learner, and model are often conflated in machine learning. A learner is a description of a learning algorithm, prediction algorithm, parameters, and hyperparameters. The learning algorithm is a mathematical strategy to estimate the unknown mapping from features to outcome as represented by a task, \\(f: \\mathcal{X}\\rightarrow \\mathcal{Y}\\). During training, data, \\(\\mathcal{D}\\), is fed into the learning algorithm and induces the model \\(\\hat{f}\\). Whereas the learner defines the framework for training and prediction, the model is the specific instantiation of this framework after training on data.\nAfter training the model, new data, \\(\\mathbf{x}^*\\), can be fed to the prediction algorithm, which is a mathematical strategy that uses the model to make predictions \\(\\hat{\\mathbf{y}}= \\hat{f}(\\mathbf{x}^*)\\). Algorithms can vary from simple linear equations with coefficients to estimate, to complex iterative procedures that differ considerably between training and predicting.\nAlgorithms usually involve parameters and hyperparameters. Parameters are learned from data whereas hyperparameters are set beforehand to guide the algorithms. Model parameters (or weights), \\(\\boldsymbol{\\theta}\\), are coefficients to be estimated during model training. Hyperparameters, \\(\\boldsymbol{\\lambda}\\), control how the algorithms are run but are not directly updated by them. Hyperparameters can be mathematical, for example the learning rate in a gradient boosting machine (Chapter 16), or structural, for example the depth of a decision tree (Chapter 14). The number of hyperparameters usually increases with learner complexity and affects its predictive performance. Often hyperparameters need to be tuned (Section 3.5) instead of manually set. Computationally, storing \\((\\hat{\\boldsymbol{\\theta}}, \\boldsymbol{\\lambda})\\) is sufficient to recreate any trained model.\n\n\n\n\n\n\nBox 1 (Ridge regression)\n\n\n\nLet \\(f : \\mathcal{X}\\rightarrow \\mathcal{Y}\\) be the regression task of interest with \\(\\mathcal{X}\\subseteq \\mathbb{R}\\) and \\(\\mathcal{Y}\\subseteq \\mathbb{R}\\). Let \\((\\mathbf{x}, \\mathbf{y}) = ((x_1, y_1), \\ldots, (x_n, y_n))\\) be data such that \\(x_i \\in \\mathcal{X}\\) and \\(y_i \\in \\mathcal{Y}\\) for all \\(i = 1,...,n\\).\nSay the learner of interest is a regularized linear regression model with learning algorithm:\n\\[\n(\\hat{\\beta}_0,\\hat{\\beta}_1):=\\mathop{\\mathrm{arg\\,min}}_{\\beta_0,\\beta_1}\\Bigg\\{\\sum_{i=1}^n\\big(y_i-(\\beta_0 +\\beta_1 x_i)\\big)^2+\\gamma\\beta_1^2\\Bigg\\}.\n\\]\nand prediction algorithm:\n\\[\n\\hat{f}(\\phi) = \\hat{\\beta}_0 + \\hat{\\beta}_1\\phi\n\\]\nThe hyperparameters are \\(\\lambda = (\\gamma \\in \\mathbb{R}_{&gt;0})\\) and the parameters are \\(\\boldsymbol{\\theta}= (\\beta_0, \\beta_1)^\\top\\). Say that \\(\\gamma = 2\\) is set and the learner is then trained by passing \\((\\mathbf{x}, \\mathbf{y})\\) to the learning algorithm and thus estimating \\(\\hat{\\boldsymbol{\\theta}}\\) and \\(\\hat{f}\\). A prediction, can then be made by passing new data \\(x^* \\in \\mathcal{X}\\) to the fitted model: \\(\\hat{y}:= \\hat{f}(x^*) = \\hat{\\beta}_0 + \\hat{\\beta}_1x^*\\).",
    "crumbs": [
      "Survival Analysis and Machine Learning",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Machine Learning</span>"
    ]
  },
  {
    "objectID": "P1C3_machinelearning.html#sec-ml-eval",
    "href": "P1C3_machinelearning.html#sec-ml-eval",
    "title": "3  Machine Learning",
    "section": "3.4 Evaluating and benchmarking",
    "text": "3.4 Evaluating and benchmarking\nTo understand if a model is ‘good’, its predictions are evaluated with a loss function. Loss functions assign a score to the discrepancy between predictions and true values, \\(L: \\mathcal{Y}\\times \\mathcal{Y}\\rightarrow \\bar{\\mathbb{R}}\\). Given (unseen) real-world data, \\((\\mathbf{X}^*, \\mathbf{y}^*)\\), and a trained model, \\(\\hat{f}\\), the loss is given by \\(L(\\hat{f}(\\mathbf{X}^*), \\mathbf{y}^*) = L(\\hat{\\mathbf{y}}, \\mathbf{y}^*)\\). For a model to be useful, it should perform well in general, meaning its generalization error should be low. The generalization error refers to the model’s performance on new data, rather than just the data encountered during training and development.\nA model should only be used to make predictions if its generalization error was estimated to be acceptable for a given context. If a model were to be trained and evaluated on the same data, the resulting loss, known as the training error, would be an overoptimistic estimate of the true generalization error (James et al. 2013). This occurs as the model is making predictions for data it has already ‘seen’ and the loss is therefore not evaluating the model’s ability to generalize to new, unseen data. Estimation of the generalization error requires data splitting, which is the process of splitting available data, \\(\\mathcal{D}\\), into training data, \\(\\mathcal{D}_{train}\\subset \\mathcal{D}\\), and testing data, \\(\\mathcal{D}_{test}= \\mathcal{D}\\setminus \\mathcal{D}_{train}\\).\nThe simplest method to estimate the generalization error is to use holdout resampling, which is the process of partitioning the data into one training dataset and one testing dataset, with the model trained on the former and predictions made for the latter. Using 2/3 of the data for training and 1/3 for testing is a common splitting ratio (Kohavi 1995). For independent and identically distributed (iid) data, it is generally best practice to partition the data randomly. This ensures that any potential patterns or information encoded in the ordering of the data are removed, as such patterns are unlikely to generalize to new, unseen data. For example, in clinical datasets, the order in which patients enter a study might inadvertently encode latent information such as which doctor was on duty at the time, which could theoretically influence patient outcomes. As this information is not explicitly captured in measured features, it is unlikely to hold predictive value for future patients. Random splitting breaks any spurious associations between the order of data and the outcomes.\nWhen data is not iid, for example spatially correlated or time-series data, then random splitting may not be advisable, see Hornung et al. (2023) for an overview of evaluation strategies in non-standard settings.\nHoldout resampling is a quick method to estimate the generalization error, and is particular useful when very large datasets are available. However, hold-out resampling has a very high variance for small datasets and there is no guarantee that evaluating the model on one hold-out split is indicative of real-world performance.\n\\(k\\)-fold cross-validation (CV) can be used as a more robust method to better estimate the generalization error (Hastie, Tibshirani, and Friedman 2001). \\(k\\)-fold CV partitions the data into \\(k\\) subsets, called folds. The training data comprises of \\(k-1\\) of the folds and the remaining one is used for testing and evaluation. This is repeated \\(k\\) times until each of the folds has been used exactly once as the testing data. The performance from each fold is averaged into a final performance estimate (Figure 3.2). It is common to use \\(k = 5\\) or \\(k = 10\\) (Breiman and Spector 1992; Kohavi 1995). This process can be repeated multiple times (repeated \\(k\\)-fold CV) and/or \\(k\\) can even be set to \\(n\\), which is known as leave-one-out cross-validation.\nCross-validation can also be stratified, which ensures that a variable of interest will have the same distribution in each fold as in the original data. This is important, and often recommended, in survival analysis to ensure that the proportion of censoring in each fold is representative of the full dataset (Casalicchio and Burk 2024; Herrmann et al. 2021).\n\n\n\n\n\n\nFigure 3.2: Three-fold cross-validation. In each iteration a different dataset is used for predictions and the other two for training. The performance from each iteration is averaged into a final, single metric. Image from Casalicchio and Burk (2024) (CC BY-NC-SA 4.0).\n\n\n\n\nRepeating resampling experiments with multiple models is referred to as a benchmark experiment. A benchmark experiment compares models by evaluating their performance on identical data, which means the same resampling strategy and folds should be used for all models. Determining if one model is actually better than another is a surprisingly complex topic (Benavoli et al. 2017; Demšar 2006; Dietterich 1998; Nadeau and Bengio 2003) and is out of scope for this book, instead any benchmark experiments performed in this book are purely for illustrative reasons and no results are expected to generalize outside of these experiments.\n\n\n\n\n\n\nBox 2 (Evaluating ridge regression)\n\n\n\nLet \\(\\mathcal{X}\\subseteq \\mathbb{R}\\) and \\(\\mathcal{Y}\\subseteq \\mathbb{R}\\) and let \\((\\mathbf{x}^*, \\mathbf{y}^*) = ((x^*_1, y^*_1), \\ldots, (x^*_m, y^*_m))\\) be data previously unseen by the model trained in Box 1 where \\(x_i \\in \\mathcal{X}\\) and \\(y_i \\in \\mathcal{Y}\\) for all \\(i = 1,...,m\\).\nPredictions are made by passing \\(\\mathbf{x}^*\\) to the fitted model yielding \\(\\hat{\\mathbf{y}}= (\\hat{y}_1, \\ldots \\hat{y}_m)\\) where \\(\\hat{y}_i := \\hat{f}(x_i^*) = \\hat{\\beta}_0 + \\hat{\\beta}_1x_i^*\\).\nSay the mean absolute error is used to evaluate the model, defined by\n\\[\nL(\\boldsymbol{\\phi}, \\boldsymbol{\\varphi}) = \\frac{1}{n} \\sum^n_{i=1} |\\phi_i - \\varphi_i|\n\\]\nwhere \\((\\boldsymbol{\\phi}, \\boldsymbol{\\varphi}) = ((\\phi_1, \\varphi_1),\\ldots,(\\phi_n, \\varphi_n))\\).\nThe model’s predictive performance is then calculated as \\(L(\\hat{\\mathbf{y}}, \\mathbf{y}^*)\\).",
    "crumbs": [
      "Survival Analysis and Machine Learning",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Machine Learning</span>"
    ]
  },
  {
    "objectID": "P1C3_machinelearning.html#sec-ml-opt",
    "href": "P1C3_machinelearning.html#sec-ml-opt",
    "title": "3  Machine Learning",
    "section": "3.5 Hyperparameter Optimization",
    "text": "3.5 Hyperparameter Optimization\nSection 3.3 introduced model hyperparameters, which control how training and prediction algorithms are run. Setting hyperparameters is a critical part of model fitting and can significantly change model performance. Tuning is the process of using internal benchmark experiments to automatically select the optimal hyper-parameter configuration. For example, the depth of trees, \\(m_r\\) in a random forest (Chapter 14) is a potential hyperparameter to tune. This hyperparameter may be tuned over a range of values, say \\([1, 15]\\) or over a discrete subset, say \\(\\{1, 5, 15\\}\\), for now assume the latter. Three random forests with \\(1\\), \\(5\\), and \\(15\\) tree depth respectively are compared in a benchmark experiment. The depth that results in the model with the optimal performance is then selected for the hyperparameter value going forward. Nested resampling is a common method to reduce bias that could occur from using overlapping data for tuning, training, or testing (Simon 2007). Nested resampling is the process of resampling the training set again for tuning and then the optimal model is refit on the entire training data (Figure 3.3).\n\n\n\n\n\n\nFigure 3.3: An illustration of nested resampling. The large blocks represent three-fold CV for the outer resampling for model evaluation and the small blocks represent four-fold CV for the inner resampling for hyperparameter optimization. The light blue blocks are the training sets and the dark blue blocks are the test sets. Image and caption from Becker, Schneider, and Fischer (2024) (CC BY-NC-SA 4.0).",
    "crumbs": [
      "Survival Analysis and Machine Learning",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Machine Learning</span>"
    ]
  },
  {
    "objectID": "P1C3_machinelearning.html#conclusion",
    "href": "P1C3_machinelearning.html#conclusion",
    "title": "3  Machine Learning",
    "section": "3.6 Conclusion",
    "text": "3.6 Conclusion\n\n\n\n\n\n\nKey takeaways\n\n\n\n\nMachine learning tasks define the predictive problem of interest;\nRegression tasks make predictions for continuous outcomes, such as the amount of rain tomorrow;\nClassification tasks make predictions for discrete outcomes, such as the predicted weather tomorrow;\nBoth regression and classification tasks may make determiistic predictions (a single number or category), or probabilistic predictions (the probability of a number or category);\nModels have parameters that are fit during training and hyperparameters that are set or tuned;\nModels should be evaluated on resampled data to estimate the generalization error to understand future performance.\n\n\n\n\n\n\n\n\n\nFurther reading\n\n\n\n\nThe Elements of Statistical Learning (Hastie, Tibshirani, and Friedman 2001), An Introduction to Statistical Learning (James et al. 2013), and Pattern Recognition and Machine Learning (Bishop 2006) for comprehensive introductions and overviews to machine learning.\nApplied Machine Learning Using mlr3 in R (Bischl et al. 2024) and Tidy Modeling (Kuhn and Silge 2023) for machine learning in \\(\\textsf{R}\\)\nHands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow (Géron 2019) for machine learning in Python.\nBischl et al. (2012) for discussions about more resampling strategies including bootstrapping and subsampling.\n\n\n\n\n\n\n\nBecker, Marc, Lennart Schneider, and Sebastian Fischer. 2024. “Hyperparameter Optimization.” In Applied Machine Learning Using mlr3 in R, edited by Bernd Bischl, Raphael Sonabend, Lars Kotthoff, and Michel Lang. CRC Press. https://mlr3book.mlr-org.com/hyperparameter_optimization.html.\n\n\nBenavoli, Alessio, Giorgio Corani, Janez Demšar, and Marco Zaffalon. 2017. “Time for a Change: A Tutorial for Comparing Multiple Classifiers Through Bayesian Analysis.” Journal of Machine Learning Research 18 (77): 1–36. http://jmlr.org/papers/v18/16-305.html.\n\n\nBischl, Bernd, O. Mersmann, H. Trautmann, and C. Weihs. 2012. “Resampling Methods for Meta-Model Validation with Recommendations for Evolutionary Computation.” Evolutionary Computation 20 (2): 249–75. https://doi.org/10.1162/EVCO_a_00069.\n\n\nBischl, Bernd, Raphael Sonabend, Lars Kotthoff, and Michel Lang, eds. 2024. Applied Machine Learning Using mlr3 in R. CRC Press. https://mlr3book.mlr-org.com.\n\n\nBishop, Christopher M. 2006. Pattern recognition and machine learning. springer.\n\n\nBreiman, Leo, and Philip Spector. 1992. “Submodel Selection and Evaluation in Regression. The X-Random Case.” International Statistical Review / Revue Internationale de Statistique 60 (3): 291–319. https://doi.org/10.2307/1403680.\n\n\nCasalicchio, Giuseppe, and Lukas Burk. 2024. “Evaluation and Benchmarking.” In Applied Machine Learning Using mlr3 in R, edited by Bernd Bischl, Raphael Sonabend, Lars Kotthoff, and Michel Lang. CRC Press. https://mlr3book.mlr-org.com/chapters/chapter3/evaluation_and_benchmarking.html.\n\n\nDemšar, Janez. 2006. “Statistical comparisons of classifiers over multiple data sets.” Journal of Machine Learning Research 7 (1): 1–30.\n\n\nDietterich, Thomas G. 1998. “Approximate Statistical Tests for Comparing Supervised Classification Learning Algorithms.” Neural Computation 10 (7): 1895–1923. https://doi.org/10.1162/089976698300017197.\n\n\nFoss, Natalie, and Lars Kotthoff. 2024. “Data and Basic Modeling.” In Applied Machine Learning Using mlr3 in R, edited by Bernd Bischl, Raphael Sonabend, Lars Kotthoff, and Michel Lang. CRC Press. https://mlr3book.mlr-org.com/data_and_basic_modeling.html.\n\n\nGéron, Aurélien. 2019. Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition. O’Reilly. https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/.\n\n\nHastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2001. The Elements of Statistical Learning. Springer New York Inc.\n\n\nHerrmann, Moritz, Philipp Probst, Roman Hornung, Vindi Jurinovic, and Anne-Laure Boulesteix. 2021. “Large-scale benchmark study of survival prediction methods using multi-omics data.” Briefings in Bioinformatics 22 (3). https://doi.org/10.1093/bib/bbaa167.\n\n\nHornung, Roman, Malte Nalenz, Lennart Schneider, Andreas Bender, Ludwig Bothmann, Bernd Bischl, Thomas Augustin, and Anne-Laure Boulesteix. 2023. “Evaluating Machine Learning Models in Non-Standard Settings: An Overview and New Findings.” https://arxiv.org/abs/2310.15108.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. An introduction to statistical learning. Vol. 112. New York: Springer.\n\n\nKohavi, Ron. 1995. “A study of cross-validation and bootstrap for accuracy estimation and model selection.” Ijcai 14 (2): 1137–45.\n\n\nKuhn, Max, and Julia Silge. 2023. Tidy Modeling with R. https://www.tmwr.org/.\n\n\nNadeau, Claude, and Yoshua Bengio. 2003. “Inference for the Generalization Error.” Machine Learning 52 (3): 239–81. https://doi.org/10.1023/A:1024068626366.\n\n\nSimon, Richard. 2007. “Resampling Strategies for Model Assessment and Selection.” In Fundamentals of Data Mining in Genomics and Proteomics, edited by Werner Dubitzky, Martin Granzow, and Daniel Berrar, 173–86. Boston, MA: Springer US. https://doi.org/10.1007/978-0-387-47509-7_8.",
    "crumbs": [
      "Survival Analysis and Machine Learning",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Machine Learning</span>"
    ]
  },
  {
    "objectID": "P1C4_survival.html",
    "href": "P1C4_survival.html",
    "title": "4  Survival Analysis",
    "section": "",
    "text": "4.1 Quantifying the Distribution of Event Times\nSurvival Analysis is concerned with data where the outcome is the time until an event takes place (a ‘time-to-event’). Because the collection of such data takes place in the temporal domain (it takes time to observe a duration), the event of interest is often unobservable, for example because it did not occur by the end of the data collection period. In survival analysis terminology this is referred to as censoring.\nThis chapter defines basic terminology and mathematical definitions in survival analysis, which are used throughout this book. Building upon this chapter, Chapter 5 introduces event-history analysis, which is a generalisation to settings with multiple, potentially competing or recurrent events, including multi-state outcomes. Concluding this part of the book, Chapter 6 defines different prediction tasks in survival analysis that are used by models and measures to implement machine learning methods.\nWhile these definitions and concepts are not new to survival analysis, it is imperative they are understood to build successful models. Evaluation functions (Part II) can identify if one model is better suited than another to minimize a given objective function, however they cannot identify if the objective function itself was specified correctly, which depends on the assumptions about the data generating process. Evaluating models with the wrong objective function yields meaningless results. Hence, it is of utmost importance for machine learning practitioners to be able identify and specify the survival problem present in their data correctly to ensure models are correctly fit and evaluated.\nThis section introduces functions that can be used to fully characterise a probability distribution, particular focus is given to functions that are important in survival analysis.\nNote that we can generally distinguish between event taking place in discrete time or continuous time. For example, consider the time a politician serves in parliament. If we consider the number of election cycles they stay in parliament, it would constitute discrete time, as time can only take values, \\(1, 2, 3, \\ldots\\), that is \\(Y\\in \\mathbb{N}_{&gt;0}\\). On the other hand, the time an individual stays in hospital is usually determined as the difference between the admission date-time and discharge date-time, which would constitute a continuous time \\(Y\\in \\mathbb{R}_{\\geq 0}\\).\nIn practice the differences are often blurred as time-measurement will naturally be discretized at some level and precision beyond some resolution is often not of interest (hospital length of stay might be interesting up to days or hours, but not minutes and seconds). Also discrete-time methods are often applied to continuous time data and vice versa. It is nevertheless important to make the distinction as it informs mathematical treatment and definition of the different quantities introduced below.",
    "crumbs": [
      "Survival Analysis and Machine Learning",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Survival Analysis</span>"
    ]
  },
  {
    "objectID": "P1C4_survival.html#sec-distributions",
    "href": "P1C4_survival.html#sec-distributions",
    "title": "4  Survival Analysis",
    "section": "",
    "text": "4.1.1 Continuous Time\nFor now, assume a continuous, positive, random variable \\(Y\\) taking values in (t.v.i.) \\(\\mathbb{R}_{\\geq 0}\\). A standard representation of the distribution of \\(Y\\) is given by the probability density function (pdf), \\(f_Y: \\mathbb{R}_{\\geq 0}\\rightarrow \\mathbb{R}_{\\geq 0}\\), and cumulative distribution function (cdf), \\(F_Y: \\mathbb{R}_{\\geq 0}\\rightarrow [0,1]; (\\tau) \\mapsto P(Y \\leq \\tau)\\).\nIn survival analysis, it is most common to describe the distribution of event times \\(Y\\) via the survival function and hazard function (or hazard rate) rather than the pdf or cdf. The survival function is defined as \\[\nS_Y(\\tau) = P(Y &gt; \\tau) = \\int^\\infty_\\tau f_Y(u) \\ \\mathrm{d}u,\n\\tag{4.1}\\]\nwhich is the probability that an event has not occurred by \\(\\tau \\geq 0\\) and thus the complement of the cdf: \\(S_Y(\\tau) = 1-F_Y(\\tau)\\). By definition, \\(S_Y(0)=1\\) and \\(S(\\tau)\\rightarrow 0\\) for \\(\\tau \\rightarrow \\infty\\).\nThe hazard function is given by \\[\n\\begin{aligned}\nh_Y(\\tau) &= \\lim_{\\mathrm{d}\\tau\\searrow 0}\\frac{P(\\tau  \\leq Y &lt; \\tau + \\mathrm{d}\\tau|Y \\geq \\tau)}{\\mathrm{d}\\tau} \\\\\n          &= \\lim_{\\mathrm{d}\\tau\\searrow 0}\\frac{P(Y \\in [\\tau, \\tau + \\mathrm{d}\\tau)|Y \\geq \\tau)}{\\mathrm{d}\\tau}\\\\\n          & = \\frac{f_Y(\\tau)}{S_Y(\\tau)}\n\\end{aligned}\n\\tag{4.2}\\]\nwhere \\(\\mathrm{d}\\tau\\) denotes a time-interval. The hazard rate is often interpreted as the instantaneous risk of observing an event at \\(\\tau\\), given that the event has not been observed before \\(\\tau\\). This is not a probability and \\(h_Y\\) can be greater than one.\nThe cumulative hazard function (chf) can be derived from the hazard function by \\[\nH_Y(\\tau) = \\int^\\tau_0 h_Y(u) \\ \\mathrm{d}u,\n\\tag{4.3}\\]\nand relates to the survival function via\n\\[\nH_Y(\\tau) = \\int^\\tau_0 h_Y(u) \\ \\mathrm{d}u= \\int^\\tau_0 \\frac{f_Y(u)}{S_Y(u)} \\ \\mathrm{d}u= \\int^\\tau_0 -\\frac{S'_Y(u)}{S_Y(u)} \\ \\mathrm{d}u= -\\log(S_Y(\\tau))\n\\]\nThese last relationships are particularly important, as many methods estimate the hazard rate, which is then used to calculate the cumulative hazard and survival probability \\[\nS_Y(\\tau) = \\exp(-H_Y(\\tau)) = \\exp\\left(-\\int_0^\\tau h_Y(u)\\ \\mathrm{d}u\\right)\n\\tag{4.4}\\]\nUnless necessary to avoid confusion, subscripts are dropped from \\(S_Y, h_Y\\) etc. going forward and instead these functions are referred to as \\(S\\), \\(h\\) (and so on).\nUsual regression techniques cannot be used to estimate these quantities as \\(Y\\) is only partially observed, due to different types of censoring and truncation, which are now described.\n\n\n4.1.2 Discrete Time\nNow consider a discrete, positive random variable \\(\\tilde{Y}\\) taking value in \\(\\mathbb{N}_{&gt;0}\\) and \\(\\tau\\in \\mathbb{N}_{&gt;0}\\) some time point in discrete time.\nThe discrete-time hazard rate\n\\[\nh^d_{\\tilde{Y}}(\\tau) = P(\\tilde{Y}=\\tau|\\tilde{Y} \\geq \\tau).\n\\tag{4.5}\\]\nThus, in contrast to the continuous time hazard Equation 4.2, the discrete time hazard is an actual (conditional) probability, rather than a rate and therefore might be easier to interpret.\nThe cumulative discrete time hazard is given by\n\\[\nH^d_{\\tilde{Y}}(\\tau) = \\sum_{k=1}^{\\tau}h^d_{\\tilde{Y}}(k)\n\\tag{4.6}\\]\nWe then define the inverse probability \\[\ns^d_{\\tilde{Y}}(\\tau) := 1 - h^d_{\\tilde{Y}}(\\tau) = P(\\tilde{Y}&gt; \\tau|\\tilde{Y} \\geq \\tau).\n\\]\nIt follows that the probability to survive beyond time point \\(\\tau\\) is given by\n\n\\[\nS^d_{\\tilde{Y}} = P(\\tilde{Y} &gt; \\tau) = \\prod_{k\\leq\\tau} s^d_{\\tilde{Y}}(\\tau) = \\prod_{k\\leq\\tau}(1-h^d_{\\tilde{Y}}(\\tau)),\n\\tag{4.7}\\]  and the unconditional probability for an event at time \\(\\tau\\) is  \\[\nP(\\tilde{Y}=\\tau) = S^d_{\\tilde{Y}}(\\tau-1) h^d_{\\tilde{Y}}(\\tau).\n\\tag{4.8}\\]  When applied to continuous time \\(Y\\), the follow-up is divided in \\(J\\) disjunct intervals \\((a_0,a_{1}],\\ldots,(a_{j-1},a_j]\\ldots, (a_{J-1},a_{J}],j=1,\\ldots,J\\) such that  \\[\nY \\in (a_{j-1}, a_j]\\Leftrightarrow \\tilde{Y} = j\n\\]  Thus,  \\[\nh^d_{\\tilde{Y}}(j) = P(Y \\in (a_{j-1},a_j]|Y &gt; a_{j-1})\n\\]\n\nand  \\[\nS^d_{\\tilde{Y}}(j) = P(Y &gt; a_{j}) = S_Y(a_{j})\n\\]\n\nFor more details on discrete time-to-event analysis consider (Tutz and Schmid 2016).",
    "crumbs": [
      "Survival Analysis and Machine Learning",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Survival Analysis</span>"
    ]
  },
  {
    "objectID": "P1C4_survival.html#sec-data-rc",
    "href": "P1C4_survival.html#sec-data-rc",
    "title": "4  Survival Analysis",
    "section": "4.2 Single-event, right-censored data",
    "text": "4.2 Single-event, right-censored data\nThe complexity of Survival Analysis compared to other fields arises from the fact that the outcome of interest is often only observed partially. In particular, the time-to-event is often unknown at the end of the observation period, as the event has not occurred yet.\nLet,\n\n\\(X\\) taking values in \\(\\mathbb{R}^p\\) be the generative random variable representing the data features/covariates/independent variables.\n\\(Y\\) taking values in \\(\\mathbb{R}_{\\geq 0}\\) be the (partially unobservable) true survival time.\n\\(C\\) taking values in \\(\\mathbb{R}_{\\geq 0}\\) be the (partially unobservable) true censoring time.\n\nIn the presence of censoring \\(C\\), it is impossible to fully observe the true outcome of interest, \\(Y\\). Instead, the observable variables are defined by\n\n\\(T := \\min\\{Y,C\\}\\), the outcome time (realisations are referred to as the observed outcome time); and\n\\(\\Delta := \\mathbb{I}(Y = T) = \\mathbb{I}(Y \\leq C)\\), the event indicator (also known as the censoring or status indicator).\n\nTogether \\((T,\\Delta)\\) is referred to as the survival outcome or survival tuple and they form the dependent variables. The survival outcome provides a concise mechanism for representing the outcome time and indicating which outcome (event or censoring) took place.\nA survival dataset is a \\(n \\times p\\), eal-valued matrix defined by \\(\\mathcal{D}= ((\\mathbf{x}_1, \\ t_1, \\ \\delta_1) \\cdots (\\mathbf{x}_n,t_n,\\delta_n))^\\top\\), where \\((t_i,\\delta_i)\\) are realisations of the respective random variables \\((T_i, \\Delta_i)\\) and \\(\\mathbf{x}_i\\) is a \\(p\\)-dimensional vector, \\(\\mathbf{x}_i = (x_{i;1} \\ x_{i;2} \\cdots x_{i;p})^\\top\\) of features.\nFinally, the following quantities are used frequently throughout this book and survival analysis literature more generally. Let \\((t_i, \\delta_i) \\stackrel{i.i.d.}\\sim(T,\\Delta), i = 1,...,n\\), be observed survival outcomes. Then,\nThe set of unique outcome times is the set of time-points in which at least one observation experiences the event or is censored:\n\\[\n\\mathcal{U}_O \\subseteq \\{t_i\\}_{i \\in \\{1,...,n\\}}\n\\]\nThe set of unique event times is the set of time-points in which at least one observation experiences the event (but not censored):\n\\[\n\\mathcal{U}_D \\subseteq \\{t_i: \\delta_i = 1\\}_{i \\in \\{1,...,n\\}}\n\\]\nThe ordered, unique events times may also be denoted by\n\\[\nt_{(k)},\\ k=1,\\ldots,m \\quad t_{(1)} &lt; t_{(2)} &lt; \\cdots &lt; t_{(m)}, \\quad m \\leq n\n\\]\nThe risk set at \\(\\tau\\), is the index-set of observation units at risk for the event just before \\(\\tau\\)\n\\[\n\\mathcal{R}_\\tau := \\{i: t_i \\geq \\tau\\}\n\\]\nwhere \\(i\\) is the index of an observation in the data. For right-censored data, \\(\\mathcal{R}_0 = \\{1,\\ldots,n\\}\\) and \\(\\mathcal{R}_{\\tau} \\subseteq \\mathcal{R}_{\\tau'}, \\forall \\tau &gt; \\tau'\\). Note that in a continuous setting, ‘just before’ refers to an infinitesimally smaller time than \\(\\tau\\), in practice as this is unobservable the risk set is defined at \\(\\tau\\), hence an observation may both be at risk, and experience an event (or be censored) at \\(\\tau\\).\nThe number of observations at risk at \\(\\tau\\) is the cardinality of the risk set at \\(\\tau\\),\n\\[\nn_\\tau := \\sum_i \\mathbb{I}(t_i \\geq \\tau) = |\\mathcal{R}_\\tau|\n\\]\nFinally, the number of events at \\(\\tau\\) is defined by,\n\\[\nd_\\tau := \\sum_i \\mathbb{I}(t_i = \\tau, \\delta_i = 1)\n\\]\nFor truly continuous variables, one might expect only one event to occur at each observed event time: \\(d_{t_i} = 1,\\forall i\\). In practice, ties are often observed due to finite measurement precision, such that \\(d_{\\tau} &gt; 1\\) occurs frequently in real-world datasets.\nThe quantities \\(\\mathcal{R}_\\tau\\), \\(n_\\tau\\), and \\(d_\\tau\\) underlie many models and measures in survival analysis. Several non-parametric and semi-parametric methods (Chapter 13) like the Kaplan-Meier estimator (see Section 4.3) are based on the ratio \\(d_\\tau / n_\\tau\\).\nTable 4.1 exemplifies an observed survival dataset, a subset of the tumor data (Bender and Scheipl 2018), which contains the time until death in days after operation (\\(\\delta_i=1\\) if death occurred at the outcome time \\(t_i\\) and \\(\\delta_i = 0\\) otherwise).\nIn this example, the above quantities would be:\n\n\\(\\mathcal{U}_0 = \\{268, 397, 519, 1217, 2414\\}\\): with \\(1217\\) included only once\n\\(\\mathcal{U}_D = \\{268, 397, 1217\\}\\): with the inclusion of \\(1217\\) due to the event at \\(t_1\\), not censoring at \\(t_5\\)\n\\(\\mathcal{R}_{\\tau = 1217} = \\{1, 3, 5\\}\\) (these subjects’ outcome times are greater or equal to \\(\\tau = 1217\\) so they are at risk for the event at this time)\n\\(n_{\\tau = 1217} = |\\mathcal{R}_{1217}| = 3\\)\n\\(d_{\\tau = 1217} = 1\\): As only \\(i = 1\\) experienced the event (and not censoring) at this time.\n\n\n\n\nTable 4.1: Subset of the tumor (Bender and Scheipl 2018) time-to-event dataset. Rows are individual observations (ID), \\(\\mathbf{x}_{;j}\\) columns are features, \\(t\\) is observed time-to-event, \\(\\delta\\) is the event indicator.\n\n\n\n\n\n\n\n\n\n\n\n\n\nid (\\(i\\))\nage \\((\\mathbf{x}_{;1})\\)\nsex \\((\\mathbf{x}_{;2})\\)\ncomplications \\((\\mathbf{x}_{;3})\\)\ndays (\\(\\mathbf{t}\\))\nstatus (\\(\\boldsymbol{\\delta}\\))\n\n\n\n\n1\n71\nfemale\nno\n1217\n1\n\n\n2\n70\nmale\nno\n519\n0\n\n\n3\n67\nfemale\nyes\n2414\n0\n\n\n4\n58\nmale\nno\n397\n1\n\n\n5\n39\nfemale\nyes\n1217\n0\n\n\n6\n59\nfemale\nno\n268\n1",
    "crumbs": [
      "Survival Analysis and Machine Learning",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Survival Analysis</span>"
    ]
  },
  {
    "objectID": "P1C4_survival.html#sec-surv-km",
    "href": "P1C4_survival.html#sec-surv-km",
    "title": "4  Survival Analysis",
    "section": "4.3 Kaplan-Meier estimator",
    "text": "4.3 Kaplan-Meier estimator\nBefore we go further, we introduce a simple, non-parametric estimator for the survival function (Equation 4.1), the Kaplan-Meier estimator (Kaplan and Meier 1958). The estimator is useful for visualising survival data and is a popular baseline model to compare to the predictive performance of more complex methods. In machine learning terms it can be viewed as a “featureless” learner for survival analysis.\nUsing the quantities introduced in Section 4.2, the estimator is defined by:\n\\[\n\\hat{S}_{KM}(\\tau) = \\prod_{k:t_{(k)} \\leq \\tau}\\left(1-\\frac{d_{t_{(k)}}}{n_{t_{(k)}}}\\right)\n\\tag{4.9}\\]\nwhich is a step-function at the observed ordered event times \\(t_{(k)}, k=1,\\ldots,m\\) with \\(\\hat{S}_{KM}(\\tau) = 1\\ \\forall \\tau &lt; t_{(1)}\\). It is usually estimated for all unique event times.\nFor illustration, Figure 4.1 shows the estimated survival probability obtained by applying the Kaplan-Meier estimator to the full tumor data, containing observations of \\(n=776\\) subjects. By definition, the survival function starts at \\(S(t)=1\\) at \\(t=0\\) and monotonically decreases towards \\(S(t)=0\\) for \\(t\\rightarrow \\infty\\). Dotted lines indicated the median survival, defined as the time at which the survival function reaches \\(S(t) = 0.5\\). In this example, the median survival time is approximately 1500 days, as indicated by the dashed lines. This means that 50% of the subjects are expected die within 1500 days after operation.\n\n\n\n\n\n\nFigure 4.1: Kaplan-Meier estimate for the tumor data (Bender and Scheipl 2018). The estimated survival probabilities are given by the solid step-function. Dotted lines indicate the median survival time).\n\n\n\nWhile the Kaplan-Meier estimator does not directly support estimation of covariate effects on the estimated survival probabilities, it is often used for descriptive analysis by applying the estimator to different subgroups (referred to as stratification in survival analysis). For example, Figure 4.2 shows \\(\\hat{S}_{KM}\\) separately for subjects aged 50 years or older and subjects younger than 50 years, respectively. Dashed lines again illustrate median survival times. However, note that the median survival time does not exist for the younger age group, as their estimated survival function does not cross \\(0.5\\).\n\n\n\n\n\n\nFigure 4.2: Kaplan-Meier estimate for the tumor data (Bender and Scheipl 2018) applied to subgroups of subjects of 50 or more years old and less than 50 years old, respectively. The estimated survival probabilities are given by the solid step-function. Dotted lines indicate the median survival time).\n\n\n\nSometimes the KM Estimator is also used to estimate the distribution of censoring times, for example to calculate inverse probability of censoring weights (Section 8.1.1). Throughout this book, we denote the Kaplan-Meier estimator applied to the observed censoring times \\((t_i, 1-\\delta_i)\\) as \\(\\hat{G}_{KM}\\).",
    "crumbs": [
      "Survival Analysis and Machine Learning",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Survival Analysis</span>"
    ]
  },
  {
    "objectID": "P1C4_survival.html#sec-types-of-censoring",
    "href": "P1C4_survival.html#sec-types-of-censoring",
    "title": "4  Survival Analysis",
    "section": "4.4 Types of Censoring",
    "text": "4.4 Types of Censoring\nThree types of censoring are commonly defined in survival analysis: right-censoring, left-censoring, and interval-censoring. The latter can be viewed as the most general case. Multiple types of censoring and/or truncation (Section 4.5) can occur in any given data set and it is vital to identify which types are present in order to correctly select and specify models and measures for the data.\n\nRight-censoring\nRight-censoring is the most commonly assumed form of censoring in survival data. It occurs when the event of interest was not experienced during the observation period, which may happen because it was no longer observable (for example, due to withdrawal from the study) or because the event did not happen until study end. The exact event time is unknown but it is known that the event is after the observed censoring time, hence right-censoring (imagine a timeline from left to right as in Figure 4.3).\n\n\n\n\n\n\n\nFigure 4.3: Dead and censored subjects (y-axis) over time (x-axis). Black diamonds indicate true death times and white circles indicate censoring times. Diamonds at the end of dashed lines are hypothetical (unknown in reality). Vertical line is the study end time. Subjects 1 and 2 die in the study time. Subject 3 is censored in the study and (unknown) dies within the study time. Subject 4 is censored in the study and (unknown) dies after the study. Subject 5 is censored at study end and (unknown) dies after the end of the study.\n\n\n\n\nRight-censoring can be further divided into Type-I, Type-II and random censoring. Type-I, or administrative, censoring occurs at the fixed, pre-defined end of an observation period \\(\\tau_u\\), in which case the outcome is given by \\((T_i = \\min(Y_i, \\tau_u), \\Delta_i = \\mathbb{I}(Y_i \\leq \\tau_u))\\). Censored observations are therefore represented as \\((\\tau_u, 0)\\). Type-II censoring also occurs when the observation period ends. However, in this case the study ends when a pre-defined number of subjects experienced the event of interest and hence \\(\\tau_u\\) is random.\nRandom censoring occurs when censoring times randomly follow an unknown distribution and one observes \\((T_i=\\min(Y_i,C_i), \\Delta_i = \\mathbb{I}(Y_i\\leq C_i))\\). Different types of right-censoring can, and sometimes do, co-occur in any given data set.\nIn practice, these different types of right-censoring are usually handled the same during modeling and evaluation and so this book refers to ‘right-censoring’ generally, which could occur from a combination of the above types.\n\n\nLeft- and Interval-censoring\nLeft-censoring occurs when the event is known to have happened at some unknown time before observation time, interval-censoring occurs when the event is known to have happened within some time span, but not the exact time.\nConsider a survey about phone use where participants are asked: “How old were you when you used a smart phone for the first time?”. The possible answers are:\n\nexact age of first use\ndidn’t use a smart phone yet\ndid or does use a phone but doesn’t remember age of first time use\ndid or does use a phone, remembers a specific age range\n\nThe first case represents an exactly observed event time, the second case the familiar right-censoring, as the event may occur later in life, but it is unknown when. The third case is referred to as left-censoring, we know the event occurred before the interview, but don’t know when. The fourth case is an example of interval-censoring, as we know the event occurred within some age span, but not the exact age.\nInterval- and left-censoring also often occurs in medical contexts. For example, some guidelines suggest annual screenings for skin cancer (starting from a certain age). However, the initial age at which individuals do screenings and regularity of check ups varies widely. If cancer was detected between two screenings, the observation is interval-censored. If cancer is detected at first screening, the observation is left-censored (unless the ‘age’ of the cancer can be narrowed down based on size and other characteristics, in which case it would become interval-censored).\n\n\nCensoring Notation\nIn the presence of left- or interval-censoring the usual representation of survival outcomes as \\((t_i, \\delta_i)\\) is not sufficient to denote the different types of observations in the data set. Instead, we represent the data as intervals in which the event occurs. Formally, let \\(Y_i\\) the random variable for time until the event of interest and \\(L_i, R_i\\) random variables that define an interval \\((L_i,R_i]\\) with realisations \\(l_i, r_i\\). Let further \\(t_i\\) the time of observation (for example age at interview in the phone use example) or last-follow up time for subject \\(i\\). Then the event time of subject \\(i\\) is\n\nleft-censored if \\(Y_i \\in (L_i = 0, R_i = t_i]\\);\nright-censored at \\(t_i\\) if \\(Y_i \\in (L_i = t_i, R_i = \\infty)\\);\ninterval-censored \\(Y_i \\in (L_i = l_i, R_i = r_i]\\), \\(l_i &lt; r_i \\leq t_i\\)\nexactly observed if \\(Y_i \\in (L_i = t_i, R_i = t_i]\\)\n\nIn the cancer screening example from above it holds that \\(r_i=t_i\\) and \\(l_i\\) the last check-up before \\(r_i\\). In the phone use example, the participants might specify any age range between \\(0\\) and \\(t_i\\).\nTo make this more concrete, consider phone use example data, where \\(t_i\\) is the age at interview. In practice, such data is often stored by creating two variables representing the left (\\(l_i\\)) and right border (\\(r_i\\)) of the respective intervals (\\(t_i\\) is not really needed here to define the outcome, but included for illustration).\n\n\n\nid\n\\(t_i\\)\n\\(l_i\\)\n\\(r_i\\)\n\n\n\n\n1\n13\n13\n\\(\\infty\\)\n\n\n2\n17\n15\n15\n\n\n3\n16\n14\n16\n\n\n4\n16\n13\n15\n\n\n5\n18\n0\n18\n\n\n\nHere, the first subject is right-censored at 13 years (\\(l_i=t_i = 13, r_i = \\infty\\)), the second subject remembered exactly (\\(l_i=r_i=15 &lt; t_i = 17\\)), the third subject remembers that it was after 14, but not exact age (\\(l_i = 14 &lt; r_i = 16=t_i\\)), fourth subject remembers use after 13 years and latest at 15 years of age (\\(l_i = 13 &lt; r_i = 15 &lt; t_i\\)), and the fifth subject uses a smart phone currently at age 18, but cannot specify further (\\(l_i = 0 &lt; r_i = 18 = t_i\\)).\nFrom the example above, it is clear, that right- and left-censoring are special cases of interval-censoring. However, if only right- or left-censoring is present, the likelihood and estimation simplifies (see Section 4.6). Also note that in case of left- and interval-censoring the event is known to have occurred, while for right-censoring the event didn’t occur during time under observation. For left- and right-censoring one might be tempted to consider it an event \\(\\delta_i = 1\\) without exact time, while right-censoring would be consider a non-event \\(\\delta_i = 0\\). However, technically it is assumed that the event will always occur, if we wait long enough (for right-censored data in the interval \\((t_i, \\infty]\\)). Censoring therefore means having imprecise information about the time of event rather than information about the event occurring or not occurring.",
    "crumbs": [
      "Survival Analysis and Machine Learning",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Survival Analysis</span>"
    ]
  },
  {
    "objectID": "P1C4_survival.html#dependent-vs.-informative-censoring",
    "href": "P1C4_survival.html#dependent-vs.-informative-censoring",
    "title": "4  Survival Analysis",
    "section": "Dependent vs. Informative Censoring",
    "text": "Dependent vs. Informative Censoring\nCensoring may be defined as uninformative if \\(Y \\perp \\!\\!\\! \\perp C\\) and informative otherwise. However, these definitions can be misleading as the term ‘uninformative’ could imply that \\(C\\) is independent of both \\(X\\) and \\(Y\\), and not just \\(Y\\). To avoid misinterpretation, the following definitions are used in this book:\n\nIf \\(C \\perp \\!\\!\\! \\perp X\\), censoring is feature-independent, otherwise censoring is feature-dependent.\nIf \\(C \\perp \\!\\!\\! \\perp Y\\), censoring is event-independent, otherwise censoring is event-dependent.\nIf \\((C \\perp \\!\\!\\! \\perp Y) | X\\), censoring is conditionally independent of the event given covariates, or conditionally event-independent.\nIf \\(C \\perp \\!\\!\\! \\perp(X,Y)\\), censoring is uninformative, otherwise censoring is informative.\n\nUninformative censoring can generally be well-handled by models as the true underlying distribution of survival times is not affected by censoring. In fact, in this case one could even use regression models after removing censored observations (if they do not form a high proportion of the data).\nIn reality, censoring is rarely non-informative as reasons for drop-out or missingness in outcomes tend to be related to the study of interest. Event-dependent censoring is a tricky case that, if not handled appropriately (by a competing-risks framework), can easily lead to poor model development. Imagine a study is interested in predicting the time between relapses of stroke but a patient suffers a brain aneurysm due to some separate neurological condition. There is a high possibility that a stroke may have occurred if the aneurysm had not. A survival model is unlikely to distinguish the censoring event (aneurysm) from the event of interest (stroke) and will confuse predictions.\nIn practice, the majority of models and measures assume that censoring is conditionally event-independent and hence censoring patterns can be predicted/estimated based on the covariates. For example, if studying the survival time of ill pregnant patients in hospital, then dropping out of the study due to pregnancy is clearly dependent on how many weeks pregnant the patient is when the study starts (for the sake of argument assume no early/late pregnancy due to illness).",
    "crumbs": [
      "Survival Analysis and Machine Learning",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Survival Analysis</span>"
    ]
  },
  {
    "objectID": "P1C4_survival.html#sec-truncation",
    "href": "P1C4_survival.html#sec-truncation",
    "title": "4  Survival Analysis",
    "section": "4.5 Censoring vs. Truncation",
    "text": "4.5 Censoring vs. Truncation\nA common confusion is to conflate censoring and truncation, which is problematic as the methods to handle them differ substantially. Outside of time-to-event settings, truncation usually refers to truncating (or removing) an entire subject from a dataset. As discussed in Chapter 1, truncation in survival analysis refers to partially truncating a period of time and is quite common in the more general event history setting (Chapter 5).\nWhile censored observations have incomplete information about the time-to-event, they are still part of the data set. Whereas truncation leads to observations not entering the data set (at least not at time 0). This will usually introduce bias that needs to be accounted for.\n\nLeft-truncation\nLeft-truncation often occurs when inclusion into a study is conditional on the occurrence of another event. Left-truncation plays an important role when modeling recurrent events or multi-state data (Chapter 5), thus the concept will be introduced in more detail.\nBy example, consider a study from the 18th century (Broström 1987), when childhood and maternal mortality were relatively high. The goal of the study was to establish the effect of a mother’s death on the survival of the infant. Since each death was reported to the authorities, an infant was added to the study if and when their mother died. To create a matched cohort, two other infants, whose mothers were alive, were matched into the study based on their age and other relevant features. Thus, groups of three infants within the study had identical features except for the status of the mother (alive or dead). Because of the study design, infants who died before their mothers could never enter into the study. A mother’s death is thus referred to as left-truncation event and the infant’s age at time of inclusion into the study is referred to as left-truncation time.\nMore formally, let \\(t^L_i\\) the subject-specific left-truncation time. Then we only observe subjects with \\(y_i &gt; t^L_i\\) and subjects with \\(y_i &lt; t^L_i\\) never enter the data.\nThis is illustrated in Figure 4.4. Continuing with the example above, say Infant 1 dies at \\(t_1\\), while the mother dies at some later time point \\(t_1^L\\), therefore infant 1 never enters the study. The mother of Infant 2 dies at \\(t_2^L\\), at which point the infant is included in the study and experiences an event at \\(t_2\\). Finally, say Infant 3 enters the study at \\(t_3^L\\) and is censored at 365 days when the study ends.\n\n\n\n\n\n\nFigure 4.4: Illustration of left-truncation data. Subjects 2 and 3 enter the data set as the study entry condition (mother’s death) occurs before the event of interest occurs after the left-truncation time (left-truncation time shorter than event time). Subject 1 on the other hand never enters the data as the event occurs before the study entry condition (left-truncation time longer than event time).\n\n\n\nIn this example, left-truncation biases the sample towards healthier or more robust infants, as frail infants on die earlier and thus on average before their mothers. This would bias the estimates if not properly taken into account.\nContinuing the above example, Figure 4.5 shows the difference between estimated survival probabilities when left-truncation is ignored (left panel) and taken into account (right panel), respectively. It is clear that the survival probabilities were underestimated in both groups, but more so in the group of infants whose mother died (thereby underestimating the effect of the mothers’ death on infant survival).\n\n\n\n\n\n\nFigure 4.5: Left: Kaplan-Meier estimate of survival probabilities of infants depending on status of the mother ignoring left-truncation. Right: Kaplan-Meier estimate of survival probabilities adjusting for left-truncation.\n\n\n\nTo understand this, consider an excerpt from the infants data in Table 4.2.\n\n\n\nTable 4.2: Excerpt of the infants (Broström 2024) time-to-event dataset. Rows are individual observations (id), group indicates matched infants, \\(t^L\\) is the left-truncation time (time of inclusion into the study), \\(t\\) is the observed time, \\(\\delta\\) is the event indicator.\n\n\n\n\n\ngroup\nid\n\\(t^L\\)\n\\(t\\)\n\\(\\delta\\)\nmother\n\n\n\n\n1\n1\n55\n365\n0\ndead\n\n\n1\n2\n55\n365\n0\nalive\n\n\n1\n3\n55\n365\n0\nalive\n\n\n2\n4\n13\n76\n1\ndead\n\n\n2\n5\n13\n365\n0\nalive\n\n\n2\n6\n13\n365\n0\nalive\n\n\n4\n7\n2\n16\n1\ndead\n\n\n4\n8\n2\n365\n0\nalive\n\n\n4\n9\n2\n365\n0\nalive\n\n\n\n\n\n\nNow recall the calculation of the Kaplan-Meier estimate from Section 4.3. In Table 4.2, without stratifying according to mother’s status, the first observed event time is \\(t_{(1)} = t_7=16\\). Then ignoring left-truncation,\n\n\\(\\mathcal{R}_{t_{(1)}} = \\{1,2,3,4,5,6,7,8,9\\}\\)\n\\(d_{t_{(1)}} = 1\\)\n\\(n_{t_{(1)}} = 9\\)\n\\(S(t_{(1)}) = 1 - \\frac{1}{9} \\approx 0.9\\)\n\nIn contrast, when we take left-truncation into account, subjects only enter the risk set for the event after their left-truncation time (we already know they survived until \\(t_i^L\\) so they are not at risk for the event before that time), thus\n\n\\(\\mathcal{R}_{t_{(1)}} = \\{4, 5, 6, 7, 8, 9\\}\\)\n\\(d_{t_{(1)}} = 1\\)\n\\(n_{t_{(1)}} = 6\\)\n\\(S(t_{(1)}) = 1 - \\frac{1}{6} \\approx 0.8\\)\n\nThus, the definition of the KM estimator in Equation 13.1 can still be used in case of left-truncation using the more general risk set definition\n\\[\n\\mathcal{R}_\\tau = \\{i: t_i^L \\leq \\tau \\leq t_i\\}\n\\tag{4.10}\\]\n\n\nRight-truncation\nRight-truncation often occurs in retrospective sampling based on registry data, when data is queried for cases reported by a certain cut-off time (see for example Vakulenko-Lagun, Mandel, and Betensky (2020)). A common example is the estimation of the incubation period of an infectious disease, which is the time from infection to the disease onset. Only known, symptomatic (and/or tested) cases are entered into the database. At a time \\(\\tau\\), one can only observe the subset of the infected population that has already experienced the disease, and not the population that is still incubating the disease, hence biasing the data to shorter incubation periods.\nFormally, let \\(t_i^r\\) be the right-truncation time (here time from infection until the time at which the database is queried), then subjects only enter the data set when \\(t_i &lt; t_i^r\\). This is illustrated in Figure 4.6 using three subjects. All three subjects were infected during the observation period, however, the right-truncation time \\(t_2^r\\) of subject 2 is shorter than the incubation period \\(t_2\\) for this subject, thus at the time of querying the data base, this subject will not be included in the sample, as \\(t_2 &gt; t_2^r\\).\nNote the difference to right-censoring. If subject 2 was right-censored, the subject would be in our sample and the time of infection would be known - the time of disease onset would be censored. In case of right-truncation on the other hand, the subject is not included in the sample at time of data extraction, as subjects are only included in the registry after disease onset. Overall this leads to a bias towards shorter incubation times and potentially feature values that lead to shorter incubation times.\n\n\n\n\n\n\n\nFigure 4.6: Illustration of right-truncation based on registry data. For subjects 1 and 3 the right-truncation time is longer than the incubation period, therefore they are included in the sample when the registry is queried. For subject 2 on the other hand the right-truncation time is shorter, therefore it’s excluded from the sample.\n\n\n\nAs for left-truncation, ignoring right-truncation will lead to biased estimations. While for left-truncated data simple adjustments of the risk set work for non- and semi-parametric methods like the Kaplan-Meier and Cox-type estimators, this is not the case for right-truncated data. However, parametric methods can be employed (see Section 4.6) and generalised product limit estimators for right-truncated data exist (Akritas and LaValley 2005).",
    "crumbs": [
      "Survival Analysis and Machine Learning",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Survival Analysis</span>"
    ]
  },
  {
    "objectID": "P1C4_survival.html#sec-surv-estimation",
    "href": "P1C4_survival.html#sec-surv-estimation",
    "title": "4  Survival Analysis",
    "section": "4.6 Estimation",
    "text": "4.6 Estimation\nWhile details about estimation will be given later, when different models are introduced in Part III and Part IV of the book, it is worthwhile discussing some general concepts here, namely parametric and non-parametric approaches.\n\n4.6.1 Parametric estimation\nConsider for now uncensored data \\((t_i, \\delta_i=1), i=1,\\ldots,n\\). A standard approach would be to assume a suitable distribution for the event times \\(t_i \\stackrel{iid}{\\sim} F_Y(\\boldsymbol{\\theta}), \\boldsymbol{\\theta}=(\\theta_1,\\theta_2,\\ldots)^\\top\\), and define the likelihood of the data as  \\[\n\\mathcal{L}(\\boldsymbol{\\theta}) = \\prod_{i=1}^{n}f_Y(t_i|\\boldsymbol{\\theta})\n\\tag{4.11}\\]\n\nwhere \\(f_Y\\) is the pdf of \\(F_Y\\).\nThe model parameters can then be obtained by maximizing the likelihood such that\n\\[\n\\hat{\\boldsymbol{\\theta}} = \\mathop{\\mathrm{arg\\,max}}_{\\boldsymbol{\\theta}} \\mathcal{L}(\\boldsymbol{\\theta})\n\\]\nHowever, in the presence of censoring Equation 4.11 is incorrect, as the exact event time is only known for some subjects. For example, for right-censored data (\\(\\delta_i = 0\\)) we only know that the event occurred after observed censoring time \\(t_i\\). Thus the likelihood contribution for such data points is \\(P(Y_i &gt; t_i) = S_Y(t_i)\\), whereas for observed event times (\\(\\delta_i=0\\)) the likelihood contribution is \\(f_Y(t_i)\\) as before.\nLet now \\(\\mathcal{O}= \\{i:\\delta_i = 1\\}\\) the index set of observed event times and \\(\\mathcal{RC} = \\{i:\\delta_i = 0\\}\\) the index set of censored observations. The likelihood of this data can be written as\n\\[\n\\begin{aligned}\n\\mathcal{L}(\\boldsymbol{\\theta})\n  & \\propto \\prod_{i \\in \\mathcal{O}}f_Y(t_i|\\boldsymbol{\\theta})\\prod_{i \\in \\mathcal{RC}}S_Y(t_i|\\boldsymbol{\\theta})\\nonumber\\\\\n  & = \\prod_{i=1}^n f_y(t_i|\\boldsymbol{\\theta})^{\\delta_i}S_Y(t_i|\\boldsymbol{\\theta})^{1-\\delta_i}\\\\\n  & = \\prod_{i=1}^n \\frac{f_y(t_i|\\boldsymbol{\\theta})^{\\delta_i}}{S_Y(t_i|\\boldsymbol{\\theta})^{\\delta_i}}S_Y(t_i|\\boldsymbol{\\theta})\\\\\n  & = \\prod_{i=1}^n h_Y(t_i|\\boldsymbol{\\theta})^{\\delta_i}S_Y(t_i|\\boldsymbol{\\theta})\\nonumber,\n\\end{aligned}\n\\tag{4.12}\\]\nwhere the last equality follows from Equation 4.2.\nSimilar adjustments to the likelihood can be made for other types of censoring and in the presence of truncation. Following Klein and Moeschberger (2003), we can define the individual likelihood contributions for the different types of censoring as\n\nobserved event at \\(t_i\\): \\(f_Y(t_i|\\boldsymbol{\\theta})\\)\nright-censoring: \\(P(Y_i &gt; t_i|\\boldsymbol{\\theta}) = S_Y(t_i|\\boldsymbol{\\theta})\\)\nleft-censoring: \\(P(Y_i &lt; t_i|\\boldsymbol{\\theta}) = F_Y(t_i|\\boldsymbol{\\theta}) = 1 - S_Y(t_i|\\boldsymbol{\\theta})\\)\ninterval-censoring: \\(P(l_i &lt; Y_i \\leq r_i|\\boldsymbol{\\theta}) = S_Y(l_i|\\boldsymbol{\\theta}) - S_Y(r_i|\\boldsymbol{\\theta})\\)\n\nDepending on which of the above contributions occur in the data set, we can now construct our likelihood accordingly. Let \\(\\mathcal{O}, \\mathcal{RC}, \\mathcal{LC}, \\mathcal{IC}\\) non-overlapping subsets of the observed data \\(\\mathcal{D}\\) for subjects with observed event times, right-censoring, left-censoring and interval-censoring, respectively. Assuming independence between observations and in absence of truncation, the likelihood for the observed data can be defined as\n\\[\n\\mathcal{L}(\\boldsymbol{\\theta}) \\propto \\prod_{i \\in \\mathcal{O}}f_Y(t_i|\\boldsymbol{\\theta}) \\prod_{i \\in \\mathcal{RC}}S_Y(t_i|\\boldsymbol{\\theta}) \\prod_{i \\in \\mathcal{LC}}(1-S_Y(t_i|\\boldsymbol{\\theta}))\\prod_{i \\in \\mathcal{IC}}(S_Y(l_i|\\boldsymbol{\\theta})-S_Y(r_i|\\boldsymbol{\\theta}))\n\\tag{4.13}\\]\nIn case of truncation, the adjustments are made to all observations, as we have to condition on the event occurring after/before the truncation time. The truncation adjusted likelihood contributions (assuming independence of truncation and event/censoring times) would thus be given by\n\nleft-truncation:\n\nevent: \\(f(Y_i = t_i|Y_i \\geq t_i^L, \\boldsymbol{\\theta}) = \\frac{f_Y(t_i|\\boldsymbol{\\theta})}{S_Y(t_i^L|\\boldsymbol{\\theta})}\\)\nleft-censoring: \\(P(Y_i &lt; t_i|Y_i \\geq t_i^L, \\boldsymbol{\\theta}) = \\frac{S_Y(t_i|\\boldsymbol{\\theta})}{S_Y(t_i^L|\\boldsymbol{\\theta})}\\)\ninterval-censoring: \\(P(l_i &lt; Y_i \\leq r_i|Y_i \\geq t_i^L,\\boldsymbol{\\theta}) = \\frac{S_Y(l_i|\\boldsymbol{\\theta}) - S_Y(r_i|\\boldsymbol{\\theta})}{S_Y(t_i^L|\\boldsymbol{\\theta})}\\)\n\nright-truncation:\n\nevent: \\(f(Y_i = t_i|Y_i \\leq t_i^R, \\boldsymbol{\\theta}) = \\frac{f_Y(t_i|\\boldsymbol{\\theta})}{F_Y(t_i^R|\\boldsymbol{\\theta})}\\)\nleft-censoring: \\(P(Y_i &lt; t_i|Y_i \\leq t_i^R, \\boldsymbol{\\theta}) = \\frac{S_Y(t_i|\\boldsymbol{\\theta})}{F_Y(t_i^R|\\boldsymbol{\\theta})}\\)\ninterval-censoring: \\(P(l_i &lt; Y_i \\leq r_i|Y_i \\leq t_i^R,\\boldsymbol{\\theta}) = \\frac{S_Y(l_i|\\boldsymbol{\\theta}) - S_Y(r_i|\\boldsymbol{\\theta})}{F_Y(t_i^R|\\boldsymbol{\\theta})}\\)\n\n\nNote that in in practice, data sets will often not contain all types of censoring or truncation, in which case Equation 4.13 will contain only a subset of the product terms. This has been illustrated in Equation 4.12 under absence of truncation and \\(\\mathcal{LC}=\\mathcal{IC}=\\emptyset\\).\n\n\n4.6.2 Non-parametric estimation\nAs the name suggests, non-parametric estimation (and semi-parametric estimation) techniques do not make (strong) assumptions about the underlying distribution of event times.\nA common principle for such techniques is to partition the follow into intervals or to define specific time-points during the follow-up and to estimate the continuous or discrete time hazards (Equation 4.5) for each interval/time-point. Then derive the respective estimates, for example the survival probability, based on the relationship between the hazard and other quantities (Section 4.1 or Section 4.1.2).\nThe Kaplan-Meier estimator introduced earlier (Section 4.3) is an example for this principle. There, time-points \\(t_{(k)},\\ k=1,\\ldots,m\\) are used to calculate the discrete time hazards  \\[\nh^d(t_{(k)}) = P\\left(Y\\in (t_{(k-1)},t_{(k)}]|Y&gt;t_{(k-1)}\\right)=\\frac{d_{t_{(k)}}}{n_{t_{(k)}}}.\n\\tag{4.14}\\]\nThe survival probability and the definition of the Kaplan-Meier estimator (Equation 13.1) then follow from Equation 4.7.\nSimilarly, the Nelson-Aalen estimator (Nelson (1972),Aalen (1978)) for the cumulative hazard is obtained via Equation 4.6 as  \\[\nH_{NA}(\\tau) = \\sum_{k:t_{(k)}\\leq \\tau} h^d(t_{(k)}) = \\sum_{k:t_{(k)}\\leq \\tau} \\frac{d_{t_{(k)}}}{n_{t_{(k)}}}.\n\\tag{4.15}\\]  Note that we use a continuous time valued \\(\\tau\\) for the definition, which implies that \\(H_{NA,e}(\\tau) = H_{NA,e}(t_{(k)})\\ \\forall \\tau \\in [t_{(k)}, t_{(k+1)})\\). In words: For time points between two unique event times we assume the previous value of the estimate. Similar to the Kaplan-Meier estimator, \\(H_{NA}\\) can deal with left-truncated data based on the general risk-set definition Equation 4.10.\nBased on Equation 4.4 we can also define a survival probability estimator based on the Nelson-Aalen estimator of the cumulative hazard Equation 4.15 as  \\[\nS_{NA}(\\tau) = \\exp(-H_{NA}(\\tau)).\n\\tag{4.16}\\]  This relationship is also used by Breslow (1972) to obtain survival probability estimates in the context of the Cox model (Chapter 13).\n\n\n\n\n\n\nMajor changes expected!\n\n\n\nThis page is a work in progress and major changes will be made over time.",
    "crumbs": [
      "Survival Analysis and Machine Learning",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Survival Analysis</span>"
    ]
  },
  {
    "objectID": "P1C4_survival.html#conclusion",
    "href": "P1C4_survival.html#conclusion",
    "title": "4  Survival Analysis",
    "section": "4.7 Conclusion",
    "text": "4.7 Conclusion\n\n\n\n\n\n\nKey takeaways\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFurther reading\n\n\n\n\nFor practical discussion about survival models in the context of right-censoring and left-truncation see McGough et al. (2021)\n\n\n\n\n\n\n\nAalen, Odd. 1978. “Nonparametric Inference for a Family of Counting Processes.” The Annals of Statistics 6 (4): 701–26.\n\n\nAkritas, Michael G., and Michael P. LaValley. 2005. “A Generalized Product-Limit Estimator for Truncated Data.” Nonparametric Statistics, September. https://doi.org/10.1080/10485250500038637.\n\n\nBender, Andreas, and Fabian Scheipl. 2018. “pammtools: Piece-wise exponential Additive Mixed Modeling tools.” arXiv:1806.01042 [Stat]. http://arxiv.org/abs/1806.01042.\n\n\nBreslow, N. 1972. “Discussion following ‘Regression models and life tables’ by D. R. Cox.” Journal of the Royal Statistical Society: Series B (Statistical Methodology) 34 (2): 187–220.\n\n\nBroström, Göran. 1987. “The Influence of Mother’s Death on Infant Mortality: A Case Study in Matched Data Survival Analysis.” Scandinavian Journal of Statistics 14 (2): 113–23. https://www.jstor.org/stable/4616055.\n\n\n———. 2024. Eha: Event History Analysis. https://cran.r-project.org/package=eha.\n\n\nKaplan, E. L., and Paul Meier. 1958. “Nonparametric Estimation from Incomplete Observations.” Journal of the American Statistical Association 53 (282): 457–81. https://doi.org/10.2307/2281868.\n\n\nKlein, John P, and Melvin L Moeschberger. 2003. Survival analysis: techniques for censored and truncated data. 2nd ed. Springer Science & Business Media.\n\n\nMcGough, Sarah F., Devin Incerti, Svetlana Lyalina, Ryan Copping, Balasubramanian Narasimhan, and Robert Tibshirani. 2021. “Penalized Regression for Left-Truncated and Right-Censored Survival Data.” Statistics in Medicine 40 (25): 5487–5500. https://doi.org/https://doi.org/10.1002/sim.9136.\n\n\nNelson, Wayne. 1972. “Theory and Applications of Hazard Plotting for Censored Failure Data.” Technometrics 14 (4): 945–66.\n\n\nTutz, Gerhard, and Matthias Schmid. 2016. Modeling Discrete Time-to-Event Data. Springer Series in Statistics. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-319-28158-2.\n\n\nVakulenko-Lagun, Bella, Micha Mandel, and Rebecca A. Betensky. 2020. “Inverse Probability Weighting Methods for Cox Regression with Right-Truncated Data.” Biometrics 76 (2): 484–95. https://doi.org/10.1111/biom.13162.",
    "crumbs": [
      "Survival Analysis and Machine Learning",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Survival Analysis</span>"
    ]
  },
  {
    "objectID": "P1C5_eha.html",
    "href": "P1C5_eha.html",
    "title": "5  Event-history Analysis",
    "section": "",
    "text": "5.1 A process point of view\nIn this chapter we take a more general view on time-to-event data. So far, we only considered a single potentially censored, outcome of interest. Here we explore more complex settings with multiple, potentially mutually exclusive events and recurrences of events. In this generalization, the observed data is sometimes referred to as event-history data and its analysis as event-history analysis.\nOne way to think about event history data is in terms of transitions between different states, as illustrated in Figure 5.1. Usually, a subject starts out in an initial state \\(0\\) (for example, ‘healthy’) and from there transitions to different states. States from which further transitions are possible are called transient (displayed as circles), otherwise a state is called terminal or absorbing (displayed as squares).\nIn the single event setting (Figure 5.1, upper left panel), a subject can only transition to one state (the event of interest). This setting was the focus of Chapter 4. There, the censoring event was considered independent of the event of interest. In the competing risks setting (Figure 5.1, upper right panel, Section 5.2), a subject could transition to any of the \\(q\\) mutually exclusive states, thus the subject is initially at risk for a transition to multiple states. Once one of them occurs, the process is considered to have concluded (for the modeling purposes).\nIn the recurrent events setting (Figure 5.1 lower left panel), the same event can be observed multiple times on the same subject (for example recurrent respiratory infections during one year). Two different ways to represent recurrent events are shown: (top) reset the status to \\(0\\) after occurrence of an event or (bottom) consider the \\(1\\)st, \\(2\\)nd, etc. recurrences of the event as separate states. A detail omitted in the graph: Often recurrent event processes also have a competing, absorbing event. In this more complex setting, but also in general, recurrent events are often represented as multi-state process, which we discuss next. Therefore we forgo detailed discussion of this setting in this book and refer to Cook and Lawless (2007) for a detailed account specific to recurrent events analysis.\nIn the most general case, the multi-state setting (Figure 5.1 lower right panel, Section 5.3), there are multiple transient and terminal states with potential back transitions (for example, moving between different stages of an illness with the possibility of (partial) recovery and death as terminal event).\nNote that the concepts discussed in Section 4.4 and Section 4.5 are still relevant here, as, dependent on the specific process, any transition between two states could be subject to different types of censoring and truncation. In particular, remaining in one of the transient states until the end of follow-up constitutes right-censoring with respect to all possible transitions from that state and left-truncation is particularly important as subjects enter the risk sets for a transition at different time points in context of recurrent events and multi-state settings.\nIn order to formalize the different settings more conveniently, we introduce the stochastic process  \\[\nE(\\tau) \\in \\{0,\\ldots, q\\},\\ \\tau \\geq 0,\n\\tag{5.1}\\]  which indicates the state that is occupied at time \\(\\tau\\).\nUsing this notation in the single-event setting we get \\(E(\\tau) \\in \\{0,1\\}\\) such that the hazard Equation 4.2 could be written as  \\[\n\\begin{aligned}\nh(\\tau)\n  &= \\lim_{\\mathrm{d}\\tau\\searrow 0}\\frac{P(Y \\in [\\tau, \\tau + \\mathrm{d}\\tau)|Y \\geq \\tau)}{\\mathrm{d}\\tau}\\\\\n  & = \\lim_{\\mathrm{d}\\tau\\searrow 0}\\frac{P\\left(E(\\tau + \\mathrm{d}\\tau)=1|E(\\tau-)=0\\right)}{\\mathrm{d}\\tau},\n\\end{aligned}\n\\tag{5.2}\\]  where \\(\\tau-\\) indicates the time point immediately before \\(\\tau\\).\nThis notation doesn’t yield many advantages in the single-event setting, but will shorten notation later on, particularly in the multi-state setting.",
    "crumbs": [
      "Survival Analysis and Machine Learning",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Event-history Analysis</span>"
    ]
  },
  {
    "objectID": "P1C5_eha.html#sec-competing-risks",
    "href": "P1C5_eha.html#sec-competing-risks",
    "title": "5  Event-history Analysis",
    "section": "5.2 Competing Risks",
    "text": "5.2 Competing Risks\nIn contrast to single-event survival analysis, competing risks are concerned with the time to the first of multiple, mutually exclusive events.\nTable 5.1. shows an excerpt of the sir.adm data (Allignol, Beyersmann, and Schumacher 2008) of patients on an intensive care unit (ICU). Time under observation (time) could end in one of three outcomes: \\(1\\) (discharge alive), \\(2\\) (death on ICU) or \\(0\\) (neither discharge nor death at the end of follow-up, which constitutes right-censoring at the end of study). The interest was in how pneumonia status (pneumonia) at admission to the ICU affects mortality.\n\n\n\nTable 5.1: Subset of the sir.adm dataset (Allignol, Beyersmann, and Schumacher 2008). Each row represent one subject,time is the time under observation, status indicates the outcome observed (\\(0\\): censored at the end of the study, \\(1\\): discharged alive from the ICU, \\(2\\): death in the ICU). pneumonia indicates whether a subject already had pneumonia at ICU admission.\n\n\n\n\n\ntime\nstatus\npneumonia\n\n\n\n\n8\n0\nno\n\n\n8\n0\nno\n\n\n31\n1\nyes\n\n\n5\n1\nno\n\n\n9\n2\nno\n\n\n5\n2\nno\n\n\n\n\n\n\nContrast this data to the tumor data example in Section 4.3. There, patients were followed even after hospital discharge, thus loss to follow-up could be considered reasonably independent of the event of interest (death). In this study follow-up stopped once patients were discharged. As discharged patients are healthier compared to the ones who remain on ICU, assuming independence between the time until discharge and time until death is unrealistic. Analysis of this data and how the different assumptions (independent censoring vs. competing risks) affects the estimates is discussed in Section 5.2.2 and Section 5.2.4.\n\n5.2.1 Notation and Definitions\nIn the competing risks setting, everyone starts out in the initial state \\(0\\) and can progress to one of the absorbing states \\(1,\\ldots,q\\). The goal is to characterize the process \\(E(\\tau) \\in \\{0,\\ldots, q\\}\\) in terms of transition hazards and probabilities.\nIn extension of Equation 5.2, we define cause-specific hazards  \\[\nh_{e}(\\tau) = \\lim_{\\mathrm{d}\\tau\\to 0} \\frac{P(E(\\tau + \\mathrm{d}\\tau) = e\\ |E(\\tau-)=0)}{\\mathrm{d}\\tau}.\n\\tag{5.3}\\] \nAnalogous to the single-event case, we can also define the cause-specific cumulative hazard \n\\[\nH_{e}(\\tau) = \\int_{0}^\\tau h_e(u)\\ du\n\\tag{5.4}\\] \nAs competing events are mutually exclusive at any time \\(\\tau\\), it is possible to define the all-cause hazard which is the hazard of any event occurring as the sum of all cause-specific hazards  \\[\nh(\\tau) = \\sum_{e = 1}^{q}h_{e}(\\tau),\n\\tag{5.5}\\]  as well as the all-cause cumulative hazard, which can be obtained either via the integral over the all-cause hazard (Equation 5.5) or as sum of cause-specific cumulative hazards (Equation 5.4):  \\[\nH(\\tau) = \\sum_{e=1}^q H_{e}(\\tau) = \\sum_{e=1}^{q}\\int_{0}^\\tau h_{e}(u)\\ du =\\int_{0}^\\tau \\sum_{e=1}^{q} h_{e}(u)\\ du \\int_{0}^\\tau h(u)\\ du\n\\tag{5.6}\\]  The all-cause survival probability gives the probability that none of the events occurred before \\(\\tau\\). This is usually not estimated directly but calculated from the cause specific hazards instead via Equation 5.6 and Equation 5.7:\n\\[\nS(\\tau) = P(Y &gt; \\tau) = \\exp(-H(\\tau))\n\\tag{5.7}\\]\nFinally, the probability of experiencing an event \\(e\\) before time \\(\\tau\\), which is often referred to as Cumulative Incidence Function (CIF), is given by  \\[\n\\begin{aligned}\nF_{e}(\\tau) &= P(E(\\tau) = e)  &\\ \\\\\n            & = \\int_{0}^\\tau f_e(u)\\ \\mathrm{d}u = \\int_{0}^\\tau S(u-)h_{e}(u)\\ \\mathrm{d}u,\n\\end{aligned}\n\\tag{5.8}\\]  where\n\n\\(S(u-)\\) is the probability of surviving (not experiencing any of the competing events) until the time-point shortly before \\(u\\)\n\\(f_e(u)\\mathrm{d}u = S(u-)h_{e}(u)\\mathrm{d}u\\) is the probability of experiencing event \\(e\\) at time point \\(u\\) (which follows analogously to Equation 4.2).\n\nNote that here we use the notation \\(S(u-)\\) rather than \\(S(u)\\) to make explicit that we want the probability to survive until the time point immediately before \\(u\\). This doesn’t make much difference in continuous time where \\(P(T &gt; t) = P(T\\geq t)\\), but may be important in (discrete) approximations (as in Section 5.2.2).\n\\(F_e(\\tau)\\) can be interpreted as the proportion of subjects who experienced event of type \\(e\\) until time \\(\\tau\\). Because the events are mutually exclusive, it holds that  \\[\n\\sum_{e=1}^q F_e(\\tau) + S(\\tau) = F(\\tau) + S(\\tau) = 1,\n\\]  where \\(F(\\tau)\\) is the probability that an event of any type occurring before \\(\\tau\\) and \\(S(\\tau)\\) the probability that no event occurs (Equation 5.7).\nNote that all terms of Equation 5.8 can be calculated from the individual hazards (Equation 5.3). Many estimation procedures for the CIF take this approach, consequently referred to as cause-specific hazards approach.\n\n\n5.2.2 Non-parametric estimators\nNon-parametric estimators for the cause-specific (cumulative) hazard (Equation 5.4) in the competing risks setting are derived analogous to the single event case (Section 4.6.2). The CIF then follows from Equation 5.8.\nFirst, recall from Section 4.2 the definitions of the unique ordered event times \\(t_{(k)}, k=1\\ldots,m\\), the risk-set at time \\(t_{(k)}\\), \\(\\mathcal{R}_{t_{(k)}}\\), the number of events, \\(d_{t_{(k)}}\\), and number of observations at risk \\(n_{t_{(k)}}\\). Assume partitioning of the follow-up into \\(m\\) disjunct intervals \\((t_{(k-1)}, t_{(k)}],k=1,\\ldots,m\\), such that \\(Y\\in (t_{(k-1)}, t_{(k)}] \\Leftrightarrow \\tilde{Y}=t_{(k)}\\), with \\(\\tilde{Y}\\) defined as in Chapter 21..\nAn estimate for the cause-specific hazard is derived by updating the numerator in Equation 4.14 to \\(d_{e,t_{(k)}}\\) (the number of events of type \\(e\\) at time \\(t_{(k)}\\)):  \\[\nh^d_{e}(t_{(k)}) := \\frac{d_{e,t_{(k)}}}{n_{t_{(k)}}},\\ e \\in \\{1, \\ldots, q\\}.\n\\tag{5.9}\\]  The Nelson-Aalen estimator (Equation 4.15) for the cause-specific cumulative hazard is then given by  \\[\nH_{NA,e}(\\tau) = \\sum_{k:t_{(k)}\\leq\\tau} h^d_{e}(t_{(k)}) = \\sum_{k:t_{(k)} \\leq \\tau} \\frac{d_{e,t_{(k)}}}{n_{t_{(k)}}},\n\\tag{5.10}\\]  which yields a step function for each \\(e\\), with jumps at time points \\(t_{(k)}\\).\nThe all-cause survival probability follows from Equation 5.6 and Equation 5.7 as  \\[\nS_{NA}(\\tau) = \\exp\\left(-\\sum_{e=1}^q H_{NA,e}(\\tau)\\right).\n\\]  Finally, the Aalen-Johansen (AJ) estimator (Aalen and Johansen (1978)) for the CIF follows via Equation 4.8 as  \\[\nF_{AJ,e}(\\tau) = \\sum_{k:t_{(k)}\\leq \\tau} S_{NA}(\\tau-)h^d_e(\\tau)=  \\sum_{k:t_{(k)}\\leq \\tau} S_{NA}(t_{(k-1)})\\frac{d_{e,t_{(k)}}}{n_{t_{(k)}}}\n\\tag{5.11}\\] \n\n\n5.2.3 Application to mortality of ICU patients\nFor illustration of the AJ estimator and the interpretation of the CIFs consider the analysis conducted in Beyersmann, Allignol, and Schumacher (2012), based on the data from Table 5.1. Recall that one is interested in estimation of the mortality conditional on pneumonia status at admission, while accounting for discharge from the ICU as competing risk (\\(E \\in \\{\\text{\"discharge\"}, \\text{\"death\"}\\}\\)). While the AJ estimator cannot naturally incorporate feature information, it can be applied to subgroups of the data (here based on the pneumonia status). Note that this will yield different sets of unique event times in each group, thus the AJ can have jumps at different time-points for the two groups.\nTODO: clean up text below\nFigure 5.2 shows the AJ estimates of the CIFs for each event type (discharge/death) stratified by pneumonia status. Exemplary, the proportion of subjects with pneumonia being discharged until \\(\\tau=120\\text{ days}\\) is approximately 75% (\\(\\hat{F}_{\\text{discharge}}(120) = P(Y\\leq 120, E=\\text{\"discharge\"})\\approx 0.75\\)), while approximately 25% died in the ICU (\\(\\hat{F}_{\\text{death}}(120) = P(Y\\leq 120, E=\\text{\"death\"})\\approx 0.25)\\). For patients without pneumonia we have \\(\\hat{F}_{\\text{discharge}}(120) \\approx 0.91\\) and \\(\\hat{F}_{\\text{death}} \\approx 0.09\\). In this example, \\(\\hat{F}_{\\text{discharge}} + \\hat{F}_{\\text{death}} \\approx 1\\) for both pneumonia groups, as only 14 of 747 patients were censored (neither discharge nor death) at the end of the follow-up.\n\n\n\n\n\n\nFigure 5.2: Aalen-Johansen estimator for the sir.adm data (Allignol, Beyersmann, and Schumacher 2008), stratified by pneumonia status at admission to the ICU. Left panel: Proportion of subjects discharged alive from the ICU. Right panel: Proportion of subjects who died in the ICU.\n\n\n\n\n\n5.2.4 Independent Censoring vs. Competing Risks\nIt is worth spending some time to consider the difference between independent right-censoring and competing risks. Note that for the estimation of the hazard (Equation 5.9), occurrences of competing events are implicitly assumed right-censored (as \\(d_{e,t_{(k)}}\\)) only counts events of type \\(e\\) and \\(n_{t_{(k)}}\\) contains the same subjects that would remain if events of type \\(\\tilde{e}\\neq e\\) were considered censored before \\(t_{(k)}\\). Nevertheless, competing risks are taken into account in the definition of the AJ estimator (Equation 5.11), as the all-cause survival probability (Equation 5.7) depends on all cause-specific hazards.\nIn contrast, assume that in our analysis of the sir.adm data we would consider time of discharge as independent right-censoring. As we only have one other event (death), the data could be treated as single-event, right-censored data as in Chapter 4 and therefore analyzed using the Nelson-Aalen estimator (Equation 4.16). The probability of death before some time-point \\(\\tau\\) could thus be obtained via \\(P(Y\\leq \\tau) = F(\\tau) = 1 - S_{NA}(\\tau)\\).\nFigure 5.3 shows the estimates obtained under the two assumptions. Solid lines indicate the probabilities under the competing risks assumption (identical to the right-hand side of Figure 5.2). Dashed lines are obtained under the independent right-censoring assumption. Clearly, the probabilities of dying at time \\(\\tau=120\\) are greater when independent censoring is assumed (\\(\\approx\\) 75% vs. \\(\\approx\\) 25% in the pneumonia group and \\(\\approx\\) 62% vs. \\(\\approx\\) 13% in the no pneumonia group).\n\n\n\n\n\n\nFigure 5.3: Estimation of the probability of dying in the ICU conditional on pneumonia status at admission. Dashed lines give the probabilities under assumption of right-censoring. Solid lines give the probabilities when taking into account discharge as competing risk.",
    "crumbs": [
      "Survival Analysis and Machine Learning",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Event-history Analysis</span>"
    ]
  },
  {
    "objectID": "P1C5_eha.html#sec-multi-state",
    "href": "P1C5_eha.html#sec-multi-state",
    "title": "5  Event-history Analysis",
    "section": "5.3 Multi-state Models",
    "text": "5.3 Multi-state Models\nThe multi-state process can be considered the most general type of time-to-event process, as other types (single-event, competing risks, recurrent events) can be viewed as special cases. Multi-state modeling allows realistic depiction of complex processes where subjects can start in different states and transition back and forth between them.\nFor illustration consider the prothr dataset (de Wreede, Fiocco, and Putter 2011) of liver cirrhosis patients from a randomized clinical trial with possible transitions depicted in Figure 5.4. Patients may have normal (state \\(0\\)) or abnormal (state \\(1\\)) levels of prothrombin (a protein important for blood clotting, produced by the liver) at the beginning of the trial. Some patients where treated with prednisone (which suppresses immune response and reduces inflammation) and others received a placebo. Death (state \\(2\\)) constitutes an absorbing state.\n\n\n\n\n\n\nFigure 5.4: Transition graph for the liver cirrhosis patients.\n\n\n\nThe goal of the trial was to investigate if treatment (prednisone) slows down or reverses disease progression (transitions \\(0 \\rightarrow 1\\) and \\(1 \\rightarrow 0\\)) and reduces mortality (transitions \\(0 \\rightarrow 2\\) and \\(1 \\rightarrow 2\\)).\nTable 5.2 shows a subset of the data set and contains for each subject (id)one row for each transition for which the subject was at risk for. In this example, this includes transitions that were possible, but didn’t happen (counterfactual transitions). The columns from and to indicate the initial state and the possible end state. tstart indicates the time at which the subject entered the risk set for said transitions and tstop the time point at which the subjects exited the from state (or were censored for any transition). The variable status indicates whether the transition was actually made (status = 1) or not (status = 0). This is necessary, as all possible transitions are listed, so we need an indicator for which transition actually occurred. If status=0 for all possible transitions, the subject is censored for further transitions. Finally, treatment indicates whether a patient was assigned the treatment or placebo group.\nConcretely, subject id=1 already had abnormal prothrombin levels at the beginning of the trial, thus started in state \\(1\\) with possible transitions \\(1\\rightarrow 0\\) and \\(1 \\rightarrow 2\\). In this case, the patient died, thus transition \\(1\\rightarrow 2\\) was realized after 151 days, while the transition \\(1 \\rightarrow 0\\) is a ‘counterfactual’ transition that could have happened in the time-span between tstart=0 and tend=151, but didn’t. Patient id=8 also started in state \\(1\\), but made a back transition to normal prothrombin levels after 211 days at which time they entered the risk set for transitions \\(0\\rightarrow 1\\) and \\(0\\rightarrow 2\\). Neither of the transitions occurred, as status=0 for both transitions, which means the subject remained in status \\(0\\) until the end of their follow-up at 2770 days (that is was right-censored at 2770 days). Finally, subject id=46 started in state 0 (normal prothrombin levels), transitioned to state 1 (abnormal levels) after 415 days and then died (transition \\(1\\rightarrow 2\\)) two days later. This also illustrates the importance of left-truncation (Section 4.5) in multi-state processes. For example, subjects id=1 and id=8 are at risk for the transitions \\(1 \\rightarrow 0\\) and \\(1 \\rightarrow 2\\) from the beginning of the trial (tstart = 0). Subject id=46 on the other hand starts in state 0 and only enters state \\(1\\) (and thus the risk set for the transitions \\(1\\rightarrow 0\\) and \\(1\\rightarrow 2\\)) after 415 days (tstart = 415). Other subjects in the data may never enter the risk set for these transitions by remaining in state 0 until the end of follow up or by directly transitioning to state \\(2\\). The fact that subjects enter the risk sets for different transitions at different time points technically constitutes left-truncation and thus should be taken into account accordingly (Section 5.3.4).\n\n\n\nTable 5.2: Subset of the prothr dataset (de Wreede, Fiocco, and Putter 2011).\n\n\n\n\n\nid\nfrom\nto\ntrans\ntstart\ntstop\nstatus\ntreatment\n\n\n\n\n1\n1\n0\n3\n0\n151\n0\nPlacebo\n\n\n1\n1\n2\n4\n0\n151\n1\nPlacebo\n\n\n8\n1\n0\n3\n0\n211\n1\nPrednisone\n\n\n8\n1\n2\n4\n0\n211\n0\nPrednisone\n\n\n8\n0\n1\n1\n211\n2770\n0\nPrednisone\n\n\n8\n0\n2\n2\n211\n2770\n0\nPrednisone\n\n\n46\n0\n1\n1\n0\n415\n1\nPrednisone\n\n\n46\n0\n2\n2\n0\n415\n0\nPrednisone\n\n\n46\n1\n0\n3\n415\n417\n0\nPrednisone\n\n\n46\n1\n2\n4\n415\n417\n1\nPrednisone\n\n\n\n\n\n\n\n5.3.1 Notation and Definitions\nIn the competing risks setting, we characterized the data generating process by cause-specific transitions hazards \\(h_e(\\tau)\\) (Equation 5.3). Implicitly these are transition from starting state \\(0\\) to end state \\(e\\), however, since everyone starts in stats in state \\(0\\) this information is ignored. In the multi-state setting on the other hand, subjects can be in different states at different time points. Transitions between different states are therefore characterized by transition-specific hazards, denoted by \\(h_{\\ell\\rightarrow e}(\\tau)\\) or short \\(h_{\\ell e}(\\tau)\\), where \\(\\ell\\) is the starting state and \\(e\\) the end state, \\(\\ell, e \\in \\{0,\\ldots,q\\}\\) (ignoring details such as the starting state must be a transient state and not all states are reachable from each starting state).\nLet \\(E(\\tau)\\in \\{0,\\ldots,q\\}\\) be the state process as before (Equation 5.1). Then, the transition-specific hazard can be defined as  \\[\nh_{\\ell e}(\\tau) = \\lim_{\\mathrm{d}\\tau\\to 0} \\frac{P(E(\\tau + \\mathrm{d}\\tau)=e|E(\\tau-) = \\ell)}{\\mathrm{d}\\tau}\n\\tag{5.12}\\]\nTransition hazards Equation 5.12 indicate the relative risk to enter state \\(e\\) at time \\(\\tau\\) given occupation of state \\(\\ell\\) at \\(\\tau-\\), which is the instant before \\(\\tau\\).\nAnalogous to the competing risks setting, we can define the transition specific cumulative hazards\n\\[\nH_{\\ell e}(\\tau) = \\int_{0}^{\\tau}h_{\\ell e}(u)du\n\\tag{5.13}\\]\nThe probability to transition from state \\(\\ell\\) to \\(e\\) between two time-points depends on all transitions possible from \\(\\ell\\) and potentially the transitions that have taken place in the past. Thus, other quantities of interest in the multi-state setting are the transition probabilities \\(P_{\\ell e}(\\zeta, \\tau):= P(E(\\tau) = e|E(\\zeta) = \\ell)\\), that is the probability to transition from state \\(\\ell\\) to state \\(e\\) between time points \\(\\zeta &lt; \\tau\\). Implicitly, this notation assumes that the process is Markovian: the transition probability depends only on the state at \\(\\zeta\\) and not any additional past states. Extensions do exist that relax this assumption, for example by including information about the past, but are not relevant for now.\nTransition probabilities of a multi-state process are often summarized in a matrix  \\[\n\\mathbf{P}(\\zeta, \\tau):=\n\\begin{pmatrix}\n  P_{00}(\\zeta, \\tau) & \\cdots & P_{0q}(\\zeta, \\tau)\\\\\n  \\vdots & \\ddots & \\vdots\\\\\n  P_{q0}(\\zeta, \\tau) & \\cdots & P_{qq}(\\zeta, \\tau)\\\\\n\\end{pmatrix},\n\\tag{5.14}\\]  where rows indicate starting states and columns indicate end states. Some of the elements of \\(\\mathbf{P}\\) might be zero or one depending on the specific process, presence of absorbing states and possible pathways between states. As subjects can only be in one of the \\(q+1\\) states at \\(\\tau\\), rows sum to \\(1\\):  \\[\n\\sum_{e =0}^q P_{\\ell e} = 1,\\forall \\ell \\in \\{0, \\ldots,q\\}.\n\\tag{5.15}\\] \n\n\n5.3.2 Instantaneous transition probabilities\nIn this section we briefly recap how the transition probabilities can be expressed as the product (integral) of instantaneous transition probabilities  \\[\np_{\\ell e}(\\tau) = P\\big(E(\\tau + \\mathrm{d}\\tau)=e|E(\\tau-)=\\ell\\big)\n\\tag{5.16}\\]  which can be recognized as the nominator of Equation 5.12, or intuitively as the transition probability between two subsequent time points.\nFor illustration, consider what is often referred to as an illness-death model depicted in Figure 5.5 (similar to Figure 5.4, but without back-transition), where subjects can transition from healthy state \\(0\\) to absorbing state death (\\(2\\)) either directly or via intermediate state \\(1\\).\n\n\n\n\n\n\nFigure 5.5: An illness-death model where subjects can transition from healthy state (\\(0\\)) to death (\\(2\\)) directly or via intermediate illness state (\\(1\\))\n\n\n\nIn this example, back-transitions are not possible, therefore the lower triangle of the matrix is filled with zeros and \\(P_{22}(\\zeta, \\tau) = 1, \\forall\\ \\zeta &lt; \\tau\\) by virtue of being an absorbing state. The matrix of transition probabilities is thus given as  \\[\n\\mathbf{P}(\\zeta, \\tau) =\n  \\begin{pmatrix}\n  P_{00}(\\zeta, \\tau) & P_{01}(\\zeta, \\tau) & P_{02}(\\zeta, \\tau)\\\\\n  0 & P_{11}(\\zeta, \\tau) & P_{12}(\\zeta, \\tau)\\\\\n  0 & 0 & 1\\\\\n  \\end{pmatrix}\n\\tag{5.17}\\]  First, assume that data is collected in discrete time, that is \\(\\zeta, \\tau \\in \\{0, 1, 2,\\ldots\\}, \\zeta &lt; \\tau\\) and transitions only occur at these discrete time points and not in between. Say we are interested in transition probability \\(P_{02}(4, 6)\\), that is the probability to transition from state \\(0\\) to state \\(2\\) between time points \\(\\zeta=4\\) and \\(\\tau=6\\), given we are in state \\(0\\) at time \\(\\zeta = 4\\). This is possible in the three ways depicted in Figure 5.6.\n\n\n\n\n\n\nFigure 5.6: Possible paths to transition from state \\(0\\) to state \\(2\\) between time points 4 and 6\n\n\n\n\nThus, \\(P_{02}(4,6) = \\textcolor{blue}{p_{00}(5)p_{02}(6)} + \\textcolor{green}{p_{01}(6)p_{12}(6)} + \\textcolor{orange}{p_{02}(5)}\\), where \\(p_{\\ell e}(\\tau)=P(E(\\tau)=e|E(\\tau -1) = \\ell)\\) are the probabilities for transitions \\(\\ell \\rightarrow e\\) between two subsequent discrete time points. Thus, in discrete time, the matrix of transition probabilities can be represented as a finite matrix product\n\\[\n\\mathbf{P}(\\zeta, \\tau) = \\prod_{j =\\zeta+1}^{\\tau}\n\\begin{pmatrix}\n  p_{00}(j) & p_{01}(j) & p_{02}(j)\\\\\n  0 & p_{11}(j) & p_{12}(j)\\\\\n  0 & 0 & 1\\\\\n  \\end{pmatrix}.\n\\tag{5.18}\\]\n\nFor the concrete example we thus have\n\\[\n\\begin{aligned}\n\\mathbf{P}(4, 6) &=\n\\begin{pmatrix}\nP_{00}(4, 6) & P_{01}(4, 6) & P_{02}(4, 6)\\\\\n        0 & P_{11}(4, 6) & P_{12}(4,6)\\\\\n        0 &         0 &         1\n\\end{pmatrix} = \\prod_{j=5}^6\n\\begin{pmatrix}\np_{00}(j) & p_{01}(j) & p_{02}(j)\\\\\n        0 & p_{11}(j) & p_{12}(j)\\\\\n        0 &         0 &         1\n\\end{pmatrix}\\\\\n            & =\n\\begin{pmatrix}\np_{00}(5) & p_{01}(5) & p_{02}(5)\\\\\n        0 & p_{11}(5) & p_{12}(5)\\\\\n        0 &         0 &         1\n\\end{pmatrix}\n\\begin{pmatrix}\np_{00}(6) & p_{01}(6) & p_{02}(6)\\\\\n        0 & p_{11}(6) & p_{12}(6)\\\\\n        0 &         0 &         1\n\\end{pmatrix}\\\\\n            &=\n\\begin{pmatrix}\np_{00}(5) p_{00}(6) & p_{00}(5)p_{01}(6) + p_{01}(5)p_{11}(6) & p_{00}(5)p_{02}(6) + p_{01}(5)p_{12}(6) + p_{02}(5)\\\\\n        0           & p_{11}(5) p_{11}(6)& p_{11}(5)p_{12}(6) + p_{12}(5)\\\\\n        0           &                  0 &         1\n\\end{pmatrix},\n\\end{aligned}\n\\]\nwhere the quantity of interest, \\(P_{02}(4, 6)\\) is given in the top right corner, but other transition probabilities are also readily available. For example, the probability to transition from state \\(1\\) to \\(2\\) between time points \\(\\zeta=4\\) and \\(\\tau=6\\) is given as \\(P_{12}(4, 6) = p_{11}(5)p_{12}(6) + p_{12}(5)\\).\nReturning to the continuous time setting where transitions can occur at any time point, ideas from the discrete time setting still hold. Imagine dividing the interval \\((\\zeta, \\tau]\\) into \\(J\\) intervals such that \\(\\zeta = t_{0} &lt; t_{1} &lt; \\cdots &lt; t_{j} &lt; \\cdots t_{J} = \\tau\\), assuming that no events occur between time points \\(t_{j} \\in \\mathbb{R}_+, j=1,\\ldots, J\\). Then Equation 5.18 still holds when replacing \\(p_{\\ell e}(j)\\) with \\(p_{\\ell e}(t_j)\\).\nIncreasing the number of intervals to infinity or equivalently, reducing the interval size to infinitesimally small intervals \\(du\\) where only one transition can be observed, leads to a product integral over the instantaneous transition probabilities \\(p_{\\ell e}(u)\\) (Equation 5.16), such that  \\[\n\\begin{aligned}\n\\mathbf{P}(\\zeta, \\tau) & = \\lim_{\\mathrm{d}u\\rightarrow 0}\\prod_{u \\in (\\zeta, \\tau]}\n  \\begin{pmatrix}\n    p_{00}(u) & \\cdots & p_{0q}(u)\\\\\n    \\vdots                  & \\ddots & \\vdots\\\\\n    p_{q0}(u)  & \\cdots & p_{qq}(u)\\\\\n  \\end{pmatrix}\n\\end{aligned}\n\\tag{5.19}\\] \n\n\n5.3.3 Instantaneous transition probabilities and hazards\nIn context of survival analysis we want to express the transition matrix (Equation 5.19) and thus instantaneous transition probabilities \\(p_{\\ell e}(u)\\) in terms of (cumulative) hazards. To do so, we use, somewhat informally, the following relationships\n\nFrom equations Equation 5.12 and Equation 5.13 we can equate the instantaneous transition probabilities to increments of the cumulative hazard (that is the increase in the cumulative hazard within a (fixed, infinitesimally) small interval \\(\\mathrm{d}u\\)): \\(dH_{\\ell e}(u) = h_{\\ell e}(u)d u = P\\big(E(u+du)=e|E(u-) = \\ell\\big) = p_{\\ell e}(u)\\),\nbecause of relationship Equation 5.15, diagonal elements (transitions into the same state) are set to \\(dH_{\\ell \\ell}(u) := -\\sum_{e \\neq \\ell} dH_{\\ell e}(u)\\) such that \\(1 + dH_{\\ell\\ell}(u) = 1-\\sum_{e \\neq \\ell} dH_{\\ell e}(u) = 1 - \\sum_{e\\neq \\ell}p_{\\ell e}(u) = p_{\\ell\\ell}(u)\\).\n\nConsequently, Equation 5.19 can be rewritten as  \\[\n\\begin{aligned}\n\\mathbf{P}(\\zeta, \\tau)\n                        &= \\lim_{\\mathrm{d}u\\rightarrow 0}\\prod_{u \\in (\\zeta, \\tau]}\n  \\begin{pmatrix}\n    p_{00}(u) = 1 + dH_{00}(u) & \\cdots & p_{0q}(u) = dH_{0q}(u)\\\\\n    \\vdots                  & \\ddots & \\vdots\\\\\n    p_{q0}(u) =  dH_{q0}(u)     & \\cdots & p_{qq}(u) = 1 + dH_{qq}(u)\\\\\n  \\end{pmatrix}\\nonumber\\\\\n  & \\ \\\\\n  & =  \\lim_{\\mathrm{d}u\\rightarrow 0}\\prod_{u \\in (\\zeta, \\tau]}(\\mathbf{I} + d\\mathbf{H}(u)),\\nonumber\\\\\n\\end{aligned}\n\\tag{5.20}\\]  where \\(\\mathbf{I}\\) is a \\((q+1) \\times (q+1)\\) identity matrix and \\(d\\mathbf{H}(u)\\) is the matrix of increments of the cumulative hazard within infinitesimally small intervals. Thus, similar to the competing risks setting, relationship Equation 5.19 implies that knowledge of the transition specific (cumulative) hazards is sufficient to fully specify the multi-state process.\nAs analytical solutions of Equation 5.19 only exist for specific models, in practice, the transition probabilities are often once again approximated numerically via a finite matrix product on a discrete time grid \\(\\zeta = t_0 &lt; t_1 &lt; \\cdots &lt; t_{J-1} &lt; t_{J} = \\tau\\)  \\[\n\\mathbf{P}(\\zeta, \\tau) \\approx \\prod_{j=1}^{J}(\\mathbf{I} + \\triangle\\mathbf{H}_{\\ell e}(t_{j})),\n\\tag{5.21}\\]  where \\(\\triangle H_{\\ell e}(t_{j}) = H_{\\ell e}(t_{j}) - H_{\\ell e}(t_{j-1})\\) is the increment of the cumulative hazards between to consecutive time points.\n\n\n5.3.4 Non-parametric estimation of transition probabilities\nFrom Equation 5.21, it follows that transition probabilities can be estimated by first computing the transition-specific cumulative hazards, \\(H_{\\ell e}(\\tau)\\). Similarly to the competing risks setting (Section 5.2.2), we can first define the transition specific hazards  \\[\nh^{d}_{\\ell e}(t_{(k)}):= \\frac{d_{\\ell e,t_{(k)}}}{n_{\\ell; t_{(k)}}},\n\\]  where\n\n\\(d_{\\ell e,t_{(k)}}\\) is the number of subjects that made the transition \\(\\ell \\rightarrow e\\) at time \\(t_{(k)}\\) and\n\\(n_{\\ell; t_{(k)}}\\) is the number of subjects in state \\(\\ell\\) immediately before \\(t_{(k)}\\).\n\nThe cumulative transition-specific hazards follow as  \\[\nH_{NA,\\ell e}(\\tau) = \\sum_{k:t_{(k)}\\leq \\tau} h^d_{\\ell e}(t_{(k)}) = \\sum_{k:t_{(k)}\\leq \\tau}\\frac{d_{\\ell e,t_{(k)}}}{n_{\\ell; t_{(k)}}},\n\\] \nand transition probabilities are obtained via Equation 5.21 as  \\[\n\\mathbf{P}(\\zeta, \\tau) = \\prod_{j=1}^{J}\\big(\\mathbf{I} + \\triangle\\mathbf{H}_{NA,\\ell e}(t_{(j)})\\big).\n\\tag{5.22}\\] \n\n\n5.3.5 Application to liver cirrhosis patients\nFor illustration, consider again the prothr data set (Table 5.2), with possible transitions summarized in Figure 5.4. In contrast to the illness-death model in Figure 5.5, back transitions are possible and some subjects already start in the “abnormal” state at the beginning of the study.\nFigure 5.7 shows the transition probabilities for the four possible transitions over time for subjects who received treatment and placebo, respectively. In this example back-transitions are possible, therefore, in contrast to the cumulative incidence functions in the competing risks setting, transition probabilities (to transient states) are not monotonously increasing over time. While the probabilities to transition from normal or abnormal state to death (\\(0 \\rightarrow 2\\), \\(1 \\rightarrow 2\\)) increase over time for both groups, probabilities for transitions between the transient states (normal to abnormal and vice versa) increase in the beginning but eventually decreases over time. Overall, prednisone doesn’t appear to have a strong protective effect. Although there appears to be a reduction in \\(0 \\rightarrow 2\\) transitions and an increase in \\(1\\rightarrow 0\\) transitions between time points \\(1000\\) and \\(3000\\), this effect doesn’t seem to persist until the end of the follow up.\n\n\n\n\n\n\nFigure 5.7: Estimated transition probabilities for the different transitions of the prothrombin data example .\n\n\n\n\n\n\n\nAalen, Odd O., and Søren Johansen. 1978. “An Empirical Transition Matrix for Non-Homogeneous Markov Chains Based on Censored Observations.” Scandinavian Journal of Statistics 5 (3): 141–50. https://www.jstor.org/stable/4615704.\n\n\nAllignol, Arthur, Jan Beyersmann, and Martin Schumacher. 2008. “Mvna an r Package for the Nelson-Aalen Estimator in Multistate Models.” R News 8 (2): 48–50.\n\n\nBeyersmann, Jan, Arthur Allignol, and Martin Schumacher. 2012. Competing Risks and Multistate Models with R. Use R! New York: Springer.\n\n\nCook, Richard J., and Jerald F. Lawless. 2007. The Statistical Analysis of Recurrent Events. Statistics for Biology and Health. New York, NY: Springer. https://doi.org/10.1007/978-0-387-69810-6.\n\n\nde Wreede, Liesbeth C., Marta Fiocco, and Hein Putter. 2011. “mstate: An R Package for the Analysis of Competing Risks and Multi-State Models.” Journal of Statistical Software 38 (7): 1–30. https://doi.org/10.18637/jss.v038.i07.",
    "crumbs": [
      "Survival Analysis and Machine Learning",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Event-history Analysis</span>"
    ]
  },
  {
    "objectID": "P1C6_survtsk.html",
    "href": "P1C6_survtsk.html",
    "title": "6  Survival Task",
    "section": "",
    "text": "6.1 Predicting Risks\nThis final section of this part of the book, brings everything together and considers the different prediction types that might be of interest in the survival analysis context and introduces the notion of a survival task more formally. Throughout this chapter let \\(\\mathcal{X}\\subseteq \\mathbb{R}^{n \\times p}\\) be the feature space.\nA general survival prediction problem is one in which (Section 3.1):\nThe process of fitting is model-dependent, and can range from non-parametric methods and maximum likelihood estimation of model parameters to machine learning approaches. The model fitting process is discussed on a high-level in Section 3.1 and concrete algorithms are discussed in Part III of this book. The different survival problems are separated by prediction types or prediction problems, which can also be thought of as predictions of different representations of \\(Y\\). We consider 4 commonly used prediction types:\nThe first three of these are referred to as deterministic as they predict a single value whereas the fourth is probabilistic and returns a full survival distribution. Definitions of these are expanded on below but first note that survival predictions differ from other fields in two respects:\nSurvival prediction problems must be clearly separated as they are inherently incompatible. For example, it is not meaningful to compare a relative risk prediction from one model to a survival distribution prediction of another. Whilst these prediction types are separated above, they can be viewed as special cases of each other. Both (1.) and (2.) may be viewed as variants of (3.); and (1.), (2.), and (3.) can all be derived from (4.); this is elaborated on below and discussed fully in Chapter 19.\nThis is a common survival problem and is defined as predicting a continuous rank for an individual’s relative risk of experiencing the event. For example, given three subjects, \\(\\{i,j,k\\}\\), a relative risk prediction may predict the risk of event as \\(\\{0.1, 0.5, 10\\}\\) respectively. From these predictions, the following types of conclusions can be drawn:\nWhilst many important conclusions can be drawn from these predictions, the values themselves have no meaning when not compared to other individuals. Interpretation of these rankings depends on the model class (for example, PH and AFT models have opposite interpretations, Chapter 13) and its parametrization or implementation in specific software. For some higher ranking implies higher risk whereas others may assume that higher ranking implies lower risk. In this book, a higher ranking will always imply a higher risk of event (as in the example above).\nPredicting rankings is the primary form of the survival ranking task, defined by predicting a continuous value, \\(g: \\mathcal{X}\\rightarrow \\mathcal{R}\\) where \\(\\mathcal{R}\\subseteq \\mathbb{R}\\).",
    "crumbs": [
      "Survival Analysis and Machine Learning",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Survival Task</span>"
    ]
  },
  {
    "objectID": "P1C6_survtsk.html#sec-survtsk-risk",
    "href": "P1C6_survtsk.html#sec-survtsk-risk",
    "title": "6  Survival Task",
    "section": "",
    "text": "Conclusions comparing subjects. For example, \\(i\\) is at the least risk; the risk of \\(j\\) is only slightly higher than that of \\(i\\) but the risk of \\(k\\) is considerably higher than \\(j\\); the corresponding ranks for \\(i,j,k,\\) are \\(1,2,3\\);\nConclusions comparing risk groups. For example, thresholding the risks at \\(1.0\\) means that \\(i\\) and \\(j\\) are in a low-risk group whilst \\(k\\) is in a high-risk group.",
    "crumbs": [
      "Survival Analysis and Machine Learning",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Survival Task</span>"
    ]
  },
  {
    "objectID": "P1C6_survtsk.html#sec-survtsk-time",
    "href": "P1C6_survtsk.html#sec-survtsk-time",
    "title": "6  Survival Task",
    "section": "6.2 Predicting Survival Times",
    "text": "6.2 Predicting Survival Times\nPredicting a time to event is the problem of predicting the expectation \\(\\hat{y}=\\mathbb{E}(Y|\\mathbf{x})\\). A time-to-event prediction is a special case of a ranking prediction as an individual with a longer survival time will have a lower overall risk: if \\(\\hat{y}_i,\\hat{y}_j\\) and \\(\\hat{r}_i,\\hat{r}_j\\) are survival time and ranking predictions for subjects \\(i\\) and \\(j\\) respectively, then \\(\\hat{y}_i &gt; \\hat{y}_j \\Rightarrow \\hat{r}_i &lt; \\hat{r}_j\\).\nFor practical purposes, the expected time-to-event would be the ideal prediction type as it is easy to interpret and communicate. However, this type of prediction is rare for multiple reasons. For one, an usuall loss based on \\(f(y_i)\\) or some difference of true and predicted value, \\(y_i-\\hat{y}_i\\) is not, suitable for censored data, as \\(y_i\\) is not observed for some observations, so direct estimation/prediction of \\(\\hat{y}_i = E(Y|\\mathbf{x}_i)\\) requires some imputation of censored observations (and evaluation on new data can also only be done on observed or imputed values).\nAlternatively, one could derive the expectation by predicting the survival distribution while taking into account the censoring and obtain a time-to-event prediction by calculating expected values, but this brings its own challenges and pitfalls (see “Survival Distribution” below for details).\nPredicting survival times is the deterministic survival task, defined by predicting a continuous value in the positive Reals and is specified by \\(g: \\mathcal{X}\\rightarrow \\mathbb{R}_{\\geq 0}\\). See Section 24.1 for practical discussion around predicting in \\(\\mathbb{R}_{\\geq 0}\\) vs. \\(\\mathbb{R}_{&gt;0}\\) and continuous vs discrete time representations. Formally, whilst this is a special case of the ranking task with \\(\\mathcal{R}\\subseteq \\mathbb{R}_{\\geq 0}\\), the distinction is important as a ‘deterministic’ prediction specifically refers to forecasting a single determined outcome with a meaningful interpretation, whereas the ‘ranking’ task is not a deterministic forecast of an event.",
    "crumbs": [
      "Survival Analysis and Machine Learning",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Survival Task</span>"
    ]
  },
  {
    "objectID": "P1C6_survtsk.html#sec-survtsk-PI",
    "href": "P1C6_survtsk.html#sec-survtsk-PI",
    "title": "6  Survival Task",
    "section": "6.3 Prognostic Index Predictions",
    "text": "6.3 Prognostic Index Predictions\nIn medical terminology (which is often used in survival analysis), a prognostic index is a tool that predicts outcomes based on risk factors. Given covariates, \\(\\mathbf{X}\\in \\mathbb{R}^{n \\times p}\\), and coefficients, \\(\\boldsymbol{\\beta}\\in \\mathbb{R}^p\\), the linear predictor is defined as \\(\\boldsymbol{\\eta}:= \\mathbf{X}\\boldsymbol{\\beta}\\). Applying some function \\(g\\), which could simply be the identity function \\(g(x) = x\\), yields a prognostic index, \\(g(\\boldsymbol{\\eta})\\). A prognostic index can serve several purposes, including:\n\nScaling or normalization – simple functions to scale the linear predictor can better support interpretation and visualisation;\nCapturing non-linear effects – for example the Cox PH model (Chapter 13) applies the transformation \\(g(\\boldsymbol{\\eta}) = \\exp(\\boldsymbol{\\eta})\\) to capture more complex relationships between features and outcomes;\nAiding in interpretability – in some cases this could simply be \\(g(\\boldsymbol{\\eta}) = -\\boldsymbol{\\eta}\\) to ensure the ‘higher value implies higher risk’ interpretation.\n\nA prognostic index is a special case of the survival ranking task, assuming that there is a one-to-one mapping between the prediction and expected survival times. Once again, it is assumed in this book that a higher value for the prognostic index implies higher risk of event.",
    "crumbs": [
      "Survival Analysis and Machine Learning",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Survival Task</span>"
    ]
  },
  {
    "objectID": "P1C6_survtsk.html#sec-survtsk-dist",
    "href": "P1C6_survtsk.html#sec-survtsk-dist",
    "title": "6  Survival Task",
    "section": "6.4 Predicting Distributions",
    "text": "6.4 Predicting Distributions\nPredicting a survival distribution refers specifically to predicting the distribution of a subject’s survival time, i.e., modelling the distribution of the event occurring over \\(\\mathbb{R}_{\\geq 0}\\). Therefore, this is seen as the probabilistic analogue to the deterministic time-to-event prediction.\nDistributional prediction can, in theory, target any of the quantities introduced in Section 4.1, but predicting \\(S(t)\\) and/or \\(h(t)\\) is most common. Hazard based approaches are particularly relevant for non- and semi-parametric estimation of the distribution, where no (or few) assumptions are made about the underlying distribution of event times.\nAs mentioned above, all prediction types can theoretically be derived from a survival distribution prediction. For example, a time-to-event prediction can be obtained via \\(E(Y|\\mathbf{x}) = \\int_0^\\infty \\hat{S}(t)\\). However, for non-parametric methods the estimated cdf is often improper in the presense of censoring and thus integration requires extrapolation of the cdf (Sonabend, Bender, and Vollmer 2022). For parametric models, the distribution of event times is fully specified once the paramers of the assumed distribution have been estimated, however, if the parameters were estimated based on only a small subset of the possible domain of \\(Y\\), this essentially still constitutes extrapolation and will in most cases yield implausible predictions. A popular alternative is therefore to estimate the restricted mean survival time (RMST; Han and Jung (2022); Andersen, Hansen, and Klein (2004)).\nPredicting survival distributions is a type of probabilistic survival task, defined by predicting a conditional distribution over the positive Reals, \\(g: \\mathcal{X}\\rightarrow \\mathcal{S}\\) where \\(\\mathcal{S}\\subseteq \\operatorname{Distr}(\\mathbb{R}_{\\geq 0})\\) is a convex set of distributions on \\(\\mathbb{R}_{\\geq 0}\\).",
    "crumbs": [
      "Survival Analysis and Machine Learning",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Survival Task</span>"
    ]
  },
  {
    "objectID": "P1C6_survtsk.html#conclusion",
    "href": "P1C6_survtsk.html#conclusion",
    "title": "6  Survival Task",
    "section": "6.5 Conclusion",
    "text": "6.5 Conclusion\n\n\n\n\n\n\nKey takeaways\n\n\n\n\nThere are three survival tasks: probabilistic, deterministic, and ranking;\nProbabilistic tasks predict a survival distribution, which is the probability of an event occurring over time;\nDeterministic tasks predict a survival time, which is a useful value but hard to estimate and evaluate in practice;\nRanking tasks predict ranks that can be compared within cohorts to identify relative risks. Predicting a prognostic index is a special case of a ranking prediction.\n\n\n\n\n\n\n\n\n\nFurther reading\n\n\n\n\n\n\n\n\n\n\n\n\nAndersen, Per Kragh, Mette Gerster Hansen, and John P. Klein. 2004. “Regression Analysis of Restricted Mean Survival Time Based on Pseudo-Observations.” Lifetime Data Analysis 10 (4): 335–50. https://doi.org/10.1007/s10985-004-4771-0.\n\n\nHan, Kyunghwa, and Inkyung Jung. 2022. “Restricted Mean Survival Time for Survival Analysis: A Quick Guide for Clinical Researchers.” Korean Journal of Radiology 23 (5): 495–99. https://doi.org/10.3348/kjr.2022.0061.\n\n\nSonabend, Raphael, Andreas Bender, and Sebastian Vollmer. 2022. “Avoiding C-hacking when evaluating survival distribution predictions with discrimination measures.” Edited by Zhiyong Lu. Bioinformatics 38 (17): 4178–84. https://doi.org/10.1093/bioinformatics/btac451.",
    "crumbs": [
      "Survival Analysis and Machine Learning",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Survival Task</span>"
    ]
  },
  {
    "objectID": "P2C7_what.html",
    "href": "P2C7_what.html",
    "title": "7  What are Survival Measures?",
    "section": "",
    "text": "7.1 Survival Measures\nIn this part of the book we discuss one of the most important parts of the machine learning workflow, model evaluation (Foss and Kotthoff 2024). In the next few chapters we will discuss different metrics that can be used to measure a model’s performance but before that we will just briefly discuss why model evaluation is so important.\nIn the simplest case, without evaluation there is no way to know if predictions from a trained machine learning model are any good. Whether one uses a simple Kaplan-Meier estimator, a complex neural network, or anything in between, there is no guarantee any of these methods will actually make useful predictions for a given dataset. This could be because the dataset is inherently difficult for any model to be trained on, perhaps because it is very ‘noisy’, or because a model is simply ill-suited to the task, for example using a Cox Proportional Hazards model when its key assumptions are violated. Evaluation is therefore crucial to trusting any predictions made from a model.\nEvaluation can be used to assess in-sample and out-of-sample performance.\nIn-sample evaluation measures the quality of a model’s ‘fit’ to data, i.e., whether the model has accurately captured relationships in the training data. However, in-sample measures often cannot be applied to complex machine learning models so this part of the book omits these measures. Readers who are interested in this are are directed to Collett (2014) and Hosmer Jr, Lemeshow, and May (2011) for discussion on residuals; Choodari-Oskooei, Royston, and Parmar (2012), Kent and O’Quigley (1988) and Royston and Sauerbrei (2004) for \\(R^2\\) type measures; and finally Volinsky and Raftery (2000), HURVICH and TSAI (1989), and Liang and Zou (2008) for information criterion measures.\nOut-of-sample measures evaluate the quality of model predictions on new and previously unseen (by the model) data. By following established statistical methods for evaluation, and ensuring that robust resampling methods are used (James et al. 2013), evaluation provides a method for estimating the ‘generalisation error’, which is the expected model performance on new datasets. This is an important concept as it provides confidence about future model performance without limiting results to the current data. Survival measures are classified into measures of:\nThese measures could also be categorised into how they evaluate predictions. Discrimination measures compare predictions pairwise where pairs of observations are created and then the predictions for these pairs are compared within and across each other in some way. Calibration measures evaluate predictions holistically by looking at some ‘average’ performance across them to provide an idea of how well suited the model is to the data. Measures of predictive performance evaluate individual predictions and usually take the sample mean of these to estimate the generalisation error.\nIn the next few chapters we categorise measures by the type of survival prediction they evaluate, which is a more natural taxonomy for selecting measures, but we use the above categories when introducing each measure.",
    "crumbs": [
      "Evaluation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>What are Survival Measures?</span>"
    ]
  },
  {
    "objectID": "P2C7_what.html#survival-measures",
    "href": "P2C7_what.html#survival-measures",
    "title": "7  What are Survival Measures?",
    "section": "",
    "text": "Discrimination (aka ‘separation’) – A model’s discriminatory power refers to how well it separates observations that are at a higher or lower risk of event. For example, a model with good discrimination will predict that (at a given time) a dead patient has a higher probability of being dead than an alive patient.\nCalibration – Calibration is a roughly defined concept (Collins et al. 2014; Harrell, Lee, and Mark 1996; Rahman et al. 2017; Van Houwelingen 2000) that generally refers to how well a model captures average relationships between predicted and observed values.\nPredictive Performance – A model is said to have good predictive performance (or sometimes ‘predictive accuracy’) if its predictions for new data are ‘close to’ the truth.",
    "crumbs": [
      "Evaluation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>What are Survival Measures?</span>"
    ]
  },
  {
    "objectID": "P2C7_what.html#how-are-models-evaluated",
    "href": "P2C7_what.html#how-are-models-evaluated",
    "title": "7  What are Survival Measures?",
    "section": "7.2 How are Models Evaluated?",
    "text": "7.2 How are Models Evaluated?\nAs well as using measures to evaluate a model’s performance on a given dataset, evaluation can also be used to measure future performance, to compare and select models, and to tune internal processes. In most cases, models should not be trained/predicted/evaluated on their own, instead a number of simpler reference models should be simultaneously trained and evaluated on the same data, which is known as a ‘benchmark experiment’. This is especially important for survival models, as all survival measures depend on the censoring distribution and therefore cannot be interpreted out of context and without comparison to other models. Benchmark experiments are used to empirically compare models across the same data and measures, meaning that if one model outperforms another then that model can be selected for future experiments (though simpler models are preferred if the performance difference is marginal). A model is usually said to ‘outperform’ another if it has a lower generalisation error.\nThe process of model evaluation is dependent on the measure itself. Measures that are ‘decomposable’ (predictive performance measures) calculate scores for individual predictions and take the sample mean over all scores, on the other hand ‘aggregate’ measures (discrimination and calibration) return a single score over all predictions. The simplest method to estimate the generalisation error is ‘holdout’ resampling, where a dataset \\(\\mathcal{D}\\) is split into non-overlapping subsets for training \\(\\mathcal{D}_{train}\\) and testing \\(\\mathcal{D}_{test}\\). The model is trained on \\(\\mathcal{D}_{train}\\) and predictions, \\(\\hat{\\mathbf{y}}\\) are made based on the features in \\(\\mathcal{D}_{test}\\). The model is evaluated by using a measure, \\(L\\), to compare the predictions to the observed data in the test set, \\(L(\\mathbf{y}_{test}, \\hat{\\mathbf{y}})\\).\nWhere possible, (repeated) k-fold cross-validation (kCV) should be used for more robust estimation of the generalisation error and for model comparison. In kCV, the data is partitioned into \\(k\\) folds (often \\(k\\) is \\(5\\) or \\(10\\)), which are non-overlapping subsets. A model is trained on \\(k-1\\) folds and evaluated on the \\(k\\)th fold, this process is repeated until each of the \\(k\\) folds has acted as the test set exactly once, the computed loss from each iteration is averaged into the final loss, which provides a good estimate of the generalisation error.\nFor the rest of this part of the book we will introduce different survival measures, discuss their advantages and disadvantages, and in Chapter 12 we will provide some recommendations for choosing measures. We will not discuss the general process of model resampling or evaluation further but recommend Casalicchio and Burk (2024) to readers interested in this topic.\n\n\n\n\n\nCasalicchio, Giuseppe, and Lukas Burk. 2024. “Evaluation and Benchmarking.” In Applied Machine Learning Using mlr3 in R, edited by Bernd Bischl, Raphael Sonabend, Lars Kotthoff, and Michel Lang. CRC Press. https://mlr3book.mlr-org.com/chapters/chapter3/evaluation_and_benchmarking.html.\n\n\nChoodari-Oskooei, Babak, Patrick Royston, and Mahesh K. B. Parmar. 2012. “A simulation study of predictive ability measures in a survival model I: Explained variation measures.” Statistics in Medicine 31 (23): 2627–43. https://doi.org/10.1002/sim.4242.\n\n\nCollett, David. 2014. Modelling Survival Data in Medical Research. 3rd ed. CRC.\n\n\nCollins, Gary S., Joris A. De Groot, Susan Dutton, Omar Omar, Milensu Shanyinde, Abdelouahid Tajar, Merryn Voysey, et al. 2014. “External validation of multivariable prediction models: A systematic review of methodological conduct and reporting.” BMC Medical Research Methodology 14 (1): 1–11. https://doi.org/10.1186/1471-2288-14-40.\n\n\nFoss, Natalie, and Lars Kotthoff. 2024. “Data and Basic Modeling.” In Applied Machine Learning Using mlr3 in R, edited by Bernd Bischl, Raphael Sonabend, Lars Kotthoff, and Michel Lang. CRC Press. https://mlr3book.mlr-org.com/data_and_basic_modeling.html.\n\n\nHarrell, Frank E., Kerry L. Lee, and Daniel B. Mark. 1996. “Multivariable Prognostic Models: Issues in Developing Models, Evaluating Assumptions and Adequacy, and Measuring and Reducing Errors.” Statistics in Medicine 15: 361–87. https://doi.org/10.1002/0470023678.ch2b(i).\n\n\nHosmer Jr, David W, Stanley Lemeshow, and Susanne May. 2011. Applied survival analysis: regression modeling of time-to-event data. Vol. 618. John Wiley & Sons.\n\n\nHURVICH, CLIFFORD M, and CHIH-LING TSAI. 1989. “Regression and time series model selection in small samples.” Biometrika 76 (2): 297–307. https://doi.org/10.1093/biomet/76.2.297.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. An introduction to statistical learning. Vol. 112. New York: Springer.\n\n\nKent, John T., and John O’Quigley. 1988. “Measures of dependence for censored survival data.” Biometrika 75 (3): 525–34. https://doi.org/10.1093/biomet/75.3.525.\n\n\nLiang, Hua, and Guohua Zou. 2008. “Improved AIC Selection Strategy for Survival Analysis.” Computational Statistics & Data Analysis 52 (5): 2538–48. https://doi.org/10.1016/j.csda.2007.09.003.\n\n\nRahman, M. Shafiqur, Gareth Ambler, Babak Choodari-Oskooei, and Rumana Z. Omar. 2017. “Review and evaluation of performance measures for survival prediction models in external validation settings.” BMC Medical Research Methodology 17 (1): 1–15. https://doi.org/10.1186/s12874-017-0336-2.\n\n\nRoyston, Patrick, and Willi Sauerbrei. 2004. “A new measure of prognostic separation in survival data.” Statistics in Medicine 23 (5): 723–48. https://doi.org/10.1002/sim.1621.\n\n\nVan Houwelingen, Hans C. 2000. “Validation, calibration, revision and combination of prognostic survival models.” Statistics in Medicine 19 (24): 3401–15. https://doi.org/10.1002/1097-0258(20001230)19:24&lt;3401::AID-SIM554&gt;3.0.CO;2-2.\n\n\nVolinsky, Chris T, and Adrian E Raftery. 2000. “Bayesian Information Criterion for Censored Survival Models.” International Biometric Society 56 (1): 256–62.",
    "crumbs": [
      "Evaluation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>What are Survival Measures?</span>"
    ]
  },
  {
    "objectID": "P2C8_rank.html",
    "href": "P2C8_rank.html",
    "title": "8  Discrimination Measures",
    "section": "",
    "text": "8.1 Time-Independent Measures\nThe next measures discused are ‘discrimination measures’, which evaluate how well models separate observations into different risk groups. A model is said to have good discrimination if it correctly predicts that one observation is at higher risk of the event of interest than another, where the prediction is ‘correct’ if the observation predicted to be at higher risk does indeed experience the event sooner.\nIn the survival setting, the ‘risk’ is taken to be the continuous ranking prediction. All discrimination measures are ranking measures, which means that the exact predicted value is irrelevant, only its relative ordering is required. For example given predictions \\(\\{100,2,299.3\\}\\), only their rankings, \\(\\{2,1,3\\}\\), are used by measures of discrimination.\nThis chapter begins with time-independent measures (Section 8.1), which measure concordance between pairs of observations at a single observed time point. The next section focuses on time-dependent measures (Section 8.2), which are primarily AUC-type measures that evaluate discrimination over all possible unique time-points and integrate the results for a single metric.\nThe simplest form of discrimination measures are concordance indices, which, in general, measure the proportion of cases in which the model correctly ranks a pair of observations according to their risk. These measures may be best understood in terms of two key definitions: ‘comparable’, and ‘concordant’.\nNote that this book defines risk rankings such that a higher value implies higher risk of event and thus lower expected survival time (?sec-surv-set-types), hence a pair is concordant if \\(\\mathbb{I}(t_i &lt; t_j, r_i &gt; r_j)\\). Other sources may instead assume that higher values imply lower risk of event and hence a pair would be concordant if \\(\\mathbb{I}(t_i &lt; t_j, r_i &lt; r_j)\\).\nConcordance measures then estimate the probability of a pair being concordant, given that they are comparable:\n\\[\nP(r_i &gt; r_j | t_i &lt; t_j \\cap \\delta_i)\n\\]\nThese measures are referred to as time independent when \\(r_i,r_j\\) is not a function of time as once the observations are organised into comparable pairs, the observed survival times can be ignored. The time-dependent case is covered in Section 8.2.1.\nWhile various definitions of a ‘Concordance index’ (C-index) exist (discussed in the next section), they all represent a weighted proportion of the number of concordant pairs over the number of comparable pairs. As such, a C-index value will always be between \\([0, 1]\\) with \\(1\\) indicating perfect separation, \\(0.5\\) indicating no separation, and \\(0\\) being separation in the ‘wrong direction’, i.e. all high risk observations being ranked lower than all low risk observations.\nConcordance measures may either be reported as a value in \\([0,1]\\), a percentage, or as ‘discriminatory power’, which refers to the percentage improvement of a model’s discrimination above the baseline value of \\(0.5\\). For example, if a model has a concordance of \\(0.8\\) then its discriminatory power is \\((0.8-0.5)/0.5 = 60\\%\\). This representation of discrimination provides more information by encoding the model’s improvement over some baseline although is often confused with reporting concordance as a percentage (e.g. reporting a concordance of 0.8 as 80%). In theory this representation could result in a negative value, however this would indicate that \\(C&lt;0.5\\), which would indicate serious problems with the model that should be addressed before proceeding with further analysis. Representing measures as a percentage over a baseline is a common method to improve measure interpretability and closely relates to the ERV representation of scoring rules (Section 10.4).",
    "crumbs": [
      "Evaluation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Discrimination Measures</span>"
    ]
  },
  {
    "objectID": "P2C8_rank.html#sec-eval-crank-disc-conc",
    "href": "P2C8_rank.html#sec-eval-crank-disc-conc",
    "title": "8  Discrimination Measures",
    "section": "",
    "text": "Definition 8.1 (Concordance) Let \\((i,j)\\) be a pair of observations with outcomes \\(\\{(t_i,\\delta_i),(t_j,\\delta_j)\\}\\) and let \\(r_i,r_j \\in \\mathbb{R}\\) be their respective risk predictions. Then \\((i,j)\\) are called (F. E. J. Harrell et al. 1984; F. E. Harrell, Califf, and Pryor 1982):\n\nComparable if \\(t_i &lt; t_j\\) and \\(\\delta_i = 1\\);\nConcordant if \\(r_i &gt; r_j\\).\n\n\n\n\n\n\n\n\n\n8.1.1 Concordance Indices\nCommon concordance indices in survival analysis can be expressed as a general measure:\nLet \\(\\boldsymbol{\\hat{r}} = ({\\hat{r}}_1 \\ {\\hat{r}}_2 \\cdots {\\hat{r}}_{m})^\\top\\) be predicted risks, \\((\\mathbf{t}, \\boldsymbol{\\delta}) = ((t_1, \\delta_1) \\ (t_2, \\delta_2) \\cdots (t_m, \\delta_m))^\\top\\) be observed outcomes, let \\(W\\) be some weighting function, and let \\(\\tau\\) be a cut-off time. Then, the time-independent (‘ind’) survival concordance index is defined by,\n\\[\nC_{ind}(\\hat{\\mathbf{r}}, \\mathbf{t}, \\boldsymbol{\\delta}|\\tau) = \\frac{\\sum_{i\\neq j} W(t_i)\\mathbb{I}(t_i &lt; t_j, \\hat{r}_i &gt; \\hat{r}_j, t_i &lt; \\tau)\\delta_i}{\\sum_{i\\neq j}W(t_i)\\mathbb{I}(t_i &lt; t_j, t_i &lt; \\tau)\\delta_i}\n\\]\nThe choice of \\(W\\) specifies a particular variation of the c-index (see below). The use of the cut-off \\(\\tau\\) mitigates against decreased sample size (and therefore high variance) over time due to the removal of censored observations (see Figure 8.1)). For \\(\\tau\\) to be comparable across datasets, a common choice would be to set \\(\\tau\\) as the time at which 80%, or perhaps 90% of the data have been censored or experienced the event.\nThere are multiple methods for dealing with tied predictions and times. Strictly, tied times are incomparable given the definition of ‘comparable’ given above and hence are usually ignored in the numerator. On the other hand, ties in the prediction are more problematic but a common method is to set a value of \\(0.5\\) for observations when \\(r_i = r_j\\) (Therneau and Atkinson 2020). Specific concordance indices can be constructed by assigning a weighting scheme for \\(W\\) which generally depends on the Kaplan-Meier estimate of the survival function of the censoring distribution fit on training data, \\(\\hat{G}_{KM}\\), or the Kaplan-Meier estimate for the survival function of the survival distribution fit on training data, \\(\\hat{S}_{KM}\\), or both. Measures that use \\(\\hat{G}_{KM}\\) are referred to as Inverse Probability of Censoring Weighted (IPCW) measures as the estimated censoring distribution is utilised to weight the measure in order to compensate for removed censored observations. This is visualised in Figure 8.1 where \\(\\hat{G}_{KM}\\), \\(\\hat{G}_{KM}^{-2}\\), and \\(\\hat{S}_{KM}\\) are computed based on the whas dataset (Hosmer Jr, Lemeshow, and May 2011).\n\n\n\n\n\n\nFigure 8.1: Weighting functions obtained on the whas dataset. x-axis is follow-up time. y-axis is outputs from one of three weighting functions: \\(\\hat{G}_{KM}\\), survival function based on the censoring distribution of the whas dataset (red), and \\(\\hat{G}_{KM}^{-2}\\) (green), \\(\\hat{S}_{KM}\\), marginal survival function based on original whas dataset (blue), . The vertical gray line at \\(t = \\tau=1267\\) represents the point at which \\(\\hat{G}(t)&lt;0.6\\).\n\n\n\nThe following weights have been proposed for the concordance index:\n\n\\(W(t_i) = 1\\): Harrell’s concordance index, \\(C_H\\) (F. E. J. Harrell et al. 1984; F. E. Harrell, Califf, and Pryor 1982), which is widely accepted to be the most common survival measure and imposes no weighting on the definition of concordance. The original measure given by Harrell has no cut-off, \\(\\tau = \\infty\\), however applying a cut-off is now more widely accepted in practice.\n\\(W(t_i) = [\\hat{G}_{KM}(t_i)]^{-2}\\): Uno’s C, \\(C_U\\) (Uno et al. 2011).\n\\(W(t_i) = [\\hat{G}_{KM}(t_i)]^{-1}\\)\n\\(W(t_i) = \\hat{S}_{KM}(t_i)\\)\n\\(W(t_i) = \\hat{S}_{KM}(t_i)/\\hat{G}_{KM}(t_i)\\)\n\nAll methods assume that censoring is conditionally-independent of the event given the features (?sec-surv-set-cens), otherwise weighting by \\(\\hat{S}_{KM}\\) or \\(\\hat{G}_{KM}\\) would not be applicable. It is assumed here that \\(\\hat{S}_{KM}\\) and \\(\\hat{G}_{KM}\\) are estimated on the training data and not the testing data (though the latter may be seen in some implementations, e.g. Therneau (2015)).\n\n\n8.1.2 Choosing a C-index\nWith multiple choices of weighting available, choosing a specific measure might seem daunting. Matters are only made worse by debate in the literature, reflecting uncertainty in measure choice and interpretation. In practice, when a suitable cut-of \\(\\tau\\) is chosen, all these weightings perform very similarly (Rahman et al. 2017; Schmid and Potapov 2012). For example, Table 8.1 uses the whas data again to compare Harrell’s C with measures that include IPCW weighting, when no cutoff is applied (top row) and when a cutoff is applied when \\(\\hat{G}(t)=0.6\\) (grey line in Figure 8.1). The results are almost identical when the cutoff is applied but still not massively different without the cutoff.\n\n\n\n\nTable 8.1: Comparing C-index measures (calculated on the whas dataset using a Cox model with three-fold cross-validation) with no cut-off (top) and a cut-off when \\(\\hat{G}(t)=0.6\\) (bottom). First column is Harrell’s C, second is the weighting \\(1/\\hat{G}(t)\\), third is Uno’s C.\n\n\n\n\n\n\n\\(W=1\\)\n\\(W= G^{-1}\\)\n\\(W=G^{-2}\\)\n\n\n\n\n\\(\\tau=\\infty\\)\n0.74\n0.73\n0.71\n\n\n\\(\\tau=1267\\)\n0.76\n0.75\n0.75\n\n\n\n\n\n\nOn the other hand, if a poor choice is selected for \\(\\tau\\) (cutting off too late) then IPCW measures can be highly unstable (Rahman et al. 2017), for example the variance of Uno’s C drastically increases with increased censoring (Schmid and Potapov 2012).\nIn practice, all C-index metrics provide an intuitive measure of discrimination and as such the choice of C-index is less important than the transparency in reporting. ‘C-hacking’ (R. Sonabend, Bender, and Vollmer 2022) is the deliberate, unethical procedure of calculating multiple C-indices and to selectively report one or more results to promote a particular model or result, whilst ignoring any negative findings. For example, calculating Harrell’s C and Uno’s C but only reporting the measure that shows a particular model of interest is better than another (even if the other metric shows the reverse effect). To avoid ‘C-hacking’:\n\nthe choice of C-index should be made before experiments have begun and the choice of C-index should be clearly reported;\nwhen ranking predictions are composed (Chapter 19) from distribution predictions, the composition method should be chosen and clearly described before experiments have begun.\n\nAs the C-index is highly dependent on censoring within a dataset, C-index values between experiments are not directly comparable, instead comparisons are limited to comparing model rankings, for example conclusions such as “model A outperformed model B with respect to Harrell’s C in this experiment”.",
    "crumbs": [
      "Evaluation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Discrimination Measures</span>"
    ]
  },
  {
    "objectID": "P2C8_rank.html#sec-eval-crank-timedep",
    "href": "P2C8_rank.html#sec-eval-crank-timedep",
    "title": "8  Discrimination Measures",
    "section": "8.2 Time-Dependent Measures",
    "text": "8.2 Time-Dependent Measures\nIn the time-dependent case, where the metrics are computed based on specific survival times, the majority of measures are based on the Area Under the Curve, with one exception which is a simpler concordance index.\n\n8.2.1 Concordance Indices\nIn contrast to the measures described above, Antolini’s C (Antolini, Boracchi, and Biganzoli 2005) provides a time-dependent (‘dep’) formula for the concordance index. The definition of ‘comparable’ is the same for Antolini’s C, however, concordance is now determined using the individual predicted survival probabilities calculated at the smaller event time in the pair:\n\\[\nP(\\hat{S}_i(t_i) &lt; \\hat{S}_j(t_i) | t_i &lt; t_j \\cap \\delta_i)\n\\]\nNote that observations are concordant when \\(\\hat{S}_i(t_i) &lt; \\hat{S}_j(t_i)\\) as at the time \\(t_i\\), observation \\(i\\) has experienced the event and observation \\(j\\) has not, hence the expected survival probability for \\(\\hat{S}_i(t_i)\\) should be as close to 0 as possible (noting inherent randomness may prevent the perfect \\(\\hat{S}_i(t_i)=0\\) prediction) but otherwise should be less than \\(\\hat{S}_j(t_i)\\) as \\(j\\) is still ‘alive’. Once again this probability is estimated with a metric that could include a cut-off and different weighting schemes (though this is not included in Antolini’s original definition):\n\\[\nC_{dep}(\\hat{\\mathbf{S}}, \\mathbf{t}, \\boldsymbol{\\delta}|\\tau) = \\frac{\\sum_{i\\neq j} W(t_i)\\mathbb{I}(t_i &lt; t_j, \\hat{S}_i(t_i) &lt; \\hat{S}_j(t_i), t_i &lt; \\tau)\\delta_i}{\\sum_{i\\neq j}W(t_i)\\mathbb{I}(t_i &lt; t_j, t_i &lt; \\tau)\\delta_i}\n\\]\nwhere \\(\\boldsymbol{\\hat{S}} = ({\\hat{S}}_1 \\ {\\hat{S}}_2 \\cdots {\\hat{S}}_{m})^\\top\\).\nAntolini’s C provides an intuitive method to evaluate the discrimination of a model based on distribution predictions without depending on compositions to ranking predictions.\n\n\n8.2.2 Area Under the Curve\n\n\n\n\n\n\nWarning\n\n\n\nWe are still discussing how to structure and write this section so the contents are all subject to change. The text below is ‘correct’ but we want to add more detail about estimation of AUC so the book can be more practical, otherwise we may remove the section completely, let us know your thoughts about what you’d like to see here!\n\n\nAUC, or AUROC, measures calculate the Area Under the Receiver Operating Characteristic (ROC) Curve, which is a plot of the sensitivity (or true positive rate (TPR)) against \\(1 - \\textit{specificity}\\) (or true negative rate (TNR)) at varying thresholds (described below) for the predicted probability (or risk) of event. Figure 8.2 visualises ROC curves for two classification models. The blue line is a featureless baseline that has no discrimination. The red line is a decision tree with better discrimination as it comes closer to the top-left corner.\n\n\n\n\n\n\nFigure 8.2: ROC Curves for a classification example. Red is a decision tree with good discrimination as it ‘hugs’ the top-left corner. Blue is a featureless baseline with no discrimination as it sits on \\(y = x\\).\n\n\n\nIn a classification setting with no censoring, the AUC has the same interpretation as Harrell’s C (Uno et al. 2011). AUC measures for survival analysis were developed to provide a time-dependent measure of discriminatory ability (Patrick J. Heagerty, Lumley, and Pepe 2000). In a survival setting it can reasonably be expected for a model to perform differently over time and therefore time-dependent measures are advantageous. Computation of AUC estimators is complex and as such there are limited accessible metrics available off-shelf. There is limited evidence of these estimators used in the literature, hence discussion of these measures is kept brief.\nThe AUC, TPR, and TNR are derived from the confusion matrix in a binary classification setting. Let \\(b_i,\\hat{b}_i \\in \\{0, 1\\}\\) be the true and predicted binary outcomes respectively for some observation \\(i\\). The confusion matrix is then given by:\n\n\n\n\n\\(b_i = 1\\)\n\\(b_i = 0\\)\n\n\n\\(\\hat{b}_i = 1\\)\nTP\nFP\n\n\n\\(\\hat{b}_i = 0\\)\nFN\nTN\n\n\n\nwhere \\(TN := \\sum_i \\mathbb{I}(b_i = 0, \\hat{b}_i = 0)\\) is the number of true negatives, \\(TP := \\sum_i \\mathbb{I}(b_i = 1, \\hat{b}_i = 1)\\) is the number true positives, \\(FP := \\sum_i \\mathbb{I}(b_i = 0, \\hat{b}_i = 1)\\) is the number of false positives, and \\(FN := \\sum_i \\mathbb{I}(b_i = 1, \\hat{b}_i = 0)\\) is the number of false negatives. From these are derived\n\\[\n\\begin{aligned}\n& TPR := \\frac{TP}{TP + FN} \\\\\n& TNR := \\frac{TN}{TN + FP}\n\\end{aligned}\n\\]\nIn classification, a probabilistic prediction of an event can be thresholded to obtain a deterministic prediction. For a predicted \\(\\hat{p} := \\hat{P}(b = 1)\\), and threshold \\(\\alpha\\), the thresholded binary prediction is \\(\\hat{b} := \\mathbb{I}(\\hat{p} &gt; \\alpha)\\). This is achieved in survival analysis by thresholding the linear predictor at a given time for different values of the threshold and different values of the time. All measures of TPR, TNR and AUC are in the range \\([0,1]\\) with larger values preferred.\nWeighting the linear predictor was proposed by Uno \\(\\textit{et al.}\\) (2007) (Uno et al. 2007) and provides a method for estimating TPR and TNR via\n\\[\n\\begin{split}\n&TPR_U(\\hat{\\boldsymbol{\\eta}}, \\mathbf{t}, \\boldsymbol{\\delta}| \\tau, \\alpha) =  \\frac{\\sum^m_{i=1} \\delta_i \\mathbb{I}(k(\\hat{\\eta}_i) &gt; \\alpha, t_i \\leq \\tau)[\\hat{G}_{KM}(t_i)]^{-1}}{\\sum^m_{i=1}\\delta_i\\mathbb{I}(t_i \\leq \\tau)[\\hat{G}_{KM}(t_i)]^{-1}}\n\\end{split}\n\\]\nand\n\\[\n\\begin{split}\n&TNR_U(\\hat{\\boldsymbol{\\eta}}, \\mathbf{t}| \\tau, \\alpha) \\mapsto \\frac{\\sum^m_{i=1} \\mathbb{I}(k(\\hat{\\eta}_i) \\leq \\alpha, t_i &gt; \\tau)}{\\sum^m_{i=1}\\mathbb{I}(t_i &gt; \\tau)}\n\\end{split}\n\\] where \\(\\boldsymbol{\\hat{\\eta}} = ({\\hat{\\eta}}_1 \\ {\\hat{\\eta}}_2 \\cdots {\\hat{\\eta}}_{m})^\\top\\) is a vector of predicted linear predictors, \\(\\tau\\) is the time at which to evaluate the measure, \\(\\alpha\\) is a cut-off for the linear predictor, and \\(k\\) is a known, strictly increasing, differentiable function. \\(k\\) is chosen depending on the model choice, for example if the fitted model is PH then \\(k(x) = 1 - \\exp(-\\exp(x))\\) (Uno et al. 2007). Similarities can be drawn between these equations and Uno’s concordance index, in particular the use of IPCW. Censoring is again assumed to be at least random once conditioned on features. Plotting \\(TPR_U\\) against \\(1 - TNR_U\\) for varying values of \\(\\alpha\\) provides the ROC.\nThe second method, which appears to be more prominent in the literature, is derived from Heagerty and Zheng (2005) (Patrick J. Heagerty and Zheng 2005). They define four distinct classes, in which observations are split into controls and cases.\nAn observation is a case at a given time-point if they are dead, otherwise they are a control. These definitions imply that all observations begin as controls and (hypothetically) become cases over time. Cases are then split into incident or cumulative and controls are split into static or dynamic. The choice between modelling static or dynamic controls is dependent on the question of interest. Modelling static controls implies that a ‘subject does not change disease status’ (Patrick J. Heagerty and Zheng 2005), and few methods have been developed for this setting (Kamarudin, Cox, and Kolamunnage-Dona 2017), as such the focus here is on dynamic controls. The incident/cumulative cases choice is discussed in more detail below.1\n1 All measures discussed in this section evaluate model discrimination from ‘markers’, which may be a predictive marker (model predictions) or a prognostic marker (a single covariate). This section always defines a marker as a ranking prediction, which is valid for all measures discussed here with the exception of one given at the end.The TNR for dynamic cases is defined as\n\\[\nTNR_D(\\hat{\\mathbf{r}}, N | \\alpha, \\tau) = P(\\hat{r}_i \\leq \\alpha | N_i(\\tau) = 0)\n\\] where \\(\\boldsymbol{\\hat{r}} = ({\\hat{r}}_1 \\ {\\hat{r}}_2 \\cdots {\\hat{r}}_{n})^\\top\\) is some deterministic prediction and \\(N(\\tau)\\) is a count of the number of events in \\([0,\\tau)\\). Heagerty and Zheng further specify \\(y\\) to be the predicted linear predictor \\(\\hat{\\eta}\\). Cumulative/dynamic and incident/dynamic measures are available in software packages ‘off-shelf’, these are respectively defined by\n\\[\nTPR_C(\\hat{\\mathbf{r}}, N | \\alpha, \\tau) = P(\\hat{r}_i &gt; \\alpha | N_i(\\tau) = 1)\n\\] and\n\\[\nTPR_I(\\hat{\\mathbf{r}}, N | \\alpha, \\tau) = P(\\hat{r}_i &gt; \\alpha | dN_i(\\tau) = 1)\n\\] where \\(dN_i(\\tau) = N_i(\\tau) - N_i(\\tau-)\\). Practical estimation of these quantities is not discussed here.\nThe choice between the incident/dynamic (I/D) and cumulative/dynamic (C/D) measures primarily relates to the use-case. The C/D measures are preferred if a specific time-point is of interest (Patrick J. Heagerty and Zheng 2005) and is implemented in several applications for this purpose (Kamarudin, Cox, and Kolamunnage-Dona 2017). The I/D measures are preferred when the true survival time is known and discrimination is desired at the given event time (Patrick J. Heagerty and Zheng 2005).\nDefining a time-specific AUC is now possible with\n\\[\nAUC(\\hat{\\mathbf{r}}, N | \\tau) = \\int^1_0 TPR(\\hat{\\mathbf{r}}, N | 1 - TNR^{-1}(p|\\tau), \\tau) \\ dp\n\\]\nFinally, integrating over all time-points produces a time-dependent AUC and as usual a cut-off is applied for the upper limit,\n\\[\nAUC^*(\\hat{\\mathbf{r}},N|\\tau^*) = \\int^{\\tau^*}_0 AUC(\\hat{\\mathbf{r}},N|\\tau)\\frac{2\\hat{p}_{KM}(\\tau)\\hat{S}_{KM}(\\tau)}{1 - \\hat{S}_{KM}^2(\\tau^*)} \\ d\\tau\n\\] where \\(\\hat{S}_{KM},\\hat{p}_{KM}\\) are survival and mass functions estimated with a Kaplan-Meier model on training data.\nSince Heagerty and Zheng’s paper, other methods for calculating the time-dependent AUC have been devised, including by Chambless and Diao (Chambless and Diao 2006), Song and Zhou (Song and Zhou 2008), and Hung and Chiang (Hung and Chiang 2010). These either stem from the Heagerty and Zheng paper or ignore the case/control distinction and derive the AUC via different estimation methods of TPR and TNR. Blanche \\(\\textit{et al.}\\) (2012) (Blanche, Latouche, and Viallon 2012) surveyed these and concluded ‘’regarding the choice of the retained definition for cases and controls, no clear guidance has really emerged in the literature’‘, but agree with Heagerty and Zeng on the use of C/D for clinical trials and I/D for ’pure’ evaluation of the marker. Blanche \\(\\textit{et al.}\\) (2013) (Blanche, Dartigues, and Jacqmin-Gadda 2013) published a survey of C/D AUC measures with an emphasis on non-parametric estimators with marker-dependent censoring, including their own Conditional IPCW (CIPCW) AUC, which is not discussed further here as it cannot be used for evaluating predictions (R. E. B. Sonabend 2021).\nReviews of AUC measures have produced (sometimes markedly) different results (Blanche, Latouche, and Viallon 2012; Li, Greene, and Hu 2018; Kamarudin, Cox, and Kolamunnage-Dona 2017) with no clear consensus on how and when these measures should be used. The primary advantage of these measures is to extend discrimination metrics to be time-dependent. However, it is unclear how to interpret a threshold of a linear predictor and moreover if this is even the ‘correct’ quantity to threshold, especially when survival distribution predictions are the more natural object to evaluate over time.\n\n\n\n\nAntolini, Laura, Patrizia Boracchi, and Elia Biganzoli. 2005. “A time-dependent discrimination index for survival data.” Statistics in Medicine 24 (24): 3927–44. https://doi.org/10.1002/sim.2427.\n\n\nBlanche, Paul, Jean-François Dartigues, and Hélène Jacqmin-Gadda. 2013. “Review and comparison of ROC curve estimators for a time-dependent outcome with marker-dependent censoring.” Biometrical Journal 55 (5): 687–704. https://doi.org/10.1002/bimj.201200045.\n\n\nBlanche, Paul, Aurélien Latouche, and Vivian Viallon. 2012. “Time-dependent AUC with right-censored data: a survey study,” October. https://doi.org/10.1007/978-1-4614-8981-8_11.\n\n\nChambless, Lloyd E, and Guoqing Diao. 2006. “Estimation of time-dependent area under the ROC curve for long-term risk prediction.” Statistics in Medicine 25 (20): 3474–86. https://doi.org/10.1002/sim.2299.\n\n\nHarrell, F E Jr, K L Lee, R M Califf, D B Pryor, and R A Rosati. 1984. “Regression modelling strategies for improved prognostic prediction.” Statistics in Medicine 3 (2): 143–52. https://doi.org/10.1002/sim.4780030207.\n\n\nHarrell, Frank E., Robert M. Califf, and David B. Pryor. 1982. “Evaluating the yield of medical tests.” JAMA 247 (18): 2543–46. http://dx.doi.org/10.1001/jama.1982.03320430047030.\n\n\nHeagerty, Patrick J., Thomas Lumley, and Margaret S. Pepe. 2000. “Time-Dependent ROC Curves for Censored Survival Data and a Diagnostic Marker.” Biometrics 56 (2): 337–44. https://doi.org/10.1111/j.0006-341X.2000.00337.x.\n\n\nHeagerty, Patrick J, and Yingye Zheng. 2005. “Survival Model Predictive Accuracy and ROC Curves.” Biometrics 61 (1): 92–105. https://doi.org/10.1111/j.0006-341X.2005.030814.x.\n\n\nHosmer Jr, David W, Stanley Lemeshow, and Susanne May. 2011. Applied survival analysis: regression modeling of time-to-event data. Vol. 618. John Wiley & Sons.\n\n\nHung, Hung, and Chin-Tsang Chiang. 2010. “Estimation methods for time-dependent AUC models with survival data.” The Canadian Journal of Statistics / La Revue Canadienne de Statistique 38 (1): 8–26. http://www.jstor.org/stable/27805213.\n\n\nKamarudin, Adina Najwa, Trevor Cox, and Ruwanthi Kolamunnage-Dona. 2017. “Time-dependent ROC curve analysis in medical research: Current methods and applications.” BMC Medical Research Methodology 17 (1): 1–19. https://doi.org/10.1186/s12874-017-0332-6.\n\n\nLi, Liang, Tom Greene, and Bo Hu. 2018. “A simple method to estimate the time-dependent receiver operating characteristic curve and the area under the curve with right censored data.” Statistical Methods in Medical Research 27 (8): 2264–78. https://doi.org/10.1177/0962280216680239.\n\n\nRahman, M. Shafiqur, Gareth Ambler, Babak Choodari-Oskooei, and Rumana Z. Omar. 2017. “Review and evaluation of performance measures for survival prediction models in external validation settings.” BMC Medical Research Methodology 17 (1): 1–15. https://doi.org/10.1186/s12874-017-0336-2.\n\n\nSchmid, Matthias, and Sergej Potapov. 2012. “A comparison of estimators to evaluate the discriminatory power of time-to-event models.” Statistics in Medicine 31 (23): 2588–2609. https://doi.org/10.1002/sim.5464.\n\n\nSonabend, Raphael Edward Benjamin. 2021. “A Theoretical and Methodological Framework for Machine Learning in Survival Analysis: Enabling Transparent and Accessible Predictive Modelling on Right-Censored Time-to-Event Data.” PhD, University College London (UCL). https://discovery.ucl.ac.uk/id/eprint/10129352/.\n\n\nSonabend, Raphael, Andreas Bender, and Sebastian Vollmer. 2022. “Avoiding C-hacking when evaluating survival distribution predictions with discrimination measures.” Edited by Zhiyong Lu. Bioinformatics 38 (17): 4178–84. https://doi.org/10.1093/bioinformatics/btac451.\n\n\nSong, Xiao, and Xiao-Hua Zhou. 2008. “A semiparametric approach for the covariate specific ROC curve with survival outcome.” Statistica Sinica 18 (July): 947–65.\n\n\nTherneau, Terry M. 2015. “A Package for Survival Analysis in S.” https://cran.r-project.org/package=survival.\n\n\nTherneau, Terry M., and Elizabeth Atkinson. 2020. “Concordance.” https://cran.r-project.org/web/packages/survival/vignettes/concordance.pdf.\n\n\nUno, Hajime, Tianxi Cai, Michael J. Pencina, Ralph B. D’Agostino, and L J Wei. 2011. “On the C-statistics for Evaluating Overall Adequacy of Risk Prediction Procedures with Censored Survival Data.” Statistics in Medicine 30 (10): 1105–17. https://doi.org/10.1002/sim.4154.\n\n\nUno, Hajime, Tianxi Cai, Lu Tian, and L J Wei. 2007. “Evaluating Prediction Rules for t-Year Survivors with Censored Regression Models.” Journal of the American Statistical Association 102 (478): 527–37. http://www.jstor.org/stable/27639883.",
    "crumbs": [
      "Evaluation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Discrimination Measures</span>"
    ]
  },
  {
    "objectID": "P2C9_calib.html",
    "href": "P2C9_calib.html",
    "title": "9  Calibration Measures",
    "section": "",
    "text": "9.1 Point Calibration\nCalibration measures evaluate the ‘average’ quality of survival distribution predictions. This chapter is kept relatively short as the literature in this area is scarce (Rahman et al. 2017), this is likely due to the meaning of calibration being unclear in a survival context (Van Houwelingen 2000). However the meaning of calibration is better specified once specific metrics are introduced. As with other measure classes, only measures that can generalise beyond Cox PH models are included here but note that several calibration measures for re-calibrating PH models have been discussed in the literature (Demler, Paynter, and Cook 2015; Van Houwelingen 2000).\nCalibration measures can be grouped (Andres et al. 2018) into those that evaluate distributions at a single time-point, ‘1-Calibration’ or ‘Point Calibration’ measures, and those that evaluate distributions at all time-points ‘distributional-calibration’ or ‘probabilistic calibration’ measures. A point-calibration measure will evaluate a function of the predicted distribution at a single time-point whereas a probabilistic measure evaluates the distribution over a range of time-points; in both cases the evaluated quantity is compared to the observed outcome, \\((t, \\delta)\\).\nPoint calibration measures can be further divided into metrics that evaluate calibration at a single time-point (by reduction) and measures that evaluate an entire distribution by only considering the event time. The difference may sound subtle but it affects conclusions that can be drawn. In the first case, a calibration measure can only draw conclusions at that one time-point, whereas the second case can draw conclusions about the calibration of the entire distribution. This is the same caveat as using prediction error curves for scoring rules (Section 10.3).",
    "crumbs": [
      "Evaluation",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Calibration Measures</span>"
    ]
  },
  {
    "objectID": "P2C9_calib.html#sec-eval-distr-calib-point",
    "href": "P2C9_calib.html#sec-eval-distr-calib-point",
    "title": "9  Calibration Measures",
    "section": "",
    "text": "9.1.1 Calibration by Reduction\nPoint calibration measures are implicitly reduction methods as they use classification methods to evaluate a full distribution based on a single point only (Chapter 19). For example, given a predicted survival function \\(\\hat{S}\\), one could calculate the survival function at a single time point, \\(\\hat{S}{\\tau}\\) and then use probabilistic classification calibration measures. Using this approach one may employ common calibration methods such as the Hosmer–Lemeshow test (Hosmer and Lemeshow 1980). Measuring calibration in this way can have significant drawbacks as a model may be well-calibrated at one time-point but poorly calibrated at all others (Haider et al. 2020). To mitigate this, one could perform the Hosmer–Lemeshow test (or other applicable tests) multiple times with multiple testing correction at many (or all possible) time points, however this would be less efficient and more difficult to interpret than other measures discussed in this chapter.\n\n\n9.1.2 Houwelingen’s \\(\\alpha\\)\nAs opposed to evaluating distributions at one or more arbitrary time points, one could instead evaluate distribution predictions at meaningful times. van Houwelingen proposed several measures (Van Houwelingen 2000) for calibration but only one generalises to all probabilistic survival models, termed here ‘Houwelingen’s \\(\\alpha\\)’. The measure assesses if the model correctly estimates the theoretical ‘true’ cumulative hazard function of the underlying data generating process, \\(H = \\hat{H}\\).\nThe statistic is derived by noting the closely related nature of survival analysis and counting processes, and exploiting the fact that the sum of the cumulative hazard function is an estimate for the number of events in a given time-period (Hosmer Jr, Lemeshow, and May 2011). As this result may seem surprising, below is a short experiment using \\(\\textsf{R}\\) that demonstrates how the sum of the cumulative hazard estimated by a Kaplan-Meier estimator is identical to the number of randomly simulated deaths in a dataset:\n\n    set.seed(42)\n    library(survival)\n\n    event = rbinom(100, 1, 0.7)\n    times = runif(100)\n    H = survfit(Surv(times, event) ~ 1)$cumhaz\n    c(\"Deaths\" = sum(event), \"Sum H\" = sum(H))\n\n    #&gt; Deaths      Sum H \n    #&gt;     66         66\nHouwelingen’s \\(\\alpha\\) is then defined by substituting \\(H\\) for the observed total number of deaths and summing over all predictions:\n\\[\nH_\\alpha(\\boldsymbol{\\delta}, \\hat{\\mathbf{H}}, \\mathbf{t}) = \\frac{\\sum_i \\delta_i}{\\sum_i \\hat{H}_i(t_i)}\n\\]\nwith standard error \\(SE(H_\\alpha) = \\exp(1/\\sqrt{\\sum_i \\delta_i})\\). A model is well-calibrated with respect to \\(H_\\alpha\\) if \\(H_\\alpha = 1\\).\nThe next metrics we look at evaluate models across a spectrum of points to assess calibration over time.",
    "crumbs": [
      "Evaluation",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Calibration Measures</span>"
    ]
  },
  {
    "objectID": "P2C9_calib.html#sec-eval-distr-calib-prob",
    "href": "P2C9_calib.html#sec-eval-distr-calib-prob",
    "title": "9  Calibration Measures",
    "section": "9.2 Probabilistic Calibration",
    "text": "9.2 Probabilistic Calibration\nCalibration over a range of time points may be assessed quantitatively or qualitatively, with graphical methods often favoured. Graphical methods compare the average predicted distribution to the expected distribution, which can be estimated with the Kaplan-Meier curve, discussed next.\n\n9.2.1 Kaplan-Meier Comparison\nThe simplest graphical comparison compares the average predicted survival curve to the Kaplan-Meier curve estimated on the testing data. Let \\(\\hat{S}_1,...,\\hat{S}_m\\) be predicted survival functions, then the average predicted survival function is the mixture: \\(\\bar{\\hat{S}} = \\frac{1}{m} \\sum^{m}_{i = 1} \\hat{S}_i(\\tau)\\). This estimate can be plotted next to the Kaplan-Meier estimate of the survival distribution in a test dataset (i.e., the true data for model evaluation), allowing for visual comparison of how closely these curves align. An example is given in Figure 9.1, a Cox model (CPH), random survival forest, and relative risk tree, are all compared to the Kaplan-Meier estimator. This figure highlights the advantages and disadvantages of this method. The relative risk tree is clearly poorly calibrated as it increasingly diverges from the Kaplan-Meier. In contrast, the Cox model and random forest cannot be directly compared to one another, as both models frequently overlap with each other and the Kaplan-Meier estimator. Hence it is possible to say that the Cox and forests models are better calibrated than the risk tree, however it is not possible to say which of those two is better calibrated and whether their distance from the Kaplan-Meier is significant or not at a given time (when not clearly overlapping).\n\n\n\n\n\n\nFigure 9.1: Comparing the calibration of a Cox PH (CPH), random forest (RF), and relative risk tree (RRT) to the Kaplan-Meier estimate of the survival function calculated on a test set. The calibration of RRT notably decreases over time whereas RF and CPH are closer to the Kaplan-Meier curve.\n\n\n\nThis method is useful for making broad statements such as “model X is clearly better calibrated than model Y” or “model X appears to make average predictions close to the Kaplan-Meier estimate”, but that is the limit in terms of useful conclusions. One could refine this method for more fine-grained information by instead using relative risk predictions to create ‘risk groups’ that can be plotted against a stratified Kaplan-Meier, however this method is harder to interpret and adds even more subjectivity around how many risk groups to create and how to create them (Royston and Altman 2013). The next measure we consider includes a graphical method as well as a quantitative interpretation.\n\n\n9.2.2 D-Calibration\nD-Calibration (Andres et al. 2018; Haider et al. 2020) evaluates a model’s calibration by assessing if the predicted survival distributions follow the Uniform distribution as expected, which is motivated by the result that for any random variable \\(X\\) it follows \\(S_X(x) \\sim \\mathcal{U}(0,1)\\). This can be tested using a \\(\\chi^2\\) test-statistic:\n\\[\n\\chi^2 := \\sum_{i=1}^n \\frac{(O_i - E_i)^2}{E_i}\n\\]\nwhere \\(O_1,...,O_n\\) is the observed number of events in \\(n\\) groups and \\(E_1,...,E_n\\) is the expected number of events.\nTo utilise this test, the \\([0,1]\\) codomain of \\(S_i\\) is cut into \\(B\\) disjoint contiguous intervals (‘bins’) over the full range \\([0,1]\\). Let \\(m\\) be the total number of observations, then assuming a discrete uniform distribution as the theoretical distribution, the expected number of events in each bin is \\(E_i = m/B\\) (as the probability of an observation falling into each bin is equal).\nThe observations in the \\(i\\)th bin, \\(b_i\\), are defined by the set:\n\\[\nb_i := \\{j = 1,\\ldots,m : \\lceil \\hat{S}_i(t_j)B \\rceil = i\\}\n\\]\nwhere \\(j = 1,\\ldots,m\\) are the indices of the observations, \\(\\hat{S}_i\\) are observed (i.e., predicted) survival functions, \\(t_i\\) are observed (i.e., the ground truth) outcome times, and \\(\\lceil \\cdot \\rceil\\) is the ceiling function. The observed number of events in \\(b_i\\) is then the number of observations in that set: \\(O_i = |b_i|\\).\nThe D-Calibration measure, or \\(\\chi^2\\) statistic, is now defined by,\n\\[\nD_{\\chi^2}(\\hat{\\mathbf{S}}, \\mathbf{t}) :=  \\frac{\\sum^B_{i = 1} (O_i - \\frac{m}{B})^2}{m/B}\n\\]\nwhere \\(\\hat{\\mathbf{S}} = (\\hat{S}_1 \\ \\hat{S}_2 \\cdots \\hat{S}_m)^\\top\\) and \\(\\mathbf{t}= (t_1 \\ t_2 \\cdots t_m)^\\top\\).\nThis measure has several useful properties. Firstly, one can test the null hypothesis that a model is ‘D-calibrated’ by deriving a \\(p\\)-value from comparison to \\(\\chi^2_{B-1}\\). Secondly, \\(D_{\\chi^2}\\) tends to zero as a model is increasingly well-calibrated, hence the measure can be used for model comparison. Finally, the theory lends itself to an intuitive graphical calibration method as a D-calibrated model implies:\n\\[\np = \\frac{\\sum_i \\mathbb{I}(T_i \\leq \\hat{F}_i^{-1}(p))}{m}\n\\]\nwhere \\(p\\) is some value in \\([0,1]\\), \\(\\hat{F}_i^{-1}\\) is the \\(i\\)th predicted inverse cumulative distribution function, and \\(m\\) is again the number of observations. In words, the number of events occurring at or before each quantile should be equal to the quantile itself, for example 50% of events should occur before their predicted median survival time. Therefore, one can plot \\(p\\) on the x-axis and the right hand side of the above equation on the y-axis. A D-calibrated model should result in a straight line on \\(x = y\\). This is visualised in Figure 9.2 for the same models as in Figure 9.1. This figure supports the previous findings that the relative risk tree is poorly calibrated in contrast to the Cox model and random forest but again no direct comparison between the latter models is possible.\n\n\n\n\n\n\nFigure 9.2: Comparing the D-calibration of a Cox PH (CPH), random forest (RF), and relative risk tree (RRT) to the expected distribution on y=x. As with Figure 9.1, the relative risk tree is clearly not D-calibrated (as supported by the figures in the bottom-right). The CPH and RF are closer to the y=x however neither follow it perfectly.\n\n\n\nWhilst D-calibration has the same problems as the Kaplan-Meier method with respect to visual comparison, at least in this case there are quantities to help draw more concrete solutions. For the models in Figure 9.2, it is clear that the relative risk tree is not D-calibrated with \\(p&lt;0.01\\) indicating the null hypothesis of D-calibration, i.e., the predicted quantiles not following a Discrete Uniform distribution, can be comfortably rejected. Whilst the D-calibration for the Cox model is smaller than that of the random forest, the difference is unlikely to be significant, as is seen in the overlapping curves in the figure.\nThe next chapter will look at scoring rules, which provides a more concrete method to analytically compare the predicted distributions from survival models.\n\n\n\n\nAndres, Axel, Aldo Montano-Loza, Russell Greiner, Max Uhlich, Ping Jin, Bret Hoehn, David Bigam, James Andrew Mark Shapiro, and Norman Mark Kneteman. 2018. “A novel learning algorithm to predict individual survival after liver transplantation for primary sclerosing cholangitis.” PLOS ONE 13 (3): e0193523. https://doi.org/10.1371/journal.pone.0193523.\n\n\nDemler, Olga V, Nina P Paynter, and Nancy R Cook. 2015. “Tests of calibration and goodness-of-fit in the survival setting.” Statistics in Medicine 34 (10): 1659–80. https://doi.org/10.1002/sim.6428.\n\n\nHaider, Humza, Bret Hoehn, Sarah Davis, and Russell Greiner. 2020. “Effective ways to build and evaluate individual survival distributions.” Journal of Machine Learning Research 21 (85): 1–63.\n\n\nHosmer, David W, and Stanley Lemeshow. 1980. “Goodness of fit tests for the multiple logistic regression model.” Communications in Statistics-Theory and Methods 9 (10): 1043–69.\n\n\nHosmer Jr, David W, Stanley Lemeshow, and Susanne May. 2011. Applied survival analysis: regression modeling of time-to-event data. Vol. 618. John Wiley & Sons.\n\n\nRahman, M. Shafiqur, Gareth Ambler, Babak Choodari-Oskooei, and Rumana Z. Omar. 2017. “Review and evaluation of performance measures for survival prediction models in external validation settings.” BMC Medical Research Methodology 17 (1): 1–15. https://doi.org/10.1186/s12874-017-0336-2.\n\n\nRoyston, Patrick, and Douglas G. Altman. 2013. “External validation of a Cox prognostic model: Principles and methods.” BMC Medical Research Methodology 13 (1). https://doi.org/10.1186/1471-2288-13-33.\n\n\nVan Houwelingen, Hans C. 2000. “Validation, calibration, revision and combination of prognostic survival models.” Statistics in Medicine 19 (24): 3401–15. https://doi.org/10.1002/1097-0258(20001230)19:24&lt;3401::AID-SIM554&gt;3.0.CO;2-2.",
    "crumbs": [
      "Evaluation",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Calibration Measures</span>"
    ]
  },
  {
    "objectID": "P2C10_rules.html",
    "href": "P2C10_rules.html",
    "title": "10  Evaluating Distributions by Scoring Rules",
    "section": "",
    "text": "10.1 Classification Losses\nScoring rules evaluate probabilistic predictions and (attempt to) measure the overall predictive ability of a model in terms of both calibration and discrimination (Gneiting and Raftery 2007; Murphy 1973). In contrast to calibration measures, which assess the average performance across all observations on a population level, scoring rules evaluate the sample mean of individual predictions across all observations in a test set. As well as being able to provide information at an individual level, scoring rules are also popular as probabilistic forecasts are widely recognised to be superior to deterministic predictions for capturing uncertainty in predictions (A. P. Dawid 1984; A. Philip Dawid 1986). Formalisation and development of scoring rules has primarily been due to Dawid (A. P. Dawid 1984; A. Philip Dawid 1986; A. Philip Dawid and Musio 2014) and Gneiting and Raftery (Gneiting and Raftery 2007); though the earliest measures promoting “rational” and “honest” decision making date back to the 1950s (Brier 1950; Good 1952). Few scoring rules have been proposed in survival analysis, although the past few years have seen an increase in popularity in these measures. Before delving into these measures, we will first describe scoring rules in the simpler classification setting.\nScoring rules are pointwise losses, which means a loss is calculated for all observations and the sample mean is taken as the final score. To simplify notation, we only discuss scoring rules in the context of a single observation where \\(L_i(\\hat{S}_i, t_i, \\delta_i)\\) would be the loss calculated for some observation \\(i\\) where \\(\\hat{S}_i\\) is the predicted survival function (from which other distribution functions can be derived), and \\((t_i, \\delta_i)\\) is the observed survival outcome.\nIn the simplest terms, a scoring rule compares two values and assigns them a score (hence ‘scoring rule’), formally we’d write \\(L: \\mathbb{R}\\times \\mathbb{R}\\mapsto \\bar{\\mathbb{R}}\\). In machine learning, this usually means comparing a prediction for an observation to the ground truth, so \\(L: \\mathbb{R}\\times \\mathcal{P}\\mapsto \\bar{\\mathbb{R}}\\) where \\(\\mathcal{P}\\) is a set of distributions. Crucially, scoring rules usually refer to comparisons of true and predicted distributions. As an example, take the Brier score (Brier 1950) defined by: \\[\nL_{Brier}(\\hat{p}_i, y_i) = (y_i - \\hat{p}_i(y_i))^2\n\\]\nThis scoring rule compares the ground truth to the predicted probability distribution by testing if the difference between the observed event and the truth is minimized. This is intuitive as if the event occurs and \\(y_i = 1\\), then \\(\\hat{p}_i(y_i)\\) should be as close to one as possible to minimize the loss. On the other hand, if \\(y_i = 0\\) then the better prediction would be \\(\\hat{p}_i(y_i) = 0\\).\nThis demonstrates an important property of the scoring rule, properness. A loss is proper, if it is minimized by the correct prediction. In contrast, the loss \\(L_{improper}(\\hat{p}_i, y_i) = 1 - L_{Brier}(\\hat{p}_i, y_i)\\) is still a scoring rule as it compares the ground truth to the prediction probability distribution, but it is clearly improper as the perfect prediction (\\(\\hat{p}_i(y_i) = y_i\\)) would result in a score of \\(1\\) whereas the worst prediction would result in a score or \\(0\\). Proper losses provide a method of model comparison as, by definition, predictions closest to the true distribution will result in lower expected losses.\nAnother important property is strict properness. A loss is strictly proper if the loss is uniquely minimized by the ‘correct’ prediction. Consider now the loss \\(L_0(\\hat{p}_i, y_i) = 0\\). Not only is this a strictly proper scoring rule but it is also proper. The loss can only take the value \\(0\\) and is therefore guaranteed to be minimized by the correct prediction. It is clear however that this loss is useless. In contrast, the Brier score is minimized by only one value, which is the optimal prediction (Figure 10.1). Strictly proper losses are particular important for automated model optimisation, as minimization of the loss will result in the ‘optimum score estimator based on the scoring rule’ (Gneiting and Raftery 2007).\nMathematically, a classification loss \\(L: \\mathcal{P}\\times \\mathcal{Y}\\rightarrow \\bar{\\mathbb{R}}\\) is proper if for any distributions \\(p_Y,p\\) in \\(\\mathcal{P}\\) and for any random variables \\(Y \\sim p_Y\\), it holds that \\(\\mathbb{E}[L(p_Y, Y)] \\leq \\mathbb{E}[L(p, Y)]\\). The loss is strictly proper if, in addition, \\(p = p_Y\\) uniquely minimizes the loss.\nAs well as the Brier score, which was defined above, another widely used loss is the log loss (Good 1952), defined by\n\\[\nL_{logloss}(\\hat{p}_i, y_i) = -\\log \\hat{p}_i(y_i)\n\\]\nThese losses are visualised in Figure 10.1, which highlights that both losses are strictly proper (A. Philip Dawid and Musio 2014) as they are minimized when the true prediction is made, and converge to the minimum as predictions are increasingly improved.",
    "crumbs": [
      "Evaluation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Evaluating Distributions by Scoring Rules</span>"
    ]
  },
  {
    "objectID": "P2C10_rules.html#classification-losses",
    "href": "P2C10_rules.html#classification-losses",
    "title": "10  Evaluating Distributions by Scoring Rules",
    "section": "",
    "text": "Figure 10.1: Brier and log loss scoring rules for a binary outcome and varying probabilistic predictions. x-axis is a probabilistic prediction in \\([0,1]\\), y-axis is Brier score (left) and log loss (right). Blue lines are varying Brier score/log loss over different predicted probabilities when the true outcome is 1. Red lines are varying Brier score/log loss over different predicted probabilities when the true outcome is 0. Both losses are minimized when \\(\\hat{p}_i(y_i) = y_i\\).",
    "crumbs": [
      "Evaluation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Evaluating Distributions by Scoring Rules</span>"
    ]
  },
  {
    "objectID": "P2C10_rules.html#sec-eval-distr-commonsurv",
    "href": "P2C10_rules.html#sec-eval-distr-commonsurv",
    "title": "10  Evaluating Distributions by Scoring Rules",
    "section": "10.2 Survival Losses",
    "text": "10.2 Survival Losses\n\nAnalogously to classification losses, a survival loss \\(L: \\mathcal{P}\\times \\mathbb{R}_{&gt;0}\\times \\{0,1\\}\\rightarrow \\bar{\\mathbb{R}}\\) is proper if for any distributions \\(p_Y, p\\) in \\(\\mathcal{P}\\), and for any random variables \\(Y \\sim p_Y\\), and \\(C\\) t.v.i. \\(\\mathbb{R}_{&gt;0}\\); with \\(T := \\min(Y,C)\\) and \\(\\Delta := \\mathbb{I}(T=Y)\\); it holds that, \\(\\mathbb{E}[L(p_Y, T, \\Delta)] \\leq \\mathbb{E}[L(p, T, \\Delta)]\\). The loss is strictly proper if, in addition, \\(p = p_Y\\) uniquely minimizes the loss. A survival loss is referred to as outcome-independent (strictly) proper if it is only (strictly) proper when \\(C\\) and \\(Y\\) are independent.\nWith these definitions, the rest of this chapter lists common scoring rules in survival analysis and discusses some of their properties. As with other chapters, this list is likely not exhaustive but will cover commonly used losses.\n\n10.2.1 Integrated Graf Score\nThe Integrated Graf Score (IGS) was introduced by Graf (Graf and Schumacher 1995; Graf et al. 1999) as an analogue to the integrated brier score (IBS) in regression. It is likely the commonly used scoring rule in survival analysis, possibly due to its intuitive interpretation.\nThe loss is defined by\n\\[\n\\begin{split}\nL_{IGS}(\\hat{S}_i, t_i, \\delta_i|\\hat{G}_{KM}) = \\int^{\\tau^*}_0  \\frac{\\hat{S}_i^2(\\tau) \\mathbb{I}(t_i \\leq \\tau, \\delta_i=1)}{\\hat{G}_{KM}(t_i)} + \\frac{\\hat{F}_i^2(\\tau) \\mathbb{I}(t_i &gt; \\tau)}{\\hat{G}_{KM}(\\tau)} \\ d\\tau\n\\end{split}\n\\tag{10.1}\\] where \\(\\hat{S}_i^2(\\tau) = (\\hat{S}_i(\\tau))^2\\) and \\(\\hat{F}_i^2(\\tau) = (1 - \\hat{S}_i(\\tau))^2\\), and \\(\\tau^* \\in \\mathbb{R}_{\\geq 0}\\) is an upper threshold to compute the loss up to, and \\(\\hat{G}_{KM}\\) is the Kaplan-Meier trained on the censoring distribution for IPCW (Section 8.1).\nAt first glance this might seem intimidating but it is worth taking the time to understand the intuition behind the loss. Recall the classification Brier score, \\(L(\\hat{p}_i, y_i) = (y_i - \\hat{p}_i(y))^2\\), this provides a method to compare and evaluate a probability mass function at one time-point. The integrated Brier score (IBS), also known as the CRPS, is the integral of the Brier score for all real-valued thresholds (Gneiting and Raftery 2007) and hence allows predictions to be evaluated over multiple points as \\(L(\\hat{F}_i, y_i) = \\int (\\hat{F}_i(y_i) - \\mathbb{I}(y_i \\geq x))^2 dy\\) where \\(\\hat{F}_i\\) is the predicted cumulative distribution function and \\(x\\) is some meaningful threshold. In survival analysis, \\(\\hat{F}_i(\\tau)\\) represents the probability of an observation having experienced the event at or before \\(\\tau\\), and the ground truth to compare to is therefore whether the observation has actually experienced the event at \\(\\tau\\), which is the case when \\(t_i \\leq \\tau\\). Hence the IBS becomes \\(L(\\hat{F}_i, t_i) = \\int (\\hat{F}_i(\\tau) - \\mathbb{I}(t_i \\leq \\tau))^2 d\\tau\\). Now for a given time \\(\\tau\\):\n\\[\nL(\\hat{F}_i, t) =\n\\begin{cases}\n(\\hat{F}_i(\\tau) - 1)^2 = (1 - \\hat{F}_i(\\tau)^2) = \\hat{S}_i^2(\\tau), & \\text{ if } t_i \\leq \\tau \\\\\n(\\hat{F}_i(\\tau) - 0)^2 = \\hat{F}_i^2(\\tau), & \\text{ if } t_i &gt; \\tau\n\\end{cases}\n\\tag{10.2}\\]\nIn words, if an observation has not yet experienced an outcome (\\(t_i &gt; \\tau\\)) then the loss is minimized when the cumulative distribution function (the probability of having already died) is \\(0\\), which is intuitive as the optimal prediction is correctly identifying the observation has yet to experience the event. In contrast, if the observation has experienced the outcome (\\(t_i \\leq \\tau\\)) then the loss is minimized when the survival function (the probability of surviving until \\(\\tau\\)) is \\(0\\), which follows from similar logic.\nThe final component of the Graf score is accommodating for censoring. At \\(\\tau\\) an observation will either have\n\nNot experienced the event: \\(I(t_i &gt; \\tau)\\);\nExperienced the event: \\(I(t_i \\leq \\tau, \\delta_i = 1)\\); or\nBeen censored: \\(I(t_i \\leq \\tau, \\delta_i = 0)\\)\n\nIn the Graf score, censored observations are discarded. If they were not then Equation 10.2 would imply their contribution would be treated the same as those who had experienced the event. However this assumption would be entirely wrong as a censored observation is guaranteed not to have experienced the event, hence an ideal prediction for a censored observation is a high survival probability up until the point of censoring, at which time comparison to ground truth is unknown as this is no longer observed.\nThe act of discarding censored observations means that the sample size decreases over time. To compensate for this, IPCW is used to increasingly weight predictions as \\(\\tau\\) increases. Hence, IPCW weights, \\(W_i\\) are defined such that\n\\[\nW_i =\n\\begin{cases}\n\\hat{G}_{KM}^{-1}(t_i), & \\text{ if } \\mathbb{I}(t_i \\leq \\tau, \\delta_i = 1) \\\\\n\\hat{G}_{KM}^{-1}(\\tau), & \\text{ if } \\mathbb{I}(t_i &gt; \\tau)\n\\end{cases}\n\\]\nThe weights total \\(1\\) when divided over all samples and summed (Graf et al. 1999). They are also intuitive as observations are either weighted by \\(G(\\tau)\\) when they are still alive and therefore still part of the sample, or by \\(G(t_i)\\) otherwise.\nAs well as being intuitive, when censoring is uninformative, the Graf score consistently estimates the mean square error \\(L(t, S|\\tau^*) = \\int^{\\tau^*}_0 [\\mathbb{I}(t &gt; \\tau) - S(\\tau)]^2 d\\tau\\), where \\(S\\) is the correctly specified survival function (Gerds and Schumacher 2006). However, despite these promising properties, the IGS is improper and must therefore be used with care (Rindt et al. 2022; Sonabend et al. 2024). In practice, experiments have shown that the effect of improperness is minimal and therefore this loss should be avoided for automated routines such as model tuning, however it can still be used for model evaluation.  In addition, a small adaptation of the loss results in a strictly proper scoring rule simply by altering the weights such that \\(W_i = \\hat{G}_{KM}^{-1}(t_i)\\) for all uncensored observations and \\(0\\) otherwise (Sonabend et al. 2024), resulting in the reweighted Graf score: \n\\[\nL_{RGS}(\\hat{S}_i, t_i, \\delta_i|\\hat{G}_{KM}) = \\delta_i\\mathbb{I}(t_i \\leq \\tau^*) \\int^{\\tau^*}_0 \\frac{(\\mathbb{I}(t_i \\leq \\tau) - \\hat{F}_i(\\tau))^2}{\\hat{G}_{KM}(t_i)} \\ d\\tau\n\\]\nThe addition of \\(\\mathbb{I}(t_i \\leq \\tau^*)\\) completely removes observations that experience the event after the cutoff time, \\(\\tau^*\\), this ensures there are no cases where the \\(G(t_i)\\) weighting is calculated on time after the cutoff. Including an upper threshold (i.e, \\(\\tau^* &lt; \\infty\\)) effects properness and generalization statements. For example, by evaluating a model using the RGS with a \\(\\tau^*\\) threshold, then the model may be said to only perform well up until \\(\\tau^*\\) with its performance unknown after this time.\nThe change of weighting slightly alters the interpretation of the contributions at different time-points. By example, let \\((t_i = 4, t_j = 5)\\) be two observed survival times, then at \\(\\tau = 3\\), the Graf score weighting would be \\(\\hat{G}_{KM}^{-1}(4)\\) for both observations, whereas the RGS weights would be \\((KMG^{-1}(4), KMG^{-1}(5))\\) respectively, hence there is always more ‘importance’ placed on observations that take longer to experience the event. In practice, the difference between these weights appears to be minimal (Sonabend et al. 2024) but as RGS is strictly proper, it is more suitable for automated experiments. \n\n\n10.2.2 Integrated Survival Log Loss\n\nThe integrated survival log loss (ISLL) was also proposed by Graf et al. (1999).\n\\[\nL_{ISLL}(\\hat{S}_i,t_i,\\delta_i|\\hat{G}_{KM}) = -\\int^{\\tau^*}_0  \\frac{\\log[\\hat{F}_i(\\tau)] \\mathbb{I}(t_i \\leq \\tau, \\delta_i=1)}{\\hat{G}_{KM}(t_i)} + \\frac{\\log[\\hat{S}_i(\\tau)] \\mathbb{I}(t_i &gt; \\tau)}{\\hat{G}_{KM}(\\tau)} \\ d\\tau\n\\]\nwhere \\(\\tau^* \\in \\mathbb{R}_{&gt;0}\\) is an upper threshold to compute the loss up to.\nSimilarly to the IGS, there are three ways to contribute to the loss depending on whether an observation is censored, experienced the event, or alive, at \\(\\tau\\). Whilst the IGS is routinely used in practice, there is no evidence that ISLL is used, and moreover there are no proofs (or claims) that it is proper.\nThe reweighted ISLL (RISLL) follows similarly to the RIGS and is also outcome-independent strictly proper (Sonabend et al. 2024).\n\\[\nL_{RISLL}(\\hat{S}_i, t_i, \\delta_i|\\hat{G}_{KM}) = -\\delta_i\\mathbb{I}(t_i \\leq \\tau^*) \\int^{\\tau^*}_0 \\frac{\\mathbb{I}(t_i \\leq \\tau)\\log[\\hat{F}_i(\\tau)] + \\mathbb{I}(t_i &gt; \\tau)\\log[\\hat{S}_i(\\tau)] \\ d\\tau}{\\hat{G}_{KM}(t_i)}\n\\]\n\n\n10.2.3 Survival density log loss\nAnother outcome-independent strictly proper scoring rule is the survival density log loss (SDLL) (Sonabend et al. 2024), which is given by\n\\[\nL_{SDLL}(\\hat{f}_i, t_i, \\delta_i|\\hat{G}_{KM}) = - \\frac{\\delta_i \\log[\\hat{f}_i(t_i)]}{\\hat{G}_{KM}(t_i)}\n\\]\nwhere \\(\\hat{f}_i\\) is the predicted probability density function. This loss is essentially the classification log loss (\\(-\\log(\\hat{p}_i(t_i))\\)) with added IPCW. Whilst the classification log loss has beneficial properties such as being differentiable, this is more complex for the SDLL and it is not widely used in practice. A useful alternative to the SDLL which can be readily used in automated procedures is the right-censored log loss.\n\n\n10.2.4 Right-censored log loss\nThe right-censored log loss (RCLL) is an outcome-independent strictly proper scoring rule (Avati et al. 2020) that benefits from not depending on IPCW in its construction. The RCLL is defined by\n\\[\nL_{RCLL}(\\hat{S}_i, t_i, \\delta_i) = -\\log[\\delta_i\\hat{f}_i(t_i) + (1-\\delta_i)\\hat{S}_i(t_i)]\n\\]\nThis loss is interpretable when we break it down into its two halves:\n\nIf an observation is censored at \\(t_i\\) then all the information we have is that they did not experience the event at the time, so they must be ‘alive’, hence the optimal value is \\(\\hat{S}_i(t_i) = 1\\) (which becomes \\(-log(1) = 0\\)).\nIf an observation experiences the event then the ‘best’ prediction is for the probability of the event at that time to be maximised, as pdfs are not upper-bounded this means \\(\\hat{f}_i(t_i) = \\infty\\) (and \\(-log(t_i) \\rightarrow \\infty\\) as \\(t_i \\rightarrow \\infty\\)).\n\n\n\n10.2.5 Absolute Survival Loss\nThe absolute survival loss, developed over time by Schemper and Henderson (2000) and Schmid et al. (2011), is based on the mean absolute error is very similar to the IGS but removes the squared term:\n\\[\nL_{ASL}(\\hat{S}_i, t_i, \\delta_i|\\hat{G}_{KM}) = \\int^{\\tau^*}_0 \\frac{\\hat{S}_i(\\tau)\\mathbb{I}(t_i \\leq \\tau, \\delta_i = 1)}{\\hat{G}_{KM}(t_i)} + \\frac{\\hat{F}_i(\\tau)\\mathbb{I}(t_i &gt; \\tau)}{\\hat{G}_{KM}(\\tau)} \\ d\\tau\n\\] where \\(\\hat{G}_{KM}\\) and \\(\\tau^*\\) are as defined above. Analogously to the IGS, the ASL score consistently estimates the mean absolute error when censoring is uninformative (Schmid et al. 2011) but there are also no proofs or claims of properness. The ASL and IGS tend to yield similar results (Schmid et al. 2011) but in practice there is no evidence of the ASL being widely used.",
    "crumbs": [
      "Evaluation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Evaluating Distributions by Scoring Rules</span>"
    ]
  },
  {
    "objectID": "P2C10_rules.html#sec-pecs",
    "href": "P2C10_rules.html#sec-pecs",
    "title": "10  Evaluating Distributions by Scoring Rules",
    "section": "10.3 Prediction Error Curves",
    "text": "10.3 Prediction Error Curves\n\nAs well as evaluating probabilistic outcomes with integrated scoring rules, non-integrated scoring rules can be utilised for evaluating distributions at a single point. For example, instead of evaluating a probabilistic prediction with the IGS over \\(\\mathbb{R}_{\\geq 0}\\), instead one could compute the IGS at a single time-point, \\(\\tau \\in \\mathbb{R}_{\\geq 0}\\), only. Plotting these for varying values of \\(\\tau\\) results in ‘prediction error curves’ (PECs), which provide a simple visualisation for how predictions vary over the outcome. PECs are especially useful for survival predictions as they can visualise the prediction ‘over time’. PECs are mostly used as a graphical guide when comparing few models, rather than as a formal tool for model comparison. An example for PECs is provided in Figure 10.2 for the IGS where the the Cox PH consistently outperforms the SVM.\n\n\n\n\n\n\nFigure 10.2: Prediction error curves for the CPH and SVM models from Chapter 9. x-axis is time and y-axis is the IGS computed at different time-points. The CPH (red) performs better than the SVM (blue) as it scores consistently lower. Trained and tested on randomly simulated data from $.",
    "crumbs": [
      "Evaluation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Evaluating Distributions by Scoring Rules</span>"
    ]
  },
  {
    "objectID": "P2C10_rules.html#sec-eval-distr-score-base",
    "href": "P2C10_rules.html#sec-eval-distr-score-base",
    "title": "10  Evaluating Distributions by Scoring Rules",
    "section": "10.4 Baselines and ERV",
    "text": "10.4 Baselines and ERV\nA common criticism of scoring rules is a lack of interpretability, for example, an IGS of 0.5 or 0.0005 has no meaning by itself, so below we present two methods to help overcome this problem.\nThe first method, is to make use of baselines for model comparison, which are models or values that can be utilised to provide a reference for a loss, they provide a universal method to judge all models of the same class by (Gressmann et al. 2018). In classification, it is possible to derive analytical baseline values, for example a Brier score is considered ‘good’ if it is below 0.25 or a log loss if it is below 0.693 (Figure 10.1), this is because these are the values obtained if you always predicted probabilties as \\(0.5\\), which is a reasonable basline guess in a binary classificaiton problem. In survival analysis, simple analytical expressions are not possible as losses are dependent on the unknown distributions of both the survival and censoring time. Therefore all experiments in survival analysis must include a baseline model that can produce a reference value in order to derive meaningful results. A suitable baseline model is the Kaplan-Meier estimator (Graf and Schumacher 1995; Lawless and Yuan 2010; Royston and Altman 2013), which is the simplest model that can consistently estimate the true survival function.\nAs well as directly comparing losses from a ‘sophisticated’ model to a baseline, one can also compute the percentage increase in performance between the sophisicated and baseline models, which produces a measure of explained residual variation (ERV) (Edward L. Korn and Simon 1990; Edward L. Korn and Simon 1991). For any survival loss \\(L\\), the ERV is,\n\\[\nR_L(S, B) = 1 - \\frac{L|S}{L|B}\n\\]\nwhere \\(L|S\\) and \\(L|B\\) is the loss computed with respect to predictions from the sophisticated and baseline models respectively.\nThe ERV interpretation makes reporting of scoring rules easier within and between experiments. For example, say in experiment A we have \\(L|S = 0.004\\) and \\(L|B = 0.006\\), and in experiment B we have \\(L|S = 4\\) and \\(L|B = 6\\). The sophisticated model may appear worse at first glance in experiment A (as the losses are very close) but when considering the ERV we see that the performance increase is identical (both \\(R_L = 33\\%\\)), thus providing a clearer way to compare models.",
    "crumbs": [
      "Evaluation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Evaluating Distributions by Scoring Rules</span>"
    ]
  },
  {
    "objectID": "P2C10_rules.html#conclusion",
    "href": "P2C10_rules.html#conclusion",
    "title": "10  Evaluating Distributions by Scoring Rules",
    "section": "10.5 Conclusion",
    "text": "10.5 Conclusion\n\n\n\n\n\n\nKey takeaways\n\n\n\n\nScoring rules are a useful tool for measuring a model’s overall predictive ability, taking into account calibration and discrimination.\nStrictly proper scoring rules allow models to be compared to one another, which is important when choosing models in a benchmark experiment.\nMany scoring rules for censored data are not strictly proper, however experiments suggest that improper rules still provide useful and trustworthy results (Sonabend et al. 2024)\n\n\n\n\n\n\n\n\n\nLimitations\n\n\n\n\nScoring rules can be difficult to interpret but ERV representations can be a helpful way to overcome this.\nThere is no consensus about which scoring rule to use and when so in practice multiple scoring rules may have to be reported in experiments to ensure transparency and fairness of results.\nFor non- and semi-parametric survival models that return distribution predictions, estimates of \\(f(t)\\) are not readily available and require approximations (Rindt et al. 2022), hence measures such as RCLL and SDLL can often not be directly used in practice.\n\n\n\n\n\n\n\n\n\nFurther reading\n\n\n\n\nA. Philip Dawid and Musio (2014) and Gneiting and Raftery (2007) provide a comprehensive summary of scoring rules in regression and classification settings.\nRindt et al. (2022) and Sonabend et al. (2024) review survival scoring rules.\nRahman et al. (2017) compare measures for external validation including some scoring rules.\n\n\n\n\n\n\n\nAvati, Anand, Tony Duan, Sharon Zhou, Kenneth Jung, Nigam H. Shah, and Andrew Ng. 2020. “Countdown Regression: Sharp and Calibrated Survival Predictions.” In Proceedings of Machine Learning Research, 145–55. https://proceedings.mlr.press/v115/avati20a.html http://arxiv.org/abs/1806.08324.\n\n\nBrier, Glenn. 1950. “Verification of forecasts expressed in terms of probability.” Monthly Weather Review 78 (1): 1–3.\n\n\nDawid, A P. 1984. “Present Position and Potential Developments: Some Personal Views: Statistical Theory: The Prequential Approach.” Journal of the Royal Statistical Society. Series A (General) 147 (2): 278–92. https://doi.org/10.2307/2981683.\n\n\nDawid, A Philip. 1986. “Probability Forecasting.” Encyclopedia of Statistical Sciences 7: 210–18.\n\n\nDawid, A Philip, and Monica Musio. 2014. “Theory and Applications of Proper Scoring Rules.” Metron 72 (2): 169–83. https://arxiv.org/abs/arXiv:1401.0398v1.\n\n\nGerds, Thomas A, and Martin Schumacher. 2006. “Consistent Estimation of the Expected Brier Score in General Survival Models with Right-Censored Event Times.” Biometrical Journal 48 (6): 1029–40. https://doi.org/10.1002/bimj.200610301.\n\n\nGneiting, Tilmann, and Adrian E Raftery. 2007. “Strictly Proper Scoring Rules, Prediction, and Estimation.” Journal of the American Statistical Association 102 (477): 359–78. https://doi.org/10.1198/016214506000001437.\n\n\nGood, I J. 1952. “Rational Decisions.” Journal of the Royal Statistical Society. Series B (Methodological) 14 (1): 107–14. http://www.jstor.org/stable/2984087.\n\n\nGraf, Erika, Claudia Schmoor, Willi Sauerbrei, and Martin Schumacher. 1999. “Assessment and comparison of prognostic classification schemes for survival data.” Statistics in Medicine 18 (17-18): 2529–45. https://doi.org/10.1002/(SICI)1097-0258(19990915/30)18:17/18&lt;2529::AID-SIM274&gt;3.0.CO;2-5.\n\n\nGraf, Erika, and Martin Schumacher. 1995. “An Investigation on Measures of Explained Variation in Survival Analysis.” Journal of the Royal Statistical Society. Series D (The Statistician) 44 (4): 497–507. https://doi.org/10.2307/2348898.\n\n\nGressmann, Frithjof, Franz J. Király, Bilal Mateen, and Harald Oberhauser. 2018. “Probabilistic supervised learning.” https://doi.org/10.1002/iub.552.\n\n\nKorn, Edward L., and Richard Simon. 1990. “Measures of explained variation for survival data.” Statistics in Medicine 9 (5): 487–503. https://doi.org/10.1002/sim.4780090503.\n\n\nKorn, Edward L, and Richard Simon. 1991. “Explained Residual Variation, Explained Risk, and Goodness of Fit.” The American Statistician 45 (3): 201–6. https://doi.org/10.2307/2684290.\n\n\nLawless, Jerald F, and Yan Yuan. 2010. “Estimation of prediction error for survival models.” Statistics in Medicine 29 (2): 262–74. https://doi.org/10.1002/sim.3758.\n\n\nMurphy, Allan H. 1973. “A New Vector Partition of the Probability Score.” Journal of Applied Meteorology and Climatology 12 (4): 595–600. https://doi.org/10.1175/1520-0450(1973)012&lt;0595:ANVPOT&gt;2.0.CO;2.\n\n\nRahman, M. Shafiqur, Gareth Ambler, Babak Choodari-Oskooei, and Rumana Z. Omar. 2017. “Review and evaluation of performance measures for survival prediction models in external validation settings.” BMC Medical Research Methodology 17 (1): 1–15. https://doi.org/10.1186/s12874-017-0336-2.\n\n\nRindt, David, Robert Hu, David Steinsaltz, and Dino Sejdinovic. 2022. “Survival Regression with Proper Scoring Rules and Monotonic Neural Networks,” March. http://arxiv.org/abs/2103.14755.\n\n\nRoyston, Patrick, and Douglas G. Altman. 2013. “External validation of a Cox prognostic model: Principles and methods.” BMC Medical Research Methodology 13 (1). https://doi.org/10.1186/1471-2288-13-33.\n\n\nSchemper, Michael, and Robin Henderson. 2000. “Predictive Accuracy and Explained Variation in Cox Regression.” Biometrics 56: 249–55. https://doi.org/10.1002/sim.1486.\n\n\nSchmid, Matthias, Thomas Hielscher, Thomas Augustin, and Olaf Gefeller. 2011. “A Robust Alternative to the Schemper-Henderson Estimator of Prediction Error.” Biometrics 67 (2): 524–35. https://doi.org/10.1111/j.1541-0420.2010.01459.x.\n\n\nSonabend, Raphael, John Zobolas, Philipp Kopper, Lukas Burk, and Andreas Bender. 2024. “Examining properness in the external validation of survival models with squared and logarithmic losses,” December. http://arxiv.org/abs/2212.05260.",
    "crumbs": [
      "Evaluation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Evaluating Distributions by Scoring Rules</span>"
    ]
  },
  {
    "objectID": "P2C11_time.html",
    "href": "P2C11_time.html",
    "title": "11  Evaluating Survival Time",
    "section": "",
    "text": "11.1 Distance measures\nWhen it comes to evaluating survival time predictions, there are few measures available at our disposal. As a result of survival time predictions being uncommon compared to other prediction types (?sec-surv-set-types), there are limited survival time evaluation measures in the literature. To our knowledge, there are no specialised ‘survival time measures’, instead regression measures are used by ignoring censored observations.\nBefore presenting these measures, consider what happens when censored observations are discarded. If censoring is truly independent, occurs randomly, and is very limited in the data, then there is little harm in discarding observations and treating this as a regression problem. However, if censoring is not independent, then discarding censored observations will lead to missing valuable insights about the model. For example, say the task of interest is to predict the probability of death due to kidney failure and patients are censored if they receive a transplant - this is clearly a competing risk as receiving a transplant greatly reduces the probability of death. If one were to predict the time to death for all patients and to not evaluate the quality of prediction for censored patients, then it would only be possible to conclude about the model’s performance for those who do not receive a transplant. On the surface this may appear to be of value, however, if at the time of prediction it is impossible to know who will receive a transplant (perhaps because the dataset omits relevant information such as time of hospital admission, wait on register, etc.), then for a given prediction for an observation, it would be impossible to know if the prediction is trustworthy - it would be if that patient does not receive a transplant, but would not be if they do not. In short, it is essential that predictions for individuals who end up being censored, are as good as those who are not, simply because there is no method to know which group observations will eventually fall into.\nIt is interesting to consider if IPCW strategies would compensate for this deficiency, however as we were unable to find research into this method, we have only included measures that we term ‘censoring-ignored regression measures’, which are presented in (Wang, Li, and Reddy 2019).\nSurvival time measures are often referred to as ‘distance’ measures as they measure the distance between the true, \\((t, \\delta=1)\\), and predicted, \\(\\hat{t}\\), values. These are presented in turn with brief descriptions of their interpretation.\nCensoring-ignored mean absolute error, \\(MAE_C\\)\nIn regression, the mean absolute error (MAE) is a popular measure because it is intuitive to understand as it measures the absolute difference between true and predicted outcomes; hence intuitively one can understand that a model predicting a height of 175cm is clearly better than one predicting a height of 180cm, for a person with true height of 174cm.\n\\[\nMAE_C(\\hat{\\mathbf{t}}, \\mathbf{t}, \\boldsymbol{\\delta}) = \\frac{1}{d} \\sum^m_{i=1} \\delta_i|t_i - \\hat{t}_i|\n\\]\nWhere \\(d\\) is the number of uncensored observations in the dataset, \\(d = \\sum_i \\delta_i\\).\nCensoring-ignored mean squared error\nIn comparison to MAE, the mean squared error (MSE), computes the squared differences between true and predicted values. While the MAE provides a smooth, linear, ‘penalty’ for increasingly poor predictions (i.e., the difference between an error of predicting 2 vs. 5 is still 3), but the square in the MSE means that larger errors are quickly magnified (so the difference in the above example is 9). By taking the mean over all predictions, the effect of this inflation is to increase the MSE value as larger mistakes are made.\n\\[\nMSE_C(\\hat{\\mathbf{t}}, \\mathbf{t}, \\boldsymbol{\\delta}) = \\frac{1}{d}\\sum^m_{i=1}\\delta_i(t_i - \\hat{t}_i)^2\n\\]\nWhere \\(d\\) is again the number of uncensored observations in the dataset, \\(d = \\sum_i \\delta_i\\).\nCensoring-adjusted root mean squared error\nFinally, the root mean squared error (RMSE), is simply the square root of the MSE. This allows interpretation on the original scale (as opposed to the squared scale produced by the MSE). Given the inflation effect for the MSE, the RMSE will be larger than the MAE as increasingly poor predictions are made; it is common practice for the MAE and RMSE to be reported together.\n\\[\nRMSE_C(\\hat{\\mathbf{t}}, \\mathbf{t}, \\boldsymbol{\\delta}) = \\sqrt{MSE_C(\\hat{\\mathbf{t}}, \\mathbf{t}, \\boldsymbol{\\delta})}\n\\]",
    "crumbs": [
      "Evaluation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Evaluating Survival Time</span>"
    ]
  },
  {
    "objectID": "P2C11_time.html#over--and-under-predictions",
    "href": "P2C11_time.html#over--and-under-predictions",
    "title": "11  Evaluating Survival Time",
    "section": "11.2 Over- and under-predictions",
    "text": "11.2 Over- and under-predictions\nAll of these distance measures assume that the error for an over-prediction (\\(\\hat{t}&gt; t\\)) should be equal to an under-prediction (\\(\\hat{t}&lt; t\\)), i.e., that it is ‘as bad’ if a model predicts an outcome time being 10 years longer than the truth compared to being 10 years shorter. In the survival setting, this assumption is often invalid as it is generally preferred for models to be overly cautious, hence to predict negative events to happen sooner (e.g., predict a life-support machine fails after three years not five if the truth is actually four) and to predict positive events to happen later (e.g., predict a patient recovers after four years not two if the truth is actually three). A simple method to incorporate this imbalance between over- and under-predictions is to add a weighting factor to any of the above measures, for example the \\(MAE_C\\) might become\n\\[\nMAE_C(\\hat{\\mathbf{t}}, \\mathbf{t}, \\boldsymbol{\\delta}, \\lambda, \\mu, \\phi) = \\frac{1}{d} \\sum^m_{i=1} \\delta_i|(t_i - \\hat{t}_i) [\\lambda\\mathbb{I}(t_i&gt;\\hat{t}_i) + \\mu\\mathbb{I}(t_i&lt;\\hat{t}_i) + \\phi\\mathbb{I}(t_i=\\hat{t}_i)]|\n\\]\nwhere \\(\\lambda, \\mu, \\phi\\) are any Real number to be used to weight over-, under-, and exact-predictions, and \\(d\\) is as above. The choice of these are highly context dependent and could even be tuned.\n\n\n\n\nWang, Ping, Yan Li, and Chandan K. Reddy. 2019. “Machine Learning for Survival Analysis.” ACM Computing Surveys 51 (6): 1–36. https://doi.org/10.1145/3214306.",
    "crumbs": [
      "Evaluation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Evaluating Survival Time</span>"
    ]
  },
  {
    "objectID": "P2C12_choosing.html",
    "href": "P2C12_choosing.html",
    "title": "12  Choosing Measures",
    "section": "",
    "text": "12.1 Defining the experiment\nAfter reading this part of the book, evaluating survival analysis models may appear more daunting than regression and classification settings, which, in contrast, have fewer (common) measures to choose from. In regression problems, the RMSE and MAE are common choices for evaluating how far predictions are from the truth. In classification, the Brier score or logloss may be used to evaluate probabilistic predictions and the accuracy score or TPR/TNR/FPR/FNR are common for deterministic predictions. In contrast, there are many more measures in survival analysis which are necessarily more complex, due to the need to handle censoring with many possible methods for doing so. Therefore, this final chapter aims to provide some simple to follow guidelines for selecting measures for different types of experiments.\nExperiments may be performed to make predictions for new data, compare the performance of multiple models (‘benchmark experiments’), investigate patterns in observed data, or some combination of these. Each experiment requires different choices of measures, with different levels of strictness applied to measure assumptions.",
    "crumbs": [
      "Evaluation",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Choosing Measures</span>"
    ]
  },
  {
    "objectID": "P2C12_choosing.html#defining-the-experiment",
    "href": "P2C12_choosing.html#defining-the-experiment",
    "title": "12  Choosing Measures",
    "section": "",
    "text": "12.1.1 Predictive experiments\nIn the real world, predictive experiments are most common. These are now daily occurrences as machine learning models are routinely deployed on servers to make ongoing predictions. In these cases, the exact task must be precisely stated before any model is deployed and evaluated. Common survival problems to solve include:\n\nIdentifying low and high risk groups in new data (for resource allocation);\nPredicting the survival distribution for an individual over time; and\nPredicting the survival probability for an individual at a specific time.\n\nThe first of these is a discrimination problem and it is therefore most important that the model optimises corresponding measures and that measure assumptions are justified. However, even this task may be more complex than it initially seems. For example, while some papers have shown flaws in Harrell’s C (Gönen and Heller 2005; Rahman et al. 2017; Schmid and Potapov 2012; Uno et al. 2007), others have demonstrated that common alternatives yield very similar results (Rahman et al. 2017; Therneau and Atkinson 2020) and moreover some prominent alternatives may be harder to interpret due to high variance (Rahman et al. 2017; Schmid and Potapov 2012). In predictive experiment that may require more level of automation, it is important to be careful of C-hacking (Section 8.1.2) and to avoid overoptimistic results. Hence one should not compute a range of concordance indices and report the maximum but instead calculate a single discrimination measure and then establish a pre-defined threshold to determine if the deployed model is optimal, a natural threshold would be 0.5 as anything above this is better than a baseline model. Given Harrell’s C to be increasingly over-optimistic with additional censoring (Rahman et al. 2017), it is advisable to use Uno’s C instead.\nIf the task of interest is to predict survival distributions over time, then the choice of measure is more limited and only the RCLL and the proper Graf score are recommended. Both these measures can only be interpreted with respect to a baseline so use of the ERV representation is strongly recommended. As with the previous task, establishing a threshold for performance is essential prior to deployment and for ongoing evaluation. It is less clear in these cases what this threshold might be, but the simplest starting point would be to ensure that the model continues to outperform the baseline or a simpler gold-standard model (e.g., the Cox PH).\nThe final task of interest differs from the previous by only making predictions at a specific time. In this case, prediction error curves, and single-time point calibration measures can be used, as well as scoring rules with shorter cut-offs (i.e., the upper limit of the integral). It is imperative that model performance is never extrapolated outside of the pre-specified time.\n\n\n12.1.2 Benchmark experiments\nWhen conducting benchmark experiments, it is advisable to use a spread of measures so that results can be compared across various properties. In this case, models should be tested against discrimination, calibration, and overall predictive ability (i.e., with scoring rules). As models make different types of predictions, results from these experiments should be limited to metrics that are directly comparable, in other words, two models should only be compared based on the same metric. In benchmark experiments, models are compared across the same data and same resampling strategy, hence measure assumptions become less important as they are equally valid or flawed for all models. For example, if one dataset has particularly high amounts of censoring leading to an artificially higher concordance index, then this bias would affect all models equally and the overall experiment would not be affected. Hence, in these experiments it suffices to pick one or two measures for concordance, discrimination, and predictive ability, without having to be overly concerned with the individual metric.\nThis book recommends using Harrell’s C and Uno’s C for concordance as these are simplest to compute and including both enables more confidence in model comparison, i.e., if a model outperforms another with respect to both these measures then there can be higher confidence in drawing statements about the model’s discriminatory power. For calibration, D-calibration is recommended as it can be meaningfully compared between models, and the RCLL is recommended for a scoring rule (which is proper for outcome-independent censoring). No distance measure is recommended as these do not apply to the vast majority of models. All these measures can be used for automated tuning, in the case of discrimination tuning to Harrell’s C alone should suffice (without also tuning to Uno’s C).\n\n\n12.1.3 Investigation\nInvestigating patterns in observed data is increasingly common as model interpretability methods have become more accessible (Molnar 2019). Before data can be investigated, any model that is trained on the data must first be demonstrated to be a good fit to the data. A model’s fit to data can also be evaluated by resampling the data (Chapter 3) and evaluating the predictions. In this case, it is important to choose measures that are interpretable and have justified assumptions. Calibration measures are particularly useful for evaluating if a model is well fit to data, and any of the methods described in Chapter 9 are recommended for this purpose. Discrimination measures may be useful, however, given how susceptible they are to censoring, they can be difficult to interpret on their own, and the same is true for scoring rules. One method to resolve ambiguity is to perform a benchmark experiment of multiple models on the same data (ideally with some automated tuning) and then select the best model from this experiment and refit it on the full data (Becker, Schneider, and Fischer 2024) – this is a robust, empirical method that demonstrates a clear trail to selecting a model that outperforms other potential candidates. When investigating a dataset, one may also consider using different measures to assess algorithmic fairness (Sonabend et al. 2022), any measure that can be optimised (i.e., where the lowest or highest value is the best) may be used in this case. Finally, there are survival adaptations to the well-known AIC (Liang and Zou 2008) and BIC (Volinsky and Raftery 2000) however as these are generally only applicable to ‘classical’ models (Chapter 13), they are out of scope for this book and hence have not been discussed.",
    "crumbs": [
      "Evaluation",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Choosing Measures</span>"
    ]
  },
  {
    "objectID": "P2C12_choosing.html#conclusions",
    "href": "P2C12_choosing.html#conclusions",
    "title": "12  Choosing Measures",
    "section": "12.2 Conclusions",
    "text": "12.2 Conclusions\nThis part of the book focused on survival measures. Measures may be used to evaluate model predictions, to tune a model, or to train a model (e.g., in boosting or neural networks). Unlike other settings, there are many different choices of survival measures and it can be hard to determine which to use and when. In practice, like many areas of Statistics, the most important factor is to clearly define any experiment upfront and to be clear about which measures will be used and why. As a rule of thumb, good choices for measures are Harrell’s C for evaluating discrimination, with Uno’s C supporting findings, D-calibration for calibration, and the RCLL for evaluating overall predictive ability from distribution predictions. Finally, if you are restricted to a single measure choice (e.g., for automated tuning or continuous evaluation of deployed models), then we recommended selecting a scoring rule such as RCLL which captures information about calibration and discrimination simultaneously.\n\n\n\n\nBecker, Marc, Lennart Schneider, and Sebastian Fischer. 2024. “Hyperparameter Optimization.” In Applied Machine Learning Using mlr3 in R, edited by Bernd Bischl, Raphael Sonabend, Lars Kotthoff, and Michel Lang. CRC Press. https://mlr3book.mlr-org.com/hyperparameter_optimization.html.\n\n\nGönen, Mithat, and Glenn Heller. 2005. “Concordance Probability and Discriminatory Power in Proportional Hazards Regression.” Biometrika 92 (4): 965–70.\n\n\nLiang, Hua, and Guohua Zou. 2008. “Improved AIC Selection Strategy for Survival Analysis.” Computational Statistics & Data Analysis 52 (5): 2538–48. https://doi.org/10.1016/j.csda.2007.09.003.\n\n\nMolnar, Christoph. 2019. Interpretable Machine Learning. https://christophm.github.io/interpretable-ml-book/.\n\n\nRahman, M. Shafiqur, Gareth Ambler, Babak Choodari-Oskooei, and Rumana Z. Omar. 2017. “Review and evaluation of performance measures for survival prediction models in external validation settings.” BMC Medical Research Methodology 17 (1): 1–15. https://doi.org/10.1186/s12874-017-0336-2.\n\n\nSchmid, Matthias, and Sergej Potapov. 2012. “A comparison of estimators to evaluate the discriminatory power of time-to-event models.” Statistics in Medicine 31 (23): 2588–2609. https://doi.org/10.1002/sim.5464.\n\n\nSonabend, Raphael, Florian Pfisterer, Alan Mishler, Moritz Schauer, Lukas Burk, Sumantrak Mukherjee, and Sebastian Vollmer. 2022. “Flexible Group Fairness Metrics for Survival Analysis.” In DSHealth 2022 Workshop on Applied Data Science for Healthcare at KDD2022. http://arxiv.org/abs/2206.03256.\n\n\nTherneau, Terry M., and Elizabeth Atkinson. 2020. “Concordance.” https://cran.r-project.org/web/packages/survival/vignettes/concordance.pdf.\n\n\nUno, Hajime, Tianxi Cai, Lu Tian, and L J Wei. 2007. “Evaluating Prediction Rules for t-Year Survivors with Censored Regression Models.” Journal of the American Statistical Association 102 (478): 527–37. http://www.jstor.org/stable/27639883.\n\n\nVolinsky, Chris T, and Adrian E Raftery. 2000. “Bayesian Information Criterion for Censored Survival Models.” International Biometric Society 56 (1): 256–62.",
    "crumbs": [
      "Evaluation",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Choosing Measures</span>"
    ]
  },
  {
    "objectID": "P3C13_classical.html",
    "href": "P3C13_classical.html",
    "title": "13  Classical Models",
    "section": "",
    "text": "13.1 A Review of Classical Survival Models\nTODO\nThis chapter provides a brief review of classical survival models before later chapters move on to machine learning models. ‘Classical’ models are defined with a very narrow scope in this book: low-complexity models that are either non-parametric or have parameters that can be fit with maximum likelihood estimation (or an equivalent method). In contrast, ‘machine learning’ (ML) models require more intensive model fitting procedures such as recursion or iteration. The classical models in this paper are fast to fit and highly interpretable, though can be inflexible and may make unreasonable assumptions. Whereas the ML models are more flexible with hyper-parameters however are computationally more intensive (both in terms of speed and storage), require tuning to produce ‘good’ results, and are often a ‘black-box’ with difficult interpretation.\nAs classical survival models have been studied extensively for decades, these are only discussed briefly here, primarily these are of interest as many of these models will be seen to influence machine learning extensions. The scope of the models discussed in this chapter is limited to the general book scope (?sec-surv-scope), i.e. single event with right-censoring and no competing-risks, though in some cases these are discussed.\nThere are several possible taxonomies for categorising statistical models, these include:\nTable 13.1 summarises the models discussed below into the taxonomies above for reference. Note that the Cox model is listed as predicting a continuous ranking, and not a survival distribution, which may appear inconsistent with other definitions. The reason for this is elaborated upon in Chapter 19. Though the predict-type taxonomy is favoured throughout this book, it is clearer to review classical models in increasing complexity, beginning with unconditional estimators before moving onto semi-parametric continuous ranking predictions, and finally conditional distribution predictors. The review is brief with mathematics limited to the model fundamentals but not including methods for parameter estimation. Also the review is limited to the ‘basic’ model specification and common extensions such as regularization are not discussed though they do exist for many of these models.\nAll classical models are highly transparent and accessible, with decades of research and many off-shelf implementations. Predictive performance of each model is briefly discussed as part of the review and then again in (R. E. B. Sonabend 2021).\n* 1. All models are implemented in the \\(\\textsf{R}\\) package \\(\\textbf{survival}\\) (Therneau 2015) with the exception of flexible splines, implemented in \\(\\textbf{flexsurv}\\) (Jackson 2016), and the Akritas estimator in \\(\\textbf{survivalmodels}\\) (R. Sonabend 2020). * 2. Non = non-parametric, Semi = semi-parametric, Fully = fully-parametric. * 3. Distr. = distribution, Rank = ranking.",
    "crumbs": [
      "Models",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Classical Models</span>"
    ]
  },
  {
    "objectID": "P3C13_classical.html#sec-surv-models",
    "href": "P3C13_classical.html#sec-surv-models",
    "title": "13  Classical Models",
    "section": "",
    "text": "Parametrisation Type: One of non-, semi-, or fully-parametric. \\ Non-parametric models assume that the data distribution cannot be specified with a finite set of parameters. In contrast, fully-parametric models assume the distribution can be specified with a finite set of parameters. Semi-parametric models are a hybrid of the two and are formed of a finite set of parameters and an infinite-dimensional ‘nuisance’ parameter.\nConditionality Type: One of unconditional or conditional. A conditional prediction is one that makes use of covariates in order to condition the prediction on each observation. Unconditional predictors, which are referred to below as ‘estimators’, ignore covariate data and make the same prediction for all individuals.\nPrediction Type: One of ranking, survival time, or distribution (?sec-surv-set-types).\n\n\n\n\n\n\nTable 13.1: Table of models discussed in this literature review, classified by parametrisation, prediction type, and conditionality.\n\n\n\n\n\nModel\\(^1\\)\nParametrisation\\(^2\\)\nPrediction\\(^3\\)\nConditionality\n\n\n\n\nKaplan-Meier\nNon\nDistr.\nUnconditional\n\n\nNelson-Aalen\nNon\nDistr.\nUnconditional\n\n\nAkritas\nNon\nDistr.\nConditional\n\n\nCox PH\nSemi\nRank\nConditional\n\n\nParametric PH\nFully\nDistr.\nConditional\n\n\nAccelerated Failure Time\nFully\nDistr.\nConditional\n\n\nProportional Odds\nFully\nDistr.\nConditional\n\n\nFlexible Spline\nFully\nDistr.\nConditional\n\n\n\n\n\n\n\n\n13.1.1 Non-Parametric Distribution Estimators\n\nUnconditional Estimators\nUnconditional non-parametric survival models assume no distribution for survival times and estimate the survival function using simple algorithms based on observed outcomes and no covariate data. The two most common methods are the Kaplan-Meier estimator (KaplanMeier1958?), which estimates the average survival function of a training dataset, and the Nelson-Aalen estimator (Aalen 1978; Nelson 1972), which estimates the average cumulative hazard function of a training dataset.\nThe Kaplan-Meier estimator of the survival function is given by \\[\n\\hat{S}_{KM}(\\tau|\\mathcal{D}_{train}) = \\prod_{t \\in \\mathcal{U}_O, t \\leq \\tau} \\Big(1 - \\frac{d_t}{n_t}\\Big)\n\\tag{13.1}\\] As this estimate is so important in survival models, this book will always use the symbol \\(\\hat{S}_{KM}\\) to refer to the Kaplan-Meier estimate of the average survival function fit on training data \\((T_i, \\Delta_i)\\). Another valuable function is the Kaplan-Meier estimate of the average survival function of the censoring distribution, which is the same as above but estimated on \\((T_i, 1 - \\Delta_i)\\), this will be denoted by \\(\\hat{G}_{KM}\\).\nThe Nelson-Aalen estimator for the cumulative hazard function is given by \\[\n\\hat{H}(\\tau|\\mathcal{D}_{train}) = \\sum_{t \\in \\mathcal{U}_O, t \\leq \\tau} \\frac{d_t}{n_t}\n\\tag{13.2}\\]\nThe primary advantage of these models is that they rely on heuristics from empirical outcomes only and don’t require any assumptions about the form of the data. To train the models they only require \\((T_i,\\Delta_i)\\) and both return a prediction of \\(\\mathcal{S}\\subseteq \\operatorname{Distr}(\\mathcal{T})\\) ((box-task-surv?)). In addition, both simply account for censoring and can be utilised in fitting other models or to estimate unknown censoring distributions. The Kaplan-Meier and Nelson-Aalen estimators are both consistent estimators for the survival and cumulative hazard functions respectively.\nUtilising the relationships provided in (?sec-surv-set-types), one could write the Nelson-Aalen estimator in terms of the survival function as \\(\\hat{S}_{NA} = \\exp(-\\hat{H}(\\tau|\\mathcal{D}_{train}))\\). It has been demonstrated that \\(\\hat{S}_{NA}\\) and \\(\\hat{S}_{KM}\\) are asymptotically equivalent, but that \\(\\hat{S}_{NA}\\) will provide larger estimates than \\(\\hat{S}_{KM}\\) in smaller samples (Colosimo et al. 2002). In practice, the Kaplan-Meier is the most widely utilised non-parametric estimator in survival analysis and is the simplest estimator that yields consistent estimation of a survival distribution; it is therefore a natural, and commonly utilised, ‘baseline’ model (Binder and Schumacher 2008; Herrmann et al. 2021; Huang et al. 2020; Wang, Li, and Reddy 2019): estimators that other models should be ‘judged’ against to ascertain their overall performance (Chapter 7).\nNot only can these estimators be used for analytical comparison, but they also provide intuitive methods for graphical calibration of models (Section 9.2). These models are never stuidied for prognosis directly but as baselines, components of complex models (Chapter 19), or graphical tools (Habibi et al. 2018; Jager et al. 2008; Moghimi-dehkordi et al. 2008). The reason for this is due to them having poor predictive performance as a result of omitting explanatory variables in fitting. Moreover, if the data follows a particular distribution, parametric methods will be more efficient (Wang, Li, and Reddy 2019).\n\n\nConditional Estimators\nThe Kaplan-Meier and Nelson-Aalen estimators are simple to compute and provide good estimates for the survival time distribution but in many cases they may be overly-simplistic. Conditional non-parametric estimators include the advantages described above (no assumptions about underlying data distribution) but also allow for conditioning the estimation on the covariates. This is particularly useful when estimating a censoring distribution that may depend on the data (Chapter 7). However predictive performance of conditional non-parametric estimators decreases as the number of covariates increases, and these models are especially poor when censoring is feature-dependent (Gerds and Schumacher 2006).\nThe most widely used conditional non-parametric estimator for survival analysis is the Akritas estimator (Akritas 1994) defined by \\[\n\\hat{S}(\\tau|X^*, \\mathcal{D}_{train}, \\lambda) = \\prod_{j:T_j \\leq \\tau, \\Delta_j = 1} \\Big(1 - \\frac{K(X^*, X_j|\\lambda)}{\\sum_{l = 1}^n K(X^*, X_l|\\lambda)\\mathbb{I}(T_l \\geq T_j)}\\Big)\n\\] where \\(K\\) is a kernel function, usually \\(K(x,y|\\lambda) = \\mathbb{I}(\\lvert \\hat{F}_X(x) - \\hat{F}_X(y)\\rvert &lt; \\lambda), \\lambda \\in (0, 1]\\), \\(\\hat{F}_X\\) is the empirical distribution function of the training data, \\(X_1,...,X_n\\), and \\(\\lambda\\) is a hyper-parameter. The estimator can be interpreted as a conditional Kaplan-Meier estimator which is computed on a neighbourhood of subjects closest to \\(X^*\\) (Blanche, Dartigues, and Jacqmin-Gadda 2013). To account for tied survival times, the following adaptation of the estimator is utilised (Blanche, Dartigues, and Jacqmin-Gadda 2013)\n\\[\n\\hat{S}(\\tau|X^*, \\mathcal{D}_{train}, \\lambda) = \\prod_{t \\in \\mathcal{U}_O, t \\leq \\tau} \\Big(1 - \\frac{\\sum^n_{j=1} K(X^*,X_j|\\lambda)\\mathbb{I}(T_j = t, \\Delta_j = 1)}{\\sum^n_{j=1} K(X^*,X_j|\\lambda)\\mathbb{I}(T_j \\geq t)}\\Big)\n\\tag{13.3}\\] If \\(\\lambda = 1\\) then \\(K(\\cdot|\\lambda) = 1\\) and the estimator is identical to the Kaplan-Meier estimator.\nThe non-parametric nature of the model is highlighted in (Equation 13.3), in which both the fitting and predicting stages are combined into a single equation. A new observation, \\(X^*\\), is compared to its nearest neighbours from a training dataset, \\(\\mathcal{D}_{train}\\), without a separated fitting procedure. One could consider splitting fitting and predicting in order to clearly separate between training and testing data. In this case, the fitting procedure is the estimation of \\(\\hat{F}_X\\) on training data and the prediction is given by (Equation 13.3) with \\(\\hat{F}_X\\) as an argument. This separated fit/predict method is implemented in \\(\\textbf{survivalmodels}\\) (R. Sonabend 2020). As with other non-parametric estimators, the Akritas estimator can still be considered transparent and accessible. With respect to predictive performance, the Akritas estimator has more explanatory power than non-parametric estimators due to conditioning on covariates, however this is limited to a very small number of variables and therefore this estimator is still best placed as a conditional baseline.\n\n\n\n13.1.2 Continuous Ranking and Semi-Parametric Models: Cox PH\nThe Cox Proportional Hazards (CPH) (Cox 1972), or Cox model, is likely the most widely known semi-parametric model and the most studied survival model (Habibi et al. 2018; Moghimi-dehkordi et al. 2008; Reid 1994; Wang, Li, and Reddy 2019). The Cox model assumes that the hazard for a subject is proportionally related to their explanatory variables, \\(X_1,...,X_n\\), via some baseline hazard that all subjects in a given dataset share (‘the PH assumption’). The hazard function in the Cox PH model is defined by \\[\nh(\\tau|X_i)= h_0(\\tau)\\exp(X_i\\beta)\n\\] where \\(h_0\\) is the non-negative baseline hazard function and \\(\\beta = \\beta_1,...,\\beta_p\\) where \\(\\beta_i \\in \\mathbb{R}\\) are coefficients to be fit. Note the proportional hazards (PH) assumption can be seen as the estimated hazard, \\(h(\\tau|X_i)\\), is directly proportional to the model covariates \\(\\exp(X_i\\beta)\\). Whilst a form is assumed for the ‘risk’ component of the model, \\(\\exp(X_i\\beta)\\), no assumptions are made about the distribution of \\(h_0\\), hence the model is semi-parametric.\nThe coefficients, \\(\\beta\\), are estimated by maximum likelihood estimation of the ‘partial likelihood’ (Cox 1975), which only makes use of ordered event times and does not utilise all data available (hence being ‘partial’). The partial likelihood allows study of the informative \\(\\beta\\)-parameters whilst ignoring the nuisance \\(h_0\\). The predicted linear predictor, \\(\\hat{\\eta} := X^*\\hat{\\beta}\\), can be computed from the estimated \\(\\hat{\\beta}\\) to provide a ranking prediction.\nInspection of the model is also useful without specifying the full hazard by interpreting the coefficients as ‘hazard ratios’. Let \\(p = 1\\) and \\(\\hat{\\beta} \\in \\mathbb{R}\\) and let \\(X_i,X_j \\in \\mathbb{R}\\) be the covariates of two training observations, then the hazard ratio for these observations is the ratio of their hazard functions, \\[\n\\frac{h(\\tau|X_i)}{h(\\tau|X_j)} = \\frac{h_0(\\tau)\\exp(X_i\\hat{\\beta})}{h_0(\\tau)\\exp(X_j\\hat{\\beta})} =  \\exp(\\hat{\\beta})^{X_i - X_j}\n\\]\nIf \\(\\exp(\\hat{\\beta}) = 1\\) then \\(h(\\tau|X_i) = h(\\tau|X_j)\\) and thus the covariate has no effect on the hazard. If \\(\\exp(\\hat{\\beta}) &gt; 1\\) then \\(X_i &gt; X_j \\rightarrow h(\\tau|X_i) &gt; h(\\tau|X_i)\\) and therefore the covariate is positively correlated with the hazard (increases risk of event). Finally if \\(\\exp(\\hat{\\beta}) &lt; 1\\) then \\(X_i &gt; X_j \\rightarrow h(\\tau|X_i) &lt; h(\\tau|X_i)\\) and the covariate is negatively correlated with the hazard (decreases risk of event).\nInterpreting hazard ratios is known to be a challenge, especially by clinicians who require simple statistics to communicate to patients (Sashegyi and Ferry 2017; Spruance et al. 2004). For example the full interpretation of a hazard ratio of ‘2’ for binary covariate \\(X\\) would be: ‘assuming that the risk of death is constant at all time-points then the instantaneous risk of death is twice as high in a patient with \\(X\\) than without’. Simple conclusions are limited to stating if patients are at more or less risk than others in their cohort. Further disadvantages of the model also lie in its lack of real-world interpretabilitity, these include (Reid 1994):\n\nthe PH assumption may not be realistic and the risk of event may not be constant over time;\nthe estimated baseline hazard from a non-parametric estimator is a discrete step-function resulting in a discrete survival distribution prediction despite time being continuous; and\nthe estimated baseline hazard will be constant after the last observed time-point in the training set (Gelfand et al. 2000).\n\nDespite these disadvantages, the model has been demonstrated to have excellent predictive performance and routinely outperforms (or at least does not underperform) sophisticated ML models (Gensheimer and Narasimhan 2018; Luxhoj and Shyur 1997; Van Belle et al. 2011) (and (R. E. B. Sonabend 2021)). It’s simple form and wide popularity mean that it is also highly transparent and accessible.\nThe next class of models address some of the Cox model disadvantages by making assumptions about the baseline hazard.\n\n\n13.1.3 Conditional Distribution Predictions: Parametric Linear Models\n\nParametric Proportional Hazards\nThe CPH model can be extended to a fully parametric PH model by substituting the unknown baseline hazard, \\(h_0\\), for a particular parameterisation. Common choices for distributions are Exponential, Weibull and Gompertz (Kalbfleisch and Prentice 2011; Wang, Li, and Reddy 2019); their hazard functions are summarised in ((tab-survivaldists?)) along with the respective parametric PH model. Whilst an Exponential assumption leads to the simplest hazard function, which is constant over time, this is often not realistic in real-world applications. As such the Weibull or Gompertz distributions are often preferred. Moreover, when the shape parameter, \\(\\gamma\\), is \\(1\\) in the Weibull distribution or \\(0\\) in the Gompertz distribution, their hazards reduce to a constant risk ((Figure 13.1)). As this model is fully parametric, the model parameters can be fit with maximum likelihood estimation, with the likelihood dependent on the chosen distribution.\n\n\n\nTable 13.2: Exponential, Weibull, and Gompertz hazard functions and PH specification.\n\n\n\n\n\n\n\n\n\n\nDistribution\\(^1\\)\n\\(h_0(\\tau)^2\\)\n\\(h(\\tau|X_i)^3\\)\n\n\n\n\n\\(\\operatorname{Exp}(\\lambda)\\)\n\\(\\lambda\\)\n\\(\\lambda\\exp(X_i\\beta)\\)\n\n\n\\(\\operatorname{Weibull}(\\gamma, \\lambda)\\)\n\\(\\lambda\\gamma \\tau^{\\gamma-1}\\)\n\\(\\lambda\\gamma \\tau^{\\gamma-1}\\exp(X_i\\beta)\\)\n\n\n\\(\\operatorname{Gompertz}(\\gamma, \\lambda)\\)\n\\(\\lambda \\exp(\\gamma \\tau)\\)\n\\(\\lambda \\exp(\\gamma \\tau)\\exp(X_i\\beta)\\)\n\n\n\n\n\n\n * 1. Distribution choices for baseline hazard. \\(\\gamma,\\lambda\\) are shape and scale parameters respectively. * 2. Baseline hazard function, which is the (unconditional) hazard of the distribution. * 3. PH hazard function, \\(h(\\tau|X_i) = h_0(\\tau)\\exp(X_i\\beta)\\). \n\n\n\n\n\n\nFigure 13.1: Comparing the hazard curves under Weibull and Gompertz distributions for varying values of the shape parameter; scale parameters are set so that each parametrisation has a median of 20. x-axes are time and y-axes are Weibull (top) and Gompertz (bottom) hazards as a function of time.\n\n\n\nIn the literature, the Weibull distribution tends to be favoured as the initial assumption for the survival distribution (Gensheimer and Narasimhan 2018; Habibi et al. 2018; Hielscher et al. 2010; R. and J. 1968; Rahman et al. 2017), though Gompertz is often tested in death-outcome models for its foundations in modelling human mortality (Gompertz 1825). There exist many tests for checking the goodness-of-model-fit (?sec-eval-insample) and the distribution choice can even be treated as a model hyper-parameter. Moreover it transpires that model inference and predictions are largely insensitive to the choice of distribution (Collett 2014; Reid 1994). In contrast to the Cox model, fully parametric PH models can predict absolutely continuous survival distributions, they do not treat the baseline hazard as a nuisance, and in general will result in more precise and interpretable predictions if the distribution is correctly specified (Reid 1994; Royston and Parmar 2002).\nWhilst misspecification of the distribution tends not to affect predictions too greatly, PH models will generally perform worse when the PH assumption is not valid. PH models can be extended to include time-varying coefficients or model stratification (Cox 1972) but even with these adaptations the model may not reflect reality. For example, the predicted hazard in a PH model will be either monotonically increasing or decreasing but there are many scenarios where this is not realistic, such as when recovering from a major operation where risks tends to increase in the short-term before decreasing. Accelerated failure time models overcome this disadvantage and allow more flexible modelling, discussed next.\n\n\nAccelerated Failure Time\nIn contrast to the PH assumption, where a unit increase in a covariate is a multiplicative increase in the hazard rate, the Accelerated Failure Time (AFT) assumption means that a unit increase in a covariate results in an acceleration or deceleration towards death (expanded on below). The hazard representation of an AFT model demonstrates how the interpretation of covariates differs from PH models, \\[\nh(\\tau|X_i)= h_0(\\exp(-X_i\\beta)\\tau)\\exp(-X_i\\beta)\n\\] where \\(\\beta = (\\beta_1,...,\\beta_p)\\) are model coefficients. In contrast to PH models, the ‘risk’ component, \\(\\exp(-X_i\\beta)\\), is the exponential of the negative linear predictor and therefore an increase in a covariate value results in a decrease of the predicted hazard. This representation also highlights how AFT models are more flexible than PH as the predicted hazard can be non-monotonic. For example the hazard of the Log-logistic distribution ((Figure 13.2)) is highly flexible depending on chosen parameters. Not only can the AFT model offer a wider range of shapes for the hazard function but it is more interpretable. Whereas covariates in a PH model act on the hazard, in an AFT they act on time, which is most clearly seen in the log-linear representation, \\[\n\\log Y_i = \\mu + \\alpha_1X_{i1} + \\alpha_2X_{i2} + ... + \\alpha_pX_{ip} + \\sigma\\epsilon_i\n\\] where \\(\\mu\\) and \\(\\sigma\\) are location and scale parameters respectively, \\(\\alpha_1,...,\\alpha_p\\) are model coefficients, and \\(\\epsilon_i\\) is a random error term. In this case a one unit increase in covariate \\(X_{ij}\\) means a \\(\\alpha_j\\) increase in the logarithmic survival time. For example if \\(\\exp(X_i\\alpha) = 0.5\\) then \\(i\\) ‘ages’ at double the baseline ‘speed’. Or less abstractly if studying the time until death from cancer then \\(\\exp(X_i\\alpha) = 0.5\\) can be interpreted as ‘the entire process from developing tumours to metastasis and eventual death in subject \\(i\\) is twice as fast than the normal’, where ‘normal’ refers to the baseline when all covariates are \\(0\\).\nSpecifying a particular distribution for \\(\\epsilon_i\\) yields a fully-parametric AFT model. Common distribution choices include Weibull, Exponential, Log-logistic, and Log-Normal (Kalbfleisch and Prentice 2011; Wang, Li, and Reddy 2019). The Buckley-James estimator (Buckley and James 1979) is a semi-parametric AFT model that non-parametrically estimates the distribution of the errors however this model has no theoretical justification and is rarely fit in practice (Wei 1992). The fully-parametric model has theoretical justifications, natural interpretability, and can often provide a better fit than a PH model, especially when the PH assumption is violated (Patel, Kay, and Rowell 2006; Qi 2009; Zare et al. 2015).\n\n\n\n\n\n\nFigure 13.2: Log-logistic hazard curves with a fixed scale parameter of 1 and a changing shape parameter. x-axis is time and y-axis is the log-logistic hazard as a function of time.\n\n\n\n\n\nProportional Odds\nProportional odds (PO) models (Bennett 1983) fit a proportional relationship between covariates and the odds of survival beyond a time \\(\\tau\\), \\[\nO_i(\\tau) = \\frac{S_i(\\tau)}{F_i(\\tau)} = O_0(\\tau)\\exp(X_i\\beta)\n\\] where \\(O_0\\) is the baseline odds.\nIn this model, a unit increase in a covariate is a multiplicative increase in the odds of survival after a given time and the model can be interpreted as estimating the log-odds ratio. There is no simple closed form expression for the partial likelihood of the PO model and hence in practice a Log-logistic distribution is usually assumed for the baseline odds and the model is fit by maximum likelihood estimation on the full likelihood (Bennett 1983).\nPerhaps the most useful feature of the model is convergence of hazard functions (Kirmani and Gupta 2001), which states \\(h_i(\\tau)/h_0(\\tau) \\rightarrow 1\\) as \\(\\tau \\rightarrow \\infty\\). This property accurately reflects real-world scenarios, for example if comparing chemotherapy treatment on advanced cancer survival rates, then it is expected that after a long period (say 10 years) the difference in risk between groups is likely to be negligible. This is in contrast to the PH model that assumes the hazard ratios are constant over time, which is rarely a reflection of reality.\nIn practice, the PO model is harder to fit and is less flexible than PH and AFT models, both of which can also produce odds ratios. This may be a reason for the lack of popularity of the PO model, in addition there is limited off-shelf implementations (Collett 2014). Despite PO models not being commonly utilised, they have formed useful components of neural networks (Section 17.1) and flexible parametric models (below).\n\n\nFlexible Parametric Models – Splines\nRoyston-Parmar flexible parametric models (Royston and Parmar 2002) extend PH and PO models by estimating the baseline hazard with natural cubic splines. The model was designed to keep the form of the PH or PO methods but without the semi-parametric problem of estimating a baseline hazard that does not reflect reality (see above), or the parametric problem of misspecifying the survival distribution.\nTo provide an interpretable, informative and smooth hazard, natural cubic splines are fit in place of the baseline hazard. The crux of the method is to use splines to model time on a log-scale and to either estimate the log cumulative Hazard for PH models, \\(\\log H(\\tau|X_i) = \\log H_0(\\tau) + X_i\\beta\\), or the log Odds for PO models, \\(\\log O(\\tau|X_i) = \\log O_0(\\tau) + X_i\\beta\\), where \\(\\beta\\) are model coefficients to fit, \\(H_0\\) is the baseline cumulative hazard function and \\(O_0\\) is the baseline odds function. For the flexible PH model, a Weibull distribution is the basis for the baseline distribution and a Log-logistic distribution for the baseline odds in the flexible PO model. \\(\\log H_0(\\tau)\\) and \\(\\log O_0(\\tau)\\) are estimated by natural cubic splines with coefficients fit by maximum likelihood estimation. The standard full likelihood is optimised, full details are not provided here. Between one and three internal knots are recommended for the splines and the placement of knots does not greatly impact upon the fitted model (Royston and Parmar 2002).\nAdvantages of the model include being: interpretable, flexible, can be fit with time-dependent covariates, and it returns a continuous function. Moreover many of the parameters, including the number and position of knots, are tunable, although Royston and Parmar advised against tuning and suggest often only one internal knot is required (Royston and Parmar 2002). A recent simulation study demonstrated that even with an increased number of knots (up to seven degrees of freedom), there was little bias in estimation of the survival and hazard functions (Bower et al. 2019). Despite its advantages, a 2018 review (Ng et al. 2018) found only twelve instances of published flexible parametric models since Royston and Parmar’s 2002 paper, perhaps because it is more complex to train, has a less intuitive fitting procedure than alternatives, and has limited off-shelf implementations; i.e. is less transparent and accessible than parametric alternatives.\nThe PH and AFT models are both very transparent and accessible, though require slightly more expert knowledge than the CPH in order to specify the ‘correct’ underlying probability distribution. Interestingly whilst there are many papers comparing PH and AFT models to one another using in-sample metrics (?sec-eval-insample) such as AIC (Georgousopoulou et al. 2015; Habibi et al. 2018; Moghimi-dehkordi et al. 2008; Zare et al. 2015), no benchmark experiments could be found for out-of-sample performance. PO and spline models are less transparent than PH and AFT models and are even less accessible, with very few implementations of either. No conclusions can be drawn about the predictive performance of PO or spline models due to a lack of suitable benchmark experiments.\n\n\n\n\nAalen, Odd. 1978. “Nonparametric Inference for a Family of Counting Processes.” The Annals of Statistics 6 (4): 701–26.\n\n\nAkritas, Michael G. 1994. “Nearest Neighbor Estimation of a Bivariate Distribution Under Random Censoring.” Ann. Statist. 22 (3): 1299–1327. https://doi.org/10.1214/aos/1176325630.\n\n\nBennett, Steve. 1983. “Analysis of survival data by the proportional odds model.” Statistics in Medicine 2 (2): 273–77. https://doi.org/https://doi.org/10.1002/sim.4780020223.\n\n\nBinder, Harald, and Martin Schumacher. 2008. “Allowing for mandatory covariates in boosting estimation of sparse high-dimensional survival models.” BMC Bioinformatics 9 (1): 14. https://doi.org/10.1186/1471-2105-9-14.\n\n\nBlanche, Paul, Jean-François Dartigues, and Hélène Jacqmin-Gadda. 2013. “Review and comparison of ROC curve estimators for a time-dependent outcome with marker-dependent censoring.” Biometrical Journal 55 (5): 687–704. https://doi.org/10.1002/bimj.201200045.\n\n\nBower, Hannah, Michael J Crowther, Mark J Rutherford, Therese M.-L. Andersson, Mark Clements, Xing-Rong Liu, Paul W Dickman, and Paul C Lambert. 2019. “Capturing simple and complex time-dependent effects using flexible parametric survival models: A simulation study.” Communications in Statistics - Simulation and Computation, July, 1–17. https://doi.org/10.1080/03610918.2019.1634201.\n\n\nBuckley, Jonathan, and Ian James. 1979. “Linear Regression with Censored Data.” Biometrika 66 (3): 429–36. https://doi.org/10.2307/2335161.\n\n\nCollett, David. 2014. Modelling Survival Data in Medical Research. 3rd ed. CRC.\n\n\nColosimo, Enrico, Fla´vio Ferreira, Maristela Oliveira, and Cleide Sousa. 2002. “Empirical comparisons between Kaplan-Meier and Nelson-Aalen survival function estimators.” Journal of Statistical Computation and Simulation 72 (4): 299–308. https://doi.org/10.1080/00949650212847.\n\n\nCox, D. R. 1972. “Regression Models and Life-Tables.” Journal of the Royal Statistical Society: Series B (Statistical Methodology) 34 (2): 187–220.\n\n\n———. 1975. “Partial Likelihood.” Biometrika 62 (2): 269–76. https://doi.org/10.1080/03610910701884021.\n\n\nGelfand, Alan E, Sujit K Ghosh, Cindy Christiansen, Stephen B Soumerai, and Thomas J McLaughlin. 2000. “Proportional hazards models: a latent competing risk approach.” Journal of the Royal Statistical Society: Series C (Applied Statistics) 49 (3): 385–97. https://doi.org/https://doi.org/10.1111/1467-9876.00199.\n\n\nGensheimer, Michael F., and Balasubramanian Narasimhan. 2018. “A Simple Discrete-Time Survival Model for Neural Networks,” 1–17. https://doi.org/arXiv:1805.00917v3.\n\n\nGeorgousopoulou, Ekavi N, Christos Pitsavos, Christos Mary Yannakoulia, and Demosthenes B Panagiotakos. 2015. “Comparisons between Survival Models in Predicting Cardiovascular Disease Events : Application in the ATTICA Study ( 2002-2012 ).” Journal of Statistics Applications & Probability 4 (2): 203–10.\n\n\nGerds, Thomas A, and Martin Schumacher. 2006. “Consistent Estimation of the Expected Brier Score in General Survival Models with Right-Censored Event Times.” Biometrical Journal 48 (6): 1029–40. https://doi.org/10.1002/bimj.200610301.\n\n\nGompertz, Benjamin. 1825. “On the Nature of the Function Expressive of the Law of Human Mortality, and on a New Mode of Determining the Value of Life Contingencies.” Philosophical Transactions of the Royal Society of London 115: 513–83.\n\n\nHabibi, Danial, Mohammad Rafiei, Ali Chehrei, Zahra Shayan, and Soheil Tafaqodi. 2018. “Comparison of Survival Models for Analyzing Prognostic Factors in Gastric Cancer Patients.” Asian Pacific Journal of Cancer Prevention : APJCP 19 (3): 749–53. https://doi.org/10.22034/APJCP.2018.19.3.749.\n\n\nHerrmann, Moritz, Philipp Probst, Roman Hornung, Vindi Jurinovic, and Anne-Laure Boulesteix. 2021. “Large-scale benchmark study of survival prediction methods using multi-omics data.” Briefings in Bioinformatics 22 (3). https://doi.org/10.1093/bib/bbaa167.\n\n\nHielscher, Thomas, Manuela Zucknick, Wiebke Werft, and Axel Benner. 2010. “On the Prognostic Value of Gene Expression Signatures for Censored Data BT - Advances in Data Analysis, Data Handling and Business Intelligence.” In, edited by Andreas Fink, Berthold Lausen, Wilfried Seidel, and Alfred Ultsch, 663–73. Berlin, Heidelberg: Springer Berlin Heidelberg.\n\n\nHuang, Shigao, Jie Yang, Simon Fong, and Qi Zhao. 2020. “Artificial intelligence in cancer diagnosis and prognosis: Opportunities and challenges.” Cancer Letters 471: 61–71. https://doi.org/https://doi.org/10.1016/j.canlet.2019.12.007.\n\n\nJackson, Christopher. 2016. “flexsurv: A Platform for Parametric Survival Modeling in R.” Journal of Statistical Software 70 (8): 1–33.\n\n\nJager, Kitty J, Paul C van Dijk, Carmine Zoccali, and Friedo W Dekker. 2008. “The analysis of survival data: the Kaplan–Meier method.” Kidney International 74 (5): 560–65. https://doi.org/https://doi.org/10.1038/ki.2008.217.\n\n\nKalbfleisch, John D, and Ross L Prentice. 2011. The statistical analysis of failure time data. Vol. 360. John Wiley & Sons.\n\n\nKirmani, S N U A, and Ramesh C Gupta. 2001. “On the Proportional Odds Model in Survival Analysis.” Annals of the Institute of Statistical Mathematics 53 (2): 203–16. https://doi.org/10.1023/A:1012458303498.\n\n\nLuxhoj, James T., and Huan Jyh Shyur. 1997. “Comparison of proportional hazards models and neural networks for reliability estimation.” Journal of Intelligent Manufacturing 8 (3): 227–34. https://doi.org/10.1023/A:1018525308809.\n\n\nMoghimi-dehkordi, Bijan, Azadeh Safaee, Mohamad Amin Pourhoseingholi, Reza Fatemi, Ziaoddin Tabeie, and Mohammad Reza Zali. 2008. “Statistical Comparison of Survival Models for Analysis of Cancer Data.” Asian Pacific Journal of Cancer Prevention 9: 417–20.\n\n\nNelson, Wayne. 1972. “Theory and Applications of Hazard Plotting for Censored Failure Data.” Technometrics 14 (4): 945–66.\n\n\nNg, Ryan, Kathy Kornas, Rinku Sutradhar, Walter P. Wodchis, and Laura C. Rosella. 2018. “The current application of the Royston-Parmar model for prognostic modeling in health research: a scoping review.” Diagnostic and Prognostic Research 2 (1): 4. https://doi.org/10.1186/s41512-018-0026-5.\n\n\nPatel, Katie, Richard Kay, and Lucy Rowell. 2006. “Comparing proportional hazards and accelerated failure time models: An application in influenza.” Pharmaceutical Statistics 5 (3): 213–24. https://doi.org/10.1002/pst.213.\n\n\nQi, Jiezhi. 2009. “Comparison of Proportional Hazards and Accelerated Failure Time Models.” PhD thesis.\n\n\nR., Cox, and Snell J. 1968. “A General Definition of Residuals.” Journal of the Royal Statistical Society: Series B (Statistical Methodology) 30 (2): 248–75.\n\n\nRahman, M. Shafiqur, Gareth Ambler, Babak Choodari-Oskooei, and Rumana Z. Omar. 2017. “Review and evaluation of performance measures for survival prediction models in external validation settings.” BMC Medical Research Methodology 17 (1): 1–15. https://doi.org/10.1186/s12874-017-0336-2.\n\n\nReid, Nancy. 1994. “A Conversation with Sir David Cox.” Statistical Science 9 (3): 439–55. https://doi.org/10.1214/aos/1176348654.\n\n\nRoyston, Patrick, and Mahesh K. B. Parmar. 2002. “Flexible parametric proportional-hazards and proportional-odds models for censored survival data, with application to prognostic modelling and estimation of treatment effects.” Statistics in Medicine 21 (15): 2175–97. https://doi.org/10.1002/sim.1203.\n\n\nSashegyi, Andreas, and David Ferry. 2017. “On the Interpretation of the Hazard Ratio and Communication of Survival Benefit.” The Oncologist 22 (4): 484–86. https://doi.org/10.1634/theoncologist.2016-0198.\n\n\nSonabend, Raphael. 2020. “survivalmodels: Models for Survival Analysis.” CRAN. https://raphaels1.r-universe.dev/ui#package:survivalmodels.\n\n\nSonabend, Raphael Edward Benjamin. 2021. “A Theoretical and Methodological Framework for Machine Learning in Survival Analysis: Enabling Transparent and Accessible Predictive Modelling on Right-Censored Time-to-Event Data.” PhD, University College London (UCL). https://discovery.ucl.ac.uk/id/eprint/10129352/.\n\n\nSpruance, Spotswood L, Julia E Reid, Michael Grace, and Matthew Samore. 2004. “Hazard ratio in clinical trials.” Antimicrobial Agents and Chemotherapy 48 (8): 2787–92. https://doi.org/10.1128/AAC.48.8.2787-2792.2004.\n\n\nTherneau, Terry M. 2015. “A Package for Survival Analysis in S.” https://cran.r-project.org/package=survival.\n\n\nVan Belle, Vanya, Kristiaan Pelckmans, Sabine Van Huffel, and Johan A. K. Suykens. 2011. “Support vector methods for survival analysis: A comparison between ranking and regression approaches.” Artificial Intelligence in Medicine 53 (2): 107–18. https://doi.org/10.1016/j.artmed.2011.06.006.\n\n\nWang, Ping, Yan Li, and Chandan K. Reddy. 2019. “Machine Learning for Survival Analysis.” ACM Computing Surveys 51 (6): 1–36. https://doi.org/10.1145/3214306.\n\n\nWei, L J. 1992. “The Accelerated Failure Time Model: A Useful Alternative to the Cox Regression Model in Survival Analysis.” Statistics in Medicine 11: 1871–79.\n\n\nZare, Ali, Mostafa Hosseini, Mahmood Mahmoodi, Kazem Mohammad, Hojjat Zeraati, and Kourosh Holakouie Naieni. 2015. “A Comparison between Accelerated Failure-time and Cox Proportional Hazard Models in Analyzing the Survival of Gastric Cancer Patients.” Iranian Journal of Public Health 44 (8): 1095–1102. https://doi.org/10.1007/s00606-006-0435-8.",
    "crumbs": [
      "Models",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Classical Models</span>"
    ]
  },
  {
    "objectID": "P3C14_forests.html",
    "href": "P3C14_forests.html",
    "title": "14  Random Forests",
    "section": "",
    "text": "14.1 Random Forests for Regression\nRandom forests are a composite (or ensemble) algorithm built by fitting many simpler component models, decision trees, and then averaging the results of predictions from these trees. Due to in-built variable importance properties, random forests are commonly used in high-dimensional settings when the number of variables in a dataset far exceeds the number of rows. High-dimensional datasets are very common in survival analysis, especially when considering omics, genetic and financial data. It is therefore no surprise that random survival forests, remain a popular and well-performing model in the survival setting.\nTraining of decision trees can include a large number of hyper-parameters and different training steps including ‘growing’ and subsequently ‘pruning’. However, when utilised in random forests, many of these parameters and steps can be safely ignored, hence this section only focuses on the components that primarily influence the resulting random forest. This section will start by discussing decision trees and will then introduce the bagging algorithm used to create random forests.",
    "crumbs": [
      "Models",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Random Forests</span>"
    ]
  },
  {
    "objectID": "P3C14_forests.html#random-forests-for-regression",
    "href": "P3C14_forests.html#random-forests-for-regression",
    "title": "14  Random Forests",
    "section": "",
    "text": "14.1.1 Decision Trees\nDecision trees are a (relatively) simple machine learning model that are comparatively easy to implement in software and are highly interpretable. The decision tree algorithm takes an input, a dataset, selects a variable that is used to partition the data according to some splitting rule into distinct non-overlapping datasets or nodes or leaves, and repeats this step for the resulting partitions, or branches, until some criterion has been reached. The final nodes are referred to as terminal nodes.\nBy example, (Figure 14.1) demonstrates a decision tree predicting the price that a car sells for in India (price in thousands of dollars). The dataset includes as variables the registration year, kilometers driven, fuel type (petrol or automatic), seller type (individual or dealer), transmission type (manual or automatic), and number of owners. The decision tree was trained with a maximum depth of 2 (the number of rows excluding the top), and it can be seen that with this restriction only the transmission type, registration year, and fuel type were selected variables. During training, the algorithm identified that the first optimal variable to split the data was transmission type, partitioning the data into manual and automatic cars. Manual cars are further subset by registration year whereas automatic cars are split by fuel type. It can also be seen how the average sale price (top value in each leaf) diverges between leaves as the tree splits – the average sale prices in the final leaves are the terminal node predictions.\nThe graphic highlights several core features of decision trees:\n\nThey can model non-linear and interaction effects: The hierarchical structure allows for complex interactions between variables with some variables being used to separate all observations (transmission) and others only applied to subsets (year and fuel);\nThey are highly interpretable: it is easy to visualise the tree and see how predictions are made;\nThey perform variable selection: not all variables were used to train the model.\n\nTo understand how random forests work, it is worth looking a bit more into the most important components of decision trees: splitting rules, stopping rules, and terminal node predictions.\n\n\n\n\n\n\nFigure 14.1: Predicting the price a vehicle is sold for in India using a regression tree, dataset from kaggle.com/datasets/nehalbirla/vehicle-dataset-from-cardekho. Rounded rectangles are leaves, which indicate the variable that is being split. Edges are branches, which indicate the cut-off at which the variable is split. Variables are car transmission type (manual or automatic), fuel type (petrol or diesel) and registration year. The number at the top of each leaf is the average selling price in thousands of dollars for all observations in that leaf. The numbers at the bottom of each leaf are the number of observations in the leaf, and the proportion of data contained in the leaf.\n\n\n\n\nSplitting and Stopping Rules\nPrecisely how the data partitions/splits are derived and which variables are utilised is determined by the splitting rule. The goal in each partition is to find two resulting leaves/nodes that have the greatest difference between them and thus the maximal homogeneity within each leaf, hence with each split, the data in each node should become increasingly similar. The splitting rule provides a way to measure the homogeneity within the resulting nodes. In regression, the most common splitting rule is to select a variable and cut-off (a threshold on the variable at which to separate observations) that minimises the mean squared error in the two potential resulting leaves.\nFor all decision tree and random forest algorithms going forward, let \\(L\\) denote some leaf, then let \\(L_{xy}, L_x, L_y\\) respectively be the set of observations, features, and outcomes in leaf \\(L\\). Let \\(L_{y;i}\\) be the \\(i\\)th outcome in \\(L_y\\) and finally let \\(\\bar{y}_L = \\frac{1}{|L_y|} \\sum^{|L_y|}_{i = 1} L_{y;i}\\) be the mean outcome in leaf \\(L\\).\nLet \\(j=1,\\ldots,p\\) be the index of features and let \\(c_j\\) be a possible cutoff value for feature \\(\\mathbf{x}_{;j}\\). Define \\[\n\\begin{split}\nL^a_{xy}(j,c_j) := \\{(\\mathbf{x}_i,y_i)|x_{i;j} \\boldsymbol{&lt;} c_j, i = 1,...,n\\} \\\\\nL^b_{xy}(j,c_j) := \\{(\\mathbf{x}_i,y_i)|x_{i;j} \\boldsymbol{\\geq} c_j, i = 1,...,n\\}\n\\end{split}\n\\] as the two leaves containing the set of observations resulting from partitioning variable \\(j\\) at cutoff \\(c_j\\). To simplify equations let \\(L^a, L^b\\) be shorthands for \\(L^a(j,c_j)\\) and \\(L^b(j,c_j)\\). Then a split is determined by finding the arguments, \\((j^*,c_{j^*}^*)\\) that minimise the residual sum of squares across both leaves (James et al. 2013), \\[\n(j^*, c_{j^*}^*) = \\mathop{\\mathrm{arg\\,min}}_{j, c_j} \\sum_{y \\in L^a_{y}} (y - \\bar{y}_{L^a})^2 + \\sum_{y \\in L^b_{y}} (y - \\bar{y}_{L^b})^2\n\\tag{14.1}\\]\nThis method is repeated from the first leaf to the last such that observations are included in a given leaf \\(L\\) if they satisfy all conditions from all previous branches (splits); features may be considered multiple times in the growing process allowing complex interaction effects to be captured.\nLeaves are repeatedly split until a stopping rule has been triggered – a criterion that tells the algorithm to stop partitioning data. The stopping rule is usually a condition on the number of observations in each leaf such that leaves will continue to be split until some minimum number of observations has been reached in a leaf. Other conditions may be on the depth of the tree (as in Figure 14.1 which is restricted to a maximum depth of 2), which corresponds to the number of levels of splitting. Stopping rules are often used together, for example by setting a maximum tree depth and determining a minimum number of observations per leaf. Deciding the number of minimum observations and/or the maximum depth can be performed with automated hyper-parameter optimisation.\n\n\nTerminal Node Predictions\nThe final major component of decision trees are terminal node predictions. As the name suggests, this is the part of the algorithm that determines how to actually make a prediction for a new observation. A prediction is made by ‘dropping’ the new data ‘down’ the tree according to the optimal splits that were found during training. The resulting prediction is then a simple baseline statistic computed from the training data that fell into the corresponding node. In regression, this is commonly the sample mean of the training outcome data.\nReturning to Figure 14.1, say a new data point is {transmission = Manual, fuel = Diesel, year = 2015}, then in the first split the left branch is taken as ‘transmission = Manual’, in the second split the right branch is taken as ‘year’ \\(= 2015 \\geq 2014\\), hence the new data point lands in the second terminal leaf and is predicted to sell for $7,600. The ‘fuel’ variable is ignored as it is only considered for automatic vehicles. As the final predictions are simple statistics based on training data, all potential predictions can be saved in the original trained model and no complex computations are required in the prediction algorithm.\n\n\n\n14.1.2 Random Forests\nDecision trees often overfit the training data, hence they have high variance, perform poorly on new data, and are not robust to even small changes in the original training data. Moreover, important variables can end up being ignored as only subsets of dominant variables are selected for splitting.\nTo counter these problems, random forests are designed to improve prediction accuracy and decrease variance. Random forests utilise bootstrap aggregation, or bagging (Leo Breiman 1996), to aggregate many decision trees. Bagging is a relatively simple algorithm, as follows:\n\nFor \\(b = 1,...,B\\):\n\\(D_b \\gets \\text{ Randomly sample with replacement } \\mathcal{D}_{train}\\)\n\\(\\hat{g}_b \\gets \\text{ Train a decision tree on } D_b\\)\nend For\nreturn \\(\\{\\hat{g}_b\\}^B_{b=1}\\)\n\nStep 2 is known as bootstrapping, which is the process of sampling a dataset with replacement – which is in contrast to more standard subsampling where data is sampled without replacement. Commonly, the bootstrapped sample size is the same as the original. However, as the same value may be sampled multiple times, on average the resulting data only contains around 63.2% unique observations (Efron and Tibshirani 1997). Randomness is further injected to decorrelate the trees by randomly subsetting the candidates of features to consider at each split of a tree. Therefore, every split of every tree may consider a different subset of variables. This process is repeated for \\(B\\) trees, with the final output being a collection of trained decision trees.\nPrediction from a random forest for new data \\(\\mathbf{x}^*\\) follows by making predictions from the individual trees and aggregating the results by some function \\(\\sigma\\), which is usually the sample mean for regression:\n\\[\n\\hat{g}(\\mathbf{x}^*) = \\sigma(\\hat{g}_1(\\mathbf{x}^*),...,\\hat{g}_B(\\mathbf{x}^*)) = \\frac{1}{B} \\sum^B_{b=1} \\hat{g}_b(\\mathbf{x}^*)\n\\]\nwhere \\(\\hat{g}_b(\\mathbf{x}^*)\\) is the prediction from the \\(b\\)th tree for some new data \\(\\mathbf{x}^*\\) and \\(B\\) are the total number of grown trees.\nAs discussed above, individual decision trees result in predictions with high variance that are not robust to small changes in the underlying data. Random forests decrease this variance by aggregating predictions over a large sample of decorrelated trees, where a high degree of difference between trees is promoted through the use of bootstrapped samples and random candidate feature selection at each split.\nUsually many (hundreds or thousands) trees are grown, which makes random forests robust to changes in data and ‘confident’ about individual predictions. Other advantages include having tunable and meaningful hyper-parameters, including: the number of variables to consider for a single tree, the splitting rule, and the stopping rule. Random forests treat trees as weak learners, which are not intended to be individually optimized. Instead, each tree captures a small amount of information about the data, which are combined to form a powerful representation of the dataset.\nWhilst random forests are considered a ‘black-box’, in that one cannot be reasonably expected to inspect thousands of individual trees, variable importance can still be aggregated across trees, for example by counting the frequency a variable was selected across trees, calculating the minimal depth at which a variable was used for splitting, or via permutation based feature importance. Hence the model remains more interpretable than many alternative methods. Finally, random forests are less prone to overfitting and this can be relatively easily controlled by using early-stopping methods, for example by continually growing trees until the performance of the model stops improving.",
    "crumbs": [
      "Models",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Random Forests</span>"
    ]
  },
  {
    "objectID": "P3C14_forests.html#random-survival-forests",
    "href": "P3C14_forests.html#random-survival-forests",
    "title": "14  Random Forests",
    "section": "14.2 Random Survival Forests",
    "text": "14.2 Random Survival Forests\nUnlike other machine learning methods that may require complex changes to underlying algorithms, random forests can be relatively simply adapted to random survival forests by updating the splitting rules and terminal node predictions to those that can handle censoring and can make survival predictions. This chapter is therefore focused on outlining different choices of splitting rules and terminal node predictions, which can then be flexibly combined into different models.\n\n14.2.1 Splitting Rules\nSurvival trees and RSFs have been studied for the past four decades and whilst there are many possible splitting rules (Bou-Hamad, Larocque, and Ben-Ameur 2011), only two broad classes are commonly utilised (as judged by number of available implementations, e.g., Pölsterl (2020); Wright and Ziegler (2017); H. Ishwaran et al. (2011)). The first class rely on hypothesis tests, and primarily the log-rank test, to maximise dissimilarity between splits, the second class utilises likelihood-based measures. The first is discussed in more detail as this is common in practice and is relatively straightforward to implement and understand, moreover it has been demonstrated to outperform other splitting rules (Bou-Hamad, Larocque, and Ben-Ameur 2011). Likelihood rules are more complex and require assumptions that may not be realistic, these are discussed briefly.\n\nHypothesis Tests\nThe log-rank test statistic has been widely utilized as a splitting-rule for survival analysis (Ciampi et al. 1986; B. H. Ishwaran et al. 2008; LeBlanc and Crowley 1993; Segal 1988). The log-rank test compares the survival distributions of two groups under the null-hypothesis that both groups have the same underlying risk of (immediate) events, with the hazard function used to compare underlying risk.\nLet \\(L^a\\) and \\(L^b\\) be two leaves and let \\(h^a,h^b\\) be the (theoretical, true) hazard functions in the two leaves respectively and let \\(i \\in L\\) be a shorthand for the indices of the observations in leaf \\(L\\) so that \\(i = 1,\\ldots,|L|\\). Define:\n\n\\(\\mathcal{U}_D\\), the set of unique event times across the data (in both leaves)\n\\(n_\\tau^a\\), the number of observations at risk at \\(\\tau\\) in leaf \\(a\\)\n\n\\[\nn_\\tau^a = \\sum_{i \\in L^a} \\mathbb{I}(t_i \\geq \\tau)\n\\]\n\n\\(o^a_{\\tau}\\), the observed number of events in leaf \\(a\\) at \\(\\tau\\)\n\n\\[\no^a_{\\tau} = \\sum_{i \\in L^a} \\mathbb{I}(t_i = \\tau, \\delta_i = 1)\n\\]\n\n\\(n_\\tau = n_\\tau^a + n_\\tau^b\\), the number of observations at risk at \\(\\tau\\) in both leaves\n\\(o_\\tau = o^a_{\\tau} + o^b_{\\tau}\\), the observed number of events at \\(\\tau\\) in both leaves\n\nThen, the log-rank hypothesis test is given by \\(H_0: h^a = h^b\\) with test statistic (Segal 1988), \\[\nLR(L^a) = \\frac{\\sum_{\\tau \\in \\mathcal{U}_D} (o^a_{\\tau} - e^a_{\\tau})}{\\sqrt{\\sum_{\\tau \\in \\mathcal{U}_D} v_\\tau^a}}\n\\]\nwhere:\n\n\\(e^a_{\\tau}\\) is the expected number of events in leaf \\(a\\) at \\(\\tau\\)\n\n\\[\ne^a_{\\tau} := \\frac{n_\\tau^a o_\\tau}{n_\\tau}\n\\]\n\n\\(v^a_\\tau\\) is the variance of the number of events in leaf \\(a\\) at \\(\\tau\\)\n\n\\[\nv^a_{\\tau} := e^a_{\\tau} \\Big(\\frac{n_\\tau - o_\\tau}{n_\\tau}\\Big)\\Big(\\frac{n_\\tau - n^a_\\tau}{n_\\tau - 1}\\Big)\n\\]\nThese results follow as under the assumption of equal hazards in both leafs, the number of events at each \\(\\tau \\in \\mathcal{U}_D\\) is distributed according to a Hypergeometric distribution. The same statistic results if \\(L^b\\) is instead considered.\nThe higher the log-rank statistic, the greater the dissimilarity between the two groups (Figure 14.2), thereby making it a sensible splitting rule for survival, moreover it has been shown that it works well for splitting censored data (LeBlanc and Crowley 1993). Additionally, the log-rank test requires no knowledge about the shape of the survival curves or distribution of the outcomes in either group (Bland and Altman 2004), making it ideal for an automated process that requires no user intervention.\n\n\n\n\n\n\nFigure 14.2: Panel (a) is the Kaplan-Meier estimator fit on the complete lung dataset from the \\(\\textsf{R}\\) package survival. (b-c) is the same data stratified according to whether ‘age’ is greater or less than 50 (panel b) or 75 (panel c). The higher \\(\\chi^2\\) statistic (panel c) results in a lower \\(p\\)-value and a greater difference between the stratified Kaplan-Meier curves. Hence splitting age at 75 results in a greater dissimilarity between the resulting branches and thus makes a better choice for splitting the variable.\n\n\n\nThe log-rank score rule (Hothorn and Lausen 2003) is a standardized version of the log-rank rule that could be considered as a splitting rule, though simulation studies have demonstrated non-significant improvements in predictive performance when comparing the two (B. H. Ishwaran et al. 2008). Alternative dissimiliarity measures and tests have also been suggested as splitting rules, including modified Kolmogorov-Smirnov test and Gehan-Wilcoxon tests (Ciampi et al. 1988). Simulation studies have demonstrated that both of these may have higher power and produce ‘better’ results than the log-rank statistic (Fleming et al. 1980), however neither appears to be commonly used.\nIn a competing risk setting, Gray’s test (Gray 1988) can be used instead of the log-rank test, as it compares cumulative incidence functions rather than all-cause hazards. Similarly to the log-rank test, Gray’s test also compares survival distributions using hypothesis tests to determine if there are significant differences between the groups, thus making it a suitable option to build competing risk RSFs.\n\n\nAlternative Splitting Rules\nA common alternative to the log-rank test is to instead use likelihood ratio, or deviance, statistics. When building RSFs, the likelihood-ratio statistic can be used to test if the model fit is improved or worsened with each split, thus providing a way to partition data. However, as discussed in ?sec-surv-obj, there are many different likelihoods that can be assumed for survival data, and there is no obvious way to determine if one is more sensible than another. Furthermore the choice of likelihood must fit the underlying model assumptions. For example, one could assume the data fits the proportional hazards assumption and in each split one could calculate the likelihood-ratio using the Cox PH partial likelihood. Alternatively, a parametric form could be assumed and a likelihood proposed by LeBlanc and Crowley (1992) may be calculated to test model fit. While potentially useful, these methods are implemented in very few off-shelf software packages, thus empirical comparisons to other splitting rules are lacking.\nOther rules have also been studied including comparison of residuals (Therneau, Grambsch, and Fleming 1990), scoring rules (H. Ishwaran and Kogalur 2018), distance metrics (Gordon and Olshen 1985), and concordance metrics (Schmid, Wright, and Ziegler 2016). Experiments have shown different splitting rules may perform better or worse depending on the underlying data (Schmid, Wright, and Ziegler 2016), hence one could even consider treating the splitting rule as a hyper-parameter for tuning. However, if there is a clear goal in prediction, then the choice of splitting rule can be informed by the prediction type. For example, if the goal is to maximise separation, then a log-rank splitting rule to maximise homogeneity in terminal nodes is a natural starting point. Whereas if the goal is to accurately rank observations, then a concordance splitting rule may be optimal.\n\n\n\n14.2.2 Terminal Node Prediction\nAs in the regression setting, the usual strategy for predictions is to create a simple estimate based on the training data that lands in the terminal nodes. However, as seen throughout this book, the choice of estimator in the survival setting depends on the prediction task of interest, which are now considered in turn. First, note that all terminal node predictions can only yield useful results if there are a sufficient number of uncensored observations in each terminal node. Hence, a common RSF stopping rule is the minimum number of uncensored observations per leaf, meaning a leaf is not split if that would result in too few uncensored observations in the resulting leaves.\n\nProbabilistic Predictions\nStarting with the most common survival prediction type, the algorithm requires a simple estimate for the underlying survival distribution in each of the terminal nodes, which can be estimated using the Kaplan-Meier or Nelson-Aalen methods (Hothorn et al. 2004; B. H. Ishwaran et al. 2008; LeBlanc and Crowley 1993; Segal 1988).\n\nDenote \\(b\\) as a decision tree and \\(L^{b(h)}\\) as the terminal node \\(h\\) in tree \\(b\\). Then the predicted survival function and cumulative hazard for a new observation \\(\\mathbf{x}^*\\) is,\n\\[\n\\hat{S}_{b(h)}(\\tau|\\mathbf{x}^*) = \\prod_{i:t_{(i)} \\leq \\tau} 1-\\frac{d_{t_{(i)}}}{n_{t_{(i)}}}, \\quad \\{i \\in L^{b(h)}: \\mathbf{x}^* \\in L^{b(h)}\\}\n\\tag{14.2}\\]\n\\[\n\\hat{H}_{b(h)}(\\tau|\\mathbf{x}^*) = \\sum_{i:t_{(i)} \\leq \\tau} \\frac{d_{t_{(i)}}}{n_{t_{(i)}}}, \\quad \\{i \\in L^{b(h)}: \\mathbf{x}^* \\in L^{b(h)}\\}\n\\tag{14.3}\\]\nwhere \\(t_{(i)}\\) is the ordered event times and \\(d_{t_{(i)}}\\) and \\(n_{t_{(i)}}\\) are the observed number of events, and the number of observations at risk, respectively at \\(t_{(i)}\\). See Figure 14.3 for an example using the lung dataset (Therneau 2015).\n\n\n\n\n\n\nFigure 14.3: Survival tree trained on the lung dataset from the \\(\\textsf{R}\\) package survival. The terminal node predictions are survival curves.\n\n\n\nThe bootstrapped prediction is the cumulative hazard function or survival function averaged over individual trees. Note that understanding what these bootstrapped functions represents depends on how they are calculated. By definition, a mixture of \\(n\\) distributions with cumulative distribution functions \\(F_i, i = 1,...,n\\) is given by\n\\[\nF(x) = \\sum^n_{i=1} w_i F_i(x)\n\\]\nSubsituting \\(F = 1 - S\\) and noting \\(\\sum w_i = 1\\) gives the computation \\(S(x) = \\sum^n_{i=1} w_i S_i(x)\\), allowing the bootstrapped survival function to exactly represent the mixture distribution averaged over all trees:\n\\[\n\\hat{S}_{Boot}(\\tau|\\mathbf{x}^*) = \\frac{1}{B} \\sum^B_{b=1} w_i\\hat{S}_b(\\tau|\\mathbf{x}^*)\n\\tag{14.4}\\]\nusually with \\(w_i = 1/B\\) where \\(B\\) is the number of trees.\nIn contrast, if one were to instead substitute \\(F = 1 - \\exp(-H)\\), then the mixture distribution depends on a logarithmic function that can only be approximately computed if predicted survival probabilities are close to one, which is an assumption that deteriorates over time. Therefore, to ensure the bootstrapped prediction accurately represents the underlying mixed probability distribution, the bootstrapped cumulative hazard function should be computed as:\n\\[\n\\hat{H}_{Boot}(\\tau|\\mathbf{x}^*) = - \\log (\\hat{S}_{Boot}(\\tau|\\mathbf{x}^*))\n\\tag{14.5}\\]\nAnother practical consideration to take into account is how to average the survival probabilities over the decision trees as each individual Kaplan-Meier estimate may have been trained on different time points. This is overcome by recognising that the Kaplan-Meier estimation results in a piece-wise function that can be linearly interpolated between training data. Figure 14.4 demonstrates this process for three decision trees (panel a), where the survival probability is calculated at all possible time points (panels b-c), and the average is computed with linear interpolation added between time-points (panel d).\n\n\n\n\n\n\nFigure 14.4: Bootstrapping Kaplan-Meier estimators across three decision trees (red, blue, green). Panel a) shows the individual estimates, b) shows the time points to aggregate the trees over, c) is the predicted survival probability from each tree at the desired time points, and d) is the average survival probabilities connected by a step function.\n\n\n\nExtensions to competing risks follow naturally using bootstrapped cause-specific cumulative incidence functions.\n\n\n\nDeterministic Predictions\nAs discussed in Chapter 11, predicting and evaluating survival times is a complex and fairly under-researched area. For RSFs, there is an inclination to estimate survival times based on the mean or median survival times of observations in terminal nodes, however this would lead to biased estimations. Therefore, research has tended to focus on relative risk predictions.\nAs discussed, relative risks are arbitrary values where only the resulting rank matters when comparing observations. In RSFs, each terminal node should be as homogeneous as possible, hence within a terminal node, the risk between observations should be the same. The most common method to estimate average risk appears to be a transformation from the Nelson-Aalen method (B. H. Ishwaran et al. 2008), which exploits results from counting process to provide a measure of expected mortality (Hosmer Jr, Lemeshow, and May 2011) – the same result is used in the van Houwelingen calibration measure discussed in Section 9.1.2. Given new data, \\(\\mathbf{x}^*\\), falling into terminal node \\(b(h)\\), the relative risk prediction is the sum of the predicted cumulative hazard, \\(\\hat{H}_{b(h)}\\), computed at each observation’s observed outcome time:\n\\[\n\\phi_{b(h)}(\\mathbf{x}^*) = \\sum_{i \\in \\mathcal{U}_O} \\hat{H}_{b(h)}(t_i|\\mathbf{x}^*)\n\\]\nwhere \\(\\hat{H}_{b(h)}\\) is the terminal node prediction as in Equation 14.3. This is interpreted as the number of expected events in \\(b(h)\\) and the assumption is that a terminal node with more expected events is a higher risk group than a node with less expected events. The bootstrapped risk prediction is the sample mean over all trees:\n\\[\n\\phi_{Boot}(\\mathbf{x}^*) = \\frac{1}{B} \\sum^B_{b=1} \\phi_{b(h)}(\\mathbf{x}^*)\n\\]\nMore complex methods have also been proposed that are based on the likelihood-based splitting rule and assume a PH model form (H. Ishwaran et al. 2004; LeBlanc and Crowley 1992). However, these do not appear to be in wide-spread usage.",
    "crumbs": [
      "Models",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Random Forests</span>"
    ]
  },
  {
    "objectID": "P3C14_forests.html#conclusion",
    "href": "P3C14_forests.html#conclusion",
    "title": "14  Random Forests",
    "section": "14.3 Conclusion",
    "text": "14.3 Conclusion\n\n\n\n\n\n\nKey takeaways\n\n\n\n\nRandom forests are a highly flexible algorithm that allow the various components to be adapted and altered without major changes to the underlying algorithm. This allows random survival forests (RSFs) to be readily available ‘off-shelf’ in many open-source packages;\nRSFs have in-built variable selection methods that mean they tend to perform well on high-dimensional data, routinely outperforming other models Burk et al. (2024);\nDespite having many potential hyper-parameters to tune, all are intuitive and many can even be ignored as sensible defaults exist in most off-shelf software implementations.\n\n\n\n\n\n\n\n\n\nLimitations\n\n\n\n\nDue to the number of trees and the constant bootstrapping procedures, RSFs can be more computationally intensive than other models, though still much less intensive than neural networks and other deep learning methods.\nDespite having some in-built methods for model interpretation, RSFs are still black-boxes that can be difficult to fully interpret.\nWith too few trees random forests can have similar limitations to decision trees and with too many random forests can overfit the data. Though most software has sensible defaults to prevent either scenario.\n\n\n\n\n\n\n\n\n\nFurther reading\n\n\n\n\nA comprehensive review of random survival forests (RSFs) is provided in Bou-Hamad (2011) (Bou-Hamad, Larocque, and Ben-Ameur 2011), which includes extensions to time-varying covariates and different censoring types.\nThe discussion of decision trees omitted many methods for growing and pruning trees, if you are interest in those technical details see L. Breiman et al. (1984).\nRSFs have been shown to perform well in benchmark experiments on high-dimensional data, see Herrmann et al. (2021) and Spooner et al. (2020) for examples.\nThis chapter considered the most ‘traditional’ forms of RSFs. Conditional inference forests are popular in the regression setting and whilst they are under-researched in survival, see Hothorn et al. (2005) for literature on the topic. A more recent method that seems to perform well is the (accelerated) oblique random survival forest discussed in (Jaeger2024?).\n\n\n\n\n\n\n\nBland, J Martin, and Douglas G. Altman. 2004. “The logrank test.” BMJ (Clinical Research Ed.) 328 (7447): 1073. https://doi.org/10.1136/bmj.328.7447.1073.\n\n\nBou-Hamad, Imad, Denis Larocque, and Hatem Ben-Ameur. 2011. “A review of survival trees.” Statist. Surv. 5: 44–71. https://doi.org/10.1214/09-SS047.\n\n\nBreiman, Leo. 1996. “Bagging Predictors.” Machine Learning 24 (2): 123–40. https://doi.org/10.1023/A:1018054314350.\n\n\nBreiman, L, J Friedman, C J Stone, and R A Olshen. 1984. Classification and Regression Trees. The Wadsworth and Brooks-Cole Statistics-Probability Series. Taylor & Francis. https://books.google.co.uk/books?id=JwQx-WOmSyQC.\n\n\nBurk, Lukas, John Zobolas, Bernd Bischl, Andreas Bender, Marvin N. Wright, and Raphael Sonabend. 2024. “A Large-Scale Neutral Comparison Study of Survival Models on Low-Dimensional Data,” June. http://arxiv.org/abs/2406.04098.\n\n\nCiampi, Antonio, Sheilah A Hogg, Steve McKinney, and Johanne Thiffault. 1988. “RECPAM: a computer program for recursive partition and amalgamation for censored survival data and other situations frequently occurring in biostatistics. I. Methods and program features.” Computer Methods and Programs in Biomedicine 26 (3): 239–56. https://doi.org/https://doi.org/10.1016/0169-2607(88)90004-1.\n\n\nCiampi, Antonio, Johanne Thiffault, Jean Pierre Nakache, and Bernard Asselain. 1986. “Stratification by stepwise regression, correspondence analysis and recursive partition: a comparison of three methods of analysis for survival data with covariates.” Computational Statistics and Data Analysis 4 (3): 185–204. https://doi.org/10.1016/0167-9473(86)90033-2.\n\n\nEfron, Bradley, and Robert Tibshirani. 1997. “Improvements on Cross-Validation: The .632+ Bootstrap Method.” Journal of the American Statistical Association 92 (438): 548–60. http://www.jstor.org/stable/2965703.\n\n\nFleming, Thomas R, Judith R O’Fallon, Peter C O’Brien, and David P Harrington. 1980. “Modified Kolmogorov-Smirnov Test Procedures with Application to Arbitrarily Right-Censored Data.” Biometrics 36 (4): 607–25. https://doi.org/10.2307/2556114.\n\n\nGordon, Louis, and Richard A Olshen. 1985. “Tree-structured survival analysis.” Cancer Treatment Reports 69 (10): 1065–69.\n\n\nGray, Robert J. 1988. “A Class of \\(K\\)-Sample Tests for Comparing the Cumulative Incidence of a Competing Risk.” The Annals of Statistics 16 (3): 1141–54. https://doi.org/10.1214/aos/1176350951.\n\n\nHerrmann, Moritz, Philipp Probst, Roman Hornung, Vindi Jurinovic, and Anne-Laure Boulesteix. 2021. “Large-scale benchmark study of survival prediction methods using multi-omics data.” Briefings in Bioinformatics 22 (3). https://doi.org/10.1093/bib/bbaa167.\n\n\nHosmer Jr, David W, Stanley Lemeshow, and Susanne May. 2011. Applied survival analysis: regression modeling of time-to-event data. Vol. 618. John Wiley & Sons.\n\n\nHothorn, Torsten, Peter Bühlmann, Sandrine Dudoit, Annette Molinaro, and Mark J Van Der Laan. 2005. “Survival ensembles.” Biostatistics 7 (3): 355–73. https://doi.org/10.1093/biostatistics/kxj011.\n\n\nHothorn, Torsten, and Berthold Lausen. 2003. “On the exact distribution of maximally selected rank statistics.” Computational Statistics & Data Analysis 43 (2): 121–37. https://doi.org/10.1016/S0167-9473(02)00225-6.\n\n\nHothorn, Torsten, Berthold Lausen, Axel Benner, and Martin Radespiel-Tröger. 2004. “Bagging survival trees.” Statistics in Medicine 23 (1): 77–91. https://doi.org/10.1002/sim.1593.\n\n\nIshwaran, By Hemant, Udaya B Kogalur, Eugene H Blackstone, and Michael S Lauer. 2008. “Random survival forests.” The Annals of Statistics 2 (3): 841–60. https://doi.org/10.1214/08-AOAS169.\n\n\nIshwaran, Hemant, Eugene H Blackstone, Claire E Pothier, and Michael S Lauer. 2004. “Relative Risk Forests for Exercise Heart Rate Recovery as a Predictor of Mortality.” Journal of the American Statistical Association 99 (467): 591–600. https://doi.org/10.1198/016214504000000638.\n\n\nIshwaran, Hemant, and Udaya B Kogalur. 2018. “randomForestSRC.” https://cran.r-project.org/package=randomForestSRC.\n\n\nIshwaran, Hemant, Udaya B Kogalur, Xi Chen, and Andy J Minn. 2011. “Random Survival Forests for High-Dimensional Data.” Statistical Analysis and Data Mining 4 (1): 115–32. https://doi.org/10.1002/sam.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. An introduction to statistical learning. Vol. 112. New York: Springer.\n\n\nLeBlanc, Michael, and John Crowley. 1992. “Relative Risk Trees for Censored Survival Data.” Biometrics 48 (2): 411–25. https://doi.org/10.2307/2532300.\n\n\n———. 1993. “Survival Trees by Goodness of Split.” Journal of the American Statistical Association 88 (422): 457–67. https://doi.org/10.2307/2290325.\n\n\nPölsterl, Sebastian. 2020. “scikit-survival: A Library for Time-to-Event Analysis Built on Top of scikit-learn.” Journal of Machine Learning Research 21 (212): 1–6. http://jmlr.org/papers/v21/20-729.html.\n\n\nSchmid, Matthias, Marvin Wright, and Andreas Ziegler. 2016. “On the Use of Harrell’s c for Clinical Risk Prediction via Random Survival Forests.” Expert Systems with Applications 63 (July). https://doi.org/10.1016/j.eswa.2016.07.018.\n\n\nSegal, Mark Robert. 1988. “Regression Trees for Censored Data.” Biometrics 44 (1): 35–47.\n\n\nSpooner, Annette, Emily Chen, Arcot Sowmya, Perminder Sachdev, Nicole A Kochan, Julian Trollor, and Henry Brodaty. 2020. “A comparison of machine learning methods for survival analysis of high-dimensional clinical data for dementia prediction.” Scientific Reports 10 (1): 20410. https://doi.org/10.1038/s41598-020-77220-w.\n\n\nTherneau, Terry M. 2015. “A Package for Survival Analysis in S.” https://cran.r-project.org/package=survival.\n\n\nTherneau, Terry M., Patricia M. Grambsch, and Thomas R. Fleming. 1990. “Martingale-based residuals for survival models.” Biometrika 77 (1): 147–60. https://doi.org/10.1093/biomet/77.1.147.\n\n\nWright, Marvin N., and Andreas Ziegler. 2017. “ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R.” Journal of Statistical Software 77 (1): 1–17.",
    "crumbs": [
      "Models",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Random Forests</span>"
    ]
  },
  {
    "objectID": "P3C15_svm.html",
    "href": "P3C15_svm.html",
    "title": "15  Support Vector Machines",
    "section": "",
    "text": "15.1 SVMs for Regression\nSupport vector machines are a popular class of models in regression and classification settings due to their ability to make accurate predictions for complex high-dimensional, non-linear data. Survival support vector machines (SSVMs) predict continuous responses that can be used as ranking predictions with some formulations that provide survival time interpretations. This chapter starts with SVMs in the regression setting before moving to adaptions for survival analysis.\nIn simple linear regression, the aim is to estimate the line \\(y = \\alpha + x\\beta_1\\) by estimating the \\(\\alpha,\\beta_1\\) coefficients. As the number of coefficients increases, the goal is to instead estimate the hyperplane, which divides the higher-dimensional space into two separate parts. To visualize a hyperplane, imagine looking at a room from a birds eye view that has a dividing wall cutting the room into two halves (Figure 15.1). In this view, the room appears to have two dimensions (x=left-right, y=top-bottom) and the divider is a simple line of the form \\(y = \\alpha + x\\beta_1\\). In reality, this room is actually three dimensional and has a third dimension (z=up-down) and the divider is therefore a hyperplane of the form \\(y = \\alpha + x\\beta_1 + z\\beta_2\\).\nContinuing the linear regression example, consider a simple model where the objective is to find the \\(\\boldsymbol{\\beta} = ({\\beta}_1 \\ {\\beta}_2 \\cdots {\\beta}_{p})^\\top\\) coefficients that minimize \\(\\sum^n_{i=1} (g(\\mathbf{x}_i) - y_i)^2\\) where \\(g(\\mathbf{x}_i) = \\alpha + \\mathbf{x}_i^\\top\\boldsymbol{\\beta}\\) and \\((\\mathbf{X}, \\mathbf{y})\\) is training data such that \\(\\mathbf{X}\\in \\mathbb{R}^{n \\times p}\\) and \\(\\mathbf{y}\\in \\mathbb{R}^n\\). In a higher-dimensional space, a penalty term can be added for variable selection to reduce model complexity, commonly of the form\n\\[\n\\frac{1}{2} \\sum^n_{i=1} (g(\\mathbf{x}_i) - y_i)^2 + \\frac{\\lambda}{2} \\|\\boldsymbol{\\beta}\\|^2\n\\]\nfor some penalty term \\(\\lambda \\in \\mathbb{R}\\). Minimizing this error function effectively minimizes the average difference between all predictions and true outcomes, resulting in a hyperplane that represents the best linear relationship between coefficients and outcomes.\nSimilarly to linear regression, support vector machines (SVMs) (Cortes and Vapnik 1995) also fit a hyperplane, \\(g\\), on given training data, \\(\\mathbf{X}\\). However, in SVMs, the goal is to fit a flexible (non-linear) hyperplane that minimizes the difference between predictions and the truth for individual observations. A core feature of SVMs is that one does not try to fit a hyperplane that makes perfect predictions as this would overfit the training data and is unlikely to perform well on unseen data. Instead, SVMs use a regularized error function, which allows incorrect predictions (errors) for some observations, with the magnitude of error controlled by an \\(\\epsilon&gt;0\\) parameter as well as slack parameters, \\(\\boldsymbol{\\xi'} = ({\\xi'}_1 \\ {\\xi'}_2 \\cdots {\\xi'}_{n})^\\top\\) and \\(\\boldsymbol{\\xi^*} = ({\\xi^*}_1 \\ {\\xi^*}_2 \\cdots {\\xi^*}_{n})^\\top\\) :\n\\[\n\\begin{aligned}\n& \\min_{\\boldsymbol{\\beta},\\alpha, \\boldsymbol{\\xi}', \\boldsymbol{\\xi}^*} \\frac{1}{2} \\|\\boldsymbol{\\beta}\\|^2 + C \\sum^n_{i=1}(\\xi'_i + \\xi_i^*) \\\\\n& \\textrm{subject to}\n\\begin{dcases}\ng(\\mathbf{x}_i) & \\geq y_i -\\epsilon - \\xi'_i \\\\\ng(\\mathbf{x}_i) & \\leq y_i + \\epsilon + \\xi_i^* \\\\\n\\xi'_i, \\xi_i^* & \\geq 0 \\\\\n\\end{dcases}\n\\end{aligned}\n\\tag{15.1}\\]\n\\(\\forall i\\in 1,...,n\\) where \\(g(\\mathbf{x}_i) = \\alpha + \\mathbf{x}_i^\\top\\boldsymbol{\\beta}\\) for model weights \\(\\boldsymbol{\\beta}\\in \\mathbb{R}^p\\) and \\(\\alpha \\in \\mathbb{R}\\) and the same training data \\((\\mathbf{X}, \\mathbf{y})\\) as above.\nFigure 15.2 visualizes a support vector regression model in two dimensions. The red circles are values within the \\(\\epsilon\\)-tube and are thus considered to have a negligible error. In fact, the red circles do not affect the fitting of the optimal line \\(g\\) and even if they moved around, as long as they remain within the tube, the shape of \\(g\\) would not change. In contrast the blue diamonds have an unacceptable margin of error – as an example the top blue diamond will have \\(\\xi'_i = 0\\) but \\(\\xi_i^* &gt; 0\\), thus influencing the estimation of \\(g\\). Points on or outside the epsilon tube are referred to as support vectors as they affect the construction of the hyperplane. The \\(C \\in \\mathbb{R}_{&gt;0}\\) hyperparameter controls the slack parameters and thus as \\(C\\) increases, the number of errors (and subsequently support vectors) is allowed to increase resulting in low variance but higher bias, in contrast a lower \\(C\\) is more likely to introduce overfitting with low bias but high variance (Hastie, Tibshirani, and Friedman 2001). \\(C\\) should be tuned to control this trade-off.\nThe other core feature of SVMs is exploiting the kernel trick, which uses functions known as kernels to allow the model to learn a non-linear hyperplane whilst keeping the computations limited to lower-dimensional settings. Once the model coefficients have been estimated using the optimization above, predictions for a new observation \\(\\mathbf{x}^*\\) can be made using a function of the form\n\\[\n\\hat{g}(\\mathbf{x}^*) = \\sum^n_{i=1} \\mu_iK(\\mathbf{x}^*,\\mathbf{x}_i) + \\alpha\n\\tag{15.2}\\]\nDetails (including estimation) of the \\(\\mu_i\\) Lagrange multipliers are beyond the scope of this book, references are given at the end of this chapter for the interested reader. \\(K\\) is a kernel function, with common functions including the linear kernel, \\(K(x^*,x_i) = \\sum^p_{j=1} x_{ij}x^*_j\\), radial kernel, \\(K(x^*,x_i) = \\exp(-\\omega\\sum^p_{j=1} (x_{ij} - x^*_j)^2)\\) for some \\(\\omega \\in \\mathbb{R}_{&gt;0}\\), and polynomial kernel, \\(K(x^*,x_i) = (1 + \\sum^p_{j=1} x_{ij}x^*_j)^d\\) for some \\(d \\in \\mathbb{N}_{&gt; 0}\\).\nThe choice of kernel and its parameters, the regularization parameter \\(C\\), and the acceptable error \\(\\epsilon\\), are all tunable hyper-parameters, which makes the support vector machine a highly adaptable and often well-performing machine learning method. The parameters \\(C\\) and \\(\\epsilon\\) often have no clear apriori meaning (especially true in the survival setting predicting abstract rankings) and thus require tuning over a great range of values; no tuning usually results in a poor model fit (Probst, Boulesteix, and Bischl 2019).",
    "crumbs": [
      "Models",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Support Vector Machines</span>"
    ]
  },
  {
    "objectID": "P3C15_svm.html#svms-for-regression",
    "href": "P3C15_svm.html#svms-for-regression",
    "title": "15  Support Vector Machines",
    "section": "",
    "text": "Figure 15.1: Visualising a hyperplane by viewing a 3D room in two-dimensions with a wall that is now seen as a simple line. When standing in this room, the wall will clearly exist in three dimensional space.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 15.2: Visualising a support vector machine with an \\(\\epsilon\\)-tube and slack parameters \\(\\boldsymbol{\\xi}'\\) and \\(\\boldsymbol{\\xi}^*\\). Red circles are values within the \\(\\epsilon\\)-tube and blue diamonds are support vectors on and outside the tube. x-axis is single covariate, \\(x\\), and y-axis is \\(g(x) = x\\beta_1 + \\alpha\\).",
    "crumbs": [
      "Models",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Support Vector Machines</span>"
    ]
  },
  {
    "objectID": "P3C15_svm.html#sec-surv-ml-models-svm-surv",
    "href": "P3C15_svm.html#sec-surv-ml-models-svm-surv",
    "title": "15  Support Vector Machines",
    "section": "15.2 SVMs for Survival Analysis",
    "text": "15.2 SVMs for Survival Analysis\nExtending SVMs to the survival domain (SSVMs) is a case of: i) identifying the quantity to predict; and ii) updating the optimization problem (Equation 15.1) and prediction function (Equation 15.2) to accommodate for censoring. In the first case, SSVMs can be used to either make survival time or ranking predictions, which are discussed in turn. The notation above is reused below for SSVMs, with additional notation introduced when required and now using the survival training data \\((\\mathbf{X}, \\mathbf{t}, \\boldsymbol{\\delta})\\).\n\n15.2.1 Survival time SSVMs\nTo begin, consider the objective for support vector regression with the \\(y\\) variable replaced with the usual survival time outcome \\(t\\), for all \\(i\\in 1,...,n\\):\n\\[\n\\begin{aligned}\n& \\min_{\\boldsymbol{\\beta}, \\alpha, \\boldsymbol{\\xi}', \\boldsymbol{\\xi}^*} \\frac{1}{2} \\|\\boldsymbol{\\beta}\\|^2 + C \\sum^n_{i=1}(\\xi'_i + \\xi_i^*) \\\\\n& \\textrm{subject to}\n\\begin{dcases}\ng(\\mathbf{x}_i) & \\geq t_i -\\epsilon - \\xi'_i \\\\\ng(\\mathbf{x}_i) & \\leq t_i + \\epsilon + \\xi_i^* \\\\\n\\xi'_i, \\xi_i^* & \\geq 0 \\\\\n\\end{dcases}\n\\end{aligned}\n\\tag{15.3}\\]\nIn survival analysis, this translates to fitting a hyperplane in order to predict the true survival time. However, as with all adaptations from regression to survival analysis, there needs to be a method for incorporating censoring.\nRecall the \\((t_l, t_u)\\) notation to describe censoring as introduced in Chapter 4 such that the outcome occurs within the range \\((t_l, t_u)\\).  Let \\(\\tau \\in \\mathbb{R}_{&gt;0}\\) be some known time-point, then an observation is:\n\nleft-censored if the survival time is less than \\(\\tau\\): \\((t_l, t_u) = (-\\infty, \\tau)\\);\nright-censored if the true survival time is greater than \\(\\tau\\): \\((t_l, t_u) = (\\tau, \\infty)\\); or\nuncensored if the true survival time is known to be \\(\\tau\\): \\((t_l, t_u) = (\\tau, \\tau)\\).\n\nDefine \\(\\mathcal{L}= \\{i: t_i &gt; -\\infty\\}\\) as the set of observations with a finite lower-bounded time, which can be seen above to be those that are right-censored or uncensored. Define \\(\\mathcal{U}= \\{i: t_i &lt; \\infty\\}\\) as the analogous set of observations with a finite upper-bounded time, which are those that are left-censored or uncensored.\nConsider these definitions in the context of the constraints in Equation 15.3. The first constraint ensures the hyperplane is greater than some lower-bound created by subtracting the slack parameter from the true outcome – given the set definitions above this constraint only has meaning for observations with a finite lower-bound, \\(i \\in \\mathcal{L}\\), otherwise the constraint would include \\(g(\\mathbf{x}_i) \\geq -\\infty\\), which is clearly not useful. Similarly the second constraint ensures the hyperplane is less than some upper-bound, which again can only be meaningful for observations \\(i \\in \\mathcal{U}\\). Restricting the constraints in this way leads to the optimization problem (Shivaswamy, Chu, and Jansche 2007) below and visualised in Figure 15.3:\n\\[\n\\begin{aligned}\n& \\min_{\\boldsymbol{\\beta}, \\alpha, \\boldsymbol{\\xi}', \\boldsymbol{\\xi}^*} \\frac{1}{2}\\|\\boldsymbol{\\beta}\\|^2 + C\\Big(\\sum_{i \\in \\mathcal{U}} \\xi_i + \\sum_{i \\in \\mathcal{L}} \\xi_i^*\\Big) \\\\\n& \\textrm{subject to}\n\\begin{dcases}\ng(\\mathbf{x}_i) & \\geq t_i -\\xi'_i, i \\in \\mathcal{L}\\\\\ng(\\mathbf{x}_i) & \\leq t_i + \\xi^*_i, i \\in \\mathcal{U}\\\\\n\\xi'_i \\geq 0, \\forall i\\in \\mathcal{L}; \\xi^*_i \\geq 0, \\forall i \\in \\mathcal{U}\n\\end{dcases}\n\\end{aligned}\n\\]\nIf no observations are censored then the optimization becomes the regression optimization in (Equation 15.1). Note that in SSVMs, the \\(\\epsilon\\) parameters are typically removed to better accommodate censoring and to help prevent the same penalization of over- and under-predictions. In contrast to this formulation, one could introduce more \\(\\epsilon\\) and \\(C\\) parameters to separate between under- and over-predictions and to separate right- and left-censoring, however this leads to eight tunable hyperparameters, which is inefficient and may increase overfitting (Fouodo et al. 2018; Land et al. 2011). The algorithm can be simplified to right-censoring only by removing the second constraint completely for anyone censored:\n\\[\n\\begin{aligned}\n& \\min_{\\boldsymbol{\\beta}, \\alpha, \\boldsymbol{\\xi}', \\boldsymbol{\\xi}^*} \\frac{1}{2}\\|\\boldsymbol{\\beta}\\|^2 + C \\sum_{i = 1}^n (\\xi'_i + \\xi_i^*) \\\\\n& \\textrm{subject to}\n\\begin{dcases}\ng(\\mathbf{x}_i) & \\geq t_i - \\xi^*_i \\\\\ng(\\mathbf{x}_i) & \\leq t_i + \\xi'_i, i:\\delta_i=1 \\\\\n\\xi'_i, \\xi_i^* & \\geq 0 \\\\\n\\end{dcases}\n\\end{aligned}\n\\]\n\\(\\forall i\\in 1,...,n\\). With the prediction for a new observation \\(\\mathbf{x}^*\\) calculated as,\n\\[\n\\hat{g}(\\mathbf{x}^*) = \\sum^n_{i=1} \\mu^*_i K(\\mathbf{x}_i, \\mathbf{x}^*) - \\delta_i\\mu_i'K(\\mathbf{x}_i, \\mathbf{x}^*) + \\alpha\n\\]\nWhere again \\(K\\) is a kernel function and the calculation of the Lagrange multipliers is beyond the scope of this book.\n\n\n\n\n\n\nFigure 15.3: Visualising a survival time SVM. Blue diamonds are influential support vectors, which are uncensored or left-censored when \\(g(\\mathbf{x})&lt;t\\) or uncensored or right-censored when \\(g(\\mathbf{x})&gt;t\\). Red circles are non-influential observations.\n\n\n\n\n\n15.2.2 Ranking SSVMs\nSupport vector machines can be used to estimate rankings by penalizing predictions that result in disconcordant predictions. Recall the definition of concordance from Chapter 8: ranking predictions for a pair of comparable observations \\((i, j)\\) where \\(t_i &lt; t_j \\cap \\delta_i = 1\\), are called concordant if \\(r_i &gt; r_j\\) where \\(r_i, r_j\\) are the predicted ranks for observations \\(i\\) and \\(j\\) respectively and a higher value implies greater risk. Using the prognostic index as a ranking prediction (Section 6.3), a pair of observations is concordant if \\(g(\\mathbf{x}_i) &gt; g(\\mathbf{x}_j)\\) when \\(t_i &lt; t_j\\), leading to:\n\\[\n\\begin{aligned}\n& \\min_{\\boldsymbol{\\beta}, \\alpha, \\boldsymbol{\\xi}} \\frac{1}{2}\\|\\boldsymbol{\\beta}\\|^2 + \\gamma\\sum_{i =1}^n \\xi_i \\\\\n& \\textrm{subject to}\n\\begin{dcases}\ng(\\mathbf{x}_i) - g(\\mathbf{x}_j) & \\geq \\xi_i, \\forall i,j \\in CP \\\\\n\\xi_i & \\geq 0, i = 1,...,n \\\\\n\\end{dcases}\n\\end{aligned}\n\\]\nwhere \\(CP\\) is the set of comparable pairs defined by \\(CP = \\{(i, j) : t_i &lt; t_j \\wedge \\delta_i = 1\\}\\). Given the number of pairs, the optimization problem quickly becomes difficult to solve with a very long runtime. To solve this problem Van Belle et al. (2011) found an efficient reduction that sorts observations in order of outcome time and then compares each data point \\(i\\) with the observation that has the next smallest survival time, skipping over censored observations, in maths: \\(j(i) := \\mathop{\\mathrm{arg\\,max}}_{j \\in 1,...,n} \\{t_j : t_j &lt; t_i\\}\\). This is visualized in Figure 15.4 where six observations are sorted by outcome time from smallest (left) to largest (right). Starting from right to left, the first pair is made by matching the observation to the first uncensored outcome to the left, this continues to the end. In order for all observations to be used in the optimisation, the algorithm sets the first outcome to be uncensored hence observation \\(2\\) being compared to observation \\(1\\).\n\n\n\n\n\n\nFigure 15.4: Van Belle SVM nearest neighbors reduction. Sorted observations are paired with the nearest uncensored outcome ‘to the left’. Red squares are uncensored observations and blue circles are censored. The observation with the smallest outcome time is always treated as uncensored.\n\n\n\nUsing this reduction, the algorithm becomes\n\\[\n\\begin{aligned}\n& \\min_{\\boldsymbol{\\beta}, \\alpha, \\boldsymbol{\\xi}} \\frac{1}{2}\\|\\boldsymbol{\\beta}\\|^2 + \\gamma\\sum_{i =1}^n \\xi_i \\\\\n& \\textrm{subject to}\n\\begin{dcases}\ng(\\mathbf{x}_i) - g(\\mathbf{x}_{j(i)}) & \\geq t_i - t_{j(i)} - \\xi_i \\\\\n\\xi_i & \\geq 0\n\\end{dcases}\n\\end{aligned}\n\\]\n\\(\\forall i = 1,...,n\\). Note the updated right hand side of the constraint, which plays a similar role to the \\(\\epsilon\\) parameter by allowing ‘mistakes’ in predictions without penalty.\nPredictions for a new observation \\(\\mathbf{x}^*\\) are calculated as,\n\\[\n\\hat{g}(\\mathbf{x}^*) = \\sum^n_{i=1} \\mu_i(K(\\mathbf{x}_i, \\mathbf{x}^*) - K(\\mathbf{x}_{j(i)}, \\mathbf{x}^*)) + \\alpha\n\\]\nWhere \\(\\mu_i\\) are again Lagrange multipliers.\n\n\n15.2.3 Hybrid SSVMs\nFinally, Van Belle et al. (2011) noted that the ranking algorithm could be updated to add the constraints of the regression model, thus providing a model that simultaneously optimizes for ranking whilst providing continuous values that can be interpreted as survival time predictions. This results in the hybrid SSVM with constraints \\(\\forall i = 1,...,n\\):\n\\[\n\\begin{aligned}\n& \\min_{\\boldsymbol{\\beta}, \\alpha, \\boldsymbol{\\xi}, \\boldsymbol{\\xi}', \\boldsymbol{\\xi}^*} \\frac{1}{2}\\|\\boldsymbol{\\beta}\\|^2 + \\textcolor{CornflowerBlue}{\\gamma\\sum_{i =1}^n \\xi_i} + \\textcolor{Rhodamine}{C \\sum^n_{i=1}(\\xi_i' + \\xi_i^*)} \\\\\n& \\textrm{subject to}\n\\begin{dcases}\n\\textcolor{CornflowerBlue}{g(\\mathbf{x}_i) - g(\\mathbf{x}_{j(i)})} & \\textcolor{CornflowerBlue}{\\geq t_i - t_{j(i)} - \\xi_i} \\\\\n\\textcolor{Rhodamine}{g(\\mathbf{x}_i)} & \\textcolor{Rhodamine}{\\leq t_i + \\xi^*_i, i:\\delta_i=1} \\\\\n\\textcolor{Rhodamine}{g(\\mathbf{x}_i)} & \\textcolor{Rhodamine}{\\geq t_i - \\xi'_i} \\\\\n\\textcolor{CornflowerBlue}{\\xi_i}, \\textcolor{Rhodamine}{\\xi_i', \\xi_i^*} & \\geq 0 \\\\\n\\end{dcases}\n\\end{aligned}\n\\label{eq:surv_ssvmvb2}\n\\]\nThe blue parts of the equation make up the ranking model and the red parts are the regression model. \\(\\gamma\\) is the penalty associated with the regression method and \\(C\\) is the penalty associated with the ranking method. Setting \\(\\gamma = 0\\) results in the regression SVM and \\(C = 0\\) results in the ranking SSVM. Hence, fitting the hybrid model and tuning these parameters is an efficient way to automatically detect which SSVM is best suited to a given task.\nOnce the model is fit, a prediction from given features \\(\\mathbf{x}^* \\in \\mathbb{R}^p\\), can be made using the equation below, again with the ranking and regression contributions highlighted in blue and red respectively.\n\\[\n\\hat{g}(\\mathbf{x}^*) = \\sum^n_{i=1} \\textcolor{CornflowerBlue}{\\mu_i(K(\\mathbf{x}_i, \\mathbf{x}^*) - K(\\mathbf{x}_{j(i)}, \\mathbf{x}^*))} + \\textcolor{Rhodamine}{\\mu^*_i K(\\mathbf{x}_i, \\mathbf{x}^*) - \\delta_i\\mu_i'K(\\mathbf{x}_i, \\mathbf{x}^*)} + \\alpha\n\\]\nwhere \\(\\mu_i, \\mu_i^*, \\mu_i'\\) are Lagrange multipliers and \\(K\\) is a chosen kernel function, which may have further hyper-parameters to select or tune.",
    "crumbs": [
      "Models",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Support Vector Machines</span>"
    ]
  },
  {
    "objectID": "P3C15_svm.html#conclusion",
    "href": "P3C15_svm.html#conclusion",
    "title": "15  Support Vector Machines",
    "section": "15.3 Conclusion",
    "text": "15.3 Conclusion\n\n\n\n\n\n\nKey takeaways\n\n\n\n\nSupport vector machines (SVMs) are a highly flexible machine learning method that can use the ‘kernel trick’ to represent infinite dimensional spaces in finite domains;\nSurvival SVMs (SSVMs) extend regression SVMs by either making survival time predictions, ranking predictions, or a combination of the two;\nThe hybrid SSVM provides an efficient method that encapsulates all the elements of regression and ranking SSVMs and is therefore a good model to include in benchmark experiments to test the potential of SSVMs.\n\n\n\n\n\n\n\n\n\nLimitations\n\n\n\n\nSSVMs can only perform well with extensive tuning of hyper-parameters over a wide parameter space. To-date, no papers have experimented with the tuning range for the \\(\\gamma\\) and \\(C\\) parameters, we note (Fouodo et al. 2018) tune over \\((2^{-5}, 2^5)\\).\nEven using the regression or hybrid model, the authors’ experiments with the SSVM have consistently shown ‘survival time’ estimates tend to be unrealistically large.\nDue to the above limitation, regression estimates cannot be meaningful interpreted and as a consequence there is no sensible composition to create a distribution prediction from an SSVM. Hence, we are hesitant to suggest usage of SSVMs outside of ranking-based problems.\n\n\n\n\n\n\n\n\n\nFurther reading\n\n\n\n\nShivaswamy, Chu, and Jansche (2007), Khan and Bayer Zubek (2008), Land et al. (2011), and Van Belle et al. (2011) to learn more about regression SSVMs.\nEvers and Messow (2008), Van Belle et al. (2007), Van Belle et al. (2008), and Van Belle et al. (2011) for more information about ranking SSVMs.\nGoli, Mahjub, Faradmal, and Soltanian (2016) and Goli, Mahjub, Faradmal, Mashayekhi, et al. (2016) introduce mean residual lifetime optimization SSVMs.\nFouodo et al. (2018) surveys and benchmarks SSVMs.\n\n\n\n\n\n\n\nCortes, Corinna, and Vladimir Vapnik. 1995. “Support-Vector Networks.” Machine Learning 20: 273–97. https://doi.org/10.1007/BF00994018.\n\n\nEvers, Ludger, and Claudia-Martina Messow. 2008. “Sparse kernel methods for high-dimensional survival data.” Bioinformatics 24 (14): 1632–38.\n\n\nFouodo, Cesaire J K, I Konig, C Weihs, A Ziegler, and M Wright. 2018. “Support vector machines for survival analysis with R.” The R Journal 10 (July): 412–23.\n\n\nGoli, Shahrbanoo, Hossein Mahjub, Javad Faradmal, Hoda Mashayekhi, and Ali-Reza Soltanian. 2016. “Survival Prediction and Feature Selection in Patients with Breast Cancer Using Support Vector Regression.” Edited by Francesco Pappalardo. Computational and Mathematical Methods in Medicine 2016: 2157984. https://doi.org/10.1155/2016/2157984.\n\n\nGoli, Shahrbanoo, Hossein Mahjub, Javad Faradmal, and Ali-Reza Soltanian. 2016. “Performance Evaluation of Support Vector Regression Models for Survival Analysis: A Simulation Study.” International Journal of Advanced Computer Science and Applications 7 (June). https://doi.org/10.14569/IJACSA.2016.070650.\n\n\nHastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2001. The Elements of Statistical Learning. Springer New York Inc.\n\n\nKhan, Faisal M., and Valentina Bayer Zubek. 2008. “Support vector regression for censored data (SVRc): A novel tool for survival analysis.” Proceedings - IEEE International Conference on Data Mining, ICDM, 863–68. https://doi.org/10.1109/ICDM.2008.50.\n\n\nLand, Walker H, Xingye Qiao, Dan Margolis, and Ron Gottlieb. 2011. “A new tool for survival analysis: evolutionary programming/evolutionary strategies (EP/ES) support vector regression hybrid using both censored / non-censored (event) data.” Procedia Computer Science 6: 267–72. https://doi.org/https://doi.org/10.1016/j.procs.2011.08.050.\n\n\nProbst, Philipp, Anne-Laure Boulesteix, and Bernd Bischl. 2019. “Tunability: Importance of Hyperparameters of Machine Learning Algorithms.” Journal of Machine Learning Research 20 (53): 1–32. http://jmlr.org/papers/v20/18-444.html.\n\n\nShivaswamy, Pannagadatta K., Wei Chu, and Martin Jansche. 2007. “A support vector approach to censored targets.” In Proceedings - IEEE International Conference on Data Mining, ICDM, 655–60. https://doi.org/10.1109/ICDM.2007.93.\n\n\nVan Belle, Vanya, Kristiaan Pelckmans, Johan A K Suykens, and Sabine Van Huffel. 2008. “Survival SVM: a practical scalable algorithm.” In Proceedings of the 16th European Symposium on Artificial Neural Networks (ESANN), 89–94.\n\n\nVan Belle, Vanya, Kristiaan Pelckmans, Johan A. K. Suykens, and Sabine Van Huffel. 2007. “Support Vector Machines for Survival Analysis.” In In Proceedings of the Third International Conference on Computational Intelligence in Medicine and Healthcare. 1.\n\n\nVan Belle, Vanya, Kristiaan Pelckmans, Sabine Van Huffel, and Johan A. K. Suykens. 2011. “Support vector methods for survival analysis: A comparison between ranking and regression approaches.” Artificial Intelligence in Medicine 53 (2): 107–18. https://doi.org/10.1016/j.artmed.2011.06.006.",
    "crumbs": [
      "Models",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Support Vector Machines</span>"
    ]
  },
  {
    "objectID": "P3C16_boosting.html",
    "href": "P3C16_boosting.html",
    "title": "16  Boosting Methods",
    "section": "",
    "text": "16.1 GBMs for Regression\nBoosting is a machine learning strategy that can be applied to any model class. Similarly to random forests, boosting is an ensemble method that creates a model from a ‘committee’ of learners. The committee is formed of weak learners that make poor predictions individually, which creates a slow learning approach (as opposed to ‘greedy’) that requires many iterations for a model to be a good fit to the data. Boosting models are similar to random forests in that both make predictions from a large committee of learners. However the two differ in how the members of the committee are correlated and in how they are combined to make a prediction. In random forests, each decision tree is grown independently and their predictions are combined by a simple mean calculation. In contrast, weak learners in a boosting model are fit sequentially with errors from one learner used to train the next, predictions are then made by a linear combination of predictions from each learner (Figure 16.1).\nOne of the earliest boosting algorithms is AdaBoost (Freund and Schapire 1996), which is more generally a Forward Stagewise Additive Model (FSAM) with an exponential loss (Hastie, Tibshirani, and Friedman 2001). Today, the most widely used boosting model is the Gradient Boosting Machine (GBM) (J. H. Friedman 2001) or extensions thereof.\nFigure 16.1 illustrates the process of training a GBM in a least-squares regression setting:\nPredictions are then made as \\(\\hat{\\mathbf{y}} = f_1(\\mathbf{X}) + f_2(\\mathbf{X}) + ... + f_M(\\mathbf{X})\\).\nThis is a simplification of the general gradient boosting algorithm, where the residuals are used to train the next model. More generally, a suitable, differentiable loss function relating to the problem of interest is chosen and the negative gradient is computed by comparing the predictions in each iteration with the ground truth. Residuals can be used in the regression case as these are proportional to the negative gradient of the mean squared error.\nThe algorithm above is also a simplification as no hyper-parameters other than \\(M\\) were included for controlling the algorithm. In order to reduce overfitting, three common hyper-parameters are utilised:\nNumber of iterations, \\(M\\): The number of iterations is often claimed to be the most important hyper-parameter in GBMs and it has been demonstrated that as the number of iterations increases, so too does the model performance (with respect to a given loss on test data) up to a certain point of overfitting (Buhlmann 2006; Hastie, Tibshirani, and Friedman 2001; Schmid and Hothorn 2008a). This makes sense as the foundation of boosting rests on the idea that weak learners can slowly be combined to form a single powerful model. Finding the optimal value of \\(M\\) is critical as a value too small will result in poor predictions, whilst a value too large will result in model overfitting.\nSubsampling proportion, \\(\\phi\\): Sampling a fraction, \\(\\phi\\), of the training data at each iteration can improve performance and reduce runtime (Hastie, Tibshirani, and Friedman 2001), with \\(\\phi = 0.5\\) often used. Motivated by the success of bagging in random forests, stochastic gradient boosting (J. Friedman 1999) randomly samples the data in each iteration. It appears that subsampling performs best when also combined with shrinkage (Hastie, Tibshirani, and Friedman 2001) and as with the other hyper-parameters, selection of \\(\\phi\\) is usually performed by nested cross-validation.\nStep-size, \\(\\nu\\): The step-size parameter is a shrinkage parameter that controls the contribution of each weak learner at each iteration. Several studies have demonstrated that GBMs perform better when shrinkage is applied and a value of \\(\\nu = 0.1\\) is often suggested (Buhlmann and Hothorn 2007; Hastie, Tibshirani, and Friedman 2001; J. H. Friedman 2001; Lee, Chen, and Ishwaran 2019; Schmid and Hothorn 2008a). The optimal values of \\(\\nu\\) and \\(M\\) depend on each other, such that smaller values of \\(\\nu\\) require larger values of \\(M\\), and vice versa. This is intuitive as smaller \\(\\nu\\) results in a slower learning algorithm and therefore more iterations are required to fit the model. Accurately selecting the \\(M\\) parameter is generally considered to be of more importance, and therefore a value of \\(\\nu\\) is often chosen heuristically (e.g. the common value of \\(0.1\\)) and then \\(M\\) is tuned by cross-validation and/or early-stopping, which is the process of monitoring the model’s training performance and stopping when a set performance is reached or when performance stagnates (i.e., no improvement over a set number of rounds).\nAs well as these parameters, the underlying weak learner hyper-parameters are also commonly tuned. If using a decision tree, then it is usual to restrict the number of terminal nodes in the tree to be between \\(4\\) and \\(8\\), which corresponds to two or three splits in the tree. Including these hyper-parameters, the general gradient boosting machine algorithm is as follows:\nNote:\nOnce the model is trained, predictions are made for new data, \\(\\mathbf{X}_{test}\\) with\n\\[\n\\hat{Y}= \\hat{g}(\\mathbf{X}_{test}) = g_0(\\mathbf{X}_{test}) + \\nu \\sum^M_{i=1} g_i(\\mathbf{X}_{test})\n\\]\nGBMs provide a flexible, modular algorithm, primarily comprised of a differentiable loss to minimise, \\(L\\), and the selection of weak learners. This chapter focuses on tree-based weak learners, though other weak learners are possible. Perhaps the most common alternatives are linear least squares (J. H. Friedman 2001) and smoothing splines (Bühlmann and Yu 2003), we will not discuss these further here as decision trees are primarily used for survival analysis, due the flexibility demonstrated in Chapter 14. See references at the end of the chapter for other weak learners. Extension to survival analysis therefore follows by considering alternative losses.",
    "crumbs": [
      "Models",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Boosting Methods</span>"
    ]
  },
  {
    "objectID": "P3C16_boosting.html#sec-surv-ml-models-boost-regr",
    "href": "P3C16_boosting.html#sec-surv-ml-models-boost-regr",
    "title": "16  Boosting Methods",
    "section": "",
    "text": "A weak learner, \\(f_1\\), often a decision tree of shallow depth is fit on the training data \\((\\mathbf{X}, \\mathbf{y})\\).\nPredictions from the learner, \\(f_1(\\mathbf{X})\\), are compared to the ground truth, \\(\\mathbf{y}\\), and the residuals are calculated as \\(\\mathbf{r}_1 = f_1(\\mathbf{X}) - \\mathbf{y}\\).\nThe next weak learner, \\(f_2\\), uses the previous residuals for the target prediction, \\((\\mathbf{X}, \\mathbf{r}_1)\\)\nThis is repeated to train \\(M\\) learners, \\(f_1,...,f_M\\)\n\n\n\n\n\n\n\n\nFigure 16.1: Least squares regression Boosting algorithm where the gradient is calculated as the difference between ground truth and predictions.\n\n\n\n\n\n\n\n\n\n\n\\(g_0 \\gets \\text{ Initial guess}\\)\nFor \\(m = 1,...,M\\):\n     \\(\\mathcal{D}_{train}^* \\gets \\text{ Randomly sample } \\mathcal{D}_{train}\\text{ with probability } \\phi\\)\n     \\(r_{im} \\gets -[\\frac{\\partial L(y_i, g_{m-1}(X_i))}{\\partial g_{m-1}(X_i)}], \\forall i \\in \\{i: X_i \\in \\mathcal{D}_{train}^*\\}\\)\n     Fit a weak learner, \\(h_m\\), to \\((\\mathbf{X}, \\mathbf{r}_m)\\)\n     \\(g_m \\gets g_{m-1} + \\nu h_m\\)\nend For\nreturn \\(\\hat{g}= g_M\\)\n\n\n\nThe initial guess, \\(g_0\\), is often the mean of \\(y\\) for regression problems but can also simply be \\(0\\).\nLine 4 is the calculation of the negative gradient, which is equivalent to calculating the residuals in a regression problem with the mean squared error loss.\nLines 5-6 differ between implementations, with some fitting multiple weak learners and selecting the one that minimizes a simple optimization problem. The version above is simplest to implement and quickest to run, whilst still providing good model performance.",
    "crumbs": [
      "Models",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Boosting Methods</span>"
    ]
  },
  {
    "objectID": "P3C16_boosting.html#sec-surv-ml-models-boost-surv",
    "href": "P3C16_boosting.html#sec-surv-ml-models-boost-surv",
    "title": "16  Boosting Methods",
    "section": "16.2 GBMs for Survival Analysis",
    "text": "16.2 GBMs for Survival Analysis\nUnlike other machine learning algorithms that historically ignored survival analysis, early GBM papers considered boosting in a survival context (Ridgeway 1999); though there appears to be a decade gap before further considerations were made in the survival setting. After that period, developments, discussed in this chapter, by Binder, Schmid, and Hothorn, adapted GBMs to a framework suitable for survival analysis.\nAll survival GBMs make ranking predictions and none are able to directly predict survival distributions. However, depending on the underlying model, the predictions may be indirectly composed into a survival distribution, for example algorithms that assume a proportional hazards (PH) or accelerated failure time (AFT) form. This section starts with those models with simpler underlying forms, then explores more complex alternatives.\n\n16.2.1 PH and AFT GBMs\nThe negative log-likelihood of the semi-parametric PH and fully-parametric AFT models can be derived from the (partial) likelihoods presented in ?sec-surv-obj. Given the likelihoods measure the goodness of fit of model parameters, algorithms that use these losses use boosting to train the model coefficients, \\(\\boldsymbol{\\beta}\\), hence at each iteration in the algorithm, \\(g_m(\\mathbf{x}_i) = \\mathbf{x}_i\\boldsymbol{\\beta}^{(m)}\\), where \\(\\boldsymbol{\\beta}^{(m)}\\) are the updated coefficients in iteration \\(m\\).\nThe Cox partial likelihood (Cox 1972, 1975) is given by\n\\[\nL^{PH}(\\boldsymbol{\\beta}) = \\prod^n_{i:\\delta_i=1} \\frac{\\exp(\\eta_i)}{\\sum^n_{j \\in \\mathcal{R}_{t_i}} \\exp(\\eta_j)}\n\\]\nwith corresponding negative log-likelihood\n\\[\n-l^{PH}(\\boldsymbol{\\beta}) = -\\sum^n_{i=1} \\delta_i \\Big[\\eta_i \\ - \\ \\log\\Big(\\sum^n_{j \\in \\mathcal{R}_{t_i}} \\exp(\\eta_i)\\Big)\\Big]\n\\tag{16.1}\\] where \\(\\mathcal{R}_{t_i}\\) is the set of patients at risk at time \\(t_i\\) and \\(\\eta_i = \\mathbf{x}_i\\boldsymbol{\\beta}\\).\nThe gradient of \\(-l^{PH}\\) at iteration \\(m\\) is then \\[\nr_{im} := \\delta_i - \\sum^n_{j=1} \\delta_j \\frac{\\mathbb{I}(t_i \\geq t_j) \\exp(g_{m-1}(\\mathbf{x}_i))}{\\sum_{k \\in \\mathcal{R}_{t_j}} \\exp(g_{m-1}(\\mathbf{x}_k))}\n\\tag{16.2}\\] where \\(g_{m-1}(\\mathbf{x}_i) = \\mathbf{x}_i\\boldsymbol{\\beta}^{(m-1)}\\).\nFor non-PH data, boosting an AFT model can outperform boosted PH models (Schmid and Hothorn 2008b). The AFT is defined by \\[\n\\log \\mathbf{y}= \\boldsymbol{\\eta}+ \\sigma W\n\\] where \\(W\\) is a random noise variable independent of \\(X\\), and \\(\\sigma\\) is a scale parameter controlling the amount of noise; again \\(\\boldsymbol{\\eta}= \\mathbf{X}\\boldsymbol{\\beta}\\). By assuming a distribution on \\(W\\), a distribution is assumed for the full parametric model. The model is boosted by simultaneously estimating \\(\\sigma\\) and \\(\\boldsymbol{\\beta}\\). Assuming a location-scale distribution with location \\(g(\\mathbf{x}_i)\\) and scale \\(\\sigma\\), one can derive the negative log-likelihood in the \\(m\\)th iteration as (Klein and Moeschberger 2003)\n\\[\n\\begin{split}\n-l^{AFT}_m(\\boldsymbol{\\beta}) = -\\sum^n_{i=1} \\delta_i\\Big[- \\log\\sigma + \\log f_W\\Big(\\frac{\\log(t_i) - \\hat{g}_{m-1}(\\mathbf{x}_i)}{\\hat{\\sigma}_{m-1}}\\Big)\\Big] + \\\\\n(1-\\delta_i)\\Big[\\log S_W\\Big(\\frac{\\log(t_i) - \\hat{g}_{m-1}(\\mathbf{x}_i)}{\\hat{\\sigma}_{m-1}}\\Big)\\Big]\n\\end{split}\n\\]\nwhere \\(\\hat{g}_{m-1}, \\hat{\\sigma}_{m-1}\\) are the location-scale parameters estimated in the previous iteration. Note this key difference to other GBM methods in which two estimates are made in each iteration step. After updating \\(\\hat{g}_m\\), the scale parameter, \\(\\hat{\\sigma}_m\\), is updated as \\[\n\\hat{\\sigma}_m := \\mathop{\\mathrm{arg\\,min}}_\\sigma -l^{AFT}_m(\\boldsymbol{\\beta})\n\\] \\(\\sigma_0\\) is commonly initialized as \\(1\\) (Schmid and Hothorn 2008b).\nAs well as boosting fully-parametric AFTs, one could also consider boosting semi-parametric AFTs, for example using the Gehan loss (Johnson and Long 2011) or using Buckley-James imputation (Wang and Wang 2010). However, known problems with semi-parametric AFT models and the Buckey-James procedure (Wei 1992), as well as a lack of off-shelf implementation, mean that these methods are rarely used in practice.\n\n\n16.2.2 Discrimination Boosting\nInstead of optimising models based on a given model form, one could instead estimate \\(\\hat{\\eta}\\) by optimizing a concordance index, such as Uno’s or Harrell’s C (Y. Chen et al. 2013; Mayr and Schmid 2014). Consider Uno’s C (Section 8.1): \\[\nC_U(\\hat{g}, \\mathcal{D}_{train}) = \\frac{\\sum_{i \\neq j}\\delta_i\\{\\hat{G}_{KM}(t_i)\\}^{-2}\\mathbb{I}(t_i &lt; t_j)\\mathbb{I}(\\hat{g}(\\mathbf{x}_i) &gt;\\hat{g}(\\mathbf{x}_j))}{\\sum_{i \\neq j}\\delta_i\\{\\hat{G}_{KM}(t_i)\\}^{-2}\\mathbb{I}(t_i &lt; t_j)}\n\\]\nThe GBM algorithm requires that the chosen loss, here \\(C_U\\), be differentiable with respect to \\(\\hat{g}(X)\\), which is not the case here due to the indicator term, \\(\\mathbb{I}(\\hat{g}(X_i) &gt; \\hat{g}(X_j))\\), however this term can be replaced with a sigmoid function to create a differentiable loss (Ma and Huang 2006)\n\\[\nK(u|\\omega) = \\frac{1}{1 + \\exp(-u/\\omega)}\n\\]\nwhere \\(\\omega\\) is a tunable hyper-parameter controlling the smoothness of the approximation. The measure to optimise is then,\n\\[\nC_{USmooth}(\\boldsymbol{\\beta}|\\omega) = \\sum_{i \\neq j} \\frac{k_{ij}}{1 + \\exp\\big[(\\hat{g}(X_j) - \\hat{g}(X_i))/\\omega)\\big]}\n\\tag{16.3}\\]\nwith\n\\[\nk_{ij} = \\frac{\\Delta_i (\\hat{G}_{KM}(T_i))^{-2}\\mathbb{I}(T_i &lt; T_j)}{\\sum_{i \\neq j} \\Delta_i(\\hat{G}_{KM}(T_i))^{-2}\\mathbb{I}(T_i &lt; T_j)}\n\\]\nThe negative gradient at iteration \\(m\\) for observation \\(i\\) is then calculated as,\n\\[\nr_{im} := - \\sum^n_{j = 1} k_{ij} \\frac{-\\exp(\\frac{\\hat{g}_{m-1}(\\mathbf{x}_j) - \\hat{g}_{m-1}(\\mathbf{x}_i)}{\\omega})}{\\omega(1 + \\exp(\\frac{\\hat{g}_{m-1}(\\mathbf{x}_j) - \\hat{g}_{m-1}(\\mathbf{x}_i)}{\\omega}))}\n\\tag{16.4}\\]\nThe GBM algorithm is then followed as normal with the above loss and gradient. This algorithm may be more insensitive to overfitting than others (Mayr, Hofner, and Schmid 2016), however stability selection (Meinshausen and Bühlmann 2010), which is implemented in off-shelf software packages (Hothorn et al. 2020), can be considered for variable selection.\n\n\n16.2.3 CoxBoost\nFinally, ‘CoxBoost’ is an alternative method to boost Cox models and has been demonstrated to perform well in experiments. This algorithm boosts the Cox PH by optimising the penalized partial-log likelihood; additionally the algorithm allows for mandatory (or ‘forced’) covariates (Binder and Schumacher 2008). In medical domains the inclusion of mandatory covariates may be essential, either for model interpretability, or due to prior expert knowledge. CoxBoost deviates from the algorithm presented above by instead using an offset-based approach for generalized linear models (Tutz and Binder 2007).\nLet \\(\\mathcal{I}= \\{1,...,p\\}\\) be the indices of the covariates, let \\(\\mathcal{I}_{mand}\\) be the indices of the mandatory covariates that must be included in all iterations, and let \\(\\mathcal{I}_{opt} = \\mathcal{I}\\setminus \\mathcal{I}_{mand}\\) be the indices of the optional covariates that may be included in any iteration. In the \\(m\\)th iteration, the algorithm fits a weak learner on all mandatory covariates and one optional covariate: \\[\n\\mathcal{I}_m = \\mathcal{I}_{mand} \\cup \\{x | x \\in \\mathcal{I}_{opt}\\}\n\\]\nIn addition, a penalty matrix \\(\\mathbf{P} \\in \\mathbb{R}^{p \\times p}\\) is considered such that \\(P_{ii} &gt; 0\\) implies that covariate \\(i\\) is penalized and \\(P_{ii} = 0\\) means no penalization. In practice, this is usually a diagonal matrix (Binder and Schumacher 2008) and by setting \\(P_{ii} = 0, i \\in I_{mand}\\) and \\(P_{ii} &gt; 0, i \\not\\in I_{mand}\\), only optional (non-mandatory) covariates are penalized. The penalty matrix can be allowed to vary with each iteration, which allows for a highly flexible approach, however in implementation a simpler approach is to either select a single penalty to be applied in each iteration step or to have a single penalty matrix (Binder 2013).\nAt the \\(m\\)th iteration and the \\(k\\)th set of indices to consider (\\(k = 1,...,p\\)), the loss to optimize is the penalized partial-log likelihood given by \\[\n\\begin{split}\n&l_{pen}(\\gamma_{mk}) = \\sum^n_{i=1} \\delta_i \\Big[\\eta_{i,m-1} + \\mathbf{x}_{i,\\mathcal{I}_{mk}}\\gamma^\\top_{mk}\\Big] - \\\\\n&\\quad\\delta_i\\log\\Big(\\sum^n_{j = 1} \\mathbb{I}(t_j \\leq t_i) \\exp(\\eta_{i,{m-1}} + \\mathbf{x}_{i, \\mathcal{I}_{mk}}\\gamma^\\top_{mk}\\Big) - \\lambda\\gamma_{mk}\\mathbf{P}_{mk}\\gamma^\\top_{mk}\n\\end{split}\n\\]\nwhere \\(\\eta_{i,m} = \\mathbf{x}_i\\beta_m\\), \\(\\gamma_{mk}\\) are the coefficients corresponding to the covariates in \\(\\mathcal{I}_{mk}\\) which is the possible set of candidates for a subset of total candidates \\(k = 1,...,p\\); \\(\\mathbf{P}_{mk}\\) is the penalty matrix; and \\(\\lambda\\) is a penalty hyper-parameter to be tuned or selected.\nIn each iteration, all potential candidate sets (the union of mandatory covariates and one other covariate) are updated by \\[\n\\hat{\\gamma}_{mk} = \\mathbf{I}^{-1}_{pen}(\\hat{\\gamma}_{(m-1)k})U(\\hat{\\gamma}_{(m-1)k})\n\\] where \\(U(\\gamma) = \\partial l / \\partial \\gamma (\\gamma)\\) and \\(\\mathbf{I}^{-1}_{pen} = \\partial^2 l/\\partial\\gamma\\partial\\gamma^T (\\gamma + \\lambda\\mathbf{P}_{(m-1)k})\\) are the first and second derivatives of the unpenalized partial-log-likelihood. The optimal set is then found as \\[\nk^* := \\mathop{\\mathrm{arg\\,max}}_k l_{pen}(\\hat{\\gamma}_{mk})\n\\] and the estimated coefficients are updated with \\[\n\\hat{\\beta}_m = \\hat{\\beta}_{m-1} + \\hat{\\gamma}_{mk^*}, \\quad k^* \\in \\mathcal{I}_{mk}\n\\]\nThis deviates from the standard GBM algorithm by directly optimizing \\(l_{pen}\\) and not its gradient, additionally model coefficients are iteratively updated instead of a more general model form.",
    "crumbs": [
      "Models",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Boosting Methods</span>"
    ]
  },
  {
    "objectID": "P3C16_boosting.html#conclusion",
    "href": "P3C16_boosting.html#conclusion",
    "title": "16  Boosting Methods",
    "section": "16.3 Conclusion",
    "text": "16.3 Conclusion\n\n\n\n\n\n\nKey takeaways\n\n\n\n\nGBMs are a highly flexible and powerful machine learning tool. They have proven particularly useful in survival analysis as minimal adjustments are required to make use of off-shelf software.\nThe flexibility of the algorithm allows all the models above to be implemented in relatively few open-source packages.\nThere is evidence that boosting models can outperform the Cox PH even in low-dimensional settings (Schmid and Hothorn 2008b), which is not not something all ML models can claim.\n\n\n\n\n\n\n\n\n\nLimitations\n\n\n\n\nBoosting, especially with tree learners, is viewed as a black-box model that is increasingly difficult to interpret as the number of iterations increase. However, there are several methods for increasing interpretability, such as variable importance and SHAPs (Lundberg and Lee 2017).\nBoosting often relies on intensive computing power, however, dedicated packages such as \\(\\textbf{xgboost}\\) (T. Chen et al. 2020), exist to push CPU/GPUs to their limits in order to optimise predictive performance.\n\n\n\n\n\n\n\n\n\nFurther reading\n\n\n\n\nBühlmann and Yu (2003); Hothorn et al. (2020); Wang and Wang (2010) for more general information and background on componentwise GBMs\nJ. H. Friedman (2001); Wang and Wang (2010) for linear least squares weak learners\nBühlmann and Yu (2003); J. H. Friedman (2001) for decision tree weak learners\nRidgeway (1999) for early research into GBMs for survival analysis\nJohnson and Long (2011) and Wang and Wang (2010) for semi-parametric AFT boosting\n\n\n\n\n\n\n\nBinder, Harald. 2013. “CoxBoost: Cox models by likelihood based boosting for a single survival endpoint or competing risks.” CRAN.\n\n\nBinder, Harald, and Martin Schumacher. 2008. “Allowing for mandatory covariates in boosting estimation of sparse high-dimensional survival models.” BMC Bioinformatics 9 (1): 14. https://doi.org/10.1186/1471-2105-9-14.\n\n\nBuhlmann, Peter. 2006. “Boosting for high-dimensional linear models.” Ann. Statist. 34 (2): 559–83. https://doi.org/10.1214/009053606000000092.\n\n\nBuhlmann, Peter, and Torsten Hothorn. 2007. “Boosting Algorithms: Regularization, Prediction and Model Fitting.” Statist. Sci. 22 (4): 477–505. https://doi.org/10.1214/07-STS242.\n\n\nBühlmann, Peter, and Bin Yu. 2003. “Boosting With the L2 Loss.” Journal of the American Statistical Association 98 (462): 324–39. https://doi.org/10.1198/016214503000125.\n\n\nChen, Tianqi, Tong He, Michael Benesty, Vadim Khotilovich, Yuan Tang, Hyunsu Cho, Kailong Chen, et al. 2020. “xgboost: Extreme Gradient Boosting.” CRAN. https://cran.r-project.org/package=xgboost.\n\n\nChen, Yifei, Zhenyu Jia, Dan Mercola, and Xiaohui Xie. 2013. “A Gradient Boosting Algorithm for Survival Analysis via Direct Optimization of Concordance Index.” Edited by Lev Klebanov. Computational and Mathematical Methods in Medicine 2013: 873595. https://doi.org/10.1155/2013/873595.\n\n\nCox, D. R. 1972. “Regression Models and Life-Tables.” Journal of the Royal Statistical Society: Series B (Statistical Methodology) 34 (2): 187–220.\n\n\n———. 1975. “Partial Likelihood.” Biometrika 62 (2): 269–76. https://doi.org/10.1080/03610910701884021.\n\n\nFreund, Yoav, and Robert E Schapire. 1996. “Experiments with a new boosting algorithm.” In. Citeseer.\n\n\nFriedman, Jerome. 1999. “Stochastic Gradient Boosting.” Computational Statistics & Data Analysis 38 (March): 367–78. https://doi.org/10.1016/S0167-9473(01)00065-2.\n\n\nFriedman, Jerome H. 2001. “Greedy Function Approximation: A Gradient Boosting Machine.” The Annals of Statistics 29 (5): 1189–1232. http://www.jstor.org/stable/2699986.\n\n\nHastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2001. The Elements of Statistical Learning. Springer New York Inc.\n\n\nHothorn, Torsten, Peter Buehlmann, Thomas Kneib, Matthias Schmid, and Benjamin Hofner. 2020. “mboost: Model-Based Boosting.” CRAN. https://cran.r-project.org/package=mboost.\n\n\nJohnson, Brent A, and Qi Long. 2011. “Survival ensembles by the sum of pairwise differences with application to lung cancer microarray studies.” Ann. Appl. Stat. 5 (2A): 1081–101. https://doi.org/10.1214/10-AOAS426.\n\n\nKlein, John P, and Melvin L Moeschberger. 2003. Survival analysis: techniques for censored and truncated data. 2nd ed. Springer Science & Business Media.\n\n\nLee, Donald K K, Ningyuan Chen, and Hemant Ishwaran. 2019. “Boosted nonparametric hazards with time-dependent covariates.” https://arxiv.org/abs/arXiv:1701.07926v6.\n\n\nLundberg, Scott M, and Su-In Lee. 2017. “A Unified Approach to Interpreting Model Predictions.” Advances in Neural Information Processing Systems 30.\n\n\nMa, Shuangge, and Jian Huang. 2006. “Regularized ROC method for disease classification and biomarker selection with microarray data.” Bioinformatics (Oxford, England) 21 (January): 4356–62. https://doi.org/10.1093/bioinformatics/bti724.\n\n\nMayr, Andreas, Benjamin Hofner, and Matthias Schmid. 2016. “Boosting the discriminatory power of sparse survival models via optimization of the concordance index and stability selection.” BMC Bioinformatics 17 (1): 288. https://doi.org/10.1186/s12859-016-1149-8.\n\n\nMayr, Andreas, and Matthias Schmid. 2014. “Boosting the concordance index for survival data–a unified framework to derive and evaluate biomarker combinations.” PloS One 9 (1): e84483–83. https://doi.org/10.1371/journal.pone.0084483.\n\n\nMeinshausen, Nicolai, and Peter Bühlmann. 2010. “Stability selection.” Journal of the Royal Statistical Society: Series B (Statistical Methodology) 72 (4): 417–73. https://doi.org/10.1111/j.1467-9868.2010.00740.x.\n\n\nRidgeway, Greg. 1999. “The state of boosting.” Computing Science and Statistics 31: 172–81.\n\n\nSchmid, Matthias, and Torsten Hothorn. 2008a. “Boosting additive models using component-wise P-splines.” Computational Statistics & Data Analysis 53 (2): 298–311.\n\n\n———. 2008b. “Flexible boosting of accelerated failure time models.” BMC Bioinformatics 9 (February): 269. https://doi.org/10.1186/1471-2105-9-269.\n\n\nTutz, Gerhard, and Harald Binder. 2007. “Boosting Ridge Regression.” Computational Statistics & Data Analysis 51 (February): 6044–59. https://doi.org/10.1016/j.csda.2006.11.041.\n\n\nWang, Zhu, and C Y Wang. 2010. “Buckley-James Boosting for Survival Analysis with High-Dimensional Biomarker Data.” Statistical Applications in Genetics and Molecular Biology 9 (1). https://doi.org/https://doi.org/10.2202/1544-6115.1550.\n\n\nWei, L J. 1992. “The Accelerated Failure Time Model: A Useful Alternative to the Cox Regression Model in Survival Analysis.” Statistics in Medicine 11: 1871–79.",
    "crumbs": [
      "Models",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Boosting Methods</span>"
    ]
  },
  {
    "objectID": "P3C17_neural.html",
    "href": "P3C17_neural.html",
    "title": "17  Neural Networks",
    "section": "",
    "text": "17.1 Neural Networks\nBefore starting the survey on neural networks, first a comment about their transparency and accessibility. Neural networks are infamously difficult to interpret and train, with some calling building and training neural networks an ‘art’ (Hastie, Tibshirani, and Friedman 2001). As discussed in the introduction of this book, whilst neural networks are not transparent with respect to their predictions, they are transparent with respect to implementation. In fact the simplest form of neural network, as seen below, is no more complex than a simple linear model. With regard to accessibility, whilst it is true that defining a custom neural network architecture is complex and highly subjective, established models are implemented with a default architecture and are therefore accessible ‘off-shelf’.",
    "crumbs": [
      "Models",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Neural Networks</span>"
    ]
  },
  {
    "objectID": "P3C17_neural.html#sec-surv-ml-models-nn",
    "href": "P3C17_neural.html#sec-surv-ml-models-nn",
    "title": "17  Neural Networks",
    "section": "",
    "text": "17.1.1 Neural Networks for Regression\n(Artificial) Neural networks (ANNs) are a class of model that fall within the greater paradigm of deep learning. The simplest form of ANN, a feed-forward single-hidden-layer network, is a relatively simple algorithm that relies on linear models, basic activation functions, and simple derivatives. A short introduction to feed-forward regression ANNs is provided to motivate the survival models. This focuses on single-hidden-layer models and increasing this to multiple hidden layers follows relatively simply.\nThe single hidden-layer network is defined through three equations\n\\[\n\\begin{aligned}\n& Z_m = \\sigma(\\alpha_{0m} + \\alpha^T_mX_i), \\quad m = 1,...,M \\\\\n& T = \\beta_{0k} + \\beta_k^TZ, \\quad k = 1,..,K \\\\\n& g_k(X_i) = \\phi_k(T)\n\\end{aligned}\n\\]\nwhere \\((X_1,...,X_n) \\stackrel{i.i.d.}\\sim X\\) are the usual training data, \\(\\alpha_{0m}, \\beta_0\\) are bias parameters, and \\(\\theta = \\{\\alpha_m, \\beta\\}\\) (\\(m = 1,..,,M\\)) are model weights where \\(M\\) is the number of hidden units. \\(K\\) is the number of classes in the output, which for regression is usually \\(K = 1\\). The function \\(\\phi\\) is a ‘link’ or ‘activation function’, which transforms the predictions in order to provide an outcome of the correct return type; usually in regression, \\(\\phi(x) = x\\). \\(\\sigma\\) is the ‘activation function’, which transforms outputs from each layer. The \\(\\alpha_m\\) parameters are often referred to as ‘activations’. Different activation functions may be used in each layer or the same used throughout, the choice is down to expert knowledge. Common activation functions seen in this section include the sigmoid function, \\[\n\\sigma(v) = (1 + \\exp(-v))^{-1}\n\\] tanh function, \\[\n\\sigma(v) = \\frac{\\exp(v) - \\exp(-v)}{\\exp(v) + \\exp(-v)}\n\\tag{17.1}\\] and ReLU (Nair and Hinton 2010) \\[\n\\sigma(v) = \\max(0, v)\n\\tag{17.2}\\]\nA single-hidden-layer model can also be expressed in a single equation, which highlights the relative simplicity of what may appear a complex algorithm.\n\\[\ng_k(X_i) = \\sigma_0(\\beta_{k0} + \\sum_{h=1}^H (\\beta_{kh}\\sigma_h (\\beta_{h0} + \\sum^M_{m=1} \\beta_{hm}X_{i;m}))\n\\tag{17.3}\\] where \\(H\\) are the number of hidden units, \\(\\beta\\) are the model weights, \\(\\sigma_h\\) is the activation function in unit \\(h\\), also \\(\\sigma_0\\) is the output unit activation, and \\(X_{i;m}\\) is the \\(i\\)th observation features in the \\(m\\)th hidden unit.\nAn example feed-forward single-hidden-layer regression ANN is displayed in (Figure 17.1). This model has 10 input units, 13 hidden units, and one output unit; two bias parameters are fit. The model is described as ‘feed-forward’ as there are no cycles in the node and information is passed forward from the input nodes (left) to the output node (right).\n\n\n\n\n\n\nFigure 17.1: Single-hidden-layer artificial neural network with 13 hidden units fit on the mtcars (Henderson and Velleman 1981) dataset using the \\(\\textbf{nnet}\\) (N. Venables and D. Ripley 2002) package, and (Stasinopoulos et al. 2020) for plotting. Left column are input variables, I1-I10, second column are 13 hidden units, H1-H13, right column is single output variable, O1. B1 and B2 are bias parameters.\n\n\n\n\nBack-Propagation\nThe model weights, \\(\\theta\\), in this section are commonly fit by ‘back-propagation’ although this method is often considered inefficient compared to more recent advances. A brief pseudo-algorithm for the process is provided below.\nLet \\(L\\) be a chosen loss function for model fitting, let \\(\\theta = (\\alpha, \\beta)\\) be model weights, and let \\(J \\in \\mathbb{N}_{&gt; 0}\\) be the number of iterations to train the model over. Then the back-propagation method is given by,\n\nFor \\(j = 1,...,J\\): [] Forward Pass [i.] Fix weights \\(\\theta^{(j-1)}\\). [ii.] Compute predictions \\(\\hat{Y} := \\hat{g}^{(j)}_k(X_i|\\theta^{(j-1)})\\) with (Equation 17.3). [] Backward Pass [iii.] Calculate the gradients of the loss \\(L(\\hat{Y}|\\mathcal{D}_{train})\\). [] Update *[iv.] Update \\(\\alpha^{(r)}, \\beta^{(r)}\\) with gradient descent.\nEnd For\n\nIn regression, a common choice for \\(L\\) is the squared loss, \\[\nL(\\hat{g}, \\theta|\\mathcal{D}_{train}) = \\sum_{i=1}^n (Y_i - \\hat{g}(X_i|\\theta))^2\n\\] which may help illustrate how the training outcome, \\((Y_1,...,Y_n) \\stackrel{i.i.d.}\\sim Y\\), is utilised for model fitting.\n\n\nMaking Predictions\nOnce the model is fitted, predictions for new data follow by passing the testing data as inputs to the model with fitted weights,\n\\[\ng_k(X^*) = \\sigma_0(\\hat{\\beta}_{k0} + \\sum_{h=1}^H (\\hat{\\beta}_{kh}\\sigma_h (\\hat{\\beta}_{h0} + \\sum^M_{m=1} \\hat{\\beta}_{hm}X^*_m))\n\\]\n\n\nHyper-Parameters\nIn practice, a regularization parameter, \\(\\lambda\\), is usually added to the loss function in order to help avoid overfitting. This parameter has the effect of shrinking model weights towards zero and hence in the context of ANNs regularization is usually referred to as ‘weight decay’. The value of \\(\\lambda\\) is one of three important hyper-parameters in all ANNs, the other two are: the range of values to simulate initial weights from, and the number of hidden units, \\(M\\).\nThe range of values for initial weights is usually not tuned but instead a consistent range is specified and the neural network is trained multiple times to account for randomness in initialization.\nThe regularization parameter and number of hidden units, \\(M\\), depend on each other and have a similar relationship to the learning rate and number of iterations in the GBMs (?sec-surv-ml-models-boost). Like the GBMs, it is simplest to set a high number of hidden units and then tune the regularization parameter (Bishop 2006; Hastie, Tibshirani, and Friedman 2001). Determining how many hidden layers to include, and how to connect them, is informed by expert knowledge and well beyond the scope of this book; decades of research has been required to derive sensible new configurations.\n\n\nTraining Batches\nANNs can either be trained using complete data, in batches, or online. This decision is usually data-driven and will affect the maximum number of iterations used to train the algorithm; as such this will also often be chosen by expert-knowledge and not empirical methods such as cross-validation.\n\n\nNeural Terminology\nNeural network terminology often reflects the structures of the brain. Therefore ANN units are referred to as nodes or neurons and sometimes the connections between neurons are referred to as synapses. Neurons are said to be ‘fired’ if they are ‘activated’. The simplest example of activating a neuron is with the Heaviside activation function with a threshold of \\(0\\): \\(\\sigma(v) = \\mathbb{I}(v \\geq 0)\\). Then a node is activated and passes its output to the next layer if its value is positive, otherwise it contributes no value to the next layer.\n\n\n\n17.1.2 Neural Networks for Survival Analysis\nSurveying neural networks is a non-trivial task as there has been a long history in machine learning of publishing very specific data-driven neural networks with limited applications; this is also true in survival analysis. This does mean however that where limited developments for survival were made in other machine learning classes, ANN survival adaptations have been around for several decades. A review in 2000 by Schwarzer \\(\\textit{et al.}\\) surveyed 43 ANNs for diagnosis and prognosis published in the first half of the 90s, however only up to ten of these are specifically for survival data. Of those, Schwarzer \\(\\textit{et al.}\\) deemed three to be ‘na\"ive applications to survival data’, and recommended for future research models developed by Liestl \\(\\textit{et al.}\\) (1994) (Liestol, Andersen, and Andersen 1994), Faraggi and Simon (1995) (Faraggi and Simon 1995), and Biganzoli \\(\\textit{et al.}\\) (1998) (E. Biganzoli et al. 1998).\nThis survey will not be as comprehensive as the 2000 survey, and nor has any survey since, although there have been several ANN reviews (B. D. Ripley and Ripley 2001; Huang et al. 2020a; Ohno-Machado 1996; Yang 2010; W. Zhu et al. 2020). ANNs are considered to be a black-box model, with interpretability decreasing steeply as the number of hidden layers and nodes increases. In terms of accessibility there have been relatively few open-source packages developed for survival ANNs; where these are available the focus has historically been in Python, with no \\(\\textsf{R}\\) implementations. The new \\(\\textbf{survivalmodels}\\) (R. Sonabend 2020) package, implements these Python models via \\(\\textbf{reticulate}\\) (Ushey, Allaire, and Tang 2020). No recurrent neural netwoks are included in this survey though the survival models SRN (Oh et al. 2018) and RNN-Surv (Giunchiglia, Nemchenko, and Schaar 2018) are acknowledged.\nThis survey is made slightly more difficult as neural networks are often proposed for many different tasks, which are not necessarily clearly advertised in a paper’s title or abstract. For example, many papers claim to use neural networks for survival analysis and make comparisons to Cox models, whereas the task tends to be death at a particular (usually 5-year) time-point (classification) (Han et al. 2018; Lundin et al. 1999; B. D. Ripley and Ripley 2001; R. M. Ripley, Harris, and Tarassenko 1998; Huseyin Seker et al. 2002), which is often not made clear until mid-way through the paper. Reviews and surveys have also conflated these different tasks, for example a very recent review concluded superior performance of ANNs over Cox models, when in fact this is only in classification (Huang et al. 2020b) (RM2) {sec:car_reduxstrats_mistakes}. To clarify, this form of classification task does fall into the general field of survival analysis, but not the survival task ((box-task-surv?)). Therefore this is not a comment on the classification task but a reason for omitting these models from this survey.\nUsing ANNs for feature selection (often in gene expression data) and computer vision is also very common in survival analysis, and indeed it is in this area that most success has been seen (Bello et al. 2019; Chen, Ke, and Chiu 2014; Cui et al. 2020; Lao et al. 2017; McKinney et al. 2020; Rietschel, Yoon, and Schaar 2018; H. Seker et al. 2002; Zhang et al. 2020; X. Zhu, Yao, and Huang 2016), but these are again beyond the scope of this survey.\nThe key difference between neural networks is in their output layer, required data transformations, the model prediction, and the loss function used to fit the model. Therefore the following are discussed for each of the surveyed models: the loss function for training, \\(L\\), the model prediction type, \\(\\hat{g}\\), and any required data transformation. Notation is continued from the previous surveys with the addition of \\(\\theta\\) denoting model weights (which will be different for each model).\n\n17.1.2.1 Probabilistic Survival Models\nUnlike other classes of machine learning models, the focus in ANNs has been on probabilistic models. The vast majority make these predictions via reduction to binary classification \\(\\ref{sec:car_reduxes_r7}\\). Whilst almost all of these networks implicitly reduce the problem to classification, most are not transparent in exactly how they do so and none provide clear or detailed interface points in implementation allowing for control over this reduction. Most importantly, the majority of these models do not detail how valid survival predictions are derived from the binary setting, which is not just a theoretical problem as some implementations, such as the Logistic-Hazard model in \\(\\textbf{pycox}\\) (Kvamme 2018), have been observed to make survival predictions outside the range \\([0,1]\\). This is not a statement about the performance of models in this section but a remark about the lack of transparency across all probabilistic ANNs.\nMany of these algorithms use an approach that formulate the Cox PH as a non-linear model and minimise the partial likelihood. These are referred to as ‘neural-Cox’ models and the earliest appears to have been developed by Faraggi and Simon (Faraggi and Simon 1995). All these models are technically composites that first predict a ranking, however they assume a PH form and in implementation they all appear to return a probabilistic prediction.\nANN-COX {#mod-anncox}\\ Faraggi and Simon (Faraggi and Simon 1995) proposed a non-linear PH model \\[\nh(\\tau|X_i,\\theta) = h_0(\\tau)\\exp(\\phi(X_i\\beta))\n\\tag{17.4}\\] where \\(\\phi\\) is the sigmoid function and \\(\\theta = \\{\\beta\\}\\) are model weights. This model, ‘ANN-COX’, estimates the prediction functional, \\(\\hat{g}(X^*) = \\phi(X^*\\hat{\\beta})\\). The model is trained with the partial-likelihood function \\[\nL(\\hat{g}, \\theta|\\mathcal{D}_{train}) = \\prod_{i = 1}^n \\frac{\\exp(\\sum^M_{m=1} \\alpha_m\\hat{g}_m(X^*))}{\\sum_{j \\in \\mathcal{R}_{t_i}} \\exp(\\sum^M_{m=1} \\alpha_m\\hat{g}_m(X^*))}\n\\] where \\(\\mathcal{R}_{t_i}\\) is the risk group alive at \\(t_i\\); \\(M\\) is the number of hidden units; \\(\\hat{g}_m(X^*) = (1 + \\exp(-X^*\\hat{\\beta}_m))^{-1}\\); and \\(\\theta = \\{\\beta, \\alpha\\}\\) are model weights.\nThe authors proposed a single hidden layer network, trained using back-propagation and weight optimisation with Newton-Raphson. This architecture did not outerperform a Cox PH (Faraggi and Simon 1995). Further adjustments including (now standard) pre-processing and hyper-parameter tuning did not improve the model performance (Mariani et al. 1997). Further independent studies demonstrated worse performance than the Cox model (Faraggi and Simon 1995; Xiang et al. 2000).\nCOX-NNET {#mod-coxnnet}\\ COX-NNET (Ching, Zhu, and Garmire 2018) updates the ANN-COX by instead maximising the regularized partial log-likelihood \\[\nL(\\hat{g}, \\theta|\\mathcal{D}_{train}, \\lambda) = \\sum^n_{i=1} \\Delta_i \\Big[\\hat{g}(X_i) \\ - \\ \\log\\Big(\\sum_{j \\in \\mathcal{R}_{t_i}} \\exp(\\hat{g}(X_j))\\Big)\\Big] + \\lambda(\\|\\beta\\|_2 + \\|w\\|_2)\n\\] with weights \\(\\theta = (\\beta, w)\\) and where \\(\\hat{g}(X_i) = \\sigma(wX_i + b)^T\\beta\\) for bias term \\(b\\), and activation function \\(\\sigma\\); \\(\\sigma\\) is chosen to be the tanh function ((Equation 17.1)). In addition to weight decay, dropout (Srivastava et al. 2014) is employed to prevent overfitting. Dropout can be thought of as a similar concept to the variable selection in random forests, as each node is randomly deactivated with probability \\(p\\), where \\(p\\) is a hyper-parameter to be tuned.\nIndependent simulation studies suggest that COX-NNET does not outperform the Cox PH (Michael F. Gensheimer and Narasimhan 2019).\nDeepSurv {#mod-deepsurv}\\ DeepSurv (J. L. Katzman et al. 2018) extends these models to deep learning with multiple hidden layers. The chosen error function is the average negative log-partial-likelihood with weight decay \\[\nL(\\hat{g}, \\theta|\\mathcal{D}_{train}, \\lambda) = -\\frac{1}{n^*} \\sum_{i = 1}^n \\Delta_i \\Big[ \\Big(\\hat{g}(X_i) - \\log \\sum_{j \\in \\mathcal{R}_{t_i})} \\exp(\\hat{g}(X_j)\\Big)\\Big] + \\lambda\\|\\theta\\|^2_2\n\\] where \\(n^* := \\sum^n_{i=1} \\mathbb{I}(\\Delta_i = 1)\\) is the number of uncensored observations and \\(\\hat{g}(X_i) = \\phi(X_i|\\theta)\\) is the same prediction object as the ANN-COX. State-of-the-art methods are used for data pre-processing and model training. The model architecture uses a combination of fully-connected and dropout layers. Benchmark experiments by the authors indicate that DeepSurv can outperform the Cox PH in ranking tasks (J. Katzman et al. 2016; J. L. Katzman et al. 2018) although independent experiments do not confirm this (Zhao and Feng 2020).\n*Cox-Time** {#mod-coxtime}\\ Kvamme \\(\\textit{et al.}\\) (Kvamme, Borgan, and Scheel 2019) build on these models by allowing time-varying effects. The loss function to minimise, with regularization, is given by \\[\nL(\\hat{g}, \\theta|\\mathcal{D}_{train}, \\lambda) = \\frac{1}{n} \\sum_{i:\\Delta_i = 1} \\log\\Big(\\sum_{j \\in \\mathcal{R}_{t_i}} \\exp[\\hat{g}(X_j,T_i) - \\hat{g}(X_i, T_i)]\\Big) + \\lambda \\sum_{i:\\Delta_i=1}\\sum_{j \\in \\mathcal{R}_{t_i}} |\\hat{g}(X_j,T_i)|\n\\] where \\(\\hat{g}= \\hat{g}_1,...,\\hat{g}_n\\) is the same non-linear predictor but with a time interaction and \\(\\lambda\\) is the regularization parameter. The model is trained with stochastic gradient descent and the risk set, \\(\\mathcal{R}_{t_i}\\), in the equation above is instead reduced to batches, as opposed to the complete dataset. ReLU activations (Nair and Hinton 2010) and dropout are employed in training. Benchmark experiments indicate good performance of Cox-Time, though no formal statistical comparisons are provided and hence no comment about general performance can be made.\nANN-CDP {#mod-anncdp}\\ One of the earliest ANNs that was noted by Schwarzer \\(\\textit{et al.}\\) (Schwarzer, Vach, and Schumacher 2000) was developed by Liestl \\(\\textit{et al.}\\) (Liestol, Andersen, and Andersen 1994) and predicts conditional death probabilities (hence ‘ANN-CDP’). The model first partitions the continuous survival times into disjoint intervals \\(\\mathcal{I}_k, k = 1,...,m\\) such that \\(\\mathcal{I}_k\\) is the interval \\((t_{k-1}, t_k]\\). The model then studies the logistic Cox model (proportional odds) (Cox 1972) given by \\[\n\\frac{p_k(\\mathbf{x})}{q_k(\\mathbf{x})} = \\exp(\\eta + \\theta_k)\n\\] where \\(p_k = 1-q_k\\), \\(\\theta_k = \\log(p_k(0)/q_k(0))\\) for some baseline probability of survival, \\(q_k(0)\\), to be estimated; \\(\\eta\\) is the usual linear predictor, and \\(q_k = P(T \\geq T_k | T \\geq T_{k-1})\\) is the conditional survival probability at time \\(T_k\\) given survival at time \\(T_{k-1}\\) for \\(k = 1,...,K\\) total time intervals. A logistic activation function is used to predict \\(\\hat{g}(X^*) = \\phi(\\eta + \\theta_k)\\), which provides an estimate for \\(\\hat{p}_k\\).\nThe model is trained on discrete censoring indicators \\(D_{ki}\\) such that \\(D_{ki} = 1\\) if individual \\(i\\) dies in interval \\(\\mathcal{I}_k\\) and \\(0\\) otherwise. Then with \\(K\\) output nodes and maximum likelihood estimation to find the model parameters, \\(\\hat{\\eta}\\), the final prediction provides an estimate for the conditional death probabilities \\(\\hat{p}_k\\). The negative log-likelihood to optimise is given by \\[\nL(\\hat{g}, \\theta|\\mathcal{D}_{train}) = \\sum^n_{i=1}\\sum^{m_i}_{k=1} [D_{ki}\\log(\\hat{p}_k(X_i)) + (1-D_{ki})\\log(\\hat{q}_k(X_i))]\n\\] where \\(m_i\\) is the number of intervals in which observation \\(i\\) is not censored.\nLiestl \\(\\textit{et al.}\\){} discuss different weighting options and how they correspond to the PH assumption. In the most generalised case, a weight-decay type regularization is applied to the model weights given by \\[\n\\alpha \\sum_l \\sum_k (w_{kl} - w_{k-1,l})^2\n\\] where \\(w\\) are weights, and \\(\\alpha\\) is a hyper-parameter to be tuned, which can be used alongside standard weight decay. This corresponds to penalizing deviations from proportionality thus creating a model with approximate proportionality. The authors also suggest the possibility of fixing the weights to be equal in some nodes and different in others; equal weights strictly enforces the proportionality assumption. Their simulations found that removing the proportionality assumption completely, or strictly enforcing it, gave inferior results. Comparing their model to a standard Cox PH resulted in a ‘better’ negative log-likelihood, however this is not a precise evaluation metric and an independent simulation would be preferred. Finally Listl \\(\\textit{et al.}\\) included a warning `‘The flexibility is, however, obtained at unquestionable costs: many parameters, difficult interpretation of the parameters and a slow numerical procedure’’ (Liestol, Andersen, and Andersen 1994).\nPLANN {#mod-plann}\\ Biganzoli \\(\\textit{et al.}\\) (1998) (E. Biganzoli et al. 1998) studied the same proportional-odds model as the ANN-CDP (Liestol, Andersen, and Andersen 1994). Their model utilises partial logistic regression (Efron 1988) with added hidden nodes, hence ‘PLANN’. Unlike ANN-CDP, PLANN predicts a smoothed hazard function by using smoothing splines. The continuous time outcome is again discretised into disjoint intervals \\(t_m, m = 1,...,M\\). At each time-interval, \\(t_m\\), the number of events, \\(d_m\\), and number of subjects at risk, \\(n_m\\), can be used to calculate the discrete hazard function, \\[\n\\hat{h}_m = \\frac{d_m}{n_m}, m = 1,...,M\n\\tag{17.5}\\] This quantity is used as the target to train the neural network. The survival function is then estimated by the Kaplan-Meier type estimator, \\[\n\\hat{S}(\\tau) = \\prod_{m:t_m \\leq \\tau} (1 - \\hat{h}_m)\n\\tag{17.6}\\]\nThe model is fit by employing one of the more ‘usual’ survival reduction strategies in which an observation’s survival time is treated as a covariate in the model (Tutz and Schmid 2016). As this model uses discrete time, the survival time is discretised into one of the \\(M\\) intervals. This approach removes the proportional odds constraint as interaction effects between time and covariates can be modelled (as time-updated covariates). Again the model makes predictions at a given time \\(m\\), \\(\\phi(\\theta_m + \\eta)\\), where \\(\\eta\\) is the usual linear predictor, \\(\\theta\\) is the baseline proportional odds hazard \\(\\theta_m = \\log(h_m(0)/(1-h_m(0))\\). The logistic activation provides estimates for the discrete hazard, \\[\nh_m(X_i) = \\frac{\\exp(\\theta_m + \\hat{\\eta})}{1 + \\exp(\\theta_m + \\hat{\\eta})}\n\\] which is smoothed with cubic splines (Efron 1988) that require tuning.\nA cross-entropy error function is used for training \\[\nL(\\hat{h}, \\theta|\\mathcal{D}_{train}, a) = - \\sum^M_{m = 1} \\Big[\\hat{h}_m \\log \\Big(\\frac{h_l(X_i, a_l)}{\\hat{h}_m}\\Big) + (1 - \\hat{h}_m) \\log \\Big(\\frac{1 - h_l(X_i, a_l)}{1 - \\hat{h}_m}\\Big)\\Big]n_m\n\\] where \\(h_l(X_i, a_l)\\) is the discrete hazard \\(h_l\\) with smoothing at mid-points \\(a_l\\). Weight decay can be applied and the authors suggest \\(\\lambda \\approx 0.01-0.1\\) (E. Biganzoli et al. 1998), though they make use of an AIC type criterion instead of cross-validation.\nThis model makes smoothed hazard predictions at a given time-point, \\(\\tau\\), by including \\(\\tau\\) in the input covariates \\(X_i\\). Therefore the model first requires transformation of the input data by replicating all observations and replacing the single survival indicator \\(\\Delta_i\\), with a time-dependent indicator \\(D_{ik}\\), the same approach as in ANN-CDP. Further developments have extended the PLANN to Bayesian modelling, and for competing risks (E. M. Biganzoli, Ambrogi, and Boracchi 2009).\nNo formal comparison is made to simpler model classes. The authors recommend ANNs primarily for exploration, feature selection, and understanding underlying patterns in the data (E. M. Biganzoli, Ambrogi, and Boracchi 2009).\nNnet-survival {#mod-nnetsurvival}\\ Aspects of the PLANN algorithm have been generalised into discrete-time survival algorithms in several papers (Michael F. Gensheimer and Narasimhan 2019; Kvamme2019?; Mani et al. 1999; Street 1998). Various estimates have been derived for transforming the input data to a discrete hazard or survival function. Though only one is considered here as it is the most modern and has a natural interpretation as the ‘usual’ Kaplan-Meier estimator for the survival function. Others by Street (1998) (Street 1998) and Mani (1999) (Mani et al. 1999) are acknowledged. The discrete hazard estimator (Equation 17.5), \\(\\hat{h}\\), is estimated and these values are used as the targets for the ANN. For the error function, the mean negative log-likelihood for discrete time (Kvamme2019?) is minimised to estimate \\(\\hat{h}\\), \\[\n\\begin{split}\nL(\\hat{h}, \\theta|\\mathcal{D}_{train}) = -\\frac{1}{n} \\sum^n_{i=1}\\sum^{k(T_i)}_{j=1} (\\mathbb{I}(T_i = \\tau_j, \\Delta_i = 1) \\log[\\hat{h}_i(\\tau_j)] \\ + \\\\\n(1-\\mathbb{I}(T_i = \\tau_j, \\Delta_i = 1))\\log(1 - \\hat{h}_i(\\tau_j)))\n\\end{split}\n\\] where \\(k(T_i)\\) is the time-interval index in which observation \\(i\\) dies/is censored, \\(\\tau_j\\) is the \\(j\\)th discrete time-interval, and the prediction of \\(\\hat{h}\\) is obtained via \\[\n\\hat{h}(\\tau_j|\\mathcal{D}_{train}) = [1 + \\exp(-\\hat{g}_j(\\mathcal{D}_{train}))]^{-1}\n\\] where \\(\\hat{g}_j\\) is the \\(j\\)th output for \\(j = 1,...,m\\) discrete time intervals. The number of units in the output layer for these models corresponds to the number of discrete-time intervals. Deciding the width of the time-intervals is an additional hyper-parameter to consider.\nGensheimer and Narasimhan’s ‘Nnet-survival’ (Michael F. Gensheimer and Narasimhan 2019) has two different implementations. The first assumes a PH form and predicts the linear predictor in the final layer, which can then be composed to a distribution. Their second ‘flexible’ approach instead predicts the log-odds of survival in each node, which are then converted to a conditional probability of survival, \\(1 - h_j\\), in a given interval using the sigmoid activation function. The full survival function can be derived with (Equation 17.6). The model has been demonstrated not to outperform the Cox PH with respect to Harrell’s C or the Graf (Brier) score (Michael F. Gensheimer and Narasimhan 2019).\nPC-Hazard {#mod-pchazard}\\ Kvamme and Borgan deviate from nnet-survival in their ‘PC-Hazard’ (Kvamme2019?) by first considering a discrete-time approach with a softmax activation function influenced by multi-class classification. They expand upon this by studying a piecewise constant hazard function in continuous time and defining the mean negative log-likelihood as \\[\nL(\\hat{g}, \\theta|\\mathcal{D}_{train}) = -\\frac{1}{n} \\sum^n_{i=1} \\Big(\\Delta_i X_i\\log\\tilde{\\eta}_{k(T_i)} - X_i\\tilde{\\eta}_{k(T_i)}\\rho(T_i) - \\sum^{k(T_i)-1}_{j=1} \\tilde{\\eta}_jX_i\\Big)\n\\] where \\(k(T_i)\\) and \\(\\tau_i\\) is the same as defined above, \\(\\rho(t) = \\frac{t - \\tau_{k(t)-1}}{\\Delta\\tau_{k(t)}}\\), \\(\\Delta\\tau_j = \\tau_j - \\tau_{j-1}\\), and \\(\\tilde{\\eta}_j := \\log(1 + \\exp(\\hat{g}_j(X_i))\\) where again \\(\\hat{g}_j\\) is the \\(j\\)th output for \\(j = 1,...,m\\) discrete time intervals. Once the weights have been estimated, the predicted survival function is given by \\[\n\\hat{S}(\\tau, X^*|\\mathcal{D}_{train}) = \\exp(-X^*\\tilde{\\eta}_{k(\\tau)}\\rho(\\tau)) \\prod^{k(\\tau)-1}_{j=1} \\exp(-\\tilde{\\eta}_j(X^*))\n\\] Benchmark experiments indicate similar performance to nnet-survival (Kvamme2019?), an unsurprising result given their implementations are identical with the exception of the loss function (Kvamme2019?), which is also similar for both models. A key result found that varying values for interval width lead to significant differences and therefore should be carefully tuned.\nDNNSurv {#mod-dnnsurv}\\ A very recent (pre-print) approach (Zhao and Feng 2020) instead first computes ‘pseudo-survival probabilities’ and uses these to train a regression ANN with sigmoid activation and squared error loss. These pseudo-probabilities are computed using a jackknife-style estimator given by \\[\n\\tilde{S}_{ij}(T_{j+1}, \\mathcal{R}_{t_j}) = n_j\\hat{S}(T_{j+1}|\\mathcal{R}_{t_j}) - (n_j - 1)\\hat{S}^{-i}(T_{j+1}|\\mathcal{R}_{t_j})\n\\] where \\(\\hat{S}\\) is the IPCW weighted Kaplan-Meier estimator (defined below) for risk set \\(\\mathcal{R}_{t_j}\\), \\(\\hat{S}^{-i}\\) is the Kaplan-Meier estimator for all observations in \\(\\mathcal{R}_{t_j}\\) excluding observation \\(i\\), and \\(n_j := |\\mathcal{R}_{t_j}|\\). The IPCW weighted Kaplan-Meier estimate is found via the IPCW Nelson-Aalen estimator, \\[\n\\hat{H}(\\tau|\\mathcal{D}_{train}) = \\sum^n_{i=1} \\int^\\tau_0 \\frac{\\mathbb{I}(T_i \\leq u, \\Delta_i = 1)\\hat{W}_i(u)}{\\sum^n_{j=1} \\mathbb{I}(T_j \\geq u) \\hat{W}_j(u)} \\ du\n\\] where \\(\\hat{W}_i,\\hat{W}_j\\) are subject specific IPC weights.\nIn their simulation studies, they found no improvement over other proposed neural networks. Arguably the most interesting outcome of their paper are comparisons of multiple survival ANNs at specific time-points, evaluated with C-index and Brier score. Their results indicate identical performance from all models. They also provide further evidence of neural networks not outperforming a Cox PH when the PH assumption is valid. However, in their non-PH dataset, DNNSurv appears to outperform the Cox model (no formal tests are provided). Data is replicated similarly to previous models except that no special indicator separates censoring and death, this is assumed to be handled by the IPCW pseudo probabilities.\n\nDeepHit {#mod-deephit}\\ DeepHit (Lee et al. 2018) was originally built to accommodate competing risks, but only the non-competing case is discussed here (Kvamme, Borgan, and Scheel 2019). The model builds on previous approaches by discretising the continuous time outcome, and makes use of a composite loss. It has the advantage of making no parametric assumptions and directly predicts the probability of failure in each time-interval (which again correspond to different terminal nodes), i.e. \\(\\hat{g}(\\tau_k|\\mathcal{D}_{test}) = \\hat{P}(T^* = \\tau_k|X^*)\\) where again \\(\\tau_k, k = 1,...,K\\) are the distinct time intervals. The estimated survival function is found with \\(\\hat{S}(\\tau_K|X^*) = 1 - \\sum^K_{k = 1} \\hat{g}_i(\\tau_k|X^*)\\). ReLU activations were used in all fully connected layers and a softmax activation in the final layer. The losses in the composite error function are given by \\[\nL_1(\\hat{g}, \\theta|\\mathcal{D}_{train}) = -\\sum^N_{i=1} [\\Delta_i \\log(\\hat{g}_i(T_i)) + (1-\\Delta_i)\\log(\\hat{S}_i(T_i))]\n\\] and \\[\nL_2(\\hat{g}, \\theta|\\mathcal{D}_{train}, \\sigma) = \\sum_{i \\neq j} \\Delta_i \\mathbb{I}(T_i &lt; T_j) \\sigma(\\hat{S}_i(T_i), \\hat{S}_j(T_i))\n\\] for some convex loss function \\(\\sigma\\) and where \\(\\hat{g}_i(t) = \\hat{g}(t|X_i)\\). Again these can be seen to be a cross-entropy loss and a ranking loss. Benchmark experiments demonstrate the model outperforming the Cox PH and RSFs (Lee et al. 2018) with respect to separation, and an independent experiment supports these findings (Kvamme, Borgan, and Scheel 2019). However, the same independent study demonstrated worse performance than a Cox PH with respect to the integrated Brier score (Graf et al. 1999).\n\n\n17.1.2.2 Deterministic Survival Models\nWhilst the vast majority of survival ANNs have focused on probabilistic predictions (often via ranking), a few have also tackled the deterministic or ‘hybrid’ problem.\nRankDeepSurv {#mod-rankdeepsurv}\\ Jing \\(\\textit{et al.}\\) (Jing et al. 2019) observed the past two decades of research in survival ANNs and then published a completely novel solution, RankDeepSurv, which makes predictions for the survival time \\(\\hat{T} = (\\hat{T}_1,...,\\hat{T}_n)\\). They proposed a composite loss function \\[\nL(\\hat{T}, \\theta|\\mathcal{D}_{train}, \\alpha,\\gamma,\\lambda) = \\alpha L_1(\\hat{T},T,\\Delta) + \\gamma L_2(\\hat{T},T,\\Delta) + \\lambda\\|\\theta\\|^2_2\n\\] where \\(\\theta\\) are the model weights, \\(\\alpha,\\gamma \\in \\mathbb{R}_{&gt;0}\\), \\(\\lambda\\) is the shrinkage parameter, by a slight abuse of notation \\(T = (T_1,...,T_n)\\) and \\(\\Delta = (\\Delta_1,...,\\Delta_n)\\), and \\[\nL_1(\\hat{T}, \\theta|\\mathcal{D}_{train}) = \\frac{1}{n} \\sum_{\\{i: I(i) = 1\\}} (\\hat{T}_i - T_i)^2;\n\\quad I(i) =\n\\begin{cases}\n1, & \\Delta_i = 1 \\cup (\\Delta_i = 0 \\cap \\hat{T}_i \\leq T_i) \\\\\n0, & \\text{otherwise}\n\\end{cases}\n\\] \\[\nL_2(\\hat{T}, \\theta|\\mathcal{D}_{train}) = \\frac{1}{n}\\sum^n_{\\{i,j : I(i,j) = 1\\}} [(T_j - T_i) - (\\hat{T}_j - \\hat{T}_i)]^2;\n\\quad\nI(i,j) =\n\\begin{cases}\n1, & T_j - T_i &gt; \\hat{T}_j - \\hat{T}_i \\\\\n0, & \\text{otherwise}\n\\end{cases}\n\\] where \\(\\hat{T}_i\\) is the predicted survival time for observation \\(i\\). A clear contrast can be made between these loss functions and the constraints used in SSVM-Hybrid (Van Belle et al. 2011) (Section 15.2). \\(L_1\\) is the squared second constraint in \\(\\ref{eq:surv_ssvmvb2}\\) and \\(L_2\\) is the squared first constraint in \\(\\ref{eq:surv_ssvmvb2}\\). However \\(L_1\\) in RankDeepSurv discards the squared error difference for all censored observations when the prediction is lower than the observed survival time; which is problematic as if someone is censored at time \\(T_i\\) then it is guaranteed that their true survival time is greater than \\(T_i\\) (this constraint may be more sensible if the inequality were reversed). An advantage to this loss is, like the SSVM-Hybrid, it enables a survival time interpretation for a ranking optimised model; however these ‘survival times’ should be interpreted with care.\nThe authors propose a model architecture with several fully connected layers with the ELU (Clevert, Unterthiner, and Hochreiter 2015) activation function and a single dropout layer. Determining the success of this model is not straightforward. The authors claim superiority of RankDeepSurv over Cox PH, DeepSurv, and RSFs however this is an unclear comparison (RM2) {sec:car_reduxstrats_mistakes} that requires independent study.\n\n\n\n17.1.3 Conclusions\nThere have been many advances in neural networks for survival analysis. It is not possible to review all proposed survival neural networks without diverting too far from the book scope. This survey of ANNs should demonstrate two points: firstly that the vast majority (if not all) of survival ANNs are reduction models that either find a way around censoring via imputation or discretisation of time-intervals, or by focusing on partial likelihoods only; secondly that no survival ANN is fully accessible or transparent.\nDespite ANNs being highly performant in other areas of supervised learning, there is strong evidence that the survival ANNs above are inferior to a Cox PH when the data follows the PH assumption or when variables are linearly related (Michael F. Gensheimer and Narasimhan 2018; Luxhoj and Shyur 1997; Ohno-Machado 1997; Puddu and Menotti 2012; Xiang et al. 2000; Yang 2010; Yasodhara, Bhat, and Goldenberg 2018; Zhao and Feng 2020). There are not enough experiments to make conclusions in the case when the data is non-PH. Experiments in (R. E. B. Sonabend 2021) support the finding that survival ANNs are not performant.\nThere is evidence that many papers introducing neural networks do not utilise proper methods of comparison or evaluation (Király, Mateen, and Sonabend 2018) and in conducting this survey, these findings are further supported. Many papers made claims of being ‘superior’ to the Cox model based on unfair comparisons (RM2){sec:car_reduxstrats_mistakes} or miscommunicating (or misinterpreting) results (e.g. (Fotso 2018)). At this stage, it does not seem possible to make any conclusions about the effectiveness of neural networks in survival analysis. Moreover, even the authors of these models have pointed out problems with transparency (E. M. Biganzoli, Ambrogi, and Boracchi 2009; Liestol, Andersen, and Andersen 1994), which was further highlighted by Schwarzer \\(\\textit{et al.}\\) (Schwarzer, Vach, and Schumacher 2000).\nFinally, accessibility of neural networks is also problematic. Many papers do not release their code and instead just state their networks architecture and available packages. In theory, this is enough to build the models however this does not guarantee the reproducibility that is usually expected. For users with a technical background and good coding ability, many of the models above could be implemented in one of the neural network packages in \\(\\textsf{R}\\), such as \\(\\textbf{nnet}\\) (N. Venables and D. Ripley 2002) and \\(\\textbf{neuralnet}\\) (Fritsch, Guenther, and N. Wright 2019); though in practice the only package that does contain these models, \\(\\textbf{survivalmodels}\\), does not directly implement the models in \\(\\textsf{R}\\) (which is much slower than Python) but provides a method for interfacing the Python implementations in \\(\\textbf{pycox}\\) (Kvamme 2018).\n\n\n\n\n\n\nFurther reading\n\n\n\n\nSchwarzer, Vach, and Schumacher (2000) provided an early survey of neural networks, focusing on ways in which neural networks have been ‘misused’ in the context of survival analysis. Whilst neural networks have moved on substantially since, their early observations remain valid today.\n\n\n\n\n\n\n\nBello, Ghalib A, Timothy J W Dawes, Jinming Duan, Carlo Biffi, Antonio de Marvao, Luke S G E Howard, J Simon R Gibbs, et al. 2019. “Deep-learning cardiac motion analysis for human survival prediction.” Nature Machine Intelligence 1 (2): 95–104. https://doi.org/10.1038/s42256-019-0019-2.\n\n\nBiganzoli, E M, F Ambrogi, and P Boracchi. 2009. “Partial logistic artificial neural networks (PLANN) for flexible modeling of censored survival data.” In 2009 International Joint Conference on Neural Networks, 340–46. https://doi.org/10.1109/IJCNN.2009.5178824.\n\n\nBiganzoli, Elia, Patrizia Boracchi, Luigi Mariani, and Ettore Marubini. 1998. “Feed forward neural networks for the analysis of censored survival data: a partial logistic regression approach.” Statistics in Medicine 17 (10): 1169–86. https://doi.org/10.1002/(SICI)1097-0258(19980530)17:10&lt;1169::AID-SIM796&gt;3.0.CO;2-D.\n\n\nBishop, Christopher M. 2006. Pattern recognition and machine learning. springer.\n\n\nChen, Yen-Chen, Wan-Chi Ke, and Hung-Wen Chiu. 2014. “Risk classification of cancer survival using ANN with gene expression data from multiple laboratories.” Computers in Biology and Medicine 48: 1–7. https://doi.org/https://doi.org/10.1016/j.compbiomed.2014.02.006.\n\n\nChing, Travers, Xun Zhu, and Lana X Garmire. 2018. “Cox-nnet: An artificial neural network method for prognosis prediction of high-throughput omics data.” PLOS Computational Biology 14 (4): e1006076. https://doi.org/10.1371/journal.pcbi.1006076.\n\n\nClevert, Djork-Arné, Thomas Unterthiner, and Sepp Hochreiter. 2015. “Fast and accurate deep network learning by exponential linear units (elus).” arXiv Preprint arXiv:1511.07289.\n\n\nCox, D. R. 1972. “Regression Models and Life-Tables.” Journal of the Royal Statistical Society: Series B (Statistical Methodology) 34 (2): 187–220.\n\n\nCui, Lei, Hansheng Li, Wenli Hui, Sitong Chen, Lin Yang, Yuxin Kang, Qirong Bo, and Jun Feng. 2020. “A deep learning-based framework for lung cancer survival analysis with biomarker interpretation.” BMC Bioinformatics 21 (1): 112. https://doi.org/10.1186/s12859-020-3431-z.\n\n\nEfron, Bradley. 1988. “Logistic Regression, Survival Analysis, and the Kaplan-Meier Curve.” Journal of the American Statistical Association 83 (402): 414–25. https://doi.org/10.2307/2288857.\n\n\nFaraggi, David, and Richard Simon. 1995. “A neural network model for survival data.” Statistics in Medicine 14 (1): 73–82. https://doi.org/10.1002/sim.4780140108.\n\n\nFotso, Stephane. 2018. “Deep Neural Networks for Survival Analysis Based on a Multi-Task Framework.” arXiv Preprint arXiv:1801.05512, January. http://arxiv.org/abs/1801.05512.\n\n\nFritsch, Stefan, Frauke Guenther, and Marvin N. Wright. 2019. “neuralnet: Training of Neural Networks.” CRAN. https://cran.r-project.org/package=neuralnet.\n\n\nGensheimer, Michael F., and Balasubramanian Narasimhan. 2018. “A Simple Discrete-Time Survival Model for Neural Networks,” 1–17. https://doi.org/arXiv:1805.00917v3.\n\n\nGensheimer, Michael F, and Balasubramanian Narasimhan. 2019. “A scalable discrete-time survival model for neural networks.” PeerJ 7: e6257.\n\n\nGiunchiglia, Eleonora, Anton Nemchenko, and Mihaela van der Schaar. 2018. “Rnn-surv: A deep recurrent model for survival analysis.” In International Conference on Artificial Neural Networks, 23–32. Springer.\n\n\nGraf, Erika, Claudia Schmoor, Willi Sauerbrei, and Martin Schumacher. 1999. “Assessment and comparison of prognostic classification schemes for survival data.” Statistics in Medicine 18 (17-18): 2529–45. https://doi.org/10.1002/(SICI)1097-0258(19990915/30)18:17/18&lt;2529::AID-SIM274&gt;3.0.CO;2-5.\n\n\nHan, Ilkyu, June Hyuk Kim, Heeseol Park, Han-Soo Kim, and Sung Wook Seo. 2018. “Deep learning approach for survival prediction for patients with synovial sarcoma.” Tumor Biology 40 (9): 1010428318799264. https://doi.org/10.1177/1010428318799264.\n\n\nHastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2001. The Elements of Statistical Learning. Springer New York Inc.\n\n\nHenderson, and Velleman. 1981. “Building multiple regression models interactively.” Biometrics 37: 391–411.\n\n\nHuang, Shigao, Jie Yang, Simon Fong, and Qi Zhao. 2020b. “Artificial intelligence in cancer diagnosis and prognosis: Opportunities and challenges.” Cancer Letters 471: 61–71. https://doi.org/https://doi.org/10.1016/j.canlet.2019.12.007.\n\n\n———. 2020a. “Artificial intelligence in cancer diagnosis and prognosis: Opportunities and challenges.” Cancer Letters 471: 61–71. https://doi.org/https://doi.org/10.1016/j.canlet.2019.12.007.\n\n\nJing, Bingzhong, Tao Zhang, Zixian Wang, Ying Jin, Kuiyuan Liu, Wenze Qiu, Liangru Ke, et al. 2019. “A deep survival analysis method based on ranking.” Artificial Intelligence in Medicine 98: 1–9. https://doi.org/https://doi.org/10.1016/j.artmed.2019.06.001.\n\n\nKatzman, Jared L, Uri Shaham, Alexander Cloninger, Jonathan Bates, Tingting Jiang, and Yuval Kluger. 2018. “DeepSurv: personalized treatment recommender system using a Cox proportional hazards deep neural network.” BMC Medical Research Methodology 18 (1): 24. https://doi.org/10.1186/s12874-018-0482-1.\n\n\nKatzman, Jared, Uri Shaham, Alexander Cloninger, Jonathan Bates, Tingting Jiang, and Yuval Kluger. 2016. “Deep Survival: A Deep Cox Proportional Hazards Network,” June.\n\n\nKirály, Franz J, Bilal Mateen, and Raphael Sonabend. 2018. “NIPS - Not Even Wrong? A Systematic Review of Empirically Complete Demonstrations of Algorithmic Effectiveness in the Machine Learning and Artificial Intelligence Literature.” arXiv, December. http://arxiv.org/abs/1812.07519.\n\n\nKvamme, Håvard. 2018. “Pycox.” https://pypi.org/project/pycox/.\n\n\nKvamme, Håvard, Ørnulf Borgan, and Ida Scheel. 2019. “Time-to-event prediction with neural networks and Cox regression.” Journal of Machine Learning Research 20 (129): 1–30.\n\n\nLao, Jiangwei, Yinsheng Chen, Zhi-Cheng Li, Qihua Li, Ji Zhang, Jing Liu, and Guangtao Zhai. 2017. “A Deep Learning-Based Radiomics Model for Prediction of Survival in Glioblastoma Multiforme.” Scientific Reports 7 (1): 10353. https://doi.org/10.1038/s41598-017-10649-8.\n\n\nLee, Changhee, William Zame, Jinsung Yoon, and Mihaela Van der Schaar. 2018. “DeepHit: A Deep Learning Approach to Survival Analysis With Competing Risks.” Proceedings of the AAAI Conference on Artificial Intelligence 32 (1). https://doi.org/10.1609/aaai.v32i1.11842.\n\n\nLiestol, Knut, Per Kragh Andersen, and Ulrich Andersen. 1994. “Survival analysis and neural nets.” Statistics in Medicine 13 (12): 1189–1200. https://doi.org/10.1002/sim.4780131202.\n\n\nLundin, M, J Lundin, H B Burke, S Toikkanen, L Pylkkänen, and H Joensuu. 1999. “Artificial Neural Networks Applied to Survival Prediction in Breast Cancer.” Oncology 57 (4): 281–86. https://doi.org/10.1159/000012061.\n\n\nLuxhoj, James T., and Huan Jyh Shyur. 1997. “Comparison of proportional hazards models and neural networks for reliability estimation.” Journal of Intelligent Manufacturing 8 (3): 227–34. https://doi.org/10.1023/A:1018525308809.\n\n\nMani, D R, James Drew, Andrew Betz, and Piew Datta. 1999. “Statistics and data mining techniques for lifetime value modeling.” In Proceedings of the Fifth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 94–103.\n\n\nMariani, L, D Coradini, E Biganzoli, P Boracchi, E Marubini, S Pilotti, B Salvadori, et al. 1997. “Prognostic factors for metachronous contralateral breast cancer: A comparison of the linear Cox regression model and its artificial neural network extension.” Breast Cancer Research and Treatment 44 (2): 167–78. https://doi.org/10.1023/A:1005765403093.\n\n\nMcKinney, Scott Mayer, Marcin Sieniek, Varun Godbole, Jonathan Godwin, Natasha Antropova, Hutan Ashrafian, Trevor Back, et al. 2020. “International evaluation of an AI system for breast cancer screening.” Nature 577 (7788): 89–94. https://doi.org/10.1038/s41586-019-1799-6.\n\n\nN. Venables, W, and B D. Ripley. 2002. Modern Applied Statistics with S. Springer. http://www.stats.ox.ac.uk/pub/MASS4.\n\n\nNair, Vinod, and Geoffrey E Hinton. 2010. “Rectified linear units improve restricted boltzmann machines.” In Proceedings of the 27th International Conference on Machine Learning (ICML-10), 807–14.\n\n\nOh, Sung Eun, Sung Wook Seo, Min-Gew Choi, Tae Sung Sohn, Jae Moon Bae, and Sung Kim. 2018. “Prediction of Overall Survival and Novel Classification of Patients with Gastric Cancer Using the Survival Recurrent Network.” Annals of Surgical Oncology 25 (5): 1153–59. https://doi.org/10.1245/s10434-018-6343-7.\n\n\nOhno-Machado, Lucila. 1996. “Medical applications of artificial neural networks: connectionist models of survival.” Stanford University Stanford, Calif.\n\n\n———. 1997. “A COMPARISON OF COX PROPORTIONAL HAZARDS AND ARTIFICIAL NEURAL NETWORK MODELS FOR MEDICAL PROGNOSIS The theoretical advantages and disadvantages of using different methods for predicting survival have seldom been tested in real data sets [ 1 , 2 ]. Althou.” Comput. Biol. Med 27 (1): 55–65.\n\n\nPuddu, Paolo Emilio, and Alessandro Menotti. 2012. “Artificial neural networks versus proportional hazards Cox models to predict 45-year all-cause mortality in the Italian Rural Areas of the Seven Countries Study.” BMC Medical Research Methodology 12 (1): 100. https://doi.org/10.1186/1471-2288-12-100.\n\n\nRietschel, Carl, Jinsung Yoon, and Mihaela van der Schaar. 2018. “Feature Selection for Survival Analysis with Competing Risks using Deep Learning.” arXiv Preprint arXiv:1811.09317.\n\n\nRipley, Brian D, and Ruth M Ripley. 2001. “Neural networks as statistical methods in survival analysis.” In Clinical Applications of Artificial Neural Networks, edited by Richard Dybowski and Vanya Gant, 237–55. Cambridge: Cambridge University Press. https://doi.org/DOI: 10.1017/CBO9780511543494.011.\n\n\nRipley, R M, A L Harris, and L Tarassenko. 1998. “Neural network models for breast cancer prognosis.” Neural Computing & Applications 7 (4): 367–75. https://doi.org/10.1007/BF01428127.\n\n\nSchwarzer, Guido, Werner Vach, and Martin Schumacher. 2000. “On the misuses of artificial neural networks for prognostic and diagnostic classification in oncology.” Statistics in Medicine 19 (4): 541–61. https://doi.org/10.1002/(SICI)1097-0258(20000229)19:4&lt;541::AID-SIM355&gt;3.0.CO;2-V.\n\n\nSeker, H, M O Odetayo, D Petrovic, R N G Naguib, C Bartoli, L Alasio, M S Lakshmi, G V Sherbet, and O R Hinton. 2002. “An artificial neural network based feature evaluation index for the assessment of clinical factors in breast cancer survival analysis.” In IEEE CCECE2002. Canadian Conference on Electrical and Computer Engineering. Conference Proceedings (Cat. No.02CH37373), 2:1211–1215 vol.2. https://doi.org/10.1109/CCECE.2002.1013121.\n\n\nSeker, Huseyin, Michael O Odetayo, Dobrila Petrovic, Raouf N G Naguib, C Bartoli, L Alasio, M S Lakshmi, and G V Sherbet. 2002. “Assessment of nodal involvement and survival analysis in breast cancer patients using image cytometric data: statistical, neural network and fuzzy approaches.” Anticancer Research 22 (1A): 433–38. http://europepmc.org/abstract/MED/12017328.\n\n\nSonabend, Raphael. 2020. “survivalmodels: Models for Survival Analysis.” CRAN. https://raphaels1.r-universe.dev/ui#package:survivalmodels.\n\n\nSonabend, Raphael Edward Benjamin. 2021. “A Theoretical and Methodological Framework for Machine Learning in Survival Analysis: Enabling Transparent and Accessible Predictive Modelling on Right-Censored Time-to-Event Data.” PhD, University College London (UCL). https://discovery.ucl.ac.uk/id/eprint/10129352/.\n\n\nSrivastava, Nitish, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. “Dropout: a simple way to prevent neural networks from overfitting.” The Journal of Machine Learning Research 15 (1): 1929–58.\n\n\nStasinopoulos, Mikis, Bob Rigby, Vlasios Voudouris, and Daniil Kiose. 2020. “gamlss.add: Extra Additive Terms for Generalized Additive Models for Location Scale and Shape.” CRAN. https://cran.r-project.org/package=gamlss.add.\n\n\nStreet, W Nick. 1998. “A Neural Network Model for Prognostic Prediction.” In Proceedings of the Fifteenth International Conference on Machine Learning. San Francisco.\n\n\nTutz, Gerhard, and Matthias Schmid. 2016. Modeling Discrete Time-to-Event Data. Springer Series in Statistics. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-319-28158-2.\n\n\nUshey, Kevin, J J Allaire, and Yuan Tang. 2020. “reticulate: Interface to ’Python’.” CRAN. https://cran.r-project.org/package=reticulate.\n\n\nVan Belle, Vanya, Kristiaan Pelckmans, Sabine Van Huffel, and Johan A. K. Suykens. 2011. “Support vector methods for survival analysis: A comparison between ranking and regression approaches.” Artificial Intelligence in Medicine 53 (2): 107–18. https://doi.org/10.1016/j.artmed.2011.06.006.\n\n\nXiang, Anny, Pablo Lapuerta, Alex Ryutov, Jonathan Buckley, and Stanley Azen. 2000. “Comparison of the performance of neural network methods and Cox regression for censored survival data.” Computational Statistics & Data Analysis 34 (2): 243–57. https://doi.org/https://doi.org/10.1016/S0167-9473(99)00098-5.\n\n\nYang, Yanying. 2010. “Neural Network Survival Analysis.” PhD thesis, Universiteit Gent.\n\n\nYasodhara, Angeline, Mamatha Bhat, and Anna Goldenberg. 2018. Prediction of New Onset Diabetes after Liver Transplant.\n\n\nZhang, Yucheng, Edrise M Lobo-Mueller, Paul Karanicolas, Steven Gallinger, Masoom A Haider, and Farzad Khalvati. 2020. “CNN-based survival model for pancreatic ductal adenocarcinoma in medical imaging.” BMC Medical Imaging 20 (1): 11. https://doi.org/10.1186/s12880-020-0418-1.\n\n\nZhao, Lili, and Dai Feng. 2020. “Deep Neural Networks for Survival Analysis Using Pseudo Values.” IEEE Journal of Biomedical and Health Informatics 24 (11): 3308–14. https://doi.org/10.1109/JBHI.2020.2980204.\n\n\nZhu, Wan, Longxiang Xie, Jianye Han, and Xiangqian Guo. 2020. “The Application of Deep Learning in Cancer Prognosis Prediction.” Cancers 12 (3): 603. https://doi.org/10.3390/cancers12030603.\n\n\nZhu, X, J Yao, and J Huang. 2016. “Deep convolutional neural network for survival analysis with pathological images.” In 2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), 544–47. https://doi.org/10.1109/BIBM.2016.7822579.",
    "crumbs": [
      "Models",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Neural Networks</span>"
    ]
  },
  {
    "objectID": "P3C18_choosing.html",
    "href": "P3C18_choosing.html",
    "title": "18  Choosing Models",
    "section": "",
    "text": "Page coming soon!\n\n\n\nWe are working on this page and it will be available soon!",
    "crumbs": [
      "Models",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Choosing Models</span>"
    ]
  },
  {
    "objectID": "P4C19_reductions.html",
    "href": "P4C19_reductions.html",
    "title": "19  Reductions",
    "section": "",
    "text": "Notation and Terminology\nIn this chapter, composition and reduction are formally introduced, defined and demonstrated within survival analysis. Neither of these are novel concepts in general or in survival, with several applications already seen earlier when reviewing models (particularly in neural networks), however a lack of formalisation has led to much repeated work and at times questionable applications (Section 17.1). The primary purpose of this chapter is to formalise composition and reduction for survival and to unify references and strategies for future use. These strategies are introduced in the context of minimal ‘workflows’ and graphical ‘pipelines’ in order to maximise their generalisability.\nA workflow is a generic term given to a series of sequential operations. For example a standard ML workflow is fit/predict/evaluate, which means a model is fit, predictions are made, and these are evaluated. In this book, a pipeline is the name given to a concrete workflow. Section 19.1 demonstrates how pipelines are represented in this book.\nComposition (Section 19.2) is a general process in which an object is built (or composed) from other objects and parameters. Reduction (Section 19.3) is a closely related concept that utilises composition in order to transform one problem into another. Concrete strategies for composition and reduction are detailed in sections Section 19.4 and Section 19.5.\nThe notation introduced in Chapter 4 is recapped for use in this chapter: the generative survival template for the survival setting is given by \\((X,T,\\Delta,Y,C) \\ t.v.i. \\ \\mathcal{X}\\times \\mathcal{T}\\times \\{0,1\\}\\times \\mathcal{T}\\times \\mathcal{T}\\) where \\(\\mathcal{X}\\subseteq \\mathbb{R}^p\\) and \\(\\mathcal{T}\\subseteq \\mathbb{R}_{\\geq 0}\\), where \\(C,Y\\) are unobservable, \\(T := \\min\\{Y,C\\}\\), and \\(\\Delta = \\mathbb{I}(Y = T)\\). Random survival data is given by \\((X_i,T_i,\\Delta_i,Y_i,C_i) \\stackrel{i.i.d.}\\sim(X,T,\\Delta,Y,C)\\). Usually data will instead be presented as a training dataset, \\(\\mathcal{D}_{train}= \\{(X_1,T_1,\\Delta_1),...,(X_n,T_n,\\Delta_n)\\}\\) where \\((X_i,T_i,\\Delta_i) \\stackrel{i.i.d.}\\sim(X,T,\\Delta)\\), and some test data \\(\\mathcal{D}_{test}= (X^*,T^*,\\Delta^*) \\sim (X,T,\\Delta)\\).\nFor regression models the generative template is given by \\((X,Y)\\) t.v.i. \\(\\mathcal{X}\\subseteq \\mathbb{R}^p\\) and \\(Y \\subseteq \\mathbb{R}\\). As with the survival setting, a regression training set is given by \\(\\{(X_1,Y_1),...,(X_n,Y_n)\\}\\) where \\((X_i,Y_i) \\stackrel{i.i.d.}\\sim(X,Y)\\) and some test data \\((X^*,Y^*) \\sim (X,Y)\\).",
    "crumbs": [
      "Reduction Techniques",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Reductions</span>"
    ]
  },
  {
    "objectID": "P4C19_reductions.html#sec-car-pipes",
    "href": "P4C19_reductions.html#sec-car-pipes",
    "title": "19  Reductions",
    "section": "19.1 Representing Pipelines",
    "text": "19.1 Representing Pipelines\nBefore introducing concrete composition and reduction algorithms, this section briefly demonstrates how these pipelines will be represented in this book.\nPipelines are represented by graphs designed in the following way: all are drawn with operations progressing sequentially from left to right; graphs are comprised of nodes (or ‘vertices’) and arrows (or ‘directed edges’); a rounded rectangular node represents a process such as a function or model fitting/predicting; a (regular) rectangular node represents objects such as data or hyper-parameters. Output from rounded nodes are sometimes explicitly drawn but when omitted the output from the node is the input to the next.\nThese features are demonstrated in ?fig-car-example. Say \\(y = 2\\) and \\(a = 2\\), then: data is provided (\\(y = 2\\)) and passed to the shift function (\\(f(x)=x + 2)\\), the output of this function (\\(y=4\\)) is passed directly to the next \\((h(x|a)=x^a)\\), this function requires a parameter which is also input (\\(a = 2\\)), finally the resulting output is returned (\\(y^*=16\\)). Programmatically, \\(a = 2\\) would be a hyper-parameter that is stored and passed to the required function when the function is called.\nThis pipeline is represented as a pseudo-algorithm in (alg-car-ex?), though of course is overly complicated and in practice one would just code \\((y+2)^\\wedge a\\).",
    "crumbs": [
      "Reduction Techniques",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Reductions</span>"
    ]
  },
  {
    "objectID": "P4C19_reductions.html#sec-car-comp",
    "href": "P4C19_reductions.html#sec-car-comp",
    "title": "19  Reductions",
    "section": "19.2 Introduction to Composition",
    "text": "19.2 Introduction to Composition\nThis section introduces composition, defines a taxonomy for describing compositors (Section 19.2.1), and provides some motivating examples of composition in survival analysis (Section 19.2.2).\nIn the simplest definition, a model (be it mathematical, computational, machine learning, etc.) is called a composite model if it is built of two or more constituent parts. This can be simplest defined in terms of objects. Just as objects in the real-world can be combined in some way, so can mathematical objects. The exact ‘combining’ process (or ‘compositor’) depends on the specific composition, so too do the inputs and outputs. By example, a wooden table can be thought of as a composite object (Figure 19.1). The inputs are wood and nails, the combining process is hammering (assuming the wood is pre-chopped), and the output is a surface for eating. In mathematics, this process is mirrored. Take the example of a shifted linear regression model. This is defined by a linear regression model, \\(f(x) = \\beta_0 + x\\beta_1\\), a shifting parameter, \\(\\alpha\\), and a compositor \\(g(x|\\alpha) = f(x) + \\alpha\\). Mathematically this example is overly trivial as this could be directly modelled with \\(f(x) = \\alpha + \\beta_0 + x\\beta_1\\), but algorithmically there is a difference. The composite model \\(g\\), is defined by first fitting the linear regression model, \\(f\\), and then applying a shift, \\(\\alpha\\); as opposed to fitting a directly shifted model.\n\n\n\n\n\n\nFigure 19.1: Visualising composition in the real-world. A table is a composite object built from nails and wood, which are combined with a hammer ‘compositor’. Figure not to scale.\n\n\n\n\nWhy Composition?\nTables tend to be better surfaces for eating your dinner than bundles of wood. Or in modelling terms, it is well-known that ensemble methods (e.g. random forests) will generally outperform their components (e.g. decision trees). All ensemble methods are composite models and this demonstrates one of the key use-cases of composition: improved predictive performance. The second key use-case is reduction, which is fully discussed in Section 19.3. Section 19.2.2 motivates composition in survival analysis by demonstrating how it is already prevalent but requires formalisation to make compositions more transparent and accessible.\n\n\nComposite Model vs. Sub-models\nA bundle of wood and nails is not a table and \\(1,000\\) decision trees are not a random forest, both require a compositor. The compositor in a composite model combines the components into a single model. Considering a composite model as a single model enables the hyper-parameters of the compositor and the component model(s) to be efficiently tuned whilst being evaluated as a single model. This further allows the composite to be compared to other models, including its own components, which is required to justify complexity instead of parsimony in model building (?sec-eval-why-why).\n\n\n19.2.1 Taxonomy of Compositors\nJust as there are an infinite number of ways to make a table, composition can come in infinite forms. However there are relatively few categories that these can be grouped into. Two primary taxonomies are identified here. The first is the ‘composition type’ and relates to the number of objects composed:\n[i)] i. Single-Object Composition (SOC) – This form of composition either makes use of parameters or a transformation to alter a single object. The shifted linear regression model above is one example of this, another is given in Section 19.4.3. i. Multi-Object Composition (MOC) – In contrast, this form of composition combines multiple objects into a single one. Both examples in Section 19.2.2 are multi-object compositions.\nThe second grouping is the ‘composition level’ and determines at what ‘level’ the composition takes place:\n[i)] i. Prediction Composition – This applies at the level of predictions; the component models could be forgotten at this point. Predictions may be combined from multiple models (MOC) or transformed from a single model (SOC). Both examples in Section 19.2.2 are prediction compositions. i. Task Composition – This occurs when one task (e.g. regression) is transformed to one or more others (e.g. classification), therefore always SOC. This is seen mainly in the context of reduction (Section 19.3). i. Model Composition – This is commonly seen in the context of wrappers (Section 19.5.1.4), in which one model is contained within another. i. Data Composition – This is transformation of training/testing data types, which occurs at the first stage of every pipeline.\n\n\n19.2.2 Motivation for Composition\nTwo examples are provided below to demonstrate common uses of composition in survival analysis and to motivate the compositions introduced in Section 19.4.\n\nExample 1: Cox Proportional Hazards\nCommon implementations of well-known models can themselves be viewed as composite models, the Cox PH is the most prominent example in survival analysis. Recall the model defined by\n\\[\nh(\\tau|X_i) = h_0(\\tau)\\exp(\\beta X_i)\n\\] where \\(h_0\\) is the baseline hazard and \\(\\beta\\) are the model coefficients.\nThis can be seen as a composite model as Cox defines the model in two stages (Cox 1972): first fitting the \\(\\beta\\)-coefficients using the partial likelihood and then by suggesting an estimate for the baseline distribution. This first stage produces a linear predictor return type (?sec-surv-set-types) and the second stage returns a survival distribution prediction. Therefore the Cox model for linear predictions is a single (non-composite) model, however when used to make distribution predictions then it is a composite. Cox implicitly describes the model as a composite by writing ‘’alternative simpler procedures would be worth having’’ (Cox 1972), which implies a decision in fitting (a key feature of composition). This composition is formalised in Section 19.4.1 as a general pipelins. The Cox model utilises the pipeline with a PH form and Kaplan-Meier baseline.\n\n\nExample 2: Random Survival Forests\nFully discussed in Chapter 14, random survival forests are composed from many individual decision trees via a prediction composition algorithm ((alg-rsf-pred?)). In general, random forests perform better than their component decision trees, which tends to be true of all ensemble methods. Aggregation of predictions in survival analysis requires slightly more care than other fields due to the multiple prediction types, however this is still possible and is formalised in Section 19.4.4.",
    "crumbs": [
      "Reduction Techniques",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Reductions</span>"
    ]
  },
  {
    "objectID": "P4C19_reductions.html#sec-car-redux",
    "href": "P4C19_reductions.html#sec-car-redux",
    "title": "19  Reductions",
    "section": "19.3 Introduction to Reduction",
    "text": "19.3 Introduction to Reduction\nThis section introduces reduction, motivates its use in survival analysis (Section 19.3.1), details an abstract reduction pipeline and defines the difference between a complete/incomplete reduction (Section 19.3.2), and outlines some common mistakes that have been observed in the literature when applying reduction (Section 19.3.3).\nReduction is a concept found across disciplines with varying definitions. This report uses the Langford definition: reduction is ‘’a complex problem decomposed into simpler subproblems so that a solution to the subproblems gives a solution to the complex problem’’ (Langford et al. 2016). Generalisation (or induction) is a common real-world use of reduction, for example sampling a subset of a population in order to estimate population-level results. The true answer (population-level values) may not always be found in this way but very good approximations can be made with simpler sub-problems (sub-sampling).\nReductions are workflows that utilise composition. By including hyper-parameters, even complex reduction strategies can remain relatively flexible. To illustrate reduction by example, recall the table-building example (Section 19.2) in which the task of interest is to acquire a table. The most direct but complex solution is to fell a tree and directly saw it into a table (Figure 19.2, top), clearly this is not a sensible process. Instead the problem can be reduced into simpler sub-problems: saw the tree into bundles of wood, acquire nails, and then use the ‘hammer compositor’ (Figure 19.1) to create a table (Figure 19.2, bottom).\n\n\n\n\n\n\nFigure 19.2: Visualising reduction in the real-world. The complex process (top) of directly sawing a tree into a table is inefficient and unnecessarily complex. The reduction (bottom) that involves first creating bundles of wood is simpler, more efficient, and yields the same result, though technically requiring more steps.\n\n\n\nIn a modelling example, predicting a survival distribution with the Cox model can be viewed as a reduction in which two sub-problems are solved and composed:\n\npredict continuous ranking;\nestimate baseline hazard; and\ncompose with (Section 19.4.1).\n\nThis is visualised as a reduction strategy in ?fig-car-cargraph. The entire process from defining the original problem, to combining the simpler sub-solutions (in green), is the reduction (in red).\n\n\n19.3.1 Reduction Motivation\nFormalisation of reduction positively impacts upon accessibility, transparency, and predictive performance. Improvements to predictive performance have already been demonstrated when comparing random forests to decision trees. In addition, a reduction with multiple stages and many hyper-parameters allows for fine tuning for improved transparency and model performance (usual overfitting caveat applies, as does the trade-off described in ?sec-car-pipelines-trade).\nThe survey of ANNs (Section 17.1) demonstrated how reduction is currently utilised without transparency. Many of these ANNs are implicitly reductions to probabilistic classification (Section 19.5.1.6) however none include details about how the reduction is performed. Furthermore in implementation, none provide interface points to the reduction hyper-parameters. Formalisation encourages consistent terminology, methodology and transparent implementation, which can only improve model performance by exposing further hyper-parameters.\nAccessibility is improved by formalising specific reduction workflows that previously demanded expert knowledge in deriving, building, and running these pipelines.\nFinally there is an economic and efficiency advantage to reduction. A reduction model is relatively ‘cheap’ to explore as they utilise pre-established models and components to solve a new problem. Therefore if a certain degree of predictive ability can be demonstrated from reduction models, it may not be worth the expense of pursuing more novel ideas and hence reduction can help direct future research.\n\n\n19.3.2 Task, Loss, and Data Reduction\nReduction can be categorised into task, loss, and data reduction, often these must be used in conjunction with each other. The direction of the reductions may be one- or two-way; this is visualised in ?fig-car-reduxdiag. This diagram should not be viewed as a strict fit/predict/evaluation workflow but instead as a guidance for which tasks, \\(T\\), data, \\(D\\), models, \\(M\\), and losses, \\(L\\), are required for each other. The subscript \\(O\\) refers to the original object ‘level’ before reduction, whereas the subscript \\(R\\) is in reference to the reduced object.\n\nThe individual task, model, and data compositions in the diagram are listed below, the reduction from survival to classification (Section 19.5.1) is utilised as a running example to help exposition.\n\n\\(T_O \\rightarrow T_R\\): By definition of a machine learning reduction, task reduction will always be one way. A more complex task, \\(T_O\\), is reduced to a simpler one, \\(T_R\\), for solving. \\(T_R\\) could also be multiple simpler tasks. For example, solving a survival task, \\(T_O\\), by classification, \\(T_R\\) (Section 19.5.1).\n\\(T_R \\rightarrow M_R\\): All machine learning tasks have models that are designed to solve them. For example logistic regression, \\(M_R\\), for classification tasks, \\(T_R\\).\n\\(M_R \\rightarrow M_O\\): The simpler models, \\(M_R\\), are used for the express purpose to solve the original task, \\(T_O\\), via solving the simpler ones. To solve \\(T_O\\), a compositor must be applied, which may transform one (SOC) or multiple models (MOC) at a model- or prediction-level, thus creating \\(M_O\\). For example predicting survival probabilities with logistic regression, \\(M_R\\), at times \\(1,...,\\tau^*\\) for some \\(\\tau^* \\in \\mathbb{N}_{&gt; 0}\\) (Section 19.5.1.4).\n\\(M_O \\rightarrow T_O\\): The original task should be solvable by the composite model. For example predicting a discrete survival distribution by concatenating probabilistic predictions at the times \\(1,...,\\tau^*\\) (Section 19.5.1.6).\n\\(D_O \\rightarrow D_R\\): Just as the tasks and models are reduced, the data required to fit these must likewise be reduced. Similarly to task reduction, data reduction can usually only take place in one direction, to see why this is the case take an example of data reduction by summaries. If presented with 10 data-points \\(\\{1,1,1,5,7,3,5,4,3,3\\}\\) then these could be reduced to a single point by calculating the sample mean, \\(3.3\\). Clearly given only the number \\(3.3\\) there is no strategy to recover the original data. There are very few (if any) data reduction strategies that allow recovery of the original data. Continuing the running example, survival data, \\(D_O\\), can be binned (Section 19.5.1.1) to classification data, \\(D_R\\).\n\nThere is no arrow between \\(D_O\\) and \\(M_O\\) as the composite model is never fit directly, only via composition from \\(M_R \\rightarrow M_O\\). However, the original data, \\(D_O\\), is required when evaluating the composite model against the respective loss, \\(L_O\\). Reduction should be directly comparable to non-reduction models, hence this diagram does not include loss reduction and instead insists that all models are compared against the same loss \\(L_O\\).\nA reduction is said to be complete if there is a full pipeline from \\(T_O \\rightarrow M_O\\) and the original task is solved, otherwise it is incomplete. The simplest complete reduction is comprised of the pipeline \\(T_O \\rightarrow T_R \\rightarrow M_R \\rightarrow M_O\\). Usually this is not sufficient on its own as the reduced models are fit on the reduced data, \\(D_R \\rightarrow M_R\\).\nA complete reduction can be specified by detailing:\n\nthe original task and the sub-task(s) to be solved, \\(T_O \\rightarrow T_R\\);\nthe original dataset and the transformation to the reduced one, \\(D_O \\rightarrow D_R\\) (if required); and\nthe composition from the simpler model to the complex one, \\(M_R \\rightarrow M_O\\).\n\n\n\n19.3.3 Common Mistakes in Implementation of Reduction\nIn surveying models and measures, several common mistakes in the implementation of reduction and composition were found to be particularly prevalent and problematic throughout the literature. It is assumed that these are indeed mistakes (not deliberate) and result from a lack of prior formalisation. These mistakes were even identified 20 years ago (Schwarzer, Vach, and Schumacher 2000) but are provided in more detail in order to highlight their current prevalence and why they cannot be ignored.\nRM1. Incomplete reduction. This occurs when a reduction workflow is presented as if it solves the original task but fails to do so and only the reduction strategy is solved. A common example is claiming to solve the survival task by using binary classification, e.g. erroneously claiming that a model predicts survival probabilities (which implies distribution) when it actually predicts a five year probability of death ((box-task-classif?)). This is a mistake as it misleads readers into believing that the model solves a survival task ((box-task-surv?)) when it does not. This is usually a semantic not mathematical error and results from misuse of terminology. It is important to be clear about model predict types (?sec-surv-set-types) and general terms such as ‘survival predictions’ should be avoided unless they refer to one of the three prediction tasks. RM2. Inappropriate comparisons. This is a direct consequence of (RM1) and the two are often seen together. (RM2) occurs when an incomplete reduction is directly compared to a survival model (or complete reduction model) using a measure appropriate for the reduction. This may lead to a reduction model appearing erroneously superior. For example, comparing a logistic regression to a random survival forest (RSF) (Chapter 14) for predicting survival probabilities at a single time using the accuracy measure is an unfair comparison as the RSF is optimised for distribution predictions. This would be non-problematic if a suitable composition is clearly utilised. For example a regression SSVM predicting survival time cannot be directly compared to a Cox PH. However the SSVM can be compared to a CPH composed with the probabilistic to deterministic compositor, then conclusions can be drawn about comparison to the composite survival time Cox model (and not simply a Cox PH). RM3. Na\"ive censoring deletion. This common mistake occurs when trying to reduce survival to regression or classification by simply deleting all censored observations, even if censoring is informative. This is a mistake as it creates bias in the dataset, which can be substantial if the proportion of censoring is high and informative. More robust deletion methods are described in Chapter 23. RM4. Oversampling uncensored observations. This is often seen when trying to reduce survival to regression or classification, and often alongside (RM3). Oversampling is the process of replicating observations to artificially inflate the sample size of the data. Whilst this process does not create any new information, it can help a model detect important features in the data. However, by only oversampling uncensored observations, this creates a source of bias in the data and ignores the potentially informative information provided by the proportion of censoring.",
    "crumbs": [
      "Reduction Techniques",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Reductions</span>"
    ]
  },
  {
    "objectID": "P4C19_reductions.html#sec-car-pipelines",
    "href": "P4C19_reductions.html#sec-car-pipelines",
    "title": "19  Reductions",
    "section": "19.4 Composition Strategies for Survival Analysis",
    "text": "19.4 Composition Strategies for Survival Analysis\nThough composition is common practice in survival analysis, with the Cox model being a prominent example, a lack of formalisation means a lack of consensus in simple operations. For example, it is often asked in survival analysis how a model predicting a survival distribution can be used to return a survival time prediction. A common strategy is to define the survival time prediction as the median of the predicted survival curve however there is no clear reason why this should be more sensible than returning the distribution mean, mode, or some random quantile. Formalisation allow these choices to be analytically compared both theoretically and practically as hyper-parameters in a workflow. Four prediction compositions are discussed in this section ((tab-car-taxredcar?)), three are utilised to convert prediction types between one another, the fourth is for aggregating multiple predictions. One data composition is discussed for converting survival to regression data. Each is first graphically represented and then the components are discussed in detail. As with losses in the previous chapter, compositions are discussed at an individual observation level but extend trivially to multiple observations.\n\nCompositions formalised in Section 19.4.\n\n\nID\\(^1\\)\nComposition\nType\\(^2\\)\nLevel\\(^3\\)\n\n\n\n\nC1)\nLinear predictor to distribution\nMOC\nPrediction\n\n\nC2)\nSurvival time to distribution\nMOC\nPrediction\n\n\nC3)\nDistribution to survival time\nSOC\nPrediction\n\n\nC4)\nSurvival model averaging\nMOC\nPrediction\n\n\nC5)\nSurvival to regression\nSOC\nData\n\n\n\n 1. ID for reference throughout this book. 2. Composition type. Multi-object composition (MOC) or single-object composition (SOC). 3. Composition level. \n\n19.4.1 C1) Linear Predictor \\(\\rightarrow\\) Distribution\n\nThis is a prediction-level MOC that composes a survival distribution from a predicted linear predictor and estimated baseline survival distribution. The composition (?fig-car-comp-distr) requires:\n\n\\(\\hat{\\eta}\\): Predicted linear predictor. \\(\\hat{\\eta}\\) can be tuned by including this composition multiple times in a benchmark experiment with different models predicting \\(\\hat{\\eta}\\). In theory any continuous ranking could be utilised instead of a linear predictor though results may be less sensible (?sec-car-pipelines-trade).\n\\(\\hat{S}_0\\): Estimated baseline survival function. This is usually estimated by the Kaplan-Meier estimator fit on training data, \\(\\hat{S}_{KM}\\). However any model that can predict a survival distribution can estimate the baseline distribution (caveat: see ?sec-car-pipelines-trade) by taking a uniform mixture of the predicted individual distributions: say \\(\\xi_1,...,\\xi_m\\) are m predicted distributions, then \\(\\hat{S}_0(\\tau) = \\frac{1}{m} \\sum^{m}_{i = 1} \\xi_i.S(\\tau)\\). The mixture is required as the baseline must be the same for all observations. Alternatively, parametric distributions can be assumed for the baseline, e.g. \\(\\xi = \\operatorname{Exp}(2)\\) and \\(\\xi.S(t) = \\exp(-2t)\\). As with \\(\\hat{\\eta}\\), this parameter is also tunable.\n\\(M\\): Chosen model form, which theoretically can be any non-increasing right-continuous function but is usually one of:\nProportional Hazards (PH): \\(S_{PH}(\\tau|\\eta, S_0) = S_0(\\tau)^{\\exp(\\eta)}\\)\nAccelerated Failure Time (AFT): \\(S_{AFT}(\\tau|\\eta, S_0) = S_0(\\frac{\\tau}{\\exp(\\eta)})\\)\nProportional Odds (PO): \\(S_{PO}(\\tau|\\eta, S_0) = \\frac{S_0(\\tau)}{\\exp(-\\eta) + (1-\\exp(-\\eta)) S_0(\\tau)}\\)\n\nModels that predict linear predictors will make assumptions about the model form and therefore dictate sensible choices of \\(M\\), for example the Cox model assumes a PH form. This does not mean other choices of \\(M\\) cannot be specified but that interpretation may be more difficult (?sec-car-pipelines-trade). The model form can be treated as a hyper-parameter to tune. * \\(C\\): Compositor returning the composed distribution, \\(\\zeta := C(M, \\hat{\\eta}, \\hat{S}_0)\\) where \\(\\zeta\\) has survival function \\(\\zeta.S(\\tau) = M(\\tau|\\hat{\\eta}, \\hat{S}_0)\\).\nPseudo-code for training ((alg-car-comp-distr-fit?)) and predicting ((alg-car-comp-distr-pred?)) this composition as a model ‘wrapper’ with sensible parameter choices (?sec-car-pipelines-trade) is provided in appendix (app-car?).\n\n\n19.4.2 C2) Survival Time \\(\\rightarrow\\) Distribution\n\nThis is a prediction-level MOC that composes a distribution from a predicted survival time and assumed location-scale distribution. The composition (?fig-car-comp-response) requires:\n\n\\(\\hat{T}\\): A predicted survival time. As with the previous composition, this is tunable. In theory any continuous ranking could replace \\(\\hat{T}\\), though the resulting distribution may not be sensible (?sec-car-pipelines-trade).\n\\(\\xi\\): A specified location-scale distribution, \\(\\xi(\\mu, \\sigma)\\), e.g. Normal distribution.\n\\(\\hat{\\sigma}\\): Estimated scale parameter for the distribution. This can be treated as a hyper-parameter or predicted by another model.\n\\(C\\): Compositor returning the composed distribution \\(\\zeta := C(\\xi, \\hat{T}, \\hat{\\sigma}) = \\xi(\\hat{T}, \\hat{\\sigma})\\).\n\nPseudo-code for training ((alg-car-comp-response-fit?)) and predicting ((alg-car-comp-response-pred?)) this composition as a model ‘wrapper’ with sensible parameter choices (?sec-car-pipelines-trade) is provided in appendix (app-car?).\n\n\n19.4.3 C3) Distribution \\(\\rightarrow\\) Survival Time Composition\n\nThis is a prediction-level SOC that composes a survival time from a predicted distribution. Any paper that evaluates a distribution on concordance is implicitly using this composition in some manner. Not acknowledging the composition leads to unfair model comparison (Section 19.3.3). The composition (?fig-car-comp-crank) requires:\n\n\\(\\zeta\\): A predicted survival distribution, which again is ‘tunable’.\n\\(\\phi\\): A distribution summary method. Common examples include the mean, median and mode. Other alternatives include distribution quantiles, \\(\\zeta.F^{-1}(\\alpha)\\),\\\\(\\alpha \\in [0,1]\\); \\(\\alpha\\) could be tuned as a hyper-parameter.\n\\(C\\): Compositor returning composed survival time predictions, \\(\\hat{T}:= C(\\phi, \\zeta) = \\phi(\\zeta)\\).\n\nPseudo-code for training ((alg-car-comp-crank-fit?)) and predicting ((alg-car-comp-crank-pred?)) this composition as a model ‘wrapper’ with sensible parameter choices (?sec-car-pipelines-trade) is provided in appendix (app-car?).\n\n\n19.4.4 C4) Survival Model Averaging\n\nEnsembling is likely the most common composition in machine learning. In survival it is complicated slightly as multiple prediction types means one of two possible compositions is utilised to average predictions. The (?fig-car-comp-avg) composition requires:\n\n\\(\\rho = \\rho_1,...,\\rho_B\\): \\(B\\) predictions (not necessarily from the same model) of the same type: ranking, survival time or distribution; again ‘tunable’.\n\\(w = w_1,...,w_B\\): Weights that sum to one.\n\\(C\\): Compositor returning combined predictions, \\(\\hat{\\rho} := C(\\rho, w)\\) where \\(C(\\rho, w) = \\frac{1}{B} \\sum^{B}_{i = 1} w_i \\rho_i\\), if \\(\\rho\\) are ranking of survival time predictions; or \\(C(\\rho, w) = \\zeta\\) where \\(\\zeta\\) is the distribution defined by the survival function \\(\\zeta.S(\\tau) = \\frac{1}{B} \\sum^{B}_{i = 1} w_i \\rho_i.S(\\tau)\\), if \\(\\rho\\) are distribution predictions.\n\nPseudo-code for training ((alg-car-comp-avg-fit?)) and predicting ((alg-car-comp-avg-pred?)) this composition as a model ‘wrapper’ with sensible parameter choices (?sec-car-pipelines-trade) is provided in appendix (app-car?).",
    "crumbs": [
      "Reduction Techniques",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Reductions</span>"
    ]
  },
  {
    "objectID": "P4C19_reductions.html#sec-car-reduxes",
    "href": "P4C19_reductions.html#sec-car-reduxes",
    "title": "19  Reductions",
    "section": "19.5 Novel Survival Reductions",
    "text": "19.5 Novel Survival Reductions\nThis section collects the various strategies and settings discussed previously into complete reduction workflows. (tab-car-reduxes?) lists the reductions discussed in this section with IDs for future reference. All strategies are described by visualising a graphical pipeline and then listing the composition steps required in fitting and predicting.\nThis section only includes novel reduction strategies and does not provide a survey of pre-existing strategies. This limitation is primarily due to time (and page) constraints as every method has very distinct workflows that require complex exposition. Well-established strategies are briefly mentioned below and future research is planned to survey and compare all strategies with respect to empirical performance (i.e. in benchmark experiments).\nTwo prominent reductions are ‘landmarking’ (Van Houwelingen 2007) and piecewise exponential models (Friedman 1982). Both are reductions for time-varying covariates and hence outside the scope of this book. Relevant to this book scope is a large class of strategies that utilise ‘discrete time survival analysis’ (Tutz and Schmid 2016); these strategies include reductions (R7) and (R8). Methodology for discrete time survival analysis has been seen in the literature for the past three decades (Liestol, Andersen, and Andersen 1994). The primary reduction strategy for discrete time survival analysis is implemented in the \\(\\textsf{R}\\) package discSurv. (Welchowski and Schmid 2019); this is very similar to (R7) except that it enforces stricter constraints in the composition procedures and forces a ‘discrete-hazard’ instead of ‘discrete-survival’ representation (Section 19.5.1.2).\n\n19.5.1 R7-R8) Survival \\(\\rightarrow\\) Probabilistic Classification\n\nTwo separate reductions are presented in ?fig-car-R7R8 however as both are reductions to probabilistic classification and are only different in the very last step, both are presented in this section. Steps and compositions of the reduction (?fig-car-R7R8):\nFit F1) A survival dataset, \\(\\mathcal{D}_{train}\\), is binned, \\(B\\), with a continuous to discrete data composition (Section 19.5.1.1). F2) A multi-label classification model, with adaptations for censoring, \\(g_L(D_B|\\theta)\\), is fit on the transformed dataset, \\(D_B\\). Optionally, \\(g_L\\) could be further reduced to binary, \\(g_B\\), or multi-class classification, \\(g_c\\), (Section 19.5.1.4). Predict P1) Testing survival data, \\(\\mathcal{D}_{test}\\), is passed to the trained classification model, \\(\\hat{g}\\), to predict pseudo-survival probabilities \\(\\tilde{S}\\) (or optionally hazards (Section 19.5.1.2)). P2a) Predictions can be composed, \\(T_1\\), into a survival distribution prediction, \\(\\zeta = \\zeta_1,...,\\zeta_m\\) (Section 19.5.1.6); or, P2b) Predictions can be composed, \\(T_2\\), to survival time predictions, \\(\\hat{T}= \\hat{T}_1,...,\\hat{T}_m\\) (Section 19.5.1.7).\nFurther details for binning, multi-label classification, and transformation of pseudo-survival probabilities are now provided.\n\n19.5.1.1 Composition: Binning Survival Times\nAn essential part of the reduction is the transformation from a survival dataset to a classification dataset, which requires two separate compositions. The first (discussed here) is to discretise the survival times (\\(B(\\mathcal{D}_{train}|w)\\) in ?fig-car-R7R8) and the second is to merge the survival time and censoring indicator into a single outcome (Section 19.5.1.2).\nDiscretising survival times is achieved by the common ‘binning’ composition, in which a continuous outcome is discretised into ‘bins’ according to specified thresholds. These thresholds are usually determined by specifying the width of the bins as a hyper-parameter \\(w\\). This is a common transformation and therefore further discussion is not provided here. An example is given below with the original survival data on the left and the binned data on the right (\\(w = 1\\)).\n\n\n\nX\nTime (Cont.)\nDied\n\n\n\n\n1\n1.56\n0\n\n\n2\n2\n1\n\n\n3\n3.3\n1\n\n\n4\n3.6\n0\n\n\n5\n4\n0\n\n\n\n\n\n\nX\nTime (Disc.)\nDied\n\n\n\n\n1\n[1, 2)\n0\n\n\n2\n[2, 3)\n1\n\n\n3\n[3, 4)\n1\n\n\n4\n[3, 4)\n0\n\n\n5\n[4, 5)\n0\n\n\n\n\n\n19.5.1.2 Composition: Survival to Classification Outcome\nThe binned dataset still has the unique survival data format of utilising two outcomes for training (time and status) but only making a prediction for one outcome (distribution). In order for this to be compatible with classification, the two outcome variables are composed into a single variable. This is achieved by casting the survival times into a ‘wide’ format and creating a new outcome indicator. Two outcome transformations are possible, the first represents a discrete survival function and the second represents a discrete hazard function.\n\n\nDiscrete Survival Function Composition\nIn this composition, the data in the transformed dataset represents the discrete survival function. The new indicator is defined as follows, \\[\nY_{i;\\tau} :=\n\\begin{cases}\n1, & T_i &gt; \\tau \\\\\n0, & T_i \\leq \\tau \\cap \\Delta_i = 1 \\\\\n-1, & T_i \\leq \\tau \\cap \\Delta_i = 0\n\\end{cases}\n\\] At a given discrete time \\(\\tau\\), an observation, \\(i\\), is either alive (\\(Y_{i;\\tau} = 1\\)), dead (\\(Y_{i;\\tau} = 0\\)), or censored (\\(Y_{i;\\tau} = -1\\)). Therefore \\(\\hat{P}(Y_{i;\\tau} = 1) = \\hat{S}_i(\\tau)\\), motivating this particular choice of representation.\nThis composition is demonstrated below with the binned data (left) and the composed classification data (right).\n\n\n\nX\nTime (Disc.)\nDied\n\n\n\n\n1\n[1, 2)\n0\n\n\n2\n[2, 3)\n1\n\n\n3\n[3, 4)\n1\n\n\n4\n[3, 4)\n0\n\n\n5\n[4, 5)\n0\n\n\n\n\n\n\nX\n[1,2)\n[2,3)\n[3,4)\n[4,5)\n\n\n\n\n1\n-1\n-1\n-1\n-1\n\n\n2\n1\n0\n0\n0\n\n\n3\n1\n1\n0\n0\n\n\n4\n1\n1\n-1\n-1\n\n\n5\n1\n1\n-1\n-1\n\n\n\n\n\nDiscrete Hazard Function Composition\nIn this composition, the data in the transformed dataset represents the discrete hazard function. The new indicator is defined as follows, \\[\nY^*_{i;\\tau} :=\n\\begin{cases}\n1, & T_i = \\tau \\cap \\Delta_i = 1 \\\\\n-1, & T_i = \\tau \\cap \\Delta_i = 0 \\\\\n0, & \\text{otherwise}\n\\end{cases}\n\\] At a given discrete time \\(\\tau\\), an observation, \\(i\\), either experiences the event (\\(Y^*_{i;\\tau} = 1\\)), experiences censoring (\\(Y_{i;\\tau} = -1\\)), or neither (\\(Y_{i;\\tau} = 0\\)). Utilising sequential multi-label classification problem transformation methods (Section 19.5.1.4) results in \\(\\hat{P}(Y^*_{i;\\tau} = 1) = \\hat{h}_i(\\tau)\\). If methods are utilised that do not ‘look back’ at predictions then \\(\\hat{P}(Y^*_{i;\\tau} = 1) = \\hat{p}_i(\\tau)\\) (Section 19.5.1.4).\nThis composition is demonstrated below with the binned data (left) and the composed classification data (right).\n\n\n\nX\nTime (Disc.)\nDied\n\n\n\n\n1\n[1, 2)\n0\n\n\n2\n[2, 3)\n1\n\n\n3\n[3, 4)\n1\n\n\n4\n[3, 4)\n0\n\n\n5\n[4, 5)\n0\n\n\n\n\n\n\nX\n[1,2)\n[2,3)\n[3,4)\n[4,5)\n\n\n\n\n1\n-1\n0\n0\n0\n\n\n2\n0\n1\n0\n0\n\n\n3\n0\n0\n1\n0\n\n\n4\n0\n0\n-1\n0\n\n\n5\n0\n0\n0\n-1\n\n\n\n\n\nMulti-Label Classification Data\nIn both compositions, survival data t.v.i. \\(\\mathbb{R}^p \\times \\mathbb{R}_{\\geq 0}\\times \\{0,1\\}\\) is transformed to multi-label classification data t.v.i. \\(\\mathbb{R}^p \\times \\{-1,0,1\\}^K\\) for \\(K\\) binned time-intervals. The multi-label classification task is defined in Section 19.5.1.4 with possible algorithms.\nThe discrete survival representation has a slightly more natural interpretation and is ‘easier’ for classifiers to use for training as there are more positive events (i.e. more observations alive) to train on, whereas the discrete hazard representation will have relatively few events in each time-point. However the hazard representation leads to more natural predictions (Section 19.5.1.6).\nA particular bias that may easily result from the composition of survival to classification data is now discussed.\n\n\n19.5.1.3 Reduction to Classification Bias\nThe reduction to classification bias is commonly known (Zhou et al. 2005) but is reiterated briefly here as it must be accounted for in any automated reduction to classification workflow. This bias occurs when making classification predictions about survival at a given time and incorrectly censoring patients who have not been observed long enough, instead of removing them.\nBy example, say the prediction of interest is five-year survival probabilities after a particular diagnosis, clearly a patient who has only been diagnosed for three years cannot inform this prediction. The bias is introduced if this patient is censored at five-years instead of being removed from the dataset. The result of this bias is to artificially inflate the probability of survival at each time-point as an unknown outcome is treated as censored and therefore alive.\nThis bias is simply dealt with by removing patients who have not been alive ‘long enough’. Paradoxically, even if a patient is observed to die before the time-point of interest, they should still be removed if they have not been in the dataset ‘long enough’ as failing to do so will result in a bias in the opposite direction, thus over-inflating the proportion of dead observations.\nAccounting for this bias is particularly important in the multi-label reduction as the number of observable patients will decrease over time due to censoring.\n\n\n19.5.1.4 Multi-Label Classification Algorithms\nAs the work in this section is completely out of the book scope, the full text is in appendix (app-mlc?). The most important contributions from this section are:\n\nReviewing problem transformation methods (Tsoumakas and Katakis 2007) for multi-label classification;\nIdentifying that only binary relevance, nested stacking, and classifier chains are appropriate in this reduction; and\nGeneralising these methods into a single wrapper for any binary classifier, the ‘LWrapper’.\n\n\n\n19.5.1.5 Censoring in Classification\nClassification algorithms cannot natively handle the censoring that is included in the survival reduction, but this can be incorporated using one of two approaches.\n\n\nMulti-Class Classification\nAll multi-label datasets can also handle multi-class data, hence the simplest way in which to handle censoring is to make multi-class predictions in each label for the outcome \\(Y_\\tau \\ t.v.i. \\{-1, 0, 1\\}\\). Many off-shelf classification learners can make multi-class predictions natively and simple reductions exist for those that cannot. As a disadvantage to this method, classifiers would then predict if an individual is dead or alive or censored (each mutually exclusive), and not simply alive or dead. Though this could be perceived as an advantage when censoring is informative as this will accurately reflect a real-world competing-risks set-up.\n\n\nSubsetting/Hurdle Models\nFor this approach, the multi-class task is reduced to two binary class tasks: first predict if a subject is censored or not (dead or alive) and only if the prediction for censoring is below some threshold, \\(\\alpha \\in [0, 1]\\), then predict if the subject is alive or not (dead or censored). If the probability of censoring is high in the first task then the probability of being alive is automatically set to zero in the final prediction, otherwise the prediction from the second task is used. Any classifier can utilise this approach and it has a meaningful interpretation, additionally \\(\\alpha\\) is a tunable hyper-parameter. The main disadvantage is increases to storage and run-time requirements as double the number of models may be fit.\nOnce the datasets have been composed to classification datasets and censoring is suitably incorporated by either approach, then any probabilistic classification model can be fit on the data. Predictions from these models can either be composed to a distribution prediction (R7) or a survival time prediction (R8).\n\n\n19.5.1.6 R7) Probabilistic Survival \\(\\rightarrow\\) Probabilistic Classification\n\nThis final part of the (R7) reduction is described separately for discrete hazard and survival representations of the data (Section 19.5.1.2).\n\n\nDiscrete Hazard Representation\nIn this representation recall that predictions of the positive class, \\(P(Y_\\tau = 1)\\), are estimating the quantity \\(h(\\tau)\\). These predictions provide a natural and efficient transformation from predicted hazards to survival probabilities. Let \\(\\hat{h}_i\\) be a predicted hazard function for some observation \\(i\\), then the survival function for that observation can be found with a Kaplan-Meier type estimator, \\[\n\\tilde{S}_i(\\tau^*) = \\prod_\\tau 1 - \\hat{h}_i(\\tau)\n\\] Now predictions are for a pseudo-survival function, which is ‘pseudo’ as it is not right-continuous. Resolving this is discussed below.\n\n\nDiscrete Survival Representation\nIn this representation, \\(P(Y_\\tau = 1)\\) is estimating \\(S(\\tau)\\), which means that predictions from a classification model result in discrete point predictions and not a right-continuous function. More importantly, there is no guarantee that a non-increasing function will be predicted, i.e. there is no guarantee that \\(P(Y_j = 1) &lt; P(Y_i = 1)\\), for time-points \\(j &gt; i\\).\nUnfortunately there is no optimal way of dealing with predictions of this sort and ‘mistakes’ of this kind have been observed in some software implementation. One point to note is that in practice these are quite rare as the probability of survival will always decrease over time. Therefore the ‘usual’ approach is quite ‘hacky’ and involves imputing increasing predictions with the previous prediction, formally, \\[\n\\tilde{S}({i+1}) := \\min\\{P(Y_{i+1} = 1), P(Y_i = 1)\\}, \\forall i = \\mathbb{R}_{\\geq 0}\n\\] assuming \\(\\tilde{S}(0) = 1\\). Future research should seek more robust alternatives.\n\n\nRight-Continuous Survival Function\nFrom either representation, a \\ non-increasing but non-continuous pseudo-survival function, \\(\\tilde{S}\\), is now predicted. Creating a right-continuous function (‘\\(T_1(\\tilde{S})\\)’ in ?fig-car-R7) from these point predictions (Figure 19.3 (a)) is relatively simple and well-known with accessible off-shelf software. At the very least, one can assume a constant hazard rate between predictions and cast them into a step function (Figure 19.3 (b)). This is a fairly common assumption and is usually valid as bin-width decreases. Alternatively, the point predictions can be smoothed into a continuous function with off-shelf software, for example with polynomial local regression smoothing (Figure 19.3 (c)) or generalised linear smoothing (Figure 19.3 (d)). Whichever method is chosen, the survival function is now non-increasing right-continuous and the (R7) reduction is complete.\n\n\n\n\n\n\n\n\n\n\n\n(a) Point Predictions\n\n\n\n\n\n\n\n\n\n\n\n(b) Survival Step Function\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Local polynomial regression smoothing\n\n\n\n\n\n\n\n\n\n\n\n(d) Generalised linear smoothing\n\n\n\n\n\n\n\nFigure 19.3: Survival function as a: point prediction (a), step function assuming constant risk (b), local polynomial regression smoothing (c), and generalised linear smoothing (d). (c) and (d) computed with ggplot2 (Wickham 2016).\n\n\n\n\n\n19.5.1.7 R8) Deterministic Survival \\(\\rightarrow\\) Probabilistic Classification\n\nPredicting a deterministic survival time from the multi-label classification predictions is relatively straightforward and can be viewed as a discrete analogue to (C3) (Section 19.4.3). For the discrete hazard representation, one can simply take the predicted time-point for an individual to be time at which the predicted hazard probability is highest however this could easily be problematic as there may be multiple time-points at which the predicted hazard equals \\(1\\). Instead it is cleaner to first cast the hazard to a pseudo-survival probability (Section 19.5.1.6) and then treat both representations the same.\nLet \\(\\tilde{S}_i\\) be the predicted multi-label survival probabilities for an observation \\(i\\) such that \\(\\tilde{S}_i(\\tau)\\) corresponds with \\(\\hat{P}(Y_{i;\\tau} = 1)\\) for label \\(\\tau \\in \\mathcal{K}\\) where \\(Y_{i;\\tau}\\) is defined in Section 19.5.1.2 and \\(\\mathcal{K} = \\{1,...,K\\}\\) is the set of labels for which to make predictions. Then the survival time transformation is defined by \\[\nT_2(\\tilde{S}_i) = \\inf \\{\\tau \\in \\mathcal{K} : \\tilde{S}_i(\\tau) \\leq \\beta\\}\n\\] for some \\(\\beta \\in [0, 1]\\).\nThis is interpreted as defining the predicted survival time as the first time-point in which the predicted probability of being alive drops below a certain threshold \\(\\beta\\). Usually \\(\\beta = 0.5\\), though this can be treated as a hyper-parameter for tuning. This composition can be utilised even if predictions are not non-increasing, as only the first time the predicted survival probability drops below the threshold is considered. With this composition the (R8) reduction is now complete.",
    "crumbs": [
      "Reduction Techniques",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Reductions</span>"
    ]
  },
  {
    "objectID": "P4C19_reductions.html#sec-car-conc",
    "href": "P4C19_reductions.html#sec-car-conc",
    "title": "19  Reductions",
    "section": "19.6 Conclusions",
    "text": "19.6 Conclusions\nThis chapter introduced composition and reduction to survival analysis and formalised specific strategies. Formalising these concepts allows for better quality of research and most importantly improved transparency. Clear interface points for hyper-parameters and compositions allow for reproducibility that was previously obfuscated by unclear workflows and imprecise documentation for pipelines.\nAdditionally, composition and reduction improves accessibility. Reduction workflows vastly increase the number of machine learning models that can be utilised in survival analysis, thus opening the field to those whose experience is limited to regression or classification. Formalisation of workflows allows for precise implementation of model-agnostic pipelines as computational objects, as opposed to functions that are built directly into an algorithm without external interface points.\nFinally, predictive performance is also increased by these methods, which is most prominently the case for the survival model averaging compositor (as demonstrated by RSFs).\n\n\n\n\nCox, D. R. 1972. “Regression Models and Life-Tables.” Journal of the Royal Statistical Society: Series B (Statistical Methodology) 34 (2): 187–220.\n\n\nFriedman, Michael. 1982. “Piecewise exponential models for survival data with covariates.” The Annals of Statistics 10 (1): 101–13.\n\n\nLangford, John, Paul Mineiro, Alina Beygelzimer, and Hal Daume. 2016. “Learning Reductions that Really Work.” Proceedings of the IEEE 104 (1).\n\n\nLiestol, Knut, Per Kragh Andersen, and Ulrich Andersen. 1994. “Survival analysis and neural nets.” Statistics in Medicine 13 (12): 1189–1200. https://doi.org/10.1002/sim.4780131202.\n\n\nSchwarzer, Guido, Werner Vach, and Martin Schumacher. 2000. “On the misuses of artificial neural networks for prognostic and diagnostic classification in oncology.” Statistics in Medicine 19 (4): 541–61. https://doi.org/10.1002/(SICI)1097-0258(20000229)19:4&lt;541::AID-SIM355&gt;3.0.CO;2-V.\n\n\nTsoumakas, Grigorios, and Ioannis Katakis. 2007. “Multi-Label Classification: An Overview.” International Journal of Data Warehousing and Mining 3 (3): 1–13. https://doi.org/10.4018/jdwm.2007070101.\n\n\nTutz, Gerhard, and Matthias Schmid. 2016. Modeling Discrete Time-to-Event Data. Springer Series in Statistics. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-319-28158-2.\n\n\nVan Houwelingen, Hans C. 2007. “Dynamic prediction by landmarking in event history analysis.” Scandinavian Journal of Statistics 34 (1): 70–85. https://doi.org/10.1111/j.1467-9469.2006.00529.x.\n\n\nWelchowski, Thomas, and Matthias Schmid. 2019. “discSurv: Discrete Time Survival Analysis.” CRAN. https://cran.r-project.org/package=discSurv.\n\n\nWickham, Hadley. 2016. ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\nZhou, Zheng, Elham Rahme, Michal Abrahamowicz, and Louise Pilote. 2005. “Survival Bias Associated with Time-to-Treatment Initiation in Drug Effectiveness Evaluation: A Comparison of Methods.” American Journal of Epidemiology 162 (10): 1016–23. https://doi.org/10.1093/aje/kwi307.",
    "crumbs": [
      "Reduction Techniques",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Reductions</span>"
    ]
  },
  {
    "objectID": "P4C20_competing.html",
    "href": "P4C20_competing.html",
    "title": "20  Competing Risks Pipelines",
    "section": "",
    "text": "Page coming soon!\n\n\n\nWe are working on this page and it will be available soon!",
    "crumbs": [
      "Reduction Techniques",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Competing Risks Pipelines</span>"
    ]
  },
  {
    "objectID": "P4C21_discrete.html",
    "href": "P4C21_discrete.html",
    "title": "21  Discrete Time Survival Analysis",
    "section": "",
    "text": "Page coming soon!\n\n\n\nWe are working on this page and it will be available soon!",
    "crumbs": [
      "Reduction Techniques",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Discrete Time Survival Analysis</span>"
    ]
  },
  {
    "objectID": "P4C22_poisson.html",
    "href": "P4C22_poisson.html",
    "title": "22  Connections to Poisson Regression and Processes",
    "section": "",
    "text": "Page coming soon!\n\n\n\nWe are working on this page and it will be available soon!",
    "crumbs": [
      "Reduction Techniques",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Connections to Poisson Regression and Processes</span>"
    ]
  },
  {
    "objectID": "P4C23_pseudo.html",
    "href": "P4C23_pseudo.html",
    "title": "23  Connections to Regression and Imputation",
    "section": "",
    "text": "Major changes expected!\n\n\n\nThis page is a work in progress and major changes will be made over time.\n\n\n\nTODO\n\nI think all these sections should have examples in implemented models, e.g., here we can point to SVM models and some neural nets\nWe can also point to neural nets that use reduction to essentially just predict the linear predictor via regression or to use pseudovalues\nAdd pseudovalues\nAdd prediction of the observed outcome (not survival) time\n\n\n\nThis is a data-level SOC that transforms survival data to regression data by either removing censored observations or ‘imputing’ survival times. This composition is frequently incorrectly utilised (Section 19.3.3) and therefore more detail is provided here than previous compositions. Note that the previous compositions were prediction-level transformations that occur after a survival model makes a prediction, whereas this composition is on a data-level and can take place before model training or predicting.\nIn Statistics, there are only two methods for removing ‘missing’ values: deletion and imputation; both of these have been attempted for censoring.\nCensoring can be beneficial, harmful, or neutral; each will affect the data differently if deleted or imputed. Harmful censoring occurs if the reason for censoring is negative, for example drop-out due to disease progression. Harmful censoring indicates that the true survival time is likely soon after the censoring time. Beneficial censoring occurs if censoring is positive, for example drop-out due to recovery. This indicates that the true survival time is likely far from the censoring time. Finally neutral censoring occurs when no information can be gained about the true survival time from the censoring time. Whilst the first two of these can be considered to be dependent on the outcome, neutral censoring is often the case when censoring is independent of the outcome conditional on the data, which is a standard assumption for the majority of survival models and measures.\n\n23.0.0.1 Deletion #{sec-redux-regr-del}\nDeletion is the process of removing observations from a dataset. This is usually seen in ‘complete case analysis’ in which observations with ‘missingness’, covariates with missing values, are removed from the dataset. In survival analysis this method is somewhat riskier as the subjects to delete depend on the outcome and not the features. Three methods are considered, the first two are a more brute-force approach whereas the third allows for some flexibility and tuning.\n\n\nComplete Deletion\nDeleting all censored observations is simple to implement with no computational overhead. Complete deletion results in a smaller regression dataset, which may be significantly smaller if the proportion of censoring is high. If censoring is uninformative, the dataset is suitably large and the proportion of censoring suitably low, then this method can be applied without further consideration. However if censoring is informative then deletion will add bias to the dataset, although the ‘direction’ of bias cannot be known in advance. If censoring is harmful then censored observations will likely have a similar profile to those that died, thus removing censoring will artificially inflate the proportion of those who survive. Conversely if censoring is beneficial then censored observations may be more similar to those who survive, thus removal will artificially inflate the proportion of those who die.\n\n\nOmission\nOmission is the process of omitting the censoring indicator from the dataset, thus resulting in a regression dataset that assumes all observations experienced the event. Complete deletion results in a smaller dataset of dead patients, omission results in no sample size reduction but the outcome may be incorrect. This reduction strategy is likely only justified for harmful censoring. In this case the true survival time is likely close to the censoring time and therefore treating censored observations as dead may be a fair assumption.\n\n\nIPCW\nIf censoring is conditionally-outcome independent then deletion of censored events is possible by using Inverse Probability of Censoring Weights (IPCW). This method has been seen several times throughout this book in the context of models and measures. It has been formalised as a composition technique by Vock \\(\\textit{et al.}\\) (2016) (Vock et al. 2016) although their method is limited to binary classification. Their method weights the survival time of uncensored observations by \\(w_i = 1/\\hat{G}_{KM}(T_i)\\) and deletes censored observations, where \\(\\hat{G}_{KM}\\) is the Kaplan-Meier estimate of the censoring distribution fit on training data. As previously discussed, one could instead consider the Akritas (or any other) estimator for \\(\\hat{G}_{KM}\\).\nWhilst this method does provide a ‘safer’ way to delete censored observations, there is not a necessity to do so. Instead consider the following weights \\[\nw_i = \\frac{\\Delta_i + \\alpha(1 - \\Delta_i)}{\\hat{G}_{KM}(T_i)}\n\\tag{23.1}\\] where \\(\\alpha \\in [0, 1]\\) is a hyper-parameter to tune. Setting \\(\\alpha = 1\\) equally weights censored and uncensored observations and setting \\(\\alpha = 0\\) recovers the setting in which censored observations are deleted. It is assumed \\(\\hat{G}_{KM}\\) is set to some very small \\(\\epsilon\\) when \\(\\hat{G}_{KM}(T_i) = 0\\). When \\(\\alpha \\neq 0\\) this becomes an imputation method, other imputation methods are now discussed.\n\n\n\n\n23.0.0.2 Imputation\nImputation methods estimate the values of missing data conditional on non-missing data and other covariates. Whilst the true value of the missing data can never be known, by carefully conditioning on the ‘correct’ covariates, good estimates for the missing value can be obtained to help prevent a loss of data. Imputing outcome data is more difficult than imputing covariate data as models are then trained on ‘fake’ data. However a poor imputation should still be clear when evaluating a model as testing data remains un-imputed. By imputing censoring times with estimated survival times, the censoring indicator can be removed and the dataset becomes a regression dataset.\n\n\nGamma Imputation\nGamma imputation (Jackson et al. 2014) incorporates information about whether censoring is harmful, beneficial, or neutral. The method imputes survival times by generating times from a shifted proportional hazards model\n\\[\nh(\\tau) = h_0(\\tau)\\exp(\\eta + \\gamma)\n\\]\nwhere \\(\\eta\\) is the usual linear predictor and \\(\\gamma \\in \\mathbb{R}\\) is a hyper-parameter determining the ‘type’ of censoring such that \\(\\gamma &gt; 0\\) indicates harmful censoring, \\(\\gamma &lt; 0\\) indicates beneficial censoring, and \\(\\gamma = 0\\) is neutral censoring. This imputation method has the benefit of being tunable as \\(\\gamma\\) is a hyper-parameter and there is a choice of variables to condition the imputation. No independent experiments exist studying how well this method performs, nor discussing the theoretical properties of the method.\n\n\nMRL\nThe Mean Residual Lifetime (MRL) estimator has been previously discussed in the context of SVMs (Section 15.2). Here the estimator is extended to serve as an imputation method. Recall the MRL function, \\(MRL(\\tau|\\hat{S}) = \\int^\\infty_\\tau \\hat{S}(u) \\ du/\\hat{S}(\\tau)\\), where \\(\\hat{S}\\) is an estimate of the survival function of the underlying survival distribution (e.g. \\(\\hat{S}_{KM}\\)). The MRL is interpreted as the expected remaining survival time after the time-point \\(\\tau\\). This serves as a natural imputation strategy where given the survival outcome \\((T_i, \\Delta_i)\\), the new imputed time \\(T'_i\\) is given by \\[\nT'_i = T_i + (1 - \\Delta_i)MRL(T_i|\\hat{S})\n\\] where \\(\\hat{S}\\) would be fit on the training data and could be an unconditional estimator, such as Kaplan-Meier, or conditional, such as Akritas. The resulting survival times are interpreted as the true times for those who died and the expected survival times for those who were censored.\n\n\nBuckley-James\nBuckley-James (Buckley and James 1979) is another imputation method discussed earlier (?sec-surv-ml-models-boost). The Buckley-James method uses an iterative procedure to impute censored survival times by the conditional expectation given censoring times and covariates (Wang and Wang 2010). Given the survival tuple for an outcome \\((T_i, \\Delta_i)\\), the new imputed time \\(T'_i\\) is \\[\nT'_i =\n\\begin{cases}\nT_i, & \\Delta_i = 1 \\\\\nX_i\\hat{\\beta} + \\frac{1}{\\hat{S}_{KM}(e_i)} \\sum_{e_i &lt; e_k} \\hat{p}_{KM}(e_k) e_k & \\Delta_i = 0\n\\end{cases}\n\\] where \\(\\hat{S}_{KM}\\) is the Kaplan-Meier estimator of the survival distribution estimated on training data and with associated pmf \\(\\hat{p}_{KM}\\) and \\(e_i = T_i - X_i\\hat{\\beta}\\) where \\(\\hat{\\beta}\\) are estimated coefficients of a linear regression model fit on \\((X_i, T_i)\\). Given the least squares approach, more parametric assumptions are made than other imputation methods and it is more complex to separate model fitting from imputation. Hence, this imputation may only be appropriate on a limited number of data types.\n\n\nAlternative Methods\nOther methods have been proposed for ‘imputing’ censored survival times though with either less clear discussion or to no benefit. Multiple imputation by chained equations (MICE) has been demonstrated to perform well with covariate data and even outcome data (in a non-survival setting). However no adaptations have been developed to incorporate censoring times into the imputation and therefore is less informative than Gamma imputation.\nRe-calibration of censored survival times (Vinzamuri, Li, and Reddy 2017) uses an iterative update procedure to ‘re-calibrate’ censoring times however the motivation behind the method is not sufficiently clear to be of interest in general survival modelling tasks outside of the authors’ specific pipelines.\nFinally parametric imputation is defined by making random draws from truncated probability distributions and adding these to the censoring time (P. Royston 2001; Patrick Royston, Parmar, and Altman 2008). Whilst this method is arguably the simplest method and will lead to a sufficiently random sample, i.e. not one skewed by the imputation process, in practice the randomness leads to unrealistic results, with some imputed times being very far from the original censoring times and some being very close.\n\n\n23.0.0.3 The Decision to Impute or Delete\nDeletion methods are simple to implement and fast to compute however they can lead to biasing the data or a significant sample reduction if used incorrectly. Imputation methods can incorporate tuning and have more relaxed assumptions about the censoring mechanism, though they may lead to over-confidence in the resulting outcome and therefore add bias into the dataset. In some cases, the decision to impute or delete is straightforward, for example if censoring is uninformative and only few observations are censored then complete deletion is appropriate. If it is unknown if censoring is informative then this can crudely be estimated by a benchmark experiment. Classification models can be fit on \\(\\{(X_1, \\Delta_1),...,(X_n,\\Delta_n)\\}\\) where \\((X_i, \\Delta_i) \\in \\mathcal{D}_{train}\\). Whilst not an exact test, if any model significantly outperforms a baseline, then this may indicate censoring is informative. This is demonstrated in (tab-car-predcens?), in which a logistic regression outperforms a featureless baseline in correctly predicting if an observation is censored when censoring is informative, but is no better than the baseline when censoring is uninformative.\n\n\n\nTable 23.1: Estimating censoring dependence by prediction. Sim1 is informative censoring and Sim7 is uninformative. Logistic regression is compared to a featureless baseline with the Brier score with standard errors. Censoring can be significantly predicted to 95% confidence when informative (Sim1) but not when uninformative (Sim7).\n\n\n\n\n\nData\nBaseline\nLogistic Regression\n\n\n\n\nSim1\n0.20 (0.14, 0.26)\n0.02 (0.01, 0.03)\n\n\nSim7\n0.19 (0.14, 0.24)\n0.16 (0.13, 0.19)\n\n\n\n\n\n\n\n\n\n\nBuckley, Jonathan, and Ian James. 1979. “Linear Regression with Censored Data.” Biometrika 66 (3): 429–36. https://doi.org/10.2307/2335161.\n\n\nJackson, Dan, Ian R. White, Shaun Seaman, Hannah Evans, Kathy Baisley, and James Carpenter. 2014. “Relaxing the independent censoring assumption in the Cox proportional hazards model using multiple imputation.” Statistics in Medicine 33 (27): 4681–94. https://doi.org/10.1002/sim.6274.\n\n\nRoyston, P. 2001. “The Lognormal Distribution as a Model for Survival Time in Cancer, With an Emphasis on Prognostic Factors.” Statistica Neerlandica 55 (1): 89–104. https://doi.org/10.1111/1467-9574.00158.\n\n\nRoyston, Patrick, Mahesh K B Parmar, and Douglas G Altman. 2008. “Visualizing Length of Survival in Time-to-Event Studies: A Complement to Kaplan–Meier Plots.” JNCI: Journal of the National Cancer Institute 100 (2): 92–97. https://doi.org/10.1093/jnci/djm265.\n\n\nVinzamuri, Bhanukiran, Yan Li, and Chandan K. Reddy. 2017. “Pre-processing censored survival data using inverse covariance matrix based calibration.” IEEE Transactions on Knowledge and Data Engineering 29 (10): 2111–24. https://doi.org/10.1109/TKDE.2017.2719028.\n\n\nVock, David M, Julian Wolfson, Sunayan Bandyopadhyay, Gediminas Adomavicius, Paul E Johnson, Gabriela Vazquez-Benitez, and Patrick J O’Connor. 2016. “Adapting machine learning techniques to censored time-to-event health record data: A general-purpose approach using inverse probability of censoring weighting.” Journal of Biomedical Informatics 61: 119–31. https://doi.org/https://doi.org/10.1016/j.jbi.2016.03.009.\n\n\nWang, Zhu, and C Y Wang. 2010. “Buckley-James Boosting for Survival Analysis with High-Dimensional Biomarker Data.” Statistical Applications in Genetics and Molecular Biology 9 (1). https://doi.org/https://doi.org/10.2202/1544-6115.1550.",
    "crumbs": [
      "Reduction Techniques",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Connections to Regression and Imputation</span>"
    ]
  },
  {
    "objectID": "P5C24_conclusions.html",
    "href": "P5C24_conclusions.html",
    "title": "24  Conclusions",
    "section": "",
    "text": "24.1 Common problems in survival analysis",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Conclusions</span>"
    ]
  },
  {
    "objectID": "P5C24_conclusions.html#sec-conclusions-faq",
    "href": "P5C24_conclusions.html#sec-conclusions-faq",
    "title": "24  Conclusions",
    "section": "",
    "text": "24.1.1 Data cleaning\n\nEvents at t=0\nThroughout this book we have defined survival times taking values in the non-negative Reals (zero inclusive) \\(\\mathbb{R}_{\\geq 0}\\). In practice, model implementations assume time is over the positive Reals (zero exclusive). One must therefore consider how to deal with subjects that experience the outcome at \\(0\\). There is no established best practice for dealing with this case as the answer may be data-dependent. Possible choices include:\n\nDeleting all data where the outcome occurs at \\(t=0\\), this may be appropriate if it only happens in a small number of observations and therefore deletion is unlikely to bias predictions;\nUpdate the survival time to the next smallest observed survival time. For example, if the first observation to experience the event after \\(t=0\\) happens at \\(t=0.1\\), then set \\(0.1\\) as the survival time for any observation experiencing the event at \\(t=0\\). Note this method will not be appropriate when data is over a long period, for example if measuring time over years, then there could be a substantial difference between \\(t=0\\) and \\(t=1\\);\nUpdate the survival time to a very small value \\(\\epsilon\\) that makes sense given the context of the data, e.g., \\(\\epsilon = 0.0001\\).\n\n\n\nContinuous v Discrete Time\nWe defined survival tasks throughout this book assuming continuous time predictions in \\(\\mathbb{R}_{\\geq 0}\\). In practice, many outcomes in survival analysis are recorded on a discrete scale, such as in medical statistics where outcomes are observed on a yearly, daily, monthly, hourly, etc. basis. Whilst discrete-time survival analysis exists for this purpose (Chapter 21), software implementations overwhelming use theory from the ’continuous-time setting. There has not been a lot of research into whether discrete-time methods outperform continuous-time methods when correctly applied to discrete data, however available experiments do not indicate that discrete methods outperform their continuous counterparts (Suresh, Severn, and Ghosh 2022). Therefore it is recommended to use available software implementations, even when data is recorded on a discrete scale.\n\n\n\n24.1.2 Evaluation and prediction\n\nWhich time points to make predictions for?",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Conclusions</span>"
    ]
  },
  {
    "objectID": "P5C24_conclusions.html#whats-next-for-mlsa",
    "href": "P5C24_conclusions.html#whats-next-for-mlsa",
    "title": "24  Conclusions",
    "section": "24.2 What’s next for MLSA?",
    "text": "24.2 What’s next for MLSA?\n\n\n\n\nSuresh, Krithika, Cameron Severn, and Debashis Ghosh. 2022. “Survival prediction models: an introduction to discrete-time modeling.” BMC Medical Research Methodology 22 (1): 207. https://doi.org/10.1186/s12874-022-01679-6.",
    "crumbs": [
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Conclusions</span>"
    ]
  },
  {
    "objectID": "P5C25_exercises.html",
    "href": "P5C25_exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "Page coming soon!\n\n\n\nWe are working on this page and it will be available soon!",
    "crumbs": [
      "Exercises"
    ]
  },
  {
    "objectID": "P5C26_references.html",
    "href": "P5C26_references.html",
    "title": "References",
    "section": "",
    "text": "Aalen, Odd. 1978. “Nonparametric Inference\nfor a Family of Counting Processes.” The Annals of\nStatistics 6 (4): 701–26.\n\n\nAalen, Odd O., and Søren Johansen. 1978. “An Empirical\nTransition Matrix for Non-Homogeneous Markov Chains\nBased on Censored Observations.”\nScandinavian Journal of Statistics 5 (3): 141–50. https://www.jstor.org/stable/4615704.\n\n\nAkritas, Michael G. 1994. “Nearest Neighbor\nEstimation of a Bivariate Distribution Under Random\nCensoring.” Ann. Statist. 22 (3): 1299–1327. https://doi.org/10.1214/aos/1176325630.\n\n\nAkritas, Michael G., and Michael P. LaValley. 2005. “A Generalized\nProduct-Limit Estimator for Truncated Data.” Nonparametric\nStatistics, September. https://doi.org/10.1080/10485250500038637.\n\n\nAllignol, Arthur, Jan Beyersmann, and Martin Schumacher. 2008.\n“Mvna an r Package for the Nelson-Aalen Estimator in Multistate\nModels.” R News 8 (2): 48–50.\n\n\nAndersen, Per Kragh, Mette Gerster Hansen, and John P. Klein. 2004.\n“Regression Analysis of Restricted Mean\nSurvival Time Based on Pseudo-Observations.”\nLifetime Data Analysis 10 (4): 335–50. https://doi.org/10.1007/s10985-004-4771-0.\n\n\nAndres, Axel, Aldo Montano-Loza, Russell Greiner, Max Uhlich, Ping Jin,\nBret Hoehn, David Bigam, James Andrew Mark Shapiro, and Norman Mark\nKneteman. 2018. “A novel learning algorithm\nto predict individual survival after liver transplantation for primary\nsclerosing cholangitis.” PLOS ONE 13 (3):\ne0193523. https://doi.org/10.1371/journal.pone.0193523.\n\n\nAntolini, Laura, Patrizia Boracchi, and Elia Biganzoli. 2005.\n“A time-dependent discrimination index for\nsurvival data.” Statistics in Medicine 24 (24):\n3927–44. https://doi.org/10.1002/sim.2427.\n\n\nAvati, Anand, Tony Duan, Sharon Zhou, Kenneth Jung, Nigam H. Shah, and\nAndrew Ng. 2020. “Countdown Regression: Sharp\nand Calibrated Survival Predictions.” In Proceedings\nof Machine Learning Research, 145–55. https://proceedings.mlr.press/v115/avati20a.html\nhttp://arxiv.org/abs/1806.08324.\n\n\nBecker, Marc, Lennart Schneider, and Sebastian Fischer. 2024.\n“Hyperparameter Optimization.” In Applied Machine\nLearning Using mlr3 in R,\nedited by Bernd Bischl, Raphael Sonabend, Lars Kotthoff, and Michel\nLang. CRC Press. https://mlr3book.mlr-org.com/hyperparameter_optimization.html.\n\n\nBello, Ghalib A, Timothy J W Dawes, Jinming Duan, Carlo Biffi, Antonio\nde Marvao, Luke S G E Howard, J Simon R Gibbs, et al. 2019. “Deep-learning cardiac motion analysis for human survival\nprediction.” Nature Machine Intelligence 1 (2):\n95–104. https://doi.org/10.1038/s42256-019-0019-2.\n\n\nBenavoli, Alessio, Giorgio Corani, Janez Demšar, and Marco Zaffalon.\n2017. “Time for a Change: A Tutorial for Comparing Multiple\nClassifiers Through Bayesian Analysis.” Journal of Machine\nLearning Research 18 (77): 1–36. http://jmlr.org/papers/v18/16-305.html.\n\n\nBender, Andreas, and Fabian Scheipl. 2018. “pammtools: Piece-wise exponential Additive Mixed Modeling\ntools.” arXiv:1806.01042 [Stat]. http://arxiv.org/abs/1806.01042.\n\n\nBennett, Steve. 1983. “Analysis of survival\ndata by the proportional odds model.” Statistics in\nMedicine 2 (2): 273–77. https://doi.org/https://doi.org/10.1002/sim.4780020223.\n\n\nBeyersmann, Jan, Arthur Allignol, and Martin Schumacher. 2012.\nCompeting Risks and Multistate Models with R. Use\nR! New York: Springer.\n\n\nBiganzoli, E M, F Ambrogi, and P Boracchi. 2009. “Partial logistic artificial neural networks (PLANN) for\nflexible modeling of censored survival data.” In 2009\nInternational Joint Conference on Neural Networks, 340–46. https://doi.org/10.1109/IJCNN.2009.5178824.\n\n\nBiganzoli, Elia, Patrizia Boracchi, Luigi Mariani, and Ettore Marubini.\n1998. “Feed forward neural networks for the\nanalysis of censored survival data: a partial logistic regression\napproach.” Statistics in Medicine 17 (10):\n1169–86. https://doi.org/10.1002/(SICI)1097-0258(19980530)17:10&lt;1169::AID-SIM796&gt;3.0.CO;2-D.\n\n\nBinder, Harald. 2013. “CoxBoost: Cox models\nby likelihood based boosting for a single survival endpoint or competing\nrisks.” CRAN.\n\n\nBinder, Harald, and Martin Schumacher. 2008. “Allowing for mandatory covariates in boosting estimation\nof sparse high-dimensional survival models.” BMC\nBioinformatics 9 (1): 14. https://doi.org/10.1186/1471-2105-9-14.\n\n\nBischl, Bernd, O. Mersmann, H. Trautmann, and C. Weihs. 2012.\n“Resampling Methods for Meta-Model Validation\nwith Recommendations for Evolutionary Computation.”\nEvolutionary Computation 20 (2): 249–75. https://doi.org/10.1162/EVCO_a_00069.\n\n\nBischl, Bernd, Raphael Sonabend, Lars Kotthoff, and Michel Lang, eds.\n2024. Applied Machine Learning Using mlr3 in\nR. CRC Press. https://mlr3book.mlr-org.com.\n\n\nBishop, Christopher M. 2006. Pattern\nrecognition and machine learning. springer.\n\n\nBlanche, Paul, Jean-François Dartigues, and Hélène Jacqmin-Gadda. 2013.\n“Review and comparison of ROC curve\nestimators for a time-dependent outcome with marker-dependent\ncensoring.” Biometrical Journal 55 (5): 687–704.\nhttps://doi.org/10.1002/bimj.201200045.\n\n\nBlanche, Paul, Aurélien Latouche, and Vivian Viallon. 2012. “Time-dependent AUC with right-censored data: a survey\nstudy,” October. https://doi.org/10.1007/978-1-4614-8981-8_11.\n\n\nBland, J Martin, and Douglas G. Altman. 2004. “The logrank test.” BMJ (Clinical\nResearch Ed.) 328 (7447): 1073. https://doi.org/10.1136/bmj.328.7447.1073.\n\n\nBou-Hamad, Imad, Denis Larocque, and Hatem Ben-Ameur. 2011. “A review of survival trees.” Statist.\nSurv. 5: 44–71. https://doi.org/10.1214/09-SS047.\n\n\nBower, Hannah, Michael J Crowther, Mark J Rutherford, Therese M.-L.\nAndersson, Mark Clements, Xing-Rong Liu, Paul W Dickman, and Paul C\nLambert. 2019. “Capturing simple and complex\ntime-dependent effects using flexible parametric survival models: A\nsimulation study.” Communications in Statistics -\nSimulation and Computation, July, 1–17. https://doi.org/10.1080/03610918.2019.1634201.\n\n\nBreiman, Leo. 1996. “Bagging Predictors.”\nMachine Learning 24 (2): 123–40. https://doi.org/10.1023/A:1018054314350.\n\n\nBreiman, Leo, and Philip Spector. 1992. “Submodel Selection and Evaluation in Regression. The\nX-Random Case.” International Statistical Review /\nRevue Internationale de Statistique 60 (3): 291–319. https://doi.org/10.2307/1403680.\n\n\nBreiman, L, J Friedman, C J Stone, and R A Olshen. 1984. Classification and Regression Trees. The\nWadsworth and Brooks-Cole Statistics-Probability Series. Taylor &\nFrancis. https://books.google.co.uk/books?id=JwQx-WOmSyQC.\n\n\nBreslow, N. 1972. “Discussion following\n‘Regression models and life tables’ by D. R.\nCox.” Journal of the Royal Statistical Society: Series\nB (Statistical Methodology) 34 (2): 187–220.\n\n\nBrier, Glenn. 1950. “Verification of\nforecasts expressed in terms of probability.” Monthly\nWeather Review 78 (1): 1–3.\n\n\nBroström, Göran. 1987. “The Influence of\nMother’s Death on Infant\nMortality: A Case Study in Matched Data\nSurvival Analysis.” Scandinavian Journal of\nStatistics 14 (2): 113–23. https://www.jstor.org/stable/4616055.\n\n\n———. 2024. Eha: Event History Analysis. https://cran.r-project.org/package=eha.\n\n\nBuckley, Jonathan, and Ian James. 1979. “Linear Regression with Censored Data.”\nBiometrika 66 (3): 429–36. https://doi.org/10.2307/2335161.\n\n\nBuhlmann, Peter. 2006. “Boosting for\nhigh-dimensional linear models.” Ann. Statist. 34\n(2): 559–83. https://doi.org/10.1214/009053606000000092.\n\n\nBuhlmann, Peter, and Torsten Hothorn. 2007. “Boosting Algorithms: Regularization, Prediction and Model\nFitting.” Statist. Sci. 22 (4): 477–505. https://doi.org/10.1214/07-STS242.\n\n\nBühlmann, Peter, and Bin Yu. 2003. “Boosting\nWith the L2 Loss.” Journal of the American Statistical\nAssociation 98 (462): 324–39. https://doi.org/10.1198/016214503000125.\n\n\nCasalicchio, Giuseppe, and Lukas Burk. 2024. “Evaluation and\nBenchmarking.” In Applied Machine Learning Using mlr3 in R, edited by Bernd\nBischl, Raphael Sonabend, Lars Kotthoff, and Michel Lang. CRC Press. https://mlr3book.mlr-org.com/chapters/chapter3/evaluation_and_benchmarking.html.\n\n\nChambless, Lloyd E, and Guoqing Diao. 2006. “Estimation of time-dependent area under the ROC curve for\nlong-term risk prediction.” Statistics in\nMedicine 25 (20): 3474–86. https://doi.org/10.1002/sim.2299.\n\n\nChen, Tianqi, Tong He, Michael Benesty, Vadim Khotilovich, Yuan Tang,\nHyunsu Cho, Kailong Chen, et al. 2020. “xgboost: Extreme Gradient Boosting.” CRAN.\nhttps://cran.r-project.org/package=xgboost.\n\n\nChen, Yen-Chen, Wan-Chi Ke, and Hung-Wen Chiu. 2014. “Risk classification of cancer survival using ANN with\ngene expression data from multiple laboratories.”\nComputers in Biology and Medicine 48: 1–7. https://doi.org/https://doi.org/10.1016/j.compbiomed.2014.02.006.\n\n\nChen, Yifei, Zhenyu Jia, Dan Mercola, and Xiaohui Xie. 2013.\n“A Gradient Boosting Algorithm for Survival\nAnalysis via Direct Optimization of Concordance Index.”\nEdited by Lev Klebanov. Computational and Mathematical Methods in\nMedicine 2013: 873595. https://doi.org/10.1155/2013/873595.\n\n\nChing, Travers, Xun Zhu, and Lana X Garmire. 2018. “Cox-nnet: An artificial neural network method for\nprognosis prediction of high-throughput omics data.”\nPLOS Computational Biology 14 (4): e1006076. https://doi.org/10.1371/journal.pcbi.1006076.\n\n\nChoodari-Oskooei, Babak, Patrick Royston, and Mahesh K. B. Parmar. 2012.\n“A simulation study of predictive ability\nmeasures in a survival model I: Explained variation\nmeasures.” Statistics in Medicine 31 (23):\n2627–43. https://doi.org/10.1002/sim.4242.\n\n\nCiampi, Antonio, Sheilah A Hogg, Steve McKinney, and Johanne Thiffault.\n1988. “RECPAM: a computer program for\nrecursive partition and amalgamation for censored survival data and\nother situations frequently occurring in biostatistics. I. Methods and\nprogram features.” Computer Methods and Programs in\nBiomedicine 26 (3): 239–56. https://doi.org/https://doi.org/10.1016/0169-2607(88)90004-1.\n\n\nCiampi, Antonio, Johanne Thiffault, Jean Pierre Nakache, and Bernard\nAsselain. 1986. “Stratification by stepwise\nregression, correspondence analysis and recursive partition: a\ncomparison of three methods of analysis for survival data with\ncovariates.” Computational Statistics and Data\nAnalysis 4 (3): 185–204. https://doi.org/10.1016/0167-9473(86)90033-2.\n\n\nClevert, Djork-Arné, Thomas Unterthiner, and Sepp Hochreiter. 2015.\n“Fast and accurate deep network learning by\nexponential linear units (elus).” arXiv Preprint\narXiv:1511.07289.\n\n\nCollett, David. 2014. Modelling Survival Data\nin Medical Research. 3rd ed. CRC.\n\n\nCollins, Gary S., Joris A. De Groot, Susan Dutton, Omar Omar, Milensu\nShanyinde, Abdelouahid Tajar, Merryn Voysey, et al. 2014. “External validation of multivariable prediction models: A\nsystematic review of methodological conduct and\nreporting.” BMC Medical Research Methodology 14\n(1): 1–11. https://doi.org/10.1186/1471-2288-14-40.\n\n\nColosimo, Enrico, Fla´vio Ferreira, Maristela Oliveira, and Cleide\nSousa. 2002. “Empirical comparisons between\nKaplan-Meier and Nelson-Aalen survival function\nestimators.” Journal of Statistical Computation and\nSimulation 72 (4): 299–308. https://doi.org/10.1080/00949650212847.\n\n\nCook, Richard J., and Jerald F. Lawless. 2007. The Statistical\nAnalysis of Recurrent Events. Statistics for\nBiology and Health. New York, NY: Springer. https://doi.org/10.1007/978-0-387-69810-6.\n\n\nCortes, Corinna, and Vladimir Vapnik. 1995. “Support-Vector\nNetworks.” Machine Learning 20: 273–97. https://doi.org/10.1007/BF00994018.\n\n\nCox, D. R. 1972. “Regression Models and\nLife-Tables.” Journal of the Royal Statistical\nSociety: Series B (Statistical Methodology) 34 (2): 187–220.\n\n\n———. 1975. “Partial Likelihood.”\nBiometrika 62 (2): 269–76. https://doi.org/10.1080/03610910701884021.\n\n\nCui, Lei, Hansheng Li, Wenli Hui, Sitong Chen, Lin Yang, Yuxin Kang,\nQirong Bo, and Jun Feng. 2020. “A deep\nlearning-based framework for lung cancer survival analysis with\nbiomarker interpretation.” BMC Bioinformatics 21\n(1): 112. https://doi.org/10.1186/s12859-020-3431-z.\n\n\nData Study Group Team. 2020. “Data Study Group Final Report:\nGreat Ormond Street Hospital.” https://doi.org/10.5281/zenodo.3670726.\n\n\nDawid, A P. 1984. “Present Position and\nPotential Developments: Some Personal Views: Statistical Theory: The\nPrequential Approach.” Journal of the Royal\nStatistical Society. Series A (General) 147 (2): 278–92. https://doi.org/10.2307/2981683.\n\n\nDawid, A Philip. 1986. “Probability\nForecasting.” Encyclopedia of Statistical\nSciences 7: 210–18.\n\n\nDawid, A Philip, and Monica Musio. 2014. “Theory and Applications of Proper Scoring\nRules.” Metron 72 (2): 169–83. https://arxiv.org/abs/arXiv:1401.0398v1.\n\n\nde Wreede, Liesbeth C., Marta Fiocco, and Hein Putter. 2011.\n“mstate: An R Package for\nthe Analysis of Competing Risks and Multi-State Models.”\nJournal of Statistical Software 38 (7): 1–30. https://doi.org/10.18637/jss.v038.i07.\n\n\nDemler, Olga V, Nina P Paynter, and Nancy R Cook. 2015. “Tests of calibration and goodness-of-fit in the survival\nsetting.” Statistics in Medicine 34 (10):\n1659–80. https://doi.org/10.1002/sim.6428.\n\n\nDemšar, Janez. 2006. “Statistical comparisons\nof classifiers over multiple data sets.” Journal of\nMachine Learning Research 7 (1): 1–30.\n\n\nDietterich, Thomas G. 1998. “Approximate\nStatistical Tests for Comparing Supervised Classification Learning\nAlgorithms.” Neural Computation 10 (7):\n1895–1923. https://doi.org/10.1162/089976698300017197.\n\n\nEfron, Bradley. 1988. “Logistic Regression,\nSurvival Analysis, and the Kaplan-Meier Curve.”\nJournal of the American Statistical Association 83 (402):\n414–25. https://doi.org/10.2307/2288857.\n\n\nEfron, Bradley, and Robert Tibshirani. 1997. “Improvements on\nCross-Validation: The .632+ Bootstrap Method.” Journal of the\nAmerican Statistical Association 92 (438): 548–60. http://www.jstor.org/stable/2965703.\n\n\nEvers, Ludger, and Claudia-Martina Messow. 2008. “Sparse kernel methods for high-dimensional survival\ndata.” Bioinformatics 24 (14): 1632–38.\n\n\nFaraggi, David, and Richard Simon. 1995. “A\nneural network model for survival data.” Statistics in\nMedicine 14 (1): 73–82. https://doi.org/10.1002/sim.4780140108.\n\n\nFleming, Thomas R, Judith R O’Fallon, Peter C O’Brien, and David P\nHarrington. 1980. “Modified\nKolmogorov-Smirnov Test Procedures with Application to Arbitrarily\nRight-Censored Data.” Biometrics 36 (4): 607–25.\nhttps://doi.org/10.2307/2556114.\n\n\nFoss, Natalie, and Lars Kotthoff. 2024. “Data and Basic\nModeling.” In Applied Machine Learning Using mlr3 in R, edited by Bernd\nBischl, Raphael Sonabend, Lars Kotthoff, and Michel Lang. CRC Press. https://mlr3book.mlr-org.com/data_and_basic_modeling.html.\n\n\nFotso, Stephane. 2018. “Deep Neural Networks\nfor Survival Analysis Based on a Multi-Task Framework.”\narXiv Preprint arXiv:1801.05512, January. http://arxiv.org/abs/1801.05512.\n\n\nFouodo, Cesaire J K, I Konig, C Weihs, A Ziegler, and M Wright. 2018.\n“Support vector machines for survival\nanalysis with R.” The R Journal 10 (July):\n412–23.\n\n\nFreund, Yoav, and Robert E Schapire. 1996. “Experiments with a new boosting algorithm.”\nIn. Citeseer.\n\n\nFriedman, Jerome. 1999. “Stochastic Gradient\nBoosting.” Computational Statistics & Data\nAnalysis 38 (March): 367–78. https://doi.org/10.1016/S0167-9473(01)00065-2.\n\n\nFriedman, Jerome H. 2001. “Greedy Function Approximation: A\nGradient Boosting Machine.” The Annals of\nStatistics 29 (5): 1189–1232. http://www.jstor.org/stable/2699986.\n\n\nFriedman, Michael. 1982. “Piecewise\nexponential models for survival data with covariates.”\nThe Annals of Statistics 10 (1): 101–13.\n\n\nFritsch, Stefan, Frauke Guenther, and Marvin N. Wright. 2019.\n“neuralnet: Training of Neural\nNetworks.” CRAN. https://cran.r-project.org/package=neuralnet.\n\n\nGelfand, Alan E, Sujit K Ghosh, Cindy Christiansen, Stephen B Soumerai,\nand Thomas J McLaughlin. 2000. “Proportional\nhazards models: a latent competing risk approach.”\nJournal of the Royal Statistical Society: Series C (Applied\nStatistics) 49 (3): 385–97. https://doi.org/https://doi.org/10.1111/1467-9876.00199.\n\n\nGensheimer, Michael F., and Balasubramanian Narasimhan. 2018.\n“A Simple Discrete-Time Survival Model for\nNeural Networks,” 1–17. https://doi.org/arXiv:1805.00917v3.\n\n\nGensheimer, Michael F, and Balasubramanian Narasimhan. 2019.\n“A scalable discrete-time survival model for\nneural networks.” PeerJ 7: e6257.\n\n\nGeorgousopoulou, Ekavi N, Christos Pitsavos, Christos Mary Yannakoulia,\nand Demosthenes B Panagiotakos. 2015. “Comparisons between Survival Models in Predicting\nCardiovascular Disease Events : Application in the ATTICA Study (\n2002-2012 ).” Journal of Statistics Applications &\nProbability 4 (2): 203–10.\n\n\nGerds, Thomas A, and Martin Schumacher. 2006. “Consistent Estimation of the Expected Brier Score in\nGeneral Survival Models with Right-Censored Event Times.”\nBiometrical Journal 48 (6): 1029–40. https://doi.org/10.1002/bimj.200610301.\n\n\nGéron, Aurélien. 2019. Hands-on Machine Learning with Scikit-Learn,\nKeras, and TensorFlow, 2nd Edition. O’Reilly. https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/.\n\n\nGiunchiglia, Eleonora, Anton Nemchenko, and Mihaela van der Schaar.\n2018. “Rnn-surv: A deep recurrent model for\nsurvival analysis.” In International Conference on\nArtificial Neural Networks, 23–32. Springer.\n\n\nGneiting, Tilmann, and Adrian E Raftery. 2007. “Strictly Proper Scoring Rules, Prediction, and\nEstimation.” Journal of the American Statistical\nAssociation 102 (477): 359–78. https://doi.org/10.1198/016214506000001437.\n\n\nGoli, Shahrbanoo, Hossein Mahjub, Javad Faradmal, Hoda Mashayekhi, and\nAli-Reza Soltanian. 2016. “Survival\nPrediction and Feature Selection in Patients with Breast Cancer Using\nSupport Vector Regression.” Edited by Francesco\nPappalardo. Computational and Mathematical Methods in Medicine\n2016: 2157984. https://doi.org/10.1155/2016/2157984.\n\n\nGoli, Shahrbanoo, Hossein Mahjub, Javad Faradmal, and Ali-Reza\nSoltanian. 2016. “Performance Evaluation of\nSupport Vector Regression Models for Survival Analysis: A Simulation\nStudy.” International Journal of Advanced Computer\nScience and Applications 7 (June). https://doi.org/10.14569/IJACSA.2016.070650.\n\n\nGompertz, Benjamin. 1825. “On the Nature of\nthe Function Expressive of the Law of Human Mortality, and on a New Mode\nof Determining the Value of Life Contingencies.”\nPhilosophical Transactions of the Royal Society of London 115:\n513–83.\n\n\nGönen, Mithat, and Glenn Heller. 2005. “Concordance Probability and Discriminatory Power in\nProportional Hazards Regression.” Biometrika 92\n(4): 965–70.\n\n\nGood, I J. 1952. “Rational Decisions.”\nJournal of the Royal Statistical Society. Series B\n(Methodological) 14 (1): 107–14. http://www.jstor.org/stable/2984087.\n\n\nGordon, Louis, and Richard A Olshen. 1985. “Tree-structured survival analysis.”\nCancer Treatment Reports 69 (10): 1065–69.\n\n\nGraf, Erika, Claudia Schmoor, Willi Sauerbrei, and Martin Schumacher.\n1999. “Assessment and comparison of\nprognostic classification schemes for survival data.”\nStatistics in Medicine 18 (17-18): 2529–45. https://doi.org/10.1002/(SICI)1097-0258(19990915/30)18:17/18&lt;2529::AID-SIM274&gt;3.0.CO;2-5.\n\n\nGraf, Erika, and Martin Schumacher. 1995. “An\nInvestigation on Measures of Explained Variation in Survival\nAnalysis.” Journal of the Royal Statistical Society.\nSeries D (The Statistician) 44 (4): 497–507. https://doi.org/10.2307/2348898.\n\n\nGray, Robert J. 1988. “A Class of K-Sample Tests for Comparing the\nCumulative Incidence of a Competing Risk.” The Annals\nof Statistics 16 (3): 1141–54. https://doi.org/10.1214/aos/1176350951.\n\n\nGressmann, Frithjof, Franz J. Király, Bilal Mateen, and Harald\nOberhauser. 2018. “Probabilistic supervised\nlearning.” https://doi.org/10.1002/iub.552.\n\n\nHabibi, Danial, Mohammad Rafiei, Ali Chehrei, Zahra Shayan, and Soheil\nTafaqodi. 2018. “Comparison of Survival\nModels for Analyzing Prognostic Factors in Gastric Cancer\nPatients.” Asian Pacific Journal of Cancer Prevention\n: APJCP 19 (3): 749–53. https://doi.org/10.22034/APJCP.2018.19.3.749.\n\n\nHaider, Humza, Bret Hoehn, Sarah Davis, and Russell Greiner. 2020.\n“Effective ways to build and evaluate\nindividual survival distributions.” Journal of Machine\nLearning Research 21 (85): 1–63.\n\n\nHan, Ilkyu, June Hyuk Kim, Heeseol Park, Han-Soo Kim, and Sung Wook Seo.\n2018. “Deep learning approach for survival\nprediction for patients with synovial sarcoma.” Tumor\nBiology 40 (9): 1010428318799264. https://doi.org/10.1177/1010428318799264.\n\n\nHan, Kyunghwa, and Inkyung Jung. 2022. “Restricted Mean\nSurvival Time for Survival Analysis: A Quick\nGuide for Clinical Researchers.” Korean\nJournal of Radiology 23 (5): 495–99. https://doi.org/10.3348/kjr.2022.0061.\n\n\nHarrell, F E Jr, K L Lee, R M Califf, D B Pryor, and R A Rosati. 1984.\n“Regression modelling strategies for improved\nprognostic prediction.” Statistics in Medicine 3\n(2): 143–52. https://doi.org/10.1002/sim.4780030207.\n\n\nHarrell, Frank E., Robert M. Califf, and David B. Pryor. 1982.\n“Evaluating the yield of medical\ntests.” JAMA 247 (18): 2543–46. http://dx.doi.org/10.1001/jama.1982.03320430047030.\n\n\nHarrell, Frank E., Kerry L. Lee, and Daniel B. Mark. 1996. “Multivariable Prognostic Models: Issues in Developing\nModels, Evaluating Assumptions and Adequacy, and Measuring and Reducing\nErrors.” Statistics in Medicine 15: 361–87. https://doi.org/10.1002/0470023678.ch2b(i).\n\n\nHastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2001. The Elements of Statistical Learning.\nSpringer New York Inc.\n\n\nHeagerty, Patrick J., Thomas Lumley, and Margaret S. Pepe. 2000.\n“Time-Dependent ROC Curves for Censored\nSurvival Data and a Diagnostic Marker.”\nBiometrics 56 (2): 337–44. https://doi.org/10.1111/j.0006-341X.2000.00337.x.\n\n\nHeagerty, Patrick J, and Yingye Zheng. 2005. “Survival Model Predictive Accuracy and ROC\nCurves.” Biometrics 61 (1): 92–105. https://doi.org/10.1111/j.0006-341X.2005.030814.x.\n\n\nHenderson, and Velleman. 1981. “Building\nmultiple regression models interactively.”\nBiometrics 37: 391–411.\n\n\nHerrmann, Moritz, Philipp Probst, Roman Hornung, Vindi Jurinovic, and\nAnne-Laure Boulesteix. 2021. “Large-scale\nbenchmark study of survival prediction methods using multi-omics\ndata.” Briefings in Bioinformatics 22 (3). https://doi.org/10.1093/bib/bbaa167.\n\n\nHielscher, Thomas, Manuela Zucknick, Wiebke Werft, and Axel Benner.\n2010. “On the Prognostic Value of Gene\nExpression Signatures for Censored Data BT - Advances in Data Analysis,\nData Handling and Business Intelligence.” In, edited by\nAndreas Fink, Berthold Lausen, Wilfried Seidel, and Alfred Ultsch,\n663–73. Berlin, Heidelberg: Springer Berlin Heidelberg.\n\n\nHornung, Roman, Malte Nalenz, Lennart Schneider, Andreas Bender, Ludwig\nBothmann, Bernd Bischl, Thomas Augustin, and Anne-Laure Boulesteix.\n2023. “Evaluating Machine Learning Models in Non-Standard\nSettings: An Overview and New Findings.” https://arxiv.org/abs/2310.15108.\n\n\nHosmer, David W, and Stanley Lemeshow. 1980. “Goodness of fit tests for the multiple logistic\nregression model.” Communications in Statistics-Theory\nand Methods 9 (10): 1043–69.\n\n\nHosmer Jr, David W, Stanley Lemeshow, and Susanne May. 2011. Applied survival analysis: regression modeling of\ntime-to-event data. Vol. 618. John Wiley & Sons.\n\n\nHothorn, Torsten, Peter Buehlmann, Thomas Kneib, Matthias Schmid, and\nBenjamin Hofner. 2020. “mboost: Model-Based\nBoosting.” CRAN. https://cran.r-project.org/package=mboost.\n\n\nHothorn, Torsten, Peter Bühlmann, Sandrine Dudoit, Annette Molinaro, and\nMark J Van Der Laan. 2005. “Survival\nensembles.” Biostatistics 7 (3): 355–73. https://doi.org/10.1093/biostatistics/kxj011.\n\n\nHothorn, Torsten, and Berthold Lausen. 2003. “On the exact distribution of maximally selected rank\nstatistics.” Computational Statistics & Data\nAnalysis 43 (2): 121–37. https://doi.org/10.1016/S0167-9473(02)00225-6.\n\n\nHothorn, Torsten, Berthold Lausen, Axel Benner, and Martin\nRadespiel-Tröger. 2004. “Bagging survival\ntrees.” Statistics in Medicine 23 (1): 77–91. https://doi.org/10.1002/sim.1593.\n\n\nHuang, Shigao, Jie Yang, Simon Fong, and Qi Zhao. 2020a. “Artificial intelligence in cancer diagnosis and\nprognosis: Opportunities and challenges.” Cancer\nLetters 471: 61–71. https://doi.org/https://doi.org/10.1016/j.canlet.2019.12.007.\n\n\n———. 2020b. “Artificial intelligence in\ncancer diagnosis and prognosis: Opportunities and\nchallenges.” Cancer Letters 471: 61–71.\nhttps://doi.org/https://doi.org/10.1016/j.canlet.2019.12.007.\n\n\nHung, Hung, and Chin-Tsang Chiang. 2010. “Estimation methods for time-dependent AUC models with\nsurvival data.” The Canadian Journal of Statistics /\nLa Revue Canadienne de Statistique 38 (1): 8–26. http://www.jstor.org/stable/27805213.\n\n\nHURVICH, CLIFFORD M, and CHIH-LING TSAI. 1989. “Regression and time series model selection in small\nsamples.” Biometrika 76 (2): 297–307. https://doi.org/10.1093/biomet/76.2.297.\n\n\nIshwaran, By Hemant, Udaya B Kogalur, Eugene H Blackstone, and Michael S\nLauer. 2008. “Random survival\nforests.” The Annals of Statistics 2 (3): 841–60.\nhttps://doi.org/10.1214/08-AOAS169.\n\n\nIshwaran, Hemant, Eugene H Blackstone, Claire E Pothier, and Michael S\nLauer. 2004. “Relative Risk Forests for\nExercise Heart Rate Recovery as a Predictor of Mortality.”\nJournal of the American Statistical Association 99 (467):\n591–600. https://doi.org/10.1198/016214504000000638.\n\n\nIshwaran, Hemant, and Udaya B Kogalur. 2018. “randomForestSRC.” https://cran.r-project.org/package=randomForestSRC.\n\n\nIshwaran, Hemant, Udaya B Kogalur, Xi Chen, and Andy J Minn. 2011.\n“Random Survival Forests for High-Dimensional\nData.” Statistical Analysis and Data Mining 4\n(1): 115–32. https://doi.org/10.1002/sam.\n\n\nJackson, Christopher. 2016. “flexsurv: A\nPlatform for Parametric Survival Modeling in R.”\nJournal of Statistical Software 70 (8): 1–33.\n\n\nJackson, Dan, Ian R. White, Shaun Seaman, Hannah Evans, Kathy Baisley,\nand James Carpenter. 2014. “Relaxing the\nindependent censoring assumption in the Cox proportional hazards model\nusing multiple imputation.” Statistics in\nMedicine 33 (27): 4681–94. https://doi.org/10.1002/sim.6274.\n\n\nJager, Kitty J, Paul C van Dijk, Carmine Zoccali, and Friedo W Dekker.\n2008. “The analysis of survival data: the\nKaplan–Meier method.” Kidney International 74\n(5): 560–65. https://doi.org/https://doi.org/10.1038/ki.2008.217.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani.\n2013. An introduction to statistical\nlearning. Vol. 112. New York: Springer.\n\n\nJing, Bingzhong, Tao Zhang, Zixian Wang, Ying Jin, Kuiyuan Liu, Wenze\nQiu, Liangru Ke, et al. 2019. “A deep\nsurvival analysis method based on ranking.” Artificial\nIntelligence in Medicine 98: 1–9. https://doi.org/https://doi.org/10.1016/j.artmed.2019.06.001.\n\n\nJohnson, Brent A, and Qi Long. 2011. “Survival ensembles by the sum of pairwise differences\nwith application to lung cancer microarray studies.”\nAnn. Appl. Stat. 5 (2A): 1081–101. https://doi.org/10.1214/10-AOAS426.\n\n\nKalbfleisch, J. D., and R. L. Prentice. 1973. “Marginal likelihoods based on Cox’s regression and life\nmodel.” Biometrika 60 (2): 267–78. https://doi.org/10.1093/biomet/60.2.267.\n\n\nKalbfleisch, John D, and Ross L Prentice. 2011. The statistical analysis of failure time\ndata. Vol. 360. John Wiley & Sons.\n\n\nKamarudin, Adina Najwa, Trevor Cox, and Ruwanthi Kolamunnage-Dona. 2017.\n“Time-dependent ROC curve analysis in medical\nresearch: Current methods and applications.” BMC\nMedical Research Methodology 17 (1): 1–19. https://doi.org/10.1186/s12874-017-0332-6.\n\n\nKaplan, E. L., and Paul Meier. 1958. “Nonparametric Estimation from Incomplete\nObservations.” Journal of the American Statistical\nAssociation 53 (282): 457–81. https://doi.org/10.2307/2281868.\n\n\nKatzman, Jared L, Uri Shaham, Alexander Cloninger, Jonathan Bates,\nTingting Jiang, and Yuval Kluger. 2018. “DeepSurv: personalized treatment recommender system using\na Cox proportional hazards deep neural network.” BMC\nMedical Research Methodology 18 (1): 24. https://doi.org/10.1186/s12874-018-0482-1.\n\n\nKatzman, Jared, Uri Shaham, Alexander Cloninger, Jonathan Bates,\nTingting Jiang, and Yuval Kluger. 2016. “Deep Survival: A\nDeep Cox Proportional Hazards Network,” June.\n\n\nKent, John T., and John O’Quigley. 1988. “Measures of dependence for censored survival\ndata.” Biometrika 75 (3): 525–34. https://doi.org/10.1093/biomet/75.3.525.\n\n\nKhan, Faisal M., and Valentina Bayer Zubek. 2008. “Support vector regression for censored data (SVRc): A\nnovel tool for survival analysis.” Proceedings - IEEE\nInternational Conference on Data Mining, ICDM, 863–68. https://doi.org/10.1109/ICDM.2008.50.\n\n\nKirály, Franz J, Bilal Mateen, and Raphael Sonabend. 2018. “NIPS - Not Even Wrong? A Systematic Review of Empirically\nComplete Demonstrations of Algorithmic Effectiveness in the Machine\nLearning and Artificial Intelligence Literature.”\narXiv, December. http://arxiv.org/abs/1812.07519.\n\n\nKirmani, S N U A, and Ramesh C Gupta. 2001. “On the Proportional Odds Model in Survival\nAnalysis.” Annals of the Institute of Statistical\nMathematics 53 (2): 203–16. https://doi.org/10.1023/A:1012458303498.\n\n\nKlein, John P, and Melvin L Moeschberger. 2003. Survival analysis: techniques for censored and truncated\ndata. 2nd ed. Springer Science & Business Media.\n\n\nKohavi, Ron. 1995. “A study of\ncross-validation and bootstrap for accuracy estimation and model\nselection.” Ijcai 14 (2): 1137–45.\n\n\nKorn, Edward L., and Richard Simon. 1990. “Measures of explained variation for survival\ndata.” Statistics in Medicine 9 (5): 487–503. https://doi.org/10.1002/sim.4780090503.\n\n\nKorn, Edward L, and Richard Simon. 1991. “Explained Residual Variation, Explained Risk, and\nGoodness of Fit.” The American Statistician 45\n(3): 201–6. https://doi.org/10.2307/2684290.\n\n\nKuhn, Max, and Julia Silge. 2023. Tidy Modeling with\nR. https://www.tmwr.org/.\n\n\nKvamme, Håvard. 2018. “Pycox.” https://pypi.org/project/pycox/.\n\n\nKvamme, Håvard, Ørnulf Borgan, and Ida Scheel. 2019. “Time-to-event prediction with neural networks and Cox\nregression.” Journal of Machine Learning Research\n20 (129): 1–30.\n\n\nLand, Walker H, Xingye Qiao, Dan Margolis, and Ron Gottlieb. 2011.\n“A new tool for survival analysis:\nevolutionary programming/evolutionary strategies (EP/ES) support vector\nregression hybrid using both censored / non-censored (event)\ndata.” Procedia Computer Science 6: 267–72.\nhttps://doi.org/https://doi.org/10.1016/j.procs.2011.08.050.\n\n\nLangford, John, Paul Mineiro, Alina Beygelzimer, and Hal Daume. 2016.\n“Learning Reductions that Really\nWork.” Proceedings of the IEEE 104 (1).\n\n\nLao, Jiangwei, Yinsheng Chen, Zhi-Cheng Li, Qihua Li, Ji Zhang, Jing\nLiu, and Guangtao Zhai. 2017. “A Deep\nLearning-Based Radiomics Model for Prediction of Survival in\nGlioblastoma Multiforme.” Scientific Reports 7\n(1): 10353. https://doi.org/10.1038/s41598-017-10649-8.\n\n\nLawless, Jerald F, and Yan Yuan. 2010. “Estimation of prediction error for survival\nmodels.” Statistics in Medicine 29 (2): 262–74.\nhttps://doi.org/10.1002/sim.3758.\n\n\nLeBlanc, Michael, and John Crowley. 1992. “Relative Risk Trees for Censored Survival\nData.” Biometrics 48 (2): 411–25. https://doi.org/10.2307/2532300.\n\n\n———. 1993. “Survival Trees by Goodness of\nSplit.” Journal of the American Statistical\nAssociation 88 (422): 457–67. https://doi.org/10.2307/2290325.\n\n\nLee, Changhee, William Zame, Jinsung Yoon, and Mihaela Van der Schaar.\n2018. “DeepHit: A Deep Learning Approach to\nSurvival Analysis With Competing Risks.” Proceedings\nof the AAAI Conference on Artificial Intelligence 32 (1). https://doi.org/10.1609/aaai.v32i1.11842.\n\n\nLee, Donald K K, Ningyuan Chen, and Hemant Ishwaran. 2019. “Boosted nonparametric hazards with time-dependent\ncovariates.” https://arxiv.org/abs/arXiv:1701.07926v6.\n\n\nLi, Liang, Tom Greene, and Bo Hu. 2018. “A\nsimple method to estimate the time-dependent receiver operating\ncharacteristic curve and the area under the curve with right censored\ndata.” Statistical Methods in Medical Research 27\n(8): 2264–78. https://doi.org/10.1177/0962280216680239.\n\n\nLiang, Hua, and Guohua Zou. 2008. “Improved\nAIC Selection Strategy for Survival Analysis.”\nComputational Statistics & Data Analysis 52 (5): 2538–48.\nhttps://doi.org/10.1016/j.csda.2007.09.003.\n\n\nLiestol, Knut, Per Kragh Andersen, and Ulrich Andersen. 1994.\n“Survival analysis and neural\nnets.” Statistics in Medicine 13 (12): 1189–1200.\nhttps://doi.org/10.1002/sim.4780131202.\n\n\nLundberg, Scott M, and Su-In Lee. 2017. “A\nUnified Approach to Interpreting Model Predictions.”\nAdvances in Neural Information Processing Systems 30.\n\n\nLundin, M, J Lundin, H B Burke, S Toikkanen, L Pylkkänen, and H Joensuu.\n1999. “Artificial Neural Networks Applied to\nSurvival Prediction in Breast Cancer.” Oncology\n57 (4): 281–86. https://doi.org/10.1159/000012061.\n\n\nLuxhoj, James T., and Huan Jyh Shyur. 1997. “Comparison of proportional hazards models and neural\nnetworks for reliability estimation.” Journal of\nIntelligent Manufacturing 8 (3): 227–34. https://doi.org/10.1023/A:1018525308809.\n\n\nMa, Shuangge, and Jian Huang. 2006. “Regularized ROC method for disease classification and\nbiomarker selection with microarray data.”\nBioinformatics (Oxford, England) 21 (January): 4356–62. https://doi.org/10.1093/bioinformatics/bti724.\n\n\nMani, D R, James Drew, Andrew Betz, and Piew Datta. 1999. “Statistics and data mining techniques for lifetime value\nmodeling.” In Proceedings of the Fifth ACM SIGKDD\nInternational Conference on Knowledge Discovery and Data Mining,\n94–103.\n\n\nMariani, L, D Coradini, E Biganzoli, P Boracchi, E Marubini, S Pilotti,\nB Salvadori, et al. 1997. “Prognostic factors\nfor metachronous contralateral breast cancer: A comparison of the linear\nCox regression model and its artificial neural network\nextension.” Breast Cancer Research and Treatment\n44 (2): 167–78. https://doi.org/10.1023/A:1005765403093.\n\n\nMayr, Andreas, Benjamin Hofner, and Matthias Schmid. 2016. “Boosting the discriminatory power of sparse survival\nmodels via optimization of the concordance index and stability\nselection.” BMC Bioinformatics 17 (1): 288. https://doi.org/10.1186/s12859-016-1149-8.\n\n\nMayr, Andreas, and Matthias Schmid. 2014. “Boosting the concordance index for survival data–a\nunified framework to derive and evaluate biomarker\ncombinations.” PloS One 9 (1): e84483–83. https://doi.org/10.1371/journal.pone.0084483.\n\n\nMcGough, Sarah F., Devin Incerti, Svetlana Lyalina, Ryan Copping,\nBalasubramanian Narasimhan, and Robert Tibshirani. 2021.\n“Penalized Regression for Left-Truncated and Right-Censored\nSurvival Data.” Statistics in Medicine 40 (25):\n5487–5500. https://doi.org/https://doi.org/10.1002/sim.9136.\n\n\nMcKinney, Scott Mayer, Marcin Sieniek, Varun Godbole, Jonathan Godwin,\nNatasha Antropova, Hutan Ashrafian, Trevor Back, et al. 2020.\n“International evaluation of an AI system for\nbreast cancer screening.” Nature 577 (7788):\n89–94. https://doi.org/10.1038/s41586-019-1799-6.\n\n\nMeinshausen, Nicolai, and Peter Bühlmann. 2010. “Stability selection.” Journal of the\nRoyal Statistical Society: Series B (Statistical Methodology) 72\n(4): 417–73. https://doi.org/10.1111/j.1467-9868.2010.00740.x.\n\n\nMoghimi-dehkordi, Bijan, Azadeh Safaee, Mohamad Amin Pourhoseingholi,\nReza Fatemi, Ziaoddin Tabeie, and Mohammad Reza Zali. 2008. “Statistical Comparison of Survival Models for Analysis of\nCancer Data.” Asian Pacific Journal of Cancer\nPrevention 9: 417–20.\n\n\nMolnar, Christoph. 2019. Interpretable Machine\nLearning. https://christophm.github.io/interpretable-ml-book/.\n\n\nMurphy, Allan H. 1973. “A New Vector\nPartition of the Probability Score.” Journal of\nApplied Meteorology and Climatology 12 (4): 595–600. https://doi.org/10.1175/1520-0450(1973)012&lt;0595:ANVPOT&gt;2.0.CO;2.\n\n\nN. Venables, W, and B D. Ripley. 2002. Modern\nApplied Statistics with S. Springer. http://www.stats.ox.ac.uk/pub/MASS4.\n\n\nNadeau, Claude, and Yoshua Bengio. 2003. “Inference for the Generalization Error.”\nMachine Learning 52 (3): 239–81. https://doi.org/10.1023/A:1024068626366.\n\n\nNair, Vinod, and Geoffrey E Hinton. 2010. “Rectified linear units improve restricted boltzmann\nmachines.” In Proceedings of the 27th International\nConference on Machine Learning (ICML-10), 807–14.\n\n\nNelson, Wayne. 1972. “Theory and Applications\nof Hazard Plotting for Censored Failure Data.”\nTechnometrics 14 (4): 945–66.\n\n\nNg, Ryan, Kathy Kornas, Rinku Sutradhar, Walter P. Wodchis, and Laura C.\nRosella. 2018. “The current application of\nthe Royston-Parmar model for prognostic modeling in health research: a\nscoping review.” Diagnostic and Prognostic\nResearch 2 (1): 4. https://doi.org/10.1186/s41512-018-0026-5.\n\n\nOh, Sung Eun, Sung Wook Seo, Min-Gew Choi, Tae Sung Sohn, Jae Moon Bae,\nand Sung Kim. 2018. “Prediction of Overall\nSurvival and Novel Classification of Patients with Gastric Cancer Using\nthe Survival Recurrent Network.” Annals of Surgical\nOncology 25 (5): 1153–59. https://doi.org/10.1245/s10434-018-6343-7.\n\n\nOhno-Machado, Lucila. 1996. “Medical\napplications of artificial neural networks: connectionist models of\nsurvival.” Stanford University Stanford, Calif.\n\n\n———. 1997. “A COMPARISON OF COX PROPORTIONAL\nHAZARDS AND ARTIFICIAL NEURAL NETWORK MODELS FOR MEDICAL PROGNOSIS The\ntheoretical advantages and disadvantages of using different methods for\npredicting survival have seldom been tested in real data sets [ 1 , 2 ].\nAlthou.” Comput. Biol. Med 27 (1): 55–65.\n\n\nPatel, Katie, Richard Kay, and Lucy Rowell. 2006. “Comparing proportional hazards and accelerated failure\ntime models: An application in influenza.”\nPharmaceutical Statistics 5 (3): 213–24. https://doi.org/10.1002/pst.213.\n\n\nPölsterl, Sebastian. 2020. “scikit-survival:\nA Library for Time-to-Event Analysis Built on Top of\nscikit-learn.” Journal of Machine Learning\nResearch 21 (212): 1–6. http://jmlr.org/papers/v21/20-729.html.\n\n\nProbst, Philipp, Anne-Laure Boulesteix, and Bernd Bischl. 2019.\n“Tunability: Importance of Hyperparameters of Machine Learning\nAlgorithms.” Journal of Machine Learning Research 20\n(53): 1–32. http://jmlr.org/papers/v20/18-444.html.\n\n\nPuddu, Paolo Emilio, and Alessandro Menotti. 2012. “Artificial neural networks versus proportional hazards\nCox models to predict 45-year all-cause mortality in the Italian Rural\nAreas of the Seven Countries Study.” BMC Medical\nResearch Methodology 12 (1): 100. https://doi.org/10.1186/1471-2288-12-100.\n\n\nQi, Jiezhi. 2009. “Comparison of Proportional\nHazards and Accelerated Failure Time Models.” PhD thesis.\n\n\nR., Cox, and Snell J. 1968. “A General\nDefinition of Residuals.” Journal of the Royal\nStatistical Society: Series B (Statistical Methodology) 30 (2):\n248–75.\n\n\nRahman, M. Shafiqur, Gareth Ambler, Babak Choodari-Oskooei, and Rumana\nZ. Omar. 2017. “Review and evaluation of\nperformance measures for survival prediction models in external\nvalidation settings.” BMC Medical Research\nMethodology 17 (1): 1–15. https://doi.org/10.1186/s12874-017-0336-2.\n\n\nReid, Nancy. 1994. “A Conversation with Sir\nDavid Cox.” Statistical Science 9 (3): 439–55. https://doi.org/10.1214/aos/1176348654.\n\n\nRidgeway, Greg. 1999. “The state of\nboosting.” Computing Science and Statistics 31:\n172–81.\n\n\nRietschel, Carl, Jinsung Yoon, and Mihaela van der Schaar. 2018.\n“Feature Selection for Survival Analysis with\nCompeting Risks using Deep Learning.” arXiv Preprint\narXiv:1811.09317.\n\n\nRindt, David, Robert Hu, David Steinsaltz, and Dino Sejdinovic. 2022.\n“Survival Regression with Proper Scoring\nRules and Monotonic Neural Networks,” March. http://arxiv.org/abs/2103.14755.\n\n\nRipley, Brian D, and Ruth M Ripley. 2001. “Neural networks as statistical methods in survival\nanalysis.” In Clinical Applications of Artificial\nNeural Networks, edited by Richard Dybowski and Vanya Gant, 237–55.\nCambridge: Cambridge University Press. https://doi.org/DOI:\n10.1017/CBO9780511543494.011.\n\n\nRipley, R M, A L Harris, and L Tarassenko. 1998. “Neural network models for breast cancer\nprognosis.” Neural Computing & Applications 7\n(4): 367–75. https://doi.org/10.1007/BF01428127.\n\n\nRoyston, P. 2001. “The Lognormal Distribution\nas a Model for Survival Time in Cancer, With an Emphasis on Prognostic\nFactors.” Statistica Neerlandica 55 (1): 89–104.\nhttps://doi.org/10.1111/1467-9574.00158.\n\n\nRoyston, Patrick, and Douglas G. Altman. 2013. “External validation of a Cox prognostic model: Principles\nand methods.” BMC Medical Research Methodology 13\n(1). https://doi.org/10.1186/1471-2288-13-33.\n\n\nRoyston, Patrick, Mahesh K B Parmar, and Douglas G Altman. 2008.\n“Visualizing Length of Survival in\nTime-to-Event Studies: A Complement to Kaplan–Meier\nPlots.” JNCI: Journal of the National Cancer\nInstitute 100 (2): 92–97. https://doi.org/10.1093/jnci/djm265.\n\n\nRoyston, Patrick, and Mahesh K. B. Parmar. 2002. “Flexible parametric proportional-hazards and\nproportional-odds models for censored survival data, with application to\nprognostic modelling and estimation of treatment effects.”\nStatistics in Medicine 21 (15): 2175–97. https://doi.org/10.1002/sim.1203.\n\n\nRoyston, Patrick, and Willi Sauerbrei. 2004. “A new measure of prognostic separation in survival\ndata.” Statistics in Medicine 23 (5): 723–48. https://doi.org/10.1002/sim.1621.\n\n\nSashegyi, Andreas, and David Ferry. 2017. “On\nthe Interpretation of the Hazard Ratio and Communication of Survival\nBenefit.” The Oncologist 22 (4): 484–86. https://doi.org/10.1634/theoncologist.2016-0198.\n\n\nSchemper, Michael, and Robin Henderson. 2000. “Predictive Accuracy and Explained Variation in Cox\nRegression.” Biometrics 56: 249–55. https://doi.org/10.1002/sim.1486.\n\n\nSchmid, Matthias, Thomas Hielscher, Thomas Augustin, and Olaf Gefeller.\n2011. “A Robust Alternative to the\nSchemper-Henderson Estimator of Prediction Error.”\nBiometrics 67 (2): 524–35. https://doi.org/10.1111/j.1541-0420.2010.01459.x.\n\n\nSchmid, Matthias, and Torsten Hothorn. 2008a. “Boosting additive models using component-wise\nP-splines.” Computational Statistics & Data\nAnalysis 53 (2): 298–311.\n\n\n———. 2008b. “Flexible boosting of accelerated\nfailure time models.” BMC Bioinformatics 9\n(February): 269. https://doi.org/10.1186/1471-2105-9-269.\n\n\nSchmid, Matthias, and Sergej Potapov. 2012. “A comparison of estimators to evaluate the discriminatory\npower of time-to-event models.” Statistics in\nMedicine 31 (23): 2588–2609. https://doi.org/10.1002/sim.5464.\n\n\nSchmid, Matthias, Marvin Wright, and Andreas Ziegler. 2016. “On\nthe Use of Harrell’s c for Clinical Risk Prediction via Random Survival\nForests.” Expert Systems with Applications 63 (July). https://doi.org/10.1016/j.eswa.2016.07.018.\n\n\nSchwarzer, Guido, Werner Vach, and Martin Schumacher. 2000. “On the misuses of artificial neural networks for\nprognostic and diagnostic classification in oncology.”\nStatistics in Medicine 19 (4): 541–61. https://doi.org/10.1002/(SICI)1097-0258(20000229)19:4&lt;541::AID-SIM355&gt;3.0.CO;2-V.\n\n\nSegal, Mark Robert. 1988. “Regression Trees\nfor Censored Data.” Biometrics 44 (1): 35–47.\n\n\nSeker, H, M O Odetayo, D Petrovic, R N G Naguib, C Bartoli, L Alasio, M\nS Lakshmi, G V Sherbet, and O R Hinton. 2002. “An artificial neural network based feature evaluation\nindex for the assessment of clinical factors in breast cancer survival\nanalysis.” In IEEE CCECE2002. Canadian Conference on\nElectrical and Computer Engineering. Conference Proceedings (Cat.\nNo.02CH37373), 2:1211–1215 vol.2. https://doi.org/10.1109/CCECE.2002.1013121.\n\n\nSeker, Huseyin, Michael O Odetayo, Dobrila Petrovic, Raouf N G Naguib, C\nBartoli, L Alasio, M S Lakshmi, and G V Sherbet. 2002. “Assessment of nodal involvement and survival analysis in\nbreast cancer patients using image cytometric data: statistical, neural\nnetwork and fuzzy approaches.” Anticancer\nResearch 22 (1A): 433–38. http://europepmc.org/abstract/MED/12017328.\n\n\nShivaswamy, Pannagadatta K., Wei Chu, and Martin Jansche. 2007.\n“A support vector approach to censored\ntargets.” In Proceedings - IEEE International\nConference on Data Mining, ICDM, 655–60. https://doi.org/10.1109/ICDM.2007.93.\n\n\nSimon, Richard. 2007. “Resampling Strategies for Model Assessment\nand Selection.” In Fundamentals of Data Mining in Genomics\nand Proteomics, edited by Werner Dubitzky, Martin Granzow, and\nDaniel Berrar, 173–86. Boston, MA: Springer US. https://doi.org/10.1007/978-0-387-47509-7_8.\n\n\nSonabend, Raphael. 2020. “survivalmodels:\nModels for Survival Analysis.” CRAN. https://raphaels1.r-universe.dev/ui#package:survivalmodels.\n\n\nSonabend, Raphael Edward Benjamin. 2021. “A\nTheoretical and Methodological Framework for Machine Learning in\nSurvival Analysis: Enabling Transparent and Accessible Predictive\nModelling on Right-Censored Time-to-Event Data.” PhD,\nUniversity College London (UCL). https://discovery.ucl.ac.uk/id/eprint/10129352/.\n\n\nSonabend, Raphael, Andreas Bender, and Sebastian Vollmer. 2022.\n“Avoiding C-hacking when evaluating survival\ndistribution predictions with discrimination measures.”\nEdited by Zhiyong Lu. Bioinformatics 38 (17): 4178–84. https://doi.org/10.1093/bioinformatics/btac451.\n\n\nSonabend, Raphael, Franz J Király, Andreas Bender, Bernd Bischl, and\nMichel Lang. 2021. “mlr3proba: an R package\nfor machine learning in survival analysis.” Edited by\nJonathan Wren. Bioinformatics 37 (17): 2789–91. https://doi.org/10.1093/bioinformatics/btab039.\n\n\nSonabend, Raphael, Florian Pfisterer, Alan Mishler, Moritz Schauer,\nLukas Burk, Sumantrak Mukherjee, and Sebastian Vollmer. 2022.\n“Flexible Group Fairness Metrics for Survival\nAnalysis.” In DSHealth 2022 Workshop on Applied Data\nScience for Healthcare at KDD2022. http://arxiv.org/abs/2206.03256.\n\n\nSonabend, Raphael, John Zobolas, Philipp Kopper, Lukas Burk, and Andreas\nBender. 2024. “Examining properness in the\nexternal validation of survival models with squared and logarithmic\nlosses,” December. http://arxiv.org/abs/2212.05260.\n\n\nSong, Xiao, and Xiao-Hua Zhou. 2008. “A\nsemiparametric approach for the covariate specific ROC curve with\nsurvival outcome.” Statistica Sinica 18 (July):\n947–65.\n\n\nSpooner, Annette, Emily Chen, Arcot Sowmya, Perminder Sachdev, Nicole A\nKochan, Julian Trollor, and Henry Brodaty. 2020. “A comparison of machine learning methods for survival\nanalysis of high-dimensional clinical data for dementia\nprediction.” Scientific Reports 10 (1): 20410. https://doi.org/10.1038/s41598-020-77220-w.\n\n\nSpruance, Spotswood L, Julia E Reid, Michael Grace, and Matthew Samore.\n2004. “Hazard ratio in clinical\ntrials.” Antimicrobial Agents and Chemotherapy 48\n(8): 2787–92. https://doi.org/10.1128/AAC.48.8.2787-2792.2004.\n\n\nSrivastava, Nitish, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever,\nand Ruslan Salakhutdinov. 2014. “Dropout: a\nsimple way to prevent neural networks from overfitting.”\nThe Journal of Machine Learning Research 15 (1): 1929–58.\n\n\nStasinopoulos, Mikis, Bob Rigby, Vlasios Voudouris, and Daniil Kiose.\n2020. “gamlss.add: Extra Additive Terms for\nGeneralized Additive Models for Location Scale and Shape.”\nCRAN. https://cran.r-project.org/package=gamlss.add.\n\n\nStreet, W Nick. 1998. “A Neural Network Model\nfor Prognostic Prediction.” In Proceedings of the\nFifteenth International Conference on Machine Learning. San\nFrancisco.\n\n\nSuresh, Krithika, Cameron Severn, and Debashis Ghosh. 2022. “Survival prediction models: an introduction to\ndiscrete-time modeling.” BMC Medical Research\nMethodology 22 (1): 207. https://doi.org/10.1186/s12874-022-01679-6.\n\n\nTherneau, Terry M. 2015. “A Package for\nSurvival Analysis in S.” https://cran.r-project.org/package=survival.\n\n\nTherneau, Terry M., and Elizabeth Atkinson. 2020.\n“Concordance.” https://cran.r-project.org/web/packages/survival/vignettes/concordance.pdf.\n\n\nTherneau, Terry M., Patricia M. Grambsch, and Thomas R. Fleming. 1990.\n“Martingale-based residuals for survival\nmodels.” Biometrika 77 (1): 147–60. https://doi.org/10.1093/biomet/77.1.147.\n\n\nTsoumakas, Grigorios, and Ioannis Katakis. 2007.\n“Multi-Label Classification: An Overview.”\nInternational Journal of Data Warehousing and Mining 3 (3):\n1–13. https://doi.org/10.4018/jdwm.2007070101.\n\n\nTutz, Gerhard, and Harald Binder. 2007. “Boosting Ridge\nRegression.” Computational Statistics & Data\nAnalysis 51 (February): 6044–59. https://doi.org/10.1016/j.csda.2006.11.041.\n\n\nTutz, Gerhard, and Matthias Schmid. 2016. Modeling Discrete Time-to-Event Data.\nSpringer Series in Statistics. Cham: Springer International Publishing.\nhttps://doi.org/10.1007/978-3-319-28158-2.\n\n\nUno, Hajime, Tianxi Cai, Michael J. Pencina, Ralph B. D’Agostino, and L\nJ Wei. 2011. “On the C-statistics for\nEvaluating Overall Adequacy of Risk Prediction Procedures with Censored\nSurvival Data.” Statistics in Medicine 30 (10):\n1105–17. https://doi.org/10.1002/sim.4154.\n\n\nUno, Hajime, Tianxi Cai, Lu Tian, and L J Wei. 2007. “Evaluating Prediction Rules for t-Year Survivors with\nCensored Regression Models.” Journal of the American\nStatistical Association 102 (478): 527–37. http://www.jstor.org/stable/27639883.\n\n\nUshey, Kevin, J J Allaire, and Yuan Tang. 2020. “reticulate: Interface to ’Python’.” CRAN.\nhttps://cran.r-project.org/package=reticulate.\n\n\nVakulenko-Lagun, Bella, Micha Mandel, and Rebecca A. Betensky. 2020.\n“Inverse Probability Weighting Methods for Cox\nRegression with Right-Truncated Data.”\nBiometrics 76 (2): 484–95. https://doi.org/10.1111/biom.13162.\n\n\nVan Belle, Vanya, Kristiaan Pelckmans, Johan A K Suykens, and Sabine Van\nHuffel. 2008. “Survival SVM: a practical\nscalable algorithm.” In Proceedings of the 16th\nEuropean Symposium on Artificial Neural Networks (ESANN), 89–94.\n\n\nVan Belle, Vanya, Kristiaan Pelckmans, Johan A. K. Suykens, and Sabine\nVan Huffel. 2007. “Support Vector Machines\nfor Survival Analysis.” In In Proceedings of the Third\nInternational Conference on Computational Intelligence in Medicine and\nHealthcare. 1.\n\n\nVan Belle, Vanya, Kristiaan Pelckmans, Sabine Van Huffel, and Johan A.\nK. Suykens. 2011. “Support vector methods for\nsurvival analysis: A comparison between ranking and regression\napproaches.” Artificial Intelligence in Medicine\n53 (2): 107–18. https://doi.org/10.1016/j.artmed.2011.06.006.\n\n\nVan Houwelingen, Hans C. 2000. “Validation,\ncalibration, revision and combination of prognostic survival\nmodels.” Statistics in Medicine 19 (24): 3401–15.\nhttps://doi.org/10.1002/1097-0258(20001230)19:24&lt;3401::AID-SIM554&gt;3.0.CO;2-2.\n\n\n———. 2007. “Dynamic prediction by landmarking\nin event history analysis.” Scandinavian Journal of\nStatistics 34 (1): 70–85. https://doi.org/10.1111/j.1467-9469.2006.00529.x.\n\n\nVinzamuri, Bhanukiran, Yan Li, and Chandan K. Reddy. 2017. “Pre-processing censored survival data using inverse\ncovariance matrix based calibration.” IEEE\nTransactions on Knowledge and Data Engineering 29 (10): 2111–24. https://doi.org/10.1109/TKDE.2017.2719028.\n\n\nVock, David M, Julian Wolfson, Sunayan Bandyopadhyay, Gediminas\nAdomavicius, Paul E Johnson, Gabriela Vazquez-Benitez, and Patrick J\nO’Connor. 2016. “Adapting machine learning\ntechniques to censored time-to-event health record data: A\ngeneral-purpose approach using inverse probability of censoring\nweighting.” Journal of Biomedical Informatics 61:\n119–31. https://doi.org/https://doi.org/10.1016/j.jbi.2016.03.009.\n\n\nVolinsky, Chris T, and Adrian E Raftery. 2000. “Bayesian Information Criterion for Censored Survival\nModels.” International Biometric Society 56 (1):\n256–62.\n\n\nWang, Ping, Yan Li, and Chandan K. Reddy. 2019. “Machine Learning for Survival Analysis.”\nACM Computing Surveys 51 (6): 1–36. https://doi.org/10.1145/3214306.\n\n\nWang, Zhu, and C Y Wang. 2010. “Buckley-James\nBoosting for Survival Analysis with High-Dimensional Biomarker\nData.” Statistical Applications in Genetics and\nMolecular Biology 9 (1). https://doi.org/https://doi.org/10.2202/1544-6115.1550.\n\n\nWei, L J. 1992. “The Accelerated Failure Time\nModel: A Useful Alternative to the Cox Regression Model in Survival\nAnalysis.” Statistics in Medicine 11: 1871–79.\n\n\nWelchowski, Thomas, and Matthias Schmid. 2019. “discSurv: Discrete Time Survival Analysis.”\nCRAN. https://cran.r-project.org/package=discSurv.\n\n\nWickham, Hadley. 2016. ggplot2: Elegant\nGraphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org.\n\n\nWright, Marvin N., and Andreas Ziegler. 2017. “ranger: A Fast Implementation of Random Forests for High\nDimensional Data in C++ and R.” Journal of Statistical\nSoftware 77 (1): 1–17.\n\n\nXiang, Anny, Pablo Lapuerta, Alex Ryutov, Jonathan Buckley, and Stanley\nAzen. 2000. “Comparison of the performance of\nneural network methods and Cox regression for censored survival\ndata.” Computational Statistics & Data\nAnalysis 34 (2): 243–57. https://doi.org/https://doi.org/10.1016/S0167-9473(99)00098-5.\n\n\nYang, Yanying. 2010. “Neural Network Survival\nAnalysis.” PhD thesis, Universiteit Gent.\n\n\nYasodhara, Angeline, Mamatha Bhat, and Anna Goldenberg. 2018. Prediction of New Onset Diabetes after Liver\nTransplant.\n\n\nZare, Ali, Mostafa Hosseini, Mahmood Mahmoodi, Kazem Mohammad, Hojjat\nZeraati, and Kourosh Holakouie Naieni. 2015. “A Comparison between Accelerated Failure-time and Cox\nProportional Hazard Models in Analyzing the Survival of Gastric Cancer\nPatients.” Iranian Journal of Public Health 44\n(8): 1095–1102. https://doi.org/10.1007/s00606-006-0435-8.\n\n\nZhang, Yucheng, Edrise M Lobo-Mueller, Paul Karanicolas, Steven\nGallinger, Masoom A Haider, and Farzad Khalvati. 2020. “CNN-based survival model for pancreatic ductal\nadenocarcinoma in medical imaging.” BMC Medical\nImaging 20 (1): 11. https://doi.org/10.1186/s12880-020-0418-1.\n\n\nZhao, Lili, and Dai Feng. 2020. “Deep Neural\nNetworks for Survival Analysis Using Pseudo Values.”\nIEEE Journal of Biomedical and Health Informatics 24 (11):\n3308–14. https://doi.org/10.1109/JBHI.2020.2980204.\n\n\nZhou, Zheng, Elham Rahme, Michal Abrahamowicz, and Louise Pilote. 2005.\n“Survival Bias Associated with\nTime-to-Treatment Initiation in Drug Effectiveness Evaluation: A\nComparison of Methods.” American Journal of\nEpidemiology 162 (10): 1016–23. https://doi.org/10.1093/aje/kwi307.\n\n\nZhu, Wan, Longxiang Xie, Jianye Han, and Xiangqian Guo. 2020.\n“The Application of Deep Learning in Cancer\nPrognosis Prediction.” Cancers 12 (3): 603. https://doi.org/10.3390/cancers12030603.\n\n\nZhu, X, J Yao, and J Huang. 2016. “Deep\nconvolutional neural network for survival analysis with pathological\nimages.” In 2016 IEEE International Conference on\nBioinformatics and Biomedicine (BIBM), 544–47. https://doi.org/10.1109/BIBM.2016.7822579.",
    "crumbs": [
      "References"
    ]
  }
]