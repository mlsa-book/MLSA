{{< include _setup.qmd >}}
# Preface {.unnumbered}

> "Everything happens to everybody sooner or later if there is time enough" - George Bernard Shaw

> "...but in this world nothing can be said to be certain, except death and taxes." - Benjamin Franklin

Together, the epigraphs for this book perfectly and succinctly sets up the 'survival problem'.
In maths perhaps we could be even more succinct: $\forall X (P(X) \rightarrow 1\text{ as t }\rightarrow \infty)$.
Of course, nothing is immortal and therefore there is never 'time enough'.
Thus creating the predictive 'survival problem': given an individual (object), predict when this individual will experience an event of interest.
The 'problem' in survival analysis is that we implicitly assume the individual *will* experience the event, which is of course not guaranteed (with the exception of death or taxes).
To make matters worse, the vast majority of accessible models to make survival predictions, encode an even stricter assumption, that either the event of interest will occur, or, for some completely unrelated reason, it will not.
For example, a model assumes either a marathon runner will finish a race, or they won't due to some arbitrary reason, e.g., someone else pushing them over.
This assumption does not reflect the real-world, in practice the runner may not finish the marathon due to some related reasons, such as extreme exhaustion.

When I (RS) began writing my PhD thesis I was motivated by two questions: given the enormous power of survival analysis (who doesn't want to be able to predict the future?), and given the rapid rise in interest in machine learning, i) why are more data scientists not using machine learning? ii) and why do machine learning models fail to outperform simple, classical models that have been around for decades?
The answer it transpired was fairly simple, and largely ignored by researchers (including myself), for decades.
The survival analysis problem is simply impossible.
In 1975, Anastasios Tsiatis published a paper as part of their PhD submission [@Tsiatis1975] demonstrating the 'non-identifiability problem' in survival analysis.
In the abstract of this paper, Tsiatis sums up the problem we face today: "based on the assumption that [competing events] are independent, may have no resemblance to reality".
In simpler terms, the majority of survival models encode an assumption that is very hard (/impossible) to justify in reality and in doing so, predictions made by these models "may have no resemblance to reality".
Despite this, the majority of this book is going to focus on these models, and we will come back to why after a brief detour to the alternative treatment of events.

[FIXME: Would be nice to have something from Andi here about CR]

So in this book, we will consider both the 'standard framework' and the competing risks framework.
Instead of treating these as two distinct parts to the book, we will interweave methods throughout the narrative, to highlight our belief that all practitioners should have an equally firm grasp on both settings.
Where competing risk alternatives do not yet exist, readers are directed to @sec-car which includes a section on extending *any* survival model, to the competing risks setting.
Some readers may be questioning why we event both including the non-competing framework at all, which is a reasonable question.
The answer is threefold, firstly there are times when this setting is appropriate, if you can reasonably justify that the sole reason for an event not occurring is independent of the event itself (we will see examples of this later in the book), then this framework is valid and is the simpler setting; secondly, as mentioned above, any model in this framework can be extended to competing risks, and therefore knowing about these models is still important; thirdly, so that readers who may be reviewing other academic texts, can spot errors and help correct them when found in the wild.

### How to use this book

[FIX ME]
