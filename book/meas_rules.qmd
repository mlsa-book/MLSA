---
abstract: TODO (150-200 WORDS)
---

{{< include _setup.qmd >}}

# Evaluating Distributions by Scoring Rules {#sec-eval-distr}

{{< include _wip.qmd >}}

Scoring rules evaluate probabilistic predictions and (attempt to) measure the overall predictive ability of a model, i.e. both calibration and discrimination [@Gneiting2007; @Murphy1973]. Scoring rules have been gaining in popularity for the past couple of decades since probabilistic forecasts were recognised to be superior than deterministic predictions for capturing uncertainity in predictions [@Dawid1984; @Dawid1986]. Formalisation and development of scoring rules has primarily been due to Dawid [@Dawid1984; @Dawid1986; @Dawid2014] and Gneiting and Raftery [@Gneiting2007]; though the earliest measures promoting ''rational'' and ''honest'' decision making date back to the 1950s [@Brier1950; @Good1952]. Whilst several scoring rules have been proposed for classification problems, fewer exist for probabilistic regression predictions [@Gneiting2007] and even fewer for survival analysis. In practice, only three continuous scoring rules for regression are employed (though the last two of these are often conflated), the integrated Brier score [@Brier1950], the log loss [@Good1952], and the integrated log loss.^[These often appear under many different names. The Brier score is often referred to as the 'squared-error loss', or 'quadratic score', and the log loss often appears as the 'log score', 'logarithmic loss', 'cross-entropy loss', or 'negative log-likelihood'.] In survival analysis only one scoring rule was found to be routinely employed. In fact, there is no recognised definition of a scoring rule in survival analysis, nor definitions for the fundamental scoring rule properties of (strict) properness. This section attempts to fill these gaps and to explore the proposed scoring rules for survival analysis.^[In this section a 'scoring rule' refers to the general class of measures that evaluate a probabilistic prediction and a 'loss' refers to the specific function to be minimised. As all scoring rules are optimally minimised in this survey, the terms are used interchangeably.]

This survey of survival scoring rules covers:

i. basic definitions for scoring rules and properties;
i. proposed scoring rules for survival analysis;
i. proofs for (strict) properness; and
i. baselines and standard errors for scoring rules.

Key contributions include demonstrating that no commonly-utilised survival scoring rule is proper and deriving a class of strictly proper outcome-independent scoring rules with strict assumptions (see @sec-eval-distr-score-surv for definitions and @sec-eval-distr-score-proper for proofs).

Each of these subsections is built up in complexity, starting with binary classification, then probabilistic regression, and finally survival. This is required to demonstrate how the survival setting makes use of the other two for scoring rules.

To recap the notation from @sec-surv, the three mathematical settings are defined by the generative processes:

* Regression: $(X,Y) \ t.v.i. \ \calX \times \calY$ where $\calX \subseteq \Reals^p$ and $\calY \subseteq \Reals$.
* Classification: $(X,Y) \ t.v.i. \ \calX \times \calY$ where $\calX \subseteq \Reals^p$ and $\calY = \bset$.
* Survival: $(X,T,\Delta,Y,C) \ t.v.i. \ \calX \times \calT \times \bset \times \calT \times \calT$ where $X \subseteq \Reals^p$ and $\calT \subseteq \NNReals$, where $C,Y$ are unobservable, $T := \min\{Y,C\}$, and $\Delta = \II(Y = T)$.

As the sections are clearly separated, the overloaded notation will be clear from context.

### Classification and Regression Scoring Rules {#sec-eval-distr-score-reg}

Definitions and losses in the classification setting are first discussed and then the same in the regression setting.

#### Classification

All scoring rules were initially derived from the binary classification setting, in this case scoring rules are considered to have the form in @cnj-loss-classif.

:::: {.callout-note icon=false}

## Binary classification loss

::: {#cnj-loss-classif}
Let $\calP$ be some family of distributions over $\calY = \bset$ containing at least two elements. Then for a predicted distribution in $\calP$, any real-valued function with the signature $L: \calP \times \calY \rightarrow \ExtReals$ will be considered as a *binary classification loss*.
:::

::::

Any arbitrary function can be a binary classification loss as long as it satisfies the conditions in @cnj-loss-classif, for example $L(\zeta, y) = 0$ is a valid loss for all $\zeta \in \calP$ and all $y \in \calY$. Therefore a scoring rule is generally only considered useful if it satisfies the properties below [@Gneiting2007].

::: {#def-classif-proper}

## Classification loss properness

A classification loss  $L: \calP \times \calY \rightarrow \ExtReals$ is called:

i. *Proper* if: for any distributions $p_Y,p$ in $\calP$ and for any random variables $Y \sim p_Y$, it holds that

$$
\EE[L(p_Y, Y)] \leq \EE[L(p, Y)]
$$
i. *Strictly proper* if in addition to being proper it holds, for the same quantification of variables, that

$$
\EE[L(p_Y, Y)] = \EE[L(p, Y)] \Leftrightarrow p = p_Y
$$

:::

Proper scoring rules provide a method of model comparison as, by definition, predictions closest to the true distribution will result in lower expected losses.^[Further details for model comparison are not provided here as the topic is complex and with many open questions, see e.g. [@Demsar2006; @Dietterich1998; @Nadeau2003].] On the other hand, if a scoring rule is not proper ('improper' [@Gneiting2007]) then it has no meaningful comparison as it is unknown if the optimal model would have a lower or higher loss than any sub-optimal one. A strictly proper scoring rule has additional important uses such as in model optimisation, i.e. if a loss is strictly proper then minimisation of the loss will result in the 'optimum score estimator based on the scoring rule' [@Gneiting2007]. Whilst properness is usually a minimal acceptable property for a scoring rule, it is generally not sufficient on its own. For example, take the following classification loss,

$$
L: \calP \times \calY \rightarrow \ExtReals;
\quad (\zeta, y) \mapsto 42
$$
This is proper as the loss, $L$, is always equal to $42$ and therefore is minimised by the true distribution of $Y$ but the loss is clearly useless. Properness and strict properness properties are utilised to determine if a scoring rule is performant and will be stated (if previously proved/disproved) or proved/disproved for all losses going forward.

#### Losses {.unnumbered .unlisted}


The two most widely used scoring rules for classification are the Brier score [@Brier1950] and log loss [@Good1952].^[Despite being called a 'score', the Brier score is in fact a loss to be minimised.]

The (binary classification) log loss is defined by

$$
\begin{split}
&L_{LL}:\calP \times \calY \rightarrow \NNReals; \\
&(\zeta, y) \mapsto -\II(y = 1)\log(\zeta.p(1)) - \II(y = 0)\log(\zeta.p(0))
\end{split}
$$
or more simply

$$
(\zeta, y) \mapsto -\log \zeta.p(y)
$$

The (binary classification) Brier score is defined by

$$
L_{BS}:\calP \times \calY \rightarrow [0,1]; \quad
(\zeta, y) \mapsto (y - \zeta.p(y))^2
$$

These are both strictly proper scoring rules [@Dawid2014] and are visualised in @fig-eval-brierlog to demonstrate their properties. The figure highlights the 'honesty' property of the scoring rules (i.e. their strict properness) as both losses are shown to be minimised when the true prediction is made. The plot also demonstrates baselines for interpretability (@sec-eval-distr-score-base-base). For the Brier score and log loss, any result below 0.25 and 0.693 respectively indicates a prediction better than a constant uninformed prediction of $\zeta.p(1) = 0.5$. Therefore classification scoring rules provide a method to simultaneously encourage honest predictions and have in-built informative baselines for external reference.

![Brier and log loss scoring rules for a binary outcome and varying probabilistic predictions. x-axis is a probabilistic prediction in $[0,1]$, y-axis is Brier score (left) and log loss (right). Blue lines are varying Brier score/log loss over different predicted probabilities when the true outcome is 1. Red lines are varying Brier score/log loss over different predicted probabilities when the true outcome is 0. Both losses are minimised with the correct prediction, i.e. if $\zeta.p(1) = 1$ when $y = 1$ and $\zeta.p(1) = 0$ when $y = 0$ for a predicted discrete distribution $\zeta$.](Figures/evaluation/brier_logloss.png){#fig-eval-brierlog fig-alt="TODO"}

#### Regression {#sec-eval-distr-score-reg-reg}

The definition of a probabilistic regression scoring rule follows similarly to the classification setting after a re-specification of the target domain.

:::: {.callout-note icon=false}

## Probabilistic regression loss

::: {#cnj-loss-regr}
Let $\calP$ be some family of distributions over $\calY \subseteq \Reals$ containing at least two elements. Then for a predicted distribution in $\calP$, any real-valued function with the signature $L: \calP \times \calY \rightarrow \ExtReals$ will be considered as a *probabilistic regression loss*.

:::

::::

::: {#def-regr-proper}

## Regression loss properness

A probabilistic regression loss  $L: \calP \times \calY \rightarrow \ExtReals$ is called:

i. *Proper* if: for any distributions $p_Y,p$ in $\calP$ and for any random variables $Y \sim p_Y$, it holds that

$$
\EE[L(p_Y, Y)] \leq \EE[L(p, Y)]
$$
i. *Strictly proper* if in addition to being proper it holds, for the same quantification of variables, that

$$
\EE[L(p_Y, Y)] = \EE[L(p, Y)] \Leftrightarrow p = p_Y
$$

:::

#### Losses {.unnumbered .unlisted}

In the regression setting, classification scoring rules are extended by instead considering distribution functions and integrating these over $\calY \subseteq \Reals$.

The Integrated Brier Score (IBS) is defined by,^[also known as the Continuous Ranked Probability Score (CRPS).]

$$
L_{IBS}:\calP \times \calY \rightarrow [0,1]; \quad
(\zeta, y) \mapsto \int_{\calY} (\II(y \leq \tau) - \zeta.F(\tau))^2 \ d\tau
$$ {#eq-ibs}

The extension from the classification Brier score is intuitive, instead of evaluating if the predicted pmf is 'correct' at a single point, the predicted cumulative distribution function is compared with the true event status over the entire distribution.

The log loss has two adaptations for continuous predictions. The first is analogous to the IBS and is termed the Integrated Log Loss (ILL)

$$
\begin{split}
&L_{ILL}:\calP \times \calY \rightarrow \NNReals; \\
&(\zeta, y) \mapsto - \int_{\calY} \II(y \leq \tau)\log[\zeta.F(\tau)] + \II(y > \tau)\log[\zeta.S(\tau)] \ d\tau
\end{split}
$$

This follows the 'longer' form of the binary classification log loss and considers the cumulative probability of events over all time-points. A second adaptation to the log loss instead considers the 'simpler' form and replaces the probability mass function with the probability density function. Again this measure is intuitive as a perfect distributional prediction will assign the highest point of density to the point at which the event occurs. This variant of the log loss does not have a specific name but it is termed here the 'density log loss', $L_{DLL}$, and is formally defined by,

$$
L_{DLL}:\calP \times \calY \rightarrow \NNReals; \quad
(\zeta, y) \mapsto - \log[\zeta.f(y)]
$$ {#eq-density-logloss}
where $\calP$ is a family of absolutely continuous distributions over $\calY$ with defined density functions.

All three of these losses are strictly proper [@Gneiting2007; @Gressmann2018].


### Survival Scoring Rule Definitions {#sec-eval-distr-score-surv}

Losses in the survival setting compare predicted survival distributions to the observed outcome tuple (time and censoring). A large class of survival losses additionally incorporate an estimator of the unknown censoring distribution, in order to attempt meaningful comparison. This second group of losses are termed here as 'approximate' losses as the true censoring distribution is never known and hence an estimate of the loss is approximate at best.

:::: {.callout-note icon=false}

## Survival loss

::: {#cnj-loss-surv}
Let $\calT \subseteq \NNReals$ and let $\calC, \calP$ be any two distinct families of distributions over $\calT$, containing at least two elements. Then,

* Any real-valued function with the signature $L: \calP \times \calT \times \bset \rightarrow \ExtReals$ will be considered as a *survival loss*.
* Any real-valued function with the signature $L: \calP \times \calT \times \bset \times \calC \rightarrow \ExtReals$ will be considered as an *approximate survival loss*.
:::

::::

Two separate novel definitions for (strict) properness are provided: the first captures the general case in which no assumptions are made about the censoring distribution; the second assumes that censoring is conditionally event-independent.

::: {#def-surv-proper}

## Survival loss properness

A survival loss $L: \calP \times \calT \times \bset \rightarrow \ExtReals$ is called:

i. *Proper* if: for any distributions $p_Y, p$ in $\calP$; and for any random variables $Y \sim p_Y$, and $C$ t.v.i. $\calT$; with $T := \min\{Y,C\}$ and $\Delta := \II(T=Y)$; it holds that,

$$
\EE[L(p_Y, T, \Delta)] \leq \EE[L(p, T, \Delta)]
$$
i. *Strictly proper* if in addition to being proper it holds, for the same quantification of variables, that

$$
\EE[L(p_Y, T, \Delta)] = \EE[L(p, T, \Delta)] \Leftrightarrow p = p_Y
$$
i. *Outcome-independent proper* if: for any distributions $p_Y, p$ in $\calP$; and for any random variables $Y \sim p_Y$, and $C$ t.v.i. $\calT$, where $C \indep Y$; with $T := \min\{Y,C\}$ and $\Delta := \II(T=Y)$; it holds that,

$$
\EE[L(p_Y, T, \Delta)] \leq \EE[L(p, T, \Delta)]
$$
i. *Outcome-independent strictly proper* if in addition to being outcome-independent proper it holds, for the same quantification of variables, that

$$
\EE[L(p_Y, T, \Delta)] = \EE[L(p, T, \Delta)] \Leftrightarrow p = p_Y
$$

:::

These final two definitions are 'weaker' but provide a term for losses that are improper in general but are (strictly) proper under common (though possibly strict) assumptions about the censoring distribution. Note by definition that if a loss is:

i. (strictly) proper then it is also outcome-independent (strictly) proper;
i. (outcome-independent) strictly proper then it is also (outcome-independent) proper


Analogous definitions are now provided for approximate survival losses.

::: {#def-surv-approx-proper}

## Survival approximate loss properness

An approximate survival loss $L: \calP \times \calT \times \bset \times \calC \rightarrow \ExtReals$ is called:

i. *Proper* if: for any distributions $p_Y, p$ in $\calP$ and $c \in \calC$; and for any random variables $Y \sim p_Y$ and $C \sim c$; with $T := \min\{Y,C\}$ and $\Delta := \II(T=Y)$; it holds that,

$$
\EE[L(p_Y, T, \Delta|c)] \leq \EE[L(p, T, \Delta|c)]
$$
i. *Strictly proper* if in addition to being proper it holds, for the same quantification of variables, that

$$
\EE[L(p_Y, T, \Delta|c)] = \EE[L(p, T, \Delta|c)] \Leftrightarrow p = p_Y
$$
i. *Outcome-independent proper* if: for any distributions $p_Y, p$ in $\calP$ and $c \in \calC$; and for any random variables $Y \sim p_Y$ and $C \sim c$, where $C \indep Y$; with $T := \min\{Y,C\}$ and $\Delta := \II(T=Y)$; it holds that,

$$
\EE[L(p_Y, T, \Delta|c)] \leq \EE[L(p, T, \Delta|c)]
$$
i. *Outcome-independent strictly proper* if in addition to being outcome-independent proper it holds, for the same quantification of variables, that

$$
\EE[L(p_Y, T, \Delta|c)] = \EE[L(p, T, \Delta|c)] \Leftrightarrow p = p_Y
$$

:::

As the true censoring distribution, $c$, can never be known exactly, this definition allows for approximate losses to be proper in the asymptotic (with infinite training data) if they include estimators of $c$ that are convergent in distribution. Proper approximate losses are therefore useful in modern predictive settings in which 'big data' is very common and thus estimators, such as the Kaplan-Meier, can converge to the true censoring distribution. However approximate losses may provide misleading results when the sample size is small; future research should ascertain what 'small' means for individual losses.

### Common Survival Scoring Rules {#sec-eval-distr-commonsurv}

The IBS, ILL, and DLL are now extended to the survival setting by suitably incorporating censoring and their properness properties are then discussed in @sec-eval-distr-score-proper. Measures are split into 'classes', which represent the basic form of the measure.

#### Squared Survival Losses

The analogue to the IBS for survival analysis is termed here as the Integrated Graf Score (IGS) as it was extensively discussed and promoted by Graf [@Graf1995; @Graf1999].

::: {#def-igs}

## Integrated Graf score (IGS)

$$
\begin{split}
&L_{IGS}: \calP \times \calT \times \bset \times \calC \rightarrow [0,1]; \\
&(\zeta, t, \delta|\KMG) \mapsto \int^{\tau^*}_0  \frac{\zeta.S^2(\tau) \II(t \leq \tau, \delta=1)}{\KMG(t)} + \frac{\zeta.F^2(\tau) \II(t > \tau)}{\KMG(\tau)} \ d\tau
\end{split}
$$ {#eq-igs}
where  $\zeta.S^2(\tau) = (\zeta.S(\tau))^2$, analogously for $\zeta.F^2$, and $\tau^* \in \calT$ is an upper threshold to compute the loss up to.
:::

The IGS consistently estimates the mean square error $L(t, S|\tau^*) = \int^{\tau^*}_0 [\II(t > \tau) - S(\tau)]^2 d\tau$, where $S$ is the correctly specified survival function, when censoring is uninformative only [@Gerds2006]. This is intuitive as the IGS utilises the marginal Kaplan-Meier estimator to estimate the censoring distribution. Therefore CIPCW estimates such as the Cox model or Akritas estimator could instead be considered for $\KMG$ and these have been demonstrated to have less bias when censoring is informative [@Gerds2006]. However this raises concerns as now separate models have to be trained and predicted, which could need validation themselves, and therefore the final measure is even more difficult to interpret. Graf claimed that the IGS is strictly proper [@Graf1999] however as no definition of properness was provided this claim cannot be validated. With the definition of properness provided in this book (@def-surv-approx-proper), the IGS is not even proper (@sec-eval-distr-score-proper-nonapprox).

One could instead consider extending the IBS by weighting by $\KMG(t)$ only, giving the following loss.

::: {#def-rigs}

## Reweighted Integrated Graf score (IGS$^*$)

Let $\calP$ be a family of absolutely continuous distributions over $\calT$ with defined density functions. Then the *reweighted Integrated Graf score* (IGS$^*$) is defined by

$$
\begin{split}
&L_{IGS^*}: \calP \times \calT \times \bset \times \calC \rightarrow \NNReals; \\
&(\zeta, t, \delta|\KMG) \mapsto \frac{\delta \int_{\calT} (\II(t \leq \tau) - \zeta.F(\tau))^2 \ d\tau}{\KMG(t)}
\end{split}
$$ {#eq-wsbs}
:::

IGS$^*$ is outcome-independent strictly proper (@sec-eval-distr-score-proper-strict).

#### Log Survival Losses

The ILL is similarly extended to the Integrated Survival Log Loss (ISLL) [@Graf1999].

::: {#def-isll}

## Integrated survival log loss (ISLL)

The *integrated survival log loss* (ISLL) is defined by
$$
\begin{split}
& L_{ISLL}: \calP \times \calT \times \bset \times \calC \rightarrow \NNReals; \\
& (\zeta,t,\delta|\KMG) \mapsto -\int^{\tau^*}_0  \frac{\log[\zeta.F(\tau)] \II(t \leq \tau, \delta=1)}{\KMG(t)} + \frac{\log[\zeta.S(\tau)] \II(t > \tau)}{\KMG(\tau)} \ d\tau
\end{split}
$$ {#eq-isll}

where $\tau^* \in \calT$ is an upper threshold to compute the loss up to.
:::

The ISLL is not a proper approximate survival loss (@sec-eval-distr-score-proper-nonapprox). Again one could instead a different weighting in the denominator of the measure to give the following loss.

::: {#def-risll}

## Reweighted integrated survival log loss (ISLL$^*$)

Let $\calP$ be a family of absolutely continuous distributions over $\calT$ with defined density functions. Then the *reweighted integrated survival log loss* (ISLL$^*$) is defined by

$$
\begin{split}
&L_{ISLL^*}: \calP \times \calT \times \bset \times \calC \rightarrow \NNReals;\\
&(\zeta, t, \delta|\KMG) \mapsto -\frac{\delta \int_{\calT} \II(t \leq \tau)\log[\zeta.F(\tau)] + \II(t > \tau)\log[\zeta.S(\tau)] \ d\tau}{\KMG(t)}
\end{split}
$$ {#eq-wsill}
:::

ISLL$^*$ is an outcome-independent strictly proper scoring rule (@sec-eval-distr-score-proper-strict).

The DLL can be extended in one of two ways, the first simply removes all censored observations.

::: {#def-sdll}

## Survival density log loss (SDLL)

Let $\calP$ be a family of absolutely continuous distributions over $\calT$ with defined density functions. Then the *survival density log loss* (SDLL) is defined by

$$
L_{SDLL}: \calP \times \calT \times \bset \rightarrow \NNReals; \quad (\zeta, t, \delta) \mapsto - \delta \log[\zeta.f(t)]
$$ {#eq-sdll}
:::

The SDLL is not a proper scoring rule (@sec-eval-distr-score-proper-nostrict). The second extension to DLL adds the same IPC weighting as IGS$^*$ and ISLL$^*$.

::: {#def-wsdll}

## Weighted survival density log loss (SDLL$^*$)

Let $\calP$ be a family of absolutely continuous distributions over $\calT$ with defined density functions. Then the *weighted survival density log loss* (SDLL$^*$) is defined by

$$
L_{SDLL^*}: \calP \times \calT \times \bset \times \calC \rightarrow \NNReals; \quad (\zeta, t, \delta|\KMG) \mapsto - \frac{\delta \log[\zeta.f(t)]}{\KMG(t)}
$$ {#eq-wsdll}
:::

SDLL$^*$ is outcome-independent strictly proper (@sec-eval-distr-score-proper-strict).

#### Absolute Survival Losses

Whilst the IGS and ISLL appear to be the most common losses in the literature, there is one other class to briefly mention that is based on absolute error functions. For example, the 'absolute Brier score' proposed by Schemper and Henderson [@Schemper2000] which is based on the mean absolute error. This takes a similar approach to the IGS and weights the loss at different time-points according to whether an observation is censored. Studies of this loss have demonstrated that it depends heavily on correct model specification and is biased when this is not the case [@Choodari2012b; @Schmid2011]. To prevent this bias, Schmid $\etal$ [@Schmid2011] proposed the following robust approximate loss, termed here the 'Schmid score',

$$
L(\zeta, t, \delta|\KMG) = \int^{\tau^*}_0 \frac{\zeta.S(\tau)\II(t \leq \tau, \delta = 1)}{\KMG(t)} + \frac{\zeta.F(\tau)\II(t > \tau)}{\KMG(\tau)} \ d\tau
$$
where $\KMG$ and $\tau^*$ are as defined above. Analogously to the IGS, the Schmid score consistently estimates the mean absolute error when censoring is uninformative [@Schmid2011]. Both scores tend to yield similar results [@Schmid2011].

#### Comparing Weighting Methods

The IGS and ISLL are well-established survival losses however no discussion about IGS$^*$ and ISLL$^*$ could be found in the literature. On the surface these measures may look very similar but there are two important differences, which are illustrated below with the ISLL and ISLL$^*$, recall these are defined as:

$$
\begin{split}
&L_{ISLL^*}(\zeta, t, \delta|\KMG) = -\int^{\tau^*}_0  \frac{\log[\zeta.F(\tau)]\II(t \leq \tau, \delta = 1)}{\KMG(t)} + \frac{\log[\zeta.S(\tau)]\II(t > \tau, \delta = 1)}{\KMG(t)} \ d\tau \\
&L_{ISLL}(\zeta,t,\delta|\KMG) = -\int^{\tau^*}_0  \frac{\log[\zeta.F(\tau)] \II(t \leq \tau, \delta=1)}{\KMG(t)} + \frac{\log[\zeta.S(\tau)] \II(t > \tau)}{\KMG(\tau)} \ d\tau
\end{split}
$$

The primary differences are (right hand side of equations):

i. Always removing censored observations from $L_{ISLL^*}$ (even when alive) whereas $L_{ISLL}$ includes all observations when alive.
i. $L_{ISLL^*}$ weights alive and dead observations by $\KMG(t)$ whereas $L_{ISLL}$ weights dead observations by $\KMG(t)$ and alive observations by $\KMG(\tau)$


Analytically the difference between these weighting results has major implications as $L_{ISLL^*}$ (and $L_{IGS^*}$) is outcome-independent strictly proper (@sec-eval-distr-score-proper-strict) whereas $L_{ISLL}$ (and $L_{IGS}$) is not even proper (@sec-eval-distr-score-proper-nonapprox). However whilst it has been demonstrated that the IGS consistently estimates the mean squared error [@Gerds2006], no theory exists for IGS$^*$. Similarly no study has been made on ISLL$^*$ and SDLL$^*$.

#### PECs

As well as evaluating probabilistic outcomes with integrated scoring rules, non-integrated scoring rules can also be utilised for evaluating distributions at a single point. For example, instead of evaluating a probabilistic prediction with the IGS over $\NNReals$, instead one could compute the IGS at a single time-point, $\tau \in \NNReals$, only. Plotting these for varying values of $\tau$ results in 'prediction error curves' (PECs), which provide a simple visualisation for how predictions vary over the outcome. PECs are especially useful for survival predictions as they can visualise the prediction 'over time'. PECs should only be used as a graphical guide and never for model comparison as they only provide information at a limited number of points. An example is provided in @fig-eval-pecs for the IGS; the CPH is consistently better performing than the SVM.

![Prediction error curves for the CPH and SVM models from @sec-eval-distr-calib. x-axis is time and y-axis is the IGS computed at different time-points. The CPH (red) performs better than the SVM (blue) as it scores consistently lower. Trained and tested on randomly simulated data from $\proba$.](Figures/evaluation/pecs.png){#fig-eval-eval-pecs fig-alt="TODO"}

### Properness of Survival Scoring Rules {#sec-eval-distr-score-proper}

As the IBS, ILL, and DLL are all strictly proper regression losses, one may assume the analogous survival losses are also strictly proper. No arguments could be found proving/disproving properness of the survival losses, which may be due to researchers assuming properness followed from the regression setting. Despite these estimators being demonstrated to have useful properties and to 'perform well' in simulation experiments [@Choodari2012a; @Choodari2012b; @Gerds2006], it transpires that none are proper. Key results in this section are collected in the following summary theorem.

::: {#thm}
Let $\calT \subseteq \PReals$ and let $\calC,\calP$ be two distinct families of distributions over $\calT$  containing at least two elements and let $L_R: \calP \times \calT \rightarrow \ExtReals$ be a regression scoring rule. Then the following statements are true:

i. $L_{SDLL}$ is not: a) outcome-independent proper; b) outcome-independent strictly proper; c) proper; d) strictly proper (@prop-sdll-proper).
i. Define the approximate survival loss,

$$
L_S: \calP \times \calT \times \bset \times \calC \rightarrow \ExtReals; \quad
(\zeta, t, \delta|\KMG) \mapsto \frac{\delta L_R(\zeta, t)}{\KMG(t)}
$$

Then $L_S$ is outcome-independent strictly proper if and only if $L_R$ is strictly proper (@thm-surv-regr-proper).
i. $L_{SDLL^*}, L_{IGS^*}, L_{ISLL^*}$ are all outcome-independent strictly proper (@prop-approx-proper-losses).
i. $L_{IGS}$ is not: a) outcome-independent proper; b) outcome-independent strictly proper; c) proper; d) strictly proper (@prop-eval-igs).
i. $L_{ISLL}$ is not: a) outcome-independent proper; b) outcome-independent strictly proper; c) proper; d) strictly proper (@prop-eval-isll).

:::

The following conjectures are also made:

i. No survival loss, $L: \calP \times \calT \times \bset \rightarrow \ExtReals$, is: a) outcome-independent strictly proper; b) strictly proper (@conj-no-proper-loss).
i. No approximate survival loss, $L: \calP \times \calT \times \bset \times \calC \rightarrow \ExtReals$, is strictly proper (@conj-approx-strictly).


#### Definitions and Lemmas

Important proofs in this subsection follow after these definitions and lemmas.

::: {#lem-proper-relate}
Let $L: \calP \times \calT \times \bset \rightarrow \ExtReals$ be a survival loss. Let $p_Y \in \calP$, let $Y \sim p_Y$ and $C \ t.v.i. \ \calT$ be random variables where $C \indep Y$. Let $T := \min\{Y,C\}$ and $\Delta := \II(T=Y)$. Then if $\exists p \in \calP, p \neq p_Y$, such that

$$
\EE[L(p_Y, T, \Delta)] > \EE[L(p, T, \Delta)]
$$
Then, $L$ is not:

i. outcome-independent proper;
i. outcome-independent strictly proper;
i. proper;
i. strictly proper.
:::

::: {#lem-approx-proper-relate}
Let $L: \calP \times \calT \times \bset \times \calC \rightarrow \ExtReals$ be an approximate survival loss. Let $p_Y \in \calP$ and let $c \in \calC$. Let $Y \sim p_Y$ and $C t.v.i. \calT$ be random variables. Let $T := min\{Y,C\}$ and $\Delta := \II(T=Y)$. Then if $\exists p \in \calP, p \neq p_Y$, such that

$$
\EE[L(p_Y, T, \Delta|c)] > \EE[L(p, T, \Delta|c)]
$$\mbox{}
Then: $L$ is not,

i. proper;
i. strictly proper.
:::

::: {#def-proper-terms}

## Properness terminology

Let $L: \calP \times \calT \times \bset \rightarrow \ExtReals$ be a proper scoring rule and let $p,p_Y$ be distributions in $\calP$. Let $Y \sim p_Y$ and $C$ t.v.i. $\calT$ be random variables and let $T := \min\{Y,C\}$ and $\Delta := \II(T=Y)$. Then, [@Gneiting2007]

i. $S_L(p_Y, p) := \EE[L(p, T, \Delta)]$ is defined as the *expected penalty*.
i. $H_L(p_Y) := S_L(p_Y, p_Y)$ is defined as the *(generalised) entropy of* $p_Y \in \calP$.
i. $D_L(p_Y, p) := S_L(p_Y, p) - H_L(p_Y)$ is defined as the *discrepancy* or *divergence* of $p \in \calP$ from $p_Y \in \calP$.

:::

Similar definitions follow for the expected penalty, entropy, and divergence for an approximate survival loss $L: \calP \times \calT \times \bset \times \calC \rightarrow \ExtReals$.

::: {#lem-divergence}
Let $L: \calP \times \calT \times \bset \rightarrow \ExtReals$ be a survival loss and let $p_Y$ be a distribution in $\calP$. Let $Y \sim p_Y$ and $C$ t.v.i. $\calT$ be random variables and let $T := \min\{Y,C\}$ and $\Delta := \II(T=Y)$. Then,

* $D_L(p_Y, p) \geq 0$ for all $p \in \calP$ if $L$ is proper
* $D_L(p_Y, p) > 0$ iff $L$ is strictly proper and $p \neq p_Y$
:::

::: {#def-joints}

## Joint density

Let $X$ be an absolutely continuous random variable and let $Y$ be a discrete random variable. Then,

i. The *mixed joint density* of $(X,Y)$ is defined by

$$
f_{X,Y}(x,y) = f_{X|Y}(x|y)P(Y = y)
$$
where $f_{X|Y}(x|y)$ is the conditional probability density function of $X$ given $Y = y$.
i. The *mixed joint cumulative distribution function* of $(X,Y)$ is given by

$$
F_{X,Y}(x,y) =  \sum_{z \leq y} \int_{u=-\infty}^x f_{X,Y}(u, z) \ du
$$

:::

::: {#lem-joints}
Let $X,Y$ be jointly absolutely continuous random variables supported on the Reals with joint density function $f_{X,Y}(x,y)$ and let $Z = \II(X \leq Y)$, then the mixed joint density of $(X,Z)$ is given by


$$
f_{X,Z}(x,z) =
\begin{cases}
\int^\infty_x \ f_{X,Y}(x,y) \ dy, & z = 1 \\
\int^x_{-\infty} f_{X,Y}(x,y) \ dy, & z = 0
\end{cases} \\
$$
:::

::: {#cor-joints}
Let $X,Y$ be jointly absolutely continuous random variables supported on the Reals with joint density function $f_{X,Y}(x,y)$ and let $Z = \II(X \leq Y)$. As a direct corollary to @lem-joints, if $X$ and $Y$ are independent then the mixed joint density of $(X,Z)$ is given by


$$
f_{X,Z}(x,z) =
\begin{cases}
f_X(x)S_Y(x), & z = 1 \\
f_X(x)F_Y(x), & z = 0
\end{cases}
$$
:::

::: {#lem-joints-rev}
Let $X,Y$ be jointly absolutely continuous random variables supported on the Reals with joint density function $f_{X,Y}(x,y)$ and let $Z = \II(X \leq Y)$, then the mixed joint density of $(Y,Z)$ is given by


$$
f_{Y,Z}(y,z) =
\begin{cases}
\int^y_{-\infty} f_{X,Y}(x,y) \ dx, & z = 1\\
\int^\infty_y \ f_{X,Y}(x,y) \ dx, & z = 0
\end{cases} \\
$$

In addition if $X \indep Y$, then


$$
f_{Y,Z}(y,z) =
\begin{cases}
f_Y(y)F_X(y), & z = 1\\
f_Y(y)S_X(y), & z = 0
\end{cases} \\
$$
:::

#### No Strictly Proper Survival Loss {#sec-eval-distr-score-proper-nostrict}

First it is proved that the survival density log loss is not outcome-independent proper and then a conjecture is made on the strict properness of all non-approximate losses.

::: {#prop-sdll-proper}
The survival density log loss is not:

i. outcome-independent proper
i. outcome-independent strictly proper
i. proper
i. strictly proper
:::

Not only is the $L_{SDLL}$ not outcome-independent proper but the counter-example in the proof is not even a rare edge case. Accounting for the censoring distribution is attempted by approximate losses, which are explored after the following conjecture.

::: {#conj-no-proper-loss}
Let $L: \calP \times \calT \times \bset \rightarrow \ExtReals$ be a survival loss, then $L$ is not:

i. outcome-independent strictly proper;
i. strictly proper;

:::

This conjecture is motivated by identifying that as the true censoring distribution is always unknown, a counter-example can likely always be identified to contradict the loss being strictly proper.^[This conjecture is being explored as part of a theorem in a paper with external collaborators.]

#### Strictly Proper Approximate Survival Losses {#sec-eval-distr-score-proper-strict}

By making strict assumptions about the data, some survival scoring rules can still be useful, these assumptions are:

i. survival times and censoring times are independent;
i. the training dataset is large enough to approximate the censoring distribution


With these assumptions, a large class of approximate losses can be outcome-independent strictly proper.

::: {#thm-surv-regr-proper}
Let $L_R: \calP \times \calT \rightarrow \ExtReals$ be a regression loss and define the approximate survival loss

$$
L_S: \calP \times \calT \times \bset \times \calC \rightarrow \ExtReals; \quad
(\zeta, t, \delta|\KMG) \mapsto \frac{\delta L_R(\zeta, t)}{\KMG(t)}
$$
Then $L_S$ is outcome-independent strictly proper if and only if $L_R$ is strictly proper.
:::

::: {#prop-approx-proper-losses}
The following approximate survival losses are outcome-independent strictly proper:

i. $L_{SDLL^*}$ -- @eq-wsdll
i. $L_{IGS^*}$ -- @eq-wsbs
i. $L_{ISLL^*}$ -- @eq-wsill
:::

#### Non-Proper Approximate Survival Losses {#sec-eval-distr-score-proper-nonapprox}

From the previous proofs, it would be natural to assume that $L_{IGS}$ and $L_{ISLL}$ are also outcome-independent strictly proper, however this is not the case.

::: {#prop-eval-igs}
The integrated Graf score, $L_{IGS}$, is not:

i. outcome-independent proper
i. outcome-independent strictly proper
i. proper
i. strictly proper
:::

Whilst in this counter-example the value of $D_{IGS}(\xi, \zeta)$ is very close to zero, there will be other counter-examples with a more pronounced difference, though this is not required for the proof. Also note that again this is not a rare edge case, practically this example is reflected in any real-world scenario in which the prediction is close to the truth and when the censoring and survival times follow the same distribution.

::: {#prp-eval-isll}
The integrated survival log-loss, $L_{ISLL}$, is not:

i. outcome-independent proper
i. outcome-independent strictly proper
i. proper
i. strictly proper

:::

Proof is not provided but follows with the same argumentation as the previous proposition and noting that a counter-example can always be found as $C$ is unknown and cannot be removed from the equation.

::: {#cnj-approx-strictly}
Let $L: \calP \times \calT \times \bset \times \calC \rightarrow \ExtReals$ be an approximate survival loss, then $L$ is not strictly proper.
:::

This conjecture is motivated by noting that the joint distribution of $(Y,C)$ is always unknown and thus a suitable counter-example to strict-properness can likely always be derived.^[This conjecture is being explored as part of a theorem in a paper with external collaborators.]

### Baselines and ERV {#sec-eval-distr-score-base}

A common criticism of scoring rules is a lack of interpretability, e.g. without context an IGS of 0.5 or 0.0005 have no meaning. The final part of this section very briefly looks at two methods that help increase the interpretability of scoring rules. Scoring rules may already be considered less transparent than, say, concordance indices, as the underlying mathematics is more abstract, and therefore interpretability of the measure can play a large role in increasing transparency.

#### Baselines {#sec-eval-distr-score-base-base}

A baseline is either a model or a value that can be utilised to provide a reference value for a scoring rule, they provide a universal method to judge all models of the same class by [@Gressmann2018].

In classification, an analytical baseline value can be derived for measures, i.e. a baseline model does not actually need to be fit to know what a 'good' value for the loss is. For example it is generally known that a Brier score is considered 'good' if it is below 0.25 or a log loss if it is below 0.693 (@sec-eval-distr-score-reg). Unfortunately simple analytical expressions are not possible in survival analysis as the losses are dependent on the distributions of both the survival and censoring time. Therefore all experiments in survival analysis must include a baseline model that can produce a reference value in order to derive meaningful results.

There is a clear consensus that the Kaplan-Meier estimator is the most sensible baseline model for survival modelling [@Graf1995; @Lawless2010; @Royston2013] as it is the simplest model that can consistently estimate the true survival function. One could also consider the Akritas estimator as a tunable conditional baseline (@sec-surv-models-uncond).

Baseline models are often ignored in experiments when there is overconfidence in a particular model class, this is frequently the case in survival analysis in which a novel model class may only be compared to a Cox PH. This has practical and ethical implications. The calibration example in @sec-eval-distr-calib-point demonstrates how one sophisticated model (CPH) may outperform another (SVM) and still perform worse than the Kaplan-Meier. Not including Kaplan-Meier in every experiment could lead to over-confidence in a novel model that is no better than an unconditional estimator (with no individual predictive ability).

#### Explained Residual Variation {#sec-eval-distr-score-base-erv}

Baseline models can also be utilised to derive a potentially more useful representation of scoring rules. Any scoring rule can be utilised to derive a measure of explained residual variation (ERV) [@Korn1990; @Korn1991] by standardising the loss with respect to a baseline, say Kaplan-Meier. For any survival loss $L$ (analogously for an approximate survival loss), the ERV is,

$$
\begin{split}
&R_L: \calP \times \calP \times \NNReals^m \times \bset^m \rightarrow [0,1]; \\
&(\zeta,\xi_0,t,\delta) \mapsto 1 - \frac{\mean[m]{L(\zeta,t_i,\delta_i)}}{\mean[m]{L(\xi_0,t_i,\delta_i)}}
\end{split}
$$ {#eq-eval-erv}
where $t = t_1,...,t_m, \delta = \delta_1,...,\delta_m$ and $\zeta$ should be a predicted distribution from a sophisticated (non-baseline) model and $\xi_0$ is a prediction from the Kaplan-Meier estimator.^[@eq-eval-erv assumes the numerator is always less than the denominator or more specifically that the sophisticated model is 'better' than the baseline; if this is not the case then $R_L^2 < 0$. Therefore this representation should only be utilised when the model outperforms the baseline.]

Representing a scoring rule in this manner improves interpretability by allowing for model comparison whilst simultaneously capturing the improvement from a baseline. Therefore instead of reporting some arbitrary loss value, say $L = 0.1$, one can instead report $R_L = 70%$ which demonstrates a clear improvement (of 70%) over the baseline.

## Conclusions {#sec-eval-conc}

This chapter briefly reviewed different classes of survival measures before focusing on the application of scoring rules to survival analysis.

One finding of note from the review of survival measures is the possibility that research and debate has become too focused on measures of discrimination. For example, many papers state the flaws of Harrell's C index [@Gonen2005; @Rahman2017; @Schmid2012; @Uno2007] however few acknowledge that simulation experiments have demonstrated that common alternatives yield very similar results to Harrell's C [@Rahman2017; @Therneau2020] and moreover some promimnent alternatives, such as Uno's C [@Uno2007], are actually harder to interpret due to very high variance [@Rahman2017; @Schmid2012]. Whilst all concordance indices may be considered accessible and transparent, there is considerable doubt over their performance due to influence from censoring.

Focus on discrimination could be the reason for less development in survival time and calibration measures. There is evidence [@Wang2017] of the censoring-adjusted RMSE, MAE, and MSE (@sec-eval-det) being used in evaluation but without any theoretical justification, which may lead to questionable results. Less development in calibration measures is likely due to these measures being more widely utilised for re-calibration of models and not in model comparison. The new D-Calibration measure [@Andres2018; @Haider2020] could prove useful for model comparison however independent simulation experiments and theoretical studies of the measure's properties would first be required. No calibration measures can be considered performant due to a lack of clear definition of a calibration measure for survival, moreover the reviewed measures may not even be transparent and accessible due to requiring expert interpretation.

The most problematic findings in this chapter lie in the survival scoring rules. @sec-eval-distr-score-proper proved that no commonly used scoring rule is proper, which means that any results regarding model comparison based on these measures are thrown into question. It is also conjectured that no approximate survival loss can be strictly proper (in general), which is due to the joint distribution of the censoring and survival distribution always being unknown and impossible to estimate (though the marginal censoring distribution can be estimated). As demonstrated in @sec-eval-distr-score-reg, a proper scoring rule is not necessarily a useful one and therefore is not enough for robust model validation.

As an important caveat to the findings in this chapter, this book presents one particular definition of properness for survival scoring rules. This definition is partially subjective and other definitions could instead be considered. Therefore these losses should not be immediately dismissed outright. As well as deriving new losses that are (strictly) proper with respect to the definitions provided here, research may also be directed towards finding other sensible definitions of properness, or in confirming that the definition here is the only sensible option.<!-- As these are open research questions, the scoring rules discussed in this chapter are still utilised in evaluation for the benchmark experiment in -->

This chapter demonstrates that no survival measure on its own can capture enough information to fully evaluate a survival prediction.
This is a serious problem that will either lead (or already is leading) to less interest and uptake in survival modelling, or misunderstanding and deployment of sub-optimal models. Evaluation of survival models is still possible but currently requires expert interpretation to prevent misleading results. If the aim of a study is solely in assessing a model's discriminatory power, then measures of discrimination alone are sufficient, otherwise a range of classes should be included to capture all aspects of model performance. This book advocates reporting *all* of the below to evaluate model performance:


* **Calibration**: Houwelingen's $\alpha$ and [@VanHouwelingen2007] *and* D-calibration [@Haider2020].
* **Discrimination**: Harrell's [@Harrell1984] *and* Uno's [@Uno2011] C. By including two (or even more) measures of concordance, one can determine a feasible range for the 'true' discriminatory ability of the model instead of basing results on a single measure. Time-dependent AUCs can also be considered but these may require expert-interpretation and may only be advisable for discrimination-specific studies.
* **Scoring Rules**: When censoring is outcome-independent and a large enough training dataset is available, then the re-weighted integrated Graf score and re-weighted integrated survival log-loss (@sec-eval-distr-commonsurv). Otherwise the IGS *and* ISLL [@Graf1999] which should be interpreted together to ensure consistency in results.

If survival time prediction is the primary goal then RMSE$_C$ and MAE$_C$ can be included in the analysis however these should not form the primary conclusions due to a lack of theoretical justification. Instead, scoring rules should be utilised as a distributional prediction can always be composed into a survival time prediction (@sec-car).

All measures discussed in this chapter, with the exception of the Blanche AUC, have been implemented in  $\proba$ [@pkgmlr3proba]. <!-- The listed measures above are utilised in the benchmark experiment in  -->
