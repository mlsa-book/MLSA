
---
abstract: TODO (150-200 WORDS)
---

{{< include _setup.qmd >}}

# Introduction {#sec-intro}

{{< include _wip.qmd >}}

There are many books dedicated to regression and classification as machine learning problems but tthe 'bibles' of machine learning focus almost entirely on regression and classification (@Bishop2006; @Hastie2001; @Hastie2013).
There are also excellent books dedicated to survival analysis, such as @Collett2014 and @KalbfleischPrentice1973, but without the inclusion of machine learning models.
Survival analysis has important applications to fields that directly impact day-to-day life, including healthcare, finance, and engineering.
Using regression and classification models to solve problems based on survival datasets can lead to biased results, which in turn may have negative consequences.
This book is intended to bridge the gap between survival analysis and machine learning to increase accessibility and to demystify the combined field of 'machine learning survival analysis'.

## Defining Machine Learning Survival Analysis

The purpose of this book is to formalise the use of machine learning in survival analysis, which we often refer to as 'machine learning survival analysis' (or 'MLSA').
@sec-mlsa demonstrates an example of MLSA from start to finish and the rest of the first Part of this book formalises definitions and procedures related to survival analysis and machine learning.
The purpose of this introductory chapter is to highlight the importance of survival analysis and what makes predictions in a survival setting ('survival predictions') stand out from other areas such as regression and classification.
We begin with some examples and then introduce the most important concepts that make machine learning survival analysis unique.

### Waiting for a bus

It is likely that you are making or using some form of survival predictions daily.
For example, estimating when a bus will arrive at your stop after it leaves the previous one, is a survival prediction.
On first glance, many would call this a regression problem, as regression is tasked with making continuous predictions.
However, unless you are reading this from a country that has a perfect public transport system, then it is likely you are not making this prediction based simply on all previous bus arrival times, but also with the knowledge that your bus might break down before it reaches you.
In survival analysis, we would refer to the act of a bus breaking down and not reaching its destination as a 'censoring event'.
An observation (in this case a bus) is *censored* when the event of interest (in this case, arriving at your bus stop) does not occur (in this case due to breakdown), this is illustrated in @fig-bus.
Survival analysis is unique as observations that are censored are still considered to be valuable data points to train a model on.
Instead of dismissing these broken down buses, models that make survival predictions ('survival models') instead use all data up until the point of censoring.
In other words, whilst your bus did not arrive, you do at least know that it had travelled two minutes (the 'censoring time') from its previous stop before you received an alert that it broke down, which is valuable information.

### Allocating resources

The previous example covered a common use case of survival analysis, which is estimating survival times, i.e., the time at which an event of interest will occur.
In practice, survival models usually estimate the survival time *distribution* which predicts the probability of the event over a period of time, this is more informative than just predicting a single time as the model can also attribute uncertainty to that prediction.
Another common survival problem is to rank observations (often patients) or separate them into risk groups, usually for allocating scarce resources.
As another example that occurs daily, take the process of triaging patients in an emergency department.
A patient presents with a set of symptoms, and is then triaged, which means their symptoms are assessed and used to determine how urgently they need to receive help (or if they can be dismissed from hospital).
Triaging patients is once again a survival prediction.
In this case, the event of interest is an increase in severity from initial symptoms to a more serious display of illness.
Reasons for censoring might include the patient leaving the hospital.
In this example, the survival prediction is to estimate the risk of the event occurring relative to other patients, i.e., when a new patient is triaged, how do their symptoms compare to patients who have already been through the triage process?
Are they at a higher risk and should therefore be seen by a clinician sooner?
Or can they afford to wait longer than those who have already been waiting a long time?

### 'Survival' analysis

While the term survival analysis does highlight the closely related nature of the field with medical statistics and in particular predicting survival times (i.e., the time until death), this is certainly not the only application of the field (as we have already seen in the bus example).
In engineering, the field is often referred to as 'reliability analysis', as a common task is predicting the reliability of a component in a machine, for example predicting when an engine in a plane needs to be replaced.
In economics, the term 'duration analysis' is often found, and in other areas 'failure-time analysis' may also be used.
This book uses 'survival analysis' throughout as this appears to be the most common term, however the term is used in this book to specifically refer to the case when the event of interest can occur exactly once (e.g., death).
In @sec-surv, 'event history analysis' is defined, which is a generalisation of survival analysis to the case when one or more events can occur multiple times.

One of our key aims in this book is to highlight the ubiquitous nature of survival analysis and to encourage more machine learning practitioners to use survival analysis when appropriate.
Machine learning practitioners are likely familiar with regression and classification, which are the subjects of popular machine learning books (some listed above) however there will be  cases when survival analysis should be used instead.
The previous bus example gives one such case, where regression may appear sensible on the surface however this would not succeed in handling censored data.
Another common example where survival analysis should be used but is not is to make 'T-year' probability predictions.
These predictions are commonly found when discussing severe illnesses, for example statements such as "the five-year survival rate of cancer is p%."
On the surface this may seem like a probabilistic classification problem, but once again modelling in this way would ignore censoring, for example due to some patients being lost to follow-up.
Understanding censoring in all its many forms, is the first step to identifying a survival analysis problem, the second is knowing what to predict.

### Machine learning survival analysis

Machine learning is the field of Statistics primarily concerned with building models to either predict outputs from inputs or to learn relationships from data [@Hastie2001].
This book is limited to the former case, or more specifically supervised learning, as this is the field in which the vast majority of survival problems live.
Relative to other areas of supervised learning, development in survival analysis has been slow, as we will see when discussing models in Part III.
Despite this, development of models has converged on three primary tasks of interest, or 'survival problems', which are defined by the type of prediction the model makes.
The formal definition of a machine learning survival analysis task is provided in @sec-ml, but informally one is encountering a survival problem if training a model on data where censoring is present in order to predict one of:

i. A 'relative risk': The risk of an event taking place.
i. A 'survival time': The time at which the event will take place.
i. A 'survival distribution': The probability distribution of the event times, i.e., the probability of the event occurring over time.

This presents a key difference between survival analysis and other machine learning areas.
There are three separate objects that can be predicted, and not all models can predict each one.
Moreover, each prediction type serves a different purpose and you may require deploying multiple models to serve each one.
As an example, an engineer is unlikely to care the exact time at which a plane engine fails, but they might greatly value knowing when the probability of failure increases above 50\% -- a survival distribution prediction.
Returning to the triage example, a physician cannot process a survival distribution prediction to make urgent decisions, but they could assign limited resources if it is clear that one patient is at far greater risk than another -- a relative risk prediction.

Another important difference that separates survival analysis from other statistical settings, is the focus on less common forms of distribution defining functions.
A distribution defining function is a function that uniquely defines a probability distribution, most commonly the probability density function (pdf) and cumulative distribution function (cdf).
In the context of survival analysis, the pdf at time $t$ is the likelihood of an event taking place at $t$, *independently of any past knowledge*, and the cdf is the probability that the event has *already* taken place at $t$, which is the opposite of the usual survival prediction of interest.
Hence, survival analysis predictions usually focus on predicting the *survival function*, which is simply one minus the cdf, and the *hazard function*, which is the likelihood of the event occurring at $t$ *given* that the observation has survived to at least time $t$.

These functions are formally defined in @sec-surv and are visualized in @fig-distrfunctions assuming a Gompertz distribution, which is often chosen to model adult lifespans.
The figure demonstrates the utility of the survival and hazard functions for survival analysis.
The survival function (bottom right) is a decreasing function from one to zero, at a given time point, $t$, this is interpreted as the probability of surviving until time point, $t$, or more generally the probability that the event of interest has not yet occurred.
The hazard function (top right), starts at zero and is not upper-bounded at one as it is a conditional probability.
Even though the pdf peaks just before 0.5, the hazard function continues to increase as it is conditioned on not having experienced the event, hence the risk of event just continues to increase.

```{r, echo=FALSE}
#| fig-cap: Probability density (top left), hazard (top right), cumulative density (bottom left), and survival (bottom right) functions of a Gompertz(1, 2) distribution.
#| fig-alt: "Four line graphs. The density plot increases from (0,1) to (0.4, 1.25) and then decreases to (1.5, 0). The hazard smoothly increases from (0, 0) to (1.5, 20). The cumulative density smoothly increases from (0,1) to (1.5, 1) and the survival function is the reverse shape to the cumulative density from (0, 1) to (1.5, 0)."
#| label: fig-distrfunctions
library(distr6)
library(ggplot2)
g = dstr("Gompertz", shape = 2, decorators = "ExoticStatistics")
t = seq.int(0, 1.5, length.out = 100)
d = data.frame(t = t, fun = factor(rep(c("Density", "Hazard", "Cumulative Density", "Survival"), each = 100), levels = c("Density", "Hazard", "Cumulative Density", "Survival")), y = c(g$pdf(t), g$hazard(t), g$cdf(t), g$survival(t)))
ggplot(d, aes(x = t, y = y, color = fun)) +
  geom_line() +
  facet_wrap(~fun, scales = "free", nrow = 2) +
  theme_bw() +
  theme(legend.position = "n")
```

Instead of duplicating content from machine learning or survival analysis books, this book primarily focuses on defining the suitability of different methods and models depending on the availability data.
For example, when might you consider a neural network instead of a Cox Proportional Hazards model?
When might you use a random forest instead of a support vector machine?
Is a discrimination-booted gradient boosting machine more appropriate than other objectives?
Can you even use a machine learning model if you have left-censored multi-state data (we will define these terms later)?

From fitting a model to evaluating its predictions, knowing the different prediction types is vital to interpretation of results, these will be formalised in @sec-surv.

## Censoring and Truncation

Censoring is hugely important as it allows model to capture as much information as possible without discarding useful data.

<!-- TODO: WRITTEN TO HERE -->

## Reproducibility

This book includes simulations and figures generated in $\Rstats$, the code for any figures or experiments in this book are freely available at [https://github.com/RaphaelS1/MLSA](https://github.com/RaphaelS1/MLSA) under an MIT licence and all content on this website is available under [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/).
We use `r pkg("renv")` to manage package versions, you can find our lockfile at `r link("https://github.com/RaphaelS1/MLSA/blob/main/book/renv.lock")`.
