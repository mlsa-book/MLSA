---
abstract: TODO (150-200 WORDS)
---

{{< include _setup.qmd >}}

# Survival Analysis {#sec-surv}

{{< include _wip.qmd >}}

___

TODO


___

<!-- In their broadest and most basic definitions, survival analysis is the study of temporal data from a given origin until the occurrence of one or more events or 'end-points'  [@Collett2014], and machine learning is the study of models and algorithms that learn from data in order to make predictions or find patterns  [@Hastie2001]. Reducing either field to these definitions is ill-advised. -->
<!--
Survival analysis is concerned with time-to-event data, i.e. data where the outcome is a duration from some origin until the occurrence of one or multiple events of interest.
In many medical settings, this duration will often be literal survival time, i.e. time until death after some procedure or treatment.
When collecting such data, however, the outcome of interest can often be not observed (fully), e.g. because subjects drop out of the study, haven't experienced the event of interest until end of study period or due to the occurence of another, competing event.

Often analysis of time-to-event data targets the estimation of the (improper) distribution of the event times or, equivalently, modelling the transitions between different states (e.g. alive -> dead) while taking into account censoring and truncation as well as other peculiarities of time-to-event data. However, the target of estimation can also be a relative risk score or the expected time-to-event (cf. @sec-surv-set-types for details).
 -->

*Survival Analysis* is concerned with data where the outcome is the time until an event takes place (a 'time-to-event').
Because the collection of such data takes place in the temporal domain (it takes time to observe a duration), the event of interest is often unobservable, for example because it did not occur by the end of the data collection period.
In survival analysis terminology this is refered to as *censoring*.

This chapter defines basic terminology and mathematical definitions in survival analysis, which are used throughout this book.
Building upon this chapter, @sec-eha introduces event-history analysis, which is a generalisation to settings with multiple, potentially competing or recurrent events, including multi-state outcomes.
Concluding this part of the book, @sec-survtsk defines different prediction tasks in survival analysis that are used by models and measures to implement machine learning methods.

While these definitions and concepts are not new to survival analysis, it is imperative they are understood to build successful models.
Evaluation functions (Part II) can identify if one model is better suited than another to minimize a given objective function, however they cannot identify if the objective function itself was specified correctly, which depends on the assumptions about the data generating process.
Evaluating models with the wrong objective function yields meaningless results.
Hence, it is of utmost importance for machine learning practitioners to be able identify and specify the survival problem present in their data correctly to ensure models are correctly fit and evaluated.

## Quantifying the Distribution of Event Times {#sec-distributions}

This section introduces functions that can be used to fully characteristise a probability distribution, particular focus is given to functions that are important in survival analysis.

For now, assume a continuous, positive, random variable $Y$ taking values in (t.v.i.) $\NNReals$.
A standard representation of the distribution of $Y$ is given by the probability density function (pdf), $f_Y: \NNReals \rightarrow \NNReals$, and cumulative distribution function (cdf), $F_Y: \NNReals \rightarrow [0,1]; (\tau) \mapsto P(Y \leq \tau)$.

In survival analysis, it is most common to describe the distribution of event times $Y$ via the *survival function* and *hazard function* (or *hazard rate*) rather than the pdf or cdf. The survival function is defined as
$$
S_Y(\tau) = P(Y > \tau) = \int^\infty_\tau f_Y(u) \ du,
$$
which is the probability that an event has not occurred by $\tau \geq 0$ and thus the complement of the cdf: $S_Y(\tau) = 1-F_Y(\tau)$.

The hazard function is given by
$$
h_Y(\tau) = \lim_{\Delta \searrow 0}\frac{P(\tau \leq Y < \tau + \Delta|Y \geq \tau)}{\Delta} = \frac{f_Y(\tau)}{S_Y(\tau)}.
$$

and is interpreted as the instantaneous risk of observing an event at $\tau$, given that the event has not been observed before $\tau$.
This is not a probability and $h_Y$ can be greater than one.

The cumulative hazard function (chf) can be derived from the hazard function by
$$
H_Y(\tau) = \int^\tau_0 h_Y(u) \ du,
$$

and relates to the survival function via

$$
H_Y(\tau) = \int^\tau_0 h_Y(u) \ du = \int^\tau_0 \frac{f_Y(u)}{S_Y(u)} \ du = \int^\tau_0 -\frac{S'_Y(u)}{S_Y(u)} \ du = -\log(S_Y(\tau))
$$

These last relationships are particularly important, as many methods estimate the hazard rate, which is then used to calculate the cumulative hazard and survival probability
$$S_Y(\tau) = \exp(-H_Y(\tau)) = \exp\left(-\int_0^\tau h_Y(u)\ du\right).$${#eq-surv-haz}

Unless necessary to avoid confusion, subscripts are dropped from $S_Y, h_Y$ etc. going forward and instead these functions are referred to as $S$, $h$ (and so on).

Usual regression techniques cannot be used to estimate these quantities as $Y$ is only partially observed, due to different types of censoring and truncation, which are now described.

## Single-event, right-censored data {#sec-data-rc}

Survival analysis has a more complex data setting than other fields as the 'true' data generating process is not directly observable.
The variables of interest are often theoretical and instead engineered variables are defined to capture observed information.
Let,

* $X$ taking values in $\Reals^p$ be the generative random variable representing the data *features*/*covariates*/*independent variables*.
* $Y$ taking values in $\NNReals$ be the (partially unobservable) *true survival time*.
* $C$ taking values in $\NNReals$ be the (partially unobservable) *true censoring time*.

In the presence of censoring $C$, it is impossible to fully observe the true object of interest, $Y$.
Instead, the observable variables are defined by

* $T := \min\{Y,C\}$, the *outcome time* (realisations are refered to as the *observed outcome time*); and
* $\Delta := \II(Y = T) = \II(Y \leq C)$, the *event indicator* (also known as the *censoring* or *status* indicator).

Together $(T,\Delta)$ is referred to as the *survival outcome* or *survival tuple* and they form the dependent variables.
The survival outcome provides a concise mechanism for representing the outcome time and indicating which outcome (event or censoring) took place.

A *survival dataset* is a $n \times p$ Real-valued matrix defined by $\calD = ((\xx_1 \ t_1 \ \delta_1) \cdots (\xx_n,t_n,\delta_n))^\trans$, where $(t_i,\delta_i)$ are realisations of the respective random variables  $(T_i, \Delta_i)$ and $\xx_i$ is a $p$-dimensional vector, $\xx_i = (x_{i;1} \ x_{i;2} \cdots x_{i;p})^\trans$.

Finally, the following quantities are used frequently throughout this book and survival analysis literature more generally.
Let $(t_i, \delta_i) \iid (T,\Delta), i = 1,...,n$, be observed survival outcomes.
Then,

The **set of unique outcome times** is the set of time-points in which at least one observation experiences the event or is censored:

$$
\calU_O \subseteq \{t_i\}_{i \in \{1,...,n\}}
$$

The **set of unique event times** is the set of time-points in which at least one observation experiences the event (but not censored):

$$
\calU_D \subseteq \{t_i: \delta_i = 1\}_{i \in \{1,...,n\}}
$$

The **ordered, unique events times** may also be denoted by

$$
t_{(i)},\ i=1,\ldots,m \quad t_{(1)} < t_{(2)} < \cdots < t_{(m)}, \quad m \leq n
$$

The **risk set at $\tau$**, is the index-set of observation units at risk for the event just before $\tau$

$$\calR_\tau := \{i: t_i \geq \tau\}$$

where $i$ is the index of an observation in the data.
For right-censored data, $\calR_0 = \{1,\ldots,n\}$ and $\calR_{\tau} \subseteq \calR_{\tau'}, \forall \tau > \tau'$.
Note that in a continuous setting, 'just before' refers to an infinitesimally smaller time than $\tau$, in practice as this is unobservable the risk set is defined at $\tau$, hence an observation may both be at risk, and experience an event (or be censored) at $\tau$.

The **number of observations at risk at $\tau$** is the cardinality of the risk set at $\tau$,

$$n_\tau := \sum_i \II(t_i \geq \tau) = |\calR_\tau|$$

Finally, the **number of events at $\tau$** is defined by,

$$d_\tau := \sum_i \II(t_i = \tau, \delta_i = 1)$$

For truly continuous variables, one might expect only one event to occur at each observed event time: $d_{t_i} = 1,\forall i$.
In practice, ties are often observed due to finite measurement precision, such that $d_{\tau} > 1$ occurs frequently in real-world datasets.

The quantities $\calR_\tau$, $n_\tau$, and $d_\tau$ underlie many models and measures in survival analysis.
Several non-parametric and semi-parametric methods (@sec-models-classical) like the Kaplan-Meier estimator [@Kaplan1958] are based on the ratio $d_\tau / n_\tau$.


@tbl-surv-data-rats exemplifies an observed survival dataset with a modified version of the `rats` data  [@pkgsurvival], which contains the time until occurence of a tumor ($\delta_i=1$ if a tumor occured at the outcome time $t_i$ and $\delta_i = 0$ otherwise).
In this example, the above quantities would be:

* $\calU_0 = \{49, 91, 101, 102, 104\}$: with $104$ included only once
* $\calU_D = \{49, 102, 104\}$: with the inclusion of $104$ due to the event at $t_5$, not censoring at $t_3$
* $\calR_{\tau = 102} = \{3, 5, 6\}$ (these rats' outcome times are greater or equal to $\tau = 102$ so they are at risk for the event at this time)
* $n_{\tau = 102} = |\calR_{102}| = 3$
* $d_{\tau = 104} = 1$: As only $i = 5$ experienced the event (and not censoring) at this time.

| **ID** ($i$) | **litter** $(\xx_{;1})$ | **rx** $(\xx_{;2})$ | **sexF** $(\xx_{;3})$ | **time** ($\tt$) | **status** ($\dd$) |
| -- | -- | -- | --- | -- | --|
| 1 | 1 | 1 | 1 | 101 | 0 |
| 2 | 1 | 0 | 1 | 49 | 1 |
| 3 | 1 | 0 | 1 | 104 | 0 |
| 4 | 2 | 1 | 0 | 91 | 0 |
| 5 | 2 | 0 | 0 | 104 | 1 |
| 6 | 2 | 0 | 0 | 102 | 1 |

: Subset of the `rats`  [@pkgsurvival] time-to-event dataset.
Rows are individual observations (ID), $\xx_{;j}$ columns are features, $t$ is observed time-to-event, $\delta$ is the event indicator. {#tbl-surv-data-rats}


## Kaplan-Meier estimator {#sec-surv-km}

Tthe Kaplan-Meier Estimator is a non-parametric method to estimate the survival function (@eq-surv-haz).
The estimator is useful for visualising survival data and is a popular baseline model to compare to the predictive performance of more complex methods.
In machine learning terms it can be viewed as a "featureless" learner for survival analysis.

Using the quantities just introduced, the estimator is simply defined by:

$$
\KMS(\tau) = \prod_{k:t_{(k)} \leq \tau}\left(1-\frac{d_{t_{(k)}}}{n_{t_{(k)}}}\right)
$$ {#eq-km}
which is a step-function at the  observed ordered event times $t_{(k)}, k=1,\ldots,m$ with $\hat{S}_{KM}(\tau) = 1\ \forall \tau < t_{(1)}$.

Sometimes the KM Estimator is also used to estimate the distribution of censoring times, for example to calculate inverse probability of censoring weights (@sec-eval-crank-conc).
Throughout this book, we denote the Kaplan-Meier estimator applied to the observed censoring times $(t_i, 1-\delta_i)$ as $\hat{G}_{KM}$.

## Types of Censoring

Three types of censoring are commonly defined in survival analysis: right-censoring, left-censoring, and interval-censoring.
The latter can be viewed as the most general case.
Multiple types of censoring and/or truncation (@sec-truncation) can occur in any given data set and it is vital to identify which types are present in order to correctly select models and measures for the data.
The explanations below assume only one type of censoring is present in the data, in reality different types of censoring (and truncation) often co-occur.

### Right-censoring {.unnumbered .unlisted}

Right-censoring is the most common form of censoring in survival data and it occurs when an observation has not been observed to experience the event, which may happen because they were no longer observable (for example, they withdrew from a study) or because the event happened after they were observable (for example, after a study ends).
Their exact event time is unknown but it *is* known that the event is after the observed censoring time, hence *right*-censoring (imagine a timeline from left to right as in @fig-survset-censor).

<!-- Formally let $[\tau_l, \tau_u]$ be the study period for some, $\tau_l,\tau_u \in \NNReals$.
Then right-censoring occurs when either $Y > \tau_u$, or when $Y \in [\tau_l,\tau_u]$ and $C \leq Y$.
In the first case $T = C = \tau_u$ and censoring is due to the true time-to-event being unknown as the observation period has finished.
In the latter case, a separate censoring event, such as drop-out is observed. -->

![Dead and censored subjects (y-axis) over time (x-axis). Black diamonds indicate true death times and white circles indicate censoring times. Vertical line is the study end time. Subjects 1 and 2 die in the study time. Subject 3 is censored in the study and (unknown) dies within the study time. Subject 4 is censored in the study and (unknown) dies after the study. Subject 5 dies after the end of the study.](Figures/survival/censoring.png){#fig-survset-censor fig-alt="TODO"}

<!-- FIXME: ADD REF TO THESIS IF WE KEEP THIS FIGURE -->

Right-censoring can be further divided into Type-I, Type-II and random censoring.
Type-I, or *administrative*, censoring occurs at the fixed, pre-defined end of an observation period $\tau_u$, in which case the outcome is given by $(t_i = \min(Y_i, \tau_u), \delta_i = \II(Y_i \leq \tau_u))$.
Censored observations are therefore represented as $(\tau_u, 0)$.
Type-II censoring also occurs when the observation period ends.
However, in this case the study ends when a pre-defined number of subjects experienced the event of interest and hence $\tau_u$ is random.

Random censoring occurs when censoring times *randomly* follow an unknown distribution and one observes $(t_i=\min(Y_i,C_i), \delta_i = \II(Y_i\leq C_i))$.
Different types of right-censoring can, and often do, co-occur in any given data set.

In practice, these different types of right-censoring are usually handled the same during modeling and evaluation and so this book refers to 'right-censoring' generally, which could occur from any combination of the above types.


### Left-censoring {.unnumbered .unlisted}
Left-censoring occurs when the event happens at some unknown time before the study start.
While quiet rare in medical settings, this type of data often occurs in sociology studies when retrospective interviews are conducted.

Consider a survey about phone use where users are asked: "How old were you when you used a smartphone for the first time?".
Let $a_i$ denote the age of a participant during the interview, let $t_i$ be the time at which they first used a smartphone, and let $\delta_i$ be the censoring indicator.
If the participant remembers the age they first used a phone then $(t_i, \delta_i) = (y_i, 1)$ where $y_i \leq a_i$.
On the other hand, if the individual does not remember when the event occured, then all that is known is that they started using a phone on or before their current age, so they are left-censored at $a_i$: $(t_i, \delta_i) = (a_i, 0)$, where $A_i < Y_i$.

<!-- In this example, right-censoring was ignored so $\Delta_i$ could be used as a simple binary ($0/1$) indicator.
In practice, when left- and right-censoring are both present, an additional variable is required to differentiate between left- and right-censoring as well as exact event times.
This is often solved by removing the censoring indicator from the data and adding a second time column, then left-censored data is given by $(-\infty, A_i)$, right-censored data is denoted by $(A_i, \infty)$, and actual event times are $(T_i, T_i)$. -->


### Interval-censoring {.unnumbered .unlisted}

Interval-censoring occurs when the event takes place in some interval within the observation period, but the exact time of event is unknown.
This often occurs in data resulting from regular or irregular check-ups, as often occurs in electronic health record data.
For example, say one patient is checked for skin cancer every year and another every two years.
This data would be collected on a yearly scale and over three years may look something like:

| Patient | Year | Status |
| --- | --- | --- |
| 1 | 1 | 0 |
| 1 | 2 | 1 |
| 1 | 3 | 1 |
| 2 | 1 | 0 |
| 2 | 2 | ? |
| 2 | 3 | 1 |

As data is collected annually for patient 1, it is *known* that they had skin cancer in year 2.
On the other hand, patient 2's data is only collected every other year, so whilst it is known they had cancer in year 3, it is unknown if they already had cancer the year before (assuming there's no method to test how 'old' the cancer is).
In this case, the second patient is interval censored between years one and three.

Formally, consider $L_i$ and $R_i$ two consecutive check-up times for subject $i$.
If the event is observed at $R_i$ then it must have occurred sometime before then, hence $Y_i \in (L_i, R_i]$.
If no event occured then $Y_i > R_i$ and $R_i$ is the right-censoring time.


## Censoring Notation {.unnumbered .unlisted}

The survival outcome notation defined above, $(T, \Delta)$, can lead to ambiguity when multiple censoring types are present.
For example, the survival outcome $(T, 0)$ might indicate right-censoring at time $T$ or left-censoring at time $T$.
One could resolve this by re-defining the survival tuple such that $(T, -1)$ indicates left-censoring, $(T, 0)$ indicates right-censoring, and $(T, 1)$ indicates no censoring, but this quickly clashes with notation when multiple events of interest may occur (@sec-eha).

Instead the survival outcome may be presented as a tuple of times between $(0, \infty)$ which indicate the range at which the event could take place.
Event times and all forms of (single-event) censoring times can then be represented using this tuple.
Given outcome times $t_1 < t_2 \in \PReals$, an observation:

* Is left censored at $t_2$ if their outcome is $(0, t_2)$;
* Is right-censored at $t_1$ if their outcome is $(t_1, \infty)$;
* Is interval-censored between $t_1$ and $t_2$ if their outcome is $(t_1, t_2)$
* Experiences the event at $t_1$ if their outcome is $(t_1, t_1)$

## Dependent vs. Informative Censoring {.unnumbered .unlisted}

Censoring may be defined as *uninformative* if $Y \indep C$ and *informative* otherwise.
However, these definitions can be misleading as the term 'uninformative' could imply that $C$ is independent of both $X$ *and* $Y$, and not just $Y$.
To avoid misinterpretation, the following definitions are used in this book:

* If $C \indep X$, censoring is *feature-independent*, otherwise censoring is *feature-dependent*.
* If $C \indep Y$, censoring is *event-independent*, otherwise censoring is *event-dependent*.
* If $(C \indep Y) | X$, censoring is conditionally independent of the event given covariates, or *conditionally event-independent*.
* If $C \indep (X,Y)$, censoring is *uninformative*, otherwise censoring is *informative*.

Uninformative censoring can generally be well-handled by models as the true underlying distribution of survival times is not affected by censoring.
In fact, in this case one could even use regression models after removing censored observations (if they do not form a high proportion of the data).

In reality, censoring is rarely non-informative as reasons for drop-out or missingness in outcomes tend to be related to the study of interest.
Event-dependent censoring is a tricky case that, if not handled appropriately (by a competing-risks framework), can easily lead to poor model development.
Imagine a study is interested in predicting the time between relapses of stroke but a patient suffers a brain aneurysm due to some separate neurological condition.
There is a high possibility that a stroke may have occurred if the aneurysm had not.
A survival model is unlikely to distinguish the censoring event (aneurysm) from the event of interest (stroke) and will confuse predictions.

In practice, the majority of models and measures assume that censoring is conditionally event-independent and hence censoring patterns can be predicted/estimated based on the covariates.
For example, if studying the survival time of ill pregnant patients in hospital, then dropping out of the study due to pregnancy is clearly dependent on how many weeks pregnant the patient is when the study starts (for the sake of argument assume no early/late pregnancy due to illness).

## Censoring vs. Truncation {#sec-truncation}
A common confusion is to conflate censoring and truncation, which is problematic as the methods to handle them differ substantially.
Outside of time-to-event settings, truncation usually refers to truncating (or removing) an entire subject from a dataset.
As discussed in @sec-intro, truncation in survival analysis refers to partially truncating a period of time and is quite common in the more general event history setting (@sec-sec-eha).

While censored observations have incomplete information about the time-to-event, they are still part of the data set.
Whereas truncation leads to observations not entering the data set (at least not at time 0).
This will usually introduce bias that needs to be accounted for.

### Left-truncation {.unnumbered .unlisted}

Left-truncation often occurs when study participation is conditional on the occurence of another event.
By example, consider a study from the 18th century [@brostrom.influence.1987], when childhood and maternal mortality were relatively high.
The goal of the study was to establish the effect of a mother's death on the survival of the infant.
Since each death was reported to the authorities, an infant was added to the study if and when their mother died.
To create a matched cohort, two other infants, whose mothers were alive, were matched into the study based on their age and other relevant features.
Thus, groups of three infants within the study had identical features except for the status of the mother (alive or dead).
Because of the study design, infants who died before their mothers could never enter into the study. A mother's death is thus refered to as left-truncation event and the infant's age at time of inclusion into the study is refered to as left-truncation time.

More formally, let $t^L_i$ the subject-specific left-truncation time.
Then we only observe subjects with $y_i > t^L_i$ and subjects with $y_i < t^L_i$ never enter the data.

This is illustrated in @fig-left-truncation.
Continuing with the example above, say Infant 1 dies at $t_1$, while the mother dies at some later timepoint $t_1^L$, thefore Infant 1 never enters the study. 
The mother of Infant 2 dies at $t_2^L$, at which point the infant is included in the study and experiences an event at $t_2$.
Finally, say Infant 3 enters the study at $t_3^L$ and is censored at 365 days when the study ends.

![Illustration of left-truncation data. Subjects 2 and 3 enter the data set as the study entry condition (mother's death) occurs before the event of interest occurs after the left-truncation time (left-truncation time shorter than event time). Subject 1 on the other hand never enters the data as the event occurs before the study entry condition (left-truncation time longer than event time).](Figures/survival/left-truncation.png){#fig-left-truncation fig-alt="Schematic illustration of left-truncation."}

Left-truncation plays an important role when modeling recurrent events or multi-state data, as the data generating process induces left-truncation (@sec-eha).


### Right-truncation {.unnumbered .unlisted}

Right-truncation often occurs in retrospective sampling based on registry data, when data is queried for cases reported by a certain cut-off time (see for example @vakulenko-lagun.inverse.2020).
A common example is the estimation of the incubation period of an infectious disease, which is the time from infection to the disease onset.
Only known, symptomatic (and/or tested) cases are entered into the database.
At a time $\tau$, one can only observe the subset of the infected population that has already experienced the disease, and not the population that is still incubating the disease, hence biasing the data to shorter incubation periods.

Formally, let $t_i^r$ be the right-truncation time (here time from infection until the time at which the database is queried), then subjects only enter the data set when $t_i < t_i^r$.
This is illustrated in @fig-right-truncation using three subjects.
All three subjects were infected during the observation period, however,
the right-truncation time $t_2^r$ of subject 2 is shorter than the incubation period $t_2$ for this subject, thus at the time of querying the data base, this subject will no be included in the sample, as $t_2 > t_2^r$.

Note the difference to right-censoring.
If subject 2 was right-censored, the subject would be in our sample and the time of infection would be known - the time of disease onset would be censored.
In case of right-truncation on the other hand, the subject is not included in the sample at time of data extraction, as subjects are only included in the registry after disease onset.
Overall this leads to a bias towards shorter incubation times and potentially feature values that lead to shorter incubation times.

![Illustration of right-truncation based on registry data. For subjects 1 and 3 the right-truncation time is longer than the incubation period, therefore they are included in the sample when the registry is querried. For subject 2 on the other hand the right-truncation time is shorter, therefore it's excluded from the sample.](Figures/survival/right-truncation.png){#fig-right-truncation fig-alt="Schematic illustration of right-truncation."}


## Objective functions  {#sec-surv-obj}

This section describes how the likelihood is constructed for observations subject to different types of censoring and truncation.
For machine learning survival analysis this can be used to construct the objective (or loss) function for any survival task.
Here we assume, that the distribution of event times depends on some parameter vector $\bstheta$.
Following @Klein2003, we can define the likelihood contributions for the different censoring and truncation schemes via the probability of observing the specific outcome:

- observed time to event at $t_i$: $P(Y_i = t_i|\bstheta) = f_y(t_i|\bstheta)$
- right-censoring: $P(Y_i > t_i|\bstheta) = S_Y(t_i|\bstheta)$
- left-censoring: $P(Y_i < t_i|\bstheta) = F_Y(t_i|\bstheta) = 1 - S_Y(t_i|\bstheta)$
- interval-censoring: $P(l_i \leq Y_i < r_i|\bstheta) = S_Y(l_i|\bstheta) - S_Y(r_i|\bstheta)$:
- left-truncation:
  - $\delta_i = 1$: $P(Y_i = t_i|Y_i \geq t_i^L|\bstheta) = \frac{f_Y(t_i|\bstheta)}{S_Y(t_i^L|\bstheta)}$
  - $\delta_i = 0$: $P(Y_i > t_i|Y_i \geq t_i^L|\bstheta) = \frac{S_Y(t_i|\bstheta)}{S_Y(t_i^L|\bstheta)}$
- right-truncation:
  - $\delta_i = 1$: $P(Y_i = t_i|Y_i \leq t_i^R|\bstheta) = \frac{f_Y(t_i|\bstheta)}{F_Y(t_i^R|\bstheta)}$
  - $\delta_i = 0$: $P(Y_i \geq t_i|Y_i \leq t_i^R|\bstheta) = \frac{F_Y(t_i^R|\bstheta) - F_Y(t_i|\bstheta)}{F_Y(t_i^R|\bstheta)}$

Let $\mathcal{O}$, $\mathcal{RC}$, $\mathcal{LC}$, $\mathcal{IC}$, $\mathcal{LT}$, $\mathcal{RT} \subset \mathcal{D}$ subsets of the observed data for subjects with observed event times, right-censoring, left-censoring, interval-censoring, left-truncation and right-truncation, respectively.

Then, assuming independence between observations, the objective function for the observed data can be defined as

$$\mathcal{L}(\bstheta) \propto \prod_{i \in \mathcal{O}}f_Y(t_i|\bstheta) \prod_{i \in \mathcal{RC}}S_Y(t_i|\bstheta) \prod_{i \in \mathcal{LC}}(1-S_Y(t_i|\bstheta))\cdots$$ {#eq-objective-function}

Note that in in practice, data sets will often only contain one type of censoring or truncation, if any, in which case @eq-objective-function will contain only a few product terms.
For the standard setting with right-censored data this will for example reduce to the familiar form

$$\mathcal{L}(\bstheta) \propto \prod_{i \in \mathcal{O}}f_Y(t_i|\bstheta) \prod_{i \in \mathcal{RC}}S_Y(t_i|\bstheta) = \prod_{i=1}^{n}f_Y(t_i|\bstheta)^{\delta_i}S_Y(t_i|\bstheta)^{1-\delta_i}$$



{{< include _wip.qmd >}}
