% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode,linktoc=all}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  letterpaper,
]{scrbook}

\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in,heightrounded]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{makeidx}
\usepackage{mathtools}
\usepackage{algpseudocode,algorithm,algorithmicx}
\makeindex
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[many]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\usepackage{amsthm}
\theoremstyle{plain}
\newtheorem{conjecture}{Box}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
\theoremstyle{remark}
\renewcommand*{\proofname}{Proof}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[many]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Machine Learning in Survival Analysis},
  pdfauthor={Raphael Sonabend},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Machine Learning in Survival Analysis}
\author{Raphael Sonabend}
\date{}

\begin{document}
\frontmatter
\maketitle
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[colback={shadecolor}, boxrule=0pt, enhanced, breakable, frame hidden]}{\end{tcolorbox}}\fi

\renewcommand*\contentsname{Table of contents}
{
\setcounter{tocdepth}{2}
\tableofcontents
}
\listoffigures
\listoftables
\mainmatter
\bookmarksetup{startatroot}

\hypertarget{welcome}{%
\chapter*{Welcome}\label{welcome}}
\addcontentsline{toc}{chapter}{Welcome}

\markboth{Welcome}{Welcome}

This book\ldots{}

\bookmarksetup{startatroot}

\hypertarget{preface}{%
\chapter*{Preface}\label{preface}}
\addcontentsline{toc}{chapter}{Preface}

\markboth{Preface}{Preface}

\hypertarget{symbols-and-notation}{%
\section*{Symbols and Notation}\label{symbols-and-notation}}
\addcontentsline{toc}{section}{Symbols and Notation}

\markright{Symbols and Notation}

The most common symbols and notation used throughout this book are
presented below; in rare cases where different meanings are intended
within the book, this will be made clear.

\hypertarget{cases-fonts-and-symbols}{%
\subsection*{Cases, Fonts, and Symbols}\label{cases-fonts-and-symbols}}
\addcontentsline{toc}{subsection}{Cases, Fonts, and Symbols}

Lower-case letters, \(x\), refer to fixed (`realised', `observed')
values and upper-case letters, \(X\), refer to random variables. For
example \(X\) is a random variable (r.v.) taking values in (t.v.i.) the
set \(\mathcal{X}\) if, \(X: \Omega \rightarrow \mathcal{X}\) where
\(\Omega\) is the sample space of all possible outcomes; then
\(x \in \mathcal{X}\) is a possible realised value from \(X\). A
lower-case (Greek or Latin) letter, \(x\), refers to either a single
element or a vector, which will be clear from context. Calligraphic
letters, \(\mathcal{X}\), are used to refer to sets. A lower-case
bold-face letter, \(\mathbf{x}\), refers to a matrix. If \(x\) is a
vector then \(x_i\) refers to the \(i\)th element in this vector. If
\(\mathbf{x}\) is a matrix then \(x_i\) refers to the \(i\)th row of the
matrix, \(x_{;j}\) refers to the \(j\)th column of the matrix, and
\(x_{ij}\) refers to the \(i\)th row of the \(j\)th column of matrix
\(\mathbf{x}\). Unless otherwise stated, a `vector' is used to refer to
a column vector. An element with a `hat', \(\hat{x}\), refers to the
prediction or estimation of the variable without the hat, \(x\). Inline
code and datasets will use \texttt{this\ font} and package names will
look like this
\href{https://cran.r-project.org/package=survival}{\texttt{survival}}.
Finally, any dates will be presented in the ISO format: YYYY-MM-DD.

\emph{Italicised text} emphasises a word or phrase that is the focus of
the sentence or definition. `Single quotation marks' are most often
utilised to signify that the word or phase will either be defined later
in the thesis, or to identify when a word should be taken in an English
and not mathematical sense, for example `a good model' would signify
that the phrase does not refer to a particular mathematical definition
of a model being good. `'Double quotation marks'' are reserved for
direct quotes and are always followed by the associated citation.

\hypertarget{distributions-and-random-variables}{%
\subsection*{Distributions and Random
Variables}\label{distributions-and-random-variables}}
\addcontentsline{toc}{subsection}{Distributions and Random Variables}

Two separate notations are used to represent probability distributions
and random variables. The first is the `standard' notation: let \(X\) be
a random variable following some distribution \(\zeta\), then \(f_X\) is
the probability density function of \(X\).

The second notation instead associates distribution functions directly
with the distribution and not the variable. So if \(\zeta\) is a
distribution then \(\zeta.f\) is the probability density function of
\(\zeta\); analogously for other distribution defining functions. This
notation is described in full detail when first introduced in the
thesis.

\hypertarget{variables}{%
\subsection*{Variables}\label{variables}}
\addcontentsline{toc}{subsection}{Variables}

The majority of variables will be defined when required however below
are some that are commonly used throughout this thesis.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.4737}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.5263}}@{}}
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
Variable
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} \\
\midrule()
\endhead
\(\mathbb{R}\) & Set of Reals. \\
\(\mathbb{R}_{>0}\) & Set of Positive Reals (excluding zero). \\
\(\mathbb{R}_{\geq 0}\) & Set of Non-Negative Reals (including zero). \\
\(\bar{\mathbb{R}}\) & Set of Extended Reals, equal to
\(\mathbb{R}\cup \{-\infty, +\infty\}\). \\
\(\mathbb{N}_0\) & Set of Naturals (including zero). \\
\(\mathbb{N}_{> 0}\) & Set of Positive Naturals (excluding zero). \\
\(\mathcal{N}\) & Normal distribution. \\
\(\mathcal{U}\) & Uniform distribution. \\
\(x, \mathbf{x}, X, \mathcal{X}\) & Vector, matrix, random variable, and
set of features. \\
\(y, \mathbf{y}, Y, \mathcal{Y}\) & Vector, matrix, random variable, and
set of true outcomes. \\
\(t, \mathbf{t}, T, \mathcal{T}\) & Vector, matrix, random variable, and
set of observed time outcomes. \\
\(\delta, \Delta\) & Vector and random variable of survival/censoring
indicators. \\
\(\beta\) & Vector of model coefficients, or weights. \\
\(\eta\) & Linear predictor, \(X\beta\). \\
\(\zeta.f\) & Probability density function of distribution \(\zeta\). \\
\(\zeta.F\) & Cumulative distribution function of distribution
\(\zeta\). \\
\(\zeta.h\) & Hazard function of distribution \(\zeta\). \\
\(\zeta.H\) & Cumulative hazard function of distribution \(\zeta\). \\
\(\zeta.S\) & Survival function of distribution \(\zeta\). \\
\(\mathcal{L}\) & Likelihood function. \\
\bottomrule()
\end{longtable}

The indicator function, \(\mathbb{I}(\cdot)\), expects a well-defined
logical statement \((\cdot)\) and equals \(1\) when this statement is
true, and \(0\) otherwise. Any distribution function with a `\(0\)' in
the subscript refers to the `baseline' function, e.g.~\(h_0, S_0\) are
the baseline hazard and baseline survival functions respectively.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.4737}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.5263}}@{}}
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
Function
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} \\
\midrule()
\endhead
\(\operatorname{Distr}(\mathcal{D})\) & Space of distributions over the
set \(\mathcal{D}\). \\
\(|x|\) & Absolute value of \(x\). \\
\(\|x\|\) & Euclidean norm of vector \(x\),
\(\sqrt{|x_1|^2 + ... + |x_n|^2}\). \\
\(\bar{x}\) & Sample mean of vector \(x\),
\(\frac{1}{n} \sum^{n}_{i = 1} x_i\). \\
\(\mathbb{E}(X)\) & Expectation of random variable \(X\). \\
\(\operatorname{Var}(X)\) & Variance of random variable \(X\). \\
\bottomrule()
\end{longtable}

Let \(f: \mathcal{X}\rightarrow \mathcal{Y}\) be any function with
domain \(\mathcal{X}\) and codomain \(\mathcal{Y}\). Then the
\emph{function signature} of \(f\) is
\(\mathcal{X}\rightarrow \mathcal{Y}\). Arguments and parameters are
separated in function signatures by a pipe, `\(|\)', where variables to
the left are parameters (free variables) and those to the right are
arguments (fixed). For example let \(f\) be an indicator function that
`checks' if the parameter, \(\phi\), is below the fixed argument,
\(\theta\), then \(f\) is fully defined by

\[
f: \mathbb{R}\times \mathbb{R}\rightarrow \{0,1\}; \quad (\phi|\theta) \mapsto \mathbb{I}(\phi < \theta)
\]

Traditionally arguments are not included in the formal signature and the
above could be expressed as: Let \(\theta \in \mathbb{R}\) then
\(f: \mathbb{R}\rightarrow \{0,1\}; \ (\phi) \mapsto \mathbb{I}(\phi < \theta)\).
The first notation is preferred as it clearly specifies all variables
included in the function with their domains, whether they are free or
fixed, and cleanly extends to multiple parameters and arguments.

\textbf{Acronyms}

Below is a table of acronyms used throughout this thesis (styled as they
appear in the text), these are all fully defined the first time they are
used.

\begin{longtable}[]{@{}ll@{}}
\toprule()
Acronym & Definition \\
\midrule()
\endhead
AFT & Accelerated Failure Time \\
APT & Accessible, Performant, Transparent \\
ANN & Artificial Neural Network \\
AUC & Area Under the Curve \\
cdf & Cumulative Distribution Function \\
chf & Cumulative Hazard Function \\
CPH & Cox Proportional Hazards \\
GBM & Gradient Boosting Machine \\
GLM & Generalised Linear Model \\
IGS & Integrated Graf Score \\
IPC(W) & Inverse Probability of Censoring (Weighted) \\
I(S)LL & Integrated (Survival) Log Loss \\
KM & Kaplan-Meier \\
LHS & Left Hand Side \\
MAE & Mean Absolute Error \\
ML & Machine Learning \\
pdf & Probability Density Function \\
PH & Proportional Hazards \\
PO & Proportional Odds \\
RHS & Right Hand Side \\
(R)MSE & (Root) Mean Squared Error \\
ROC & Receiver Operating Characteristic \\
R(S)F & Random (Survival) Forest \\
r.v. & Random Variable \\
(S)SVM & (Survival) Support Vector Machine \\
s.t. & Such That \\
TNR & True Negative Rate \\
TPR & True Positive Rate \\
t.v.i. & Taking Values In \\
w.r.t. & With Respect To \\
(W)(S)DLL & (Weighted) (Survival) Density Log Loss \\
\bottomrule()
\end{longtable}

\bookmarksetup{startatroot}

\hypertarget{sec-intro}{%
\chapter{Introduction}\label{sec-intro}}

Writing in the middle of a global pandemic, applications of survival
analysis are more relevant than ever. Predicting the time from onset of
COVID-19 symptoms to hospitalisation, or the time from hospitalisation
to intubation, or intubation to death, are all time-to-event predictions
that are at the centre of survival analysis. As well as morbid
applications, survival analysis predictions may be concerned with
predicting the time until a customer cancels their gym membership, or
the lifetime of a lightbulb; any event that is guaranteed (or at least
very likely) to occur can be modelled by a survival analysis prediction.
As these predictions can be so sensitive, for example a model predicting
when a child should be taken off breathing support (Data Study Group
Team 2020), the best possible predictions, evaluated to the highest
standard, are a necessity. In other fields of predictive modelling,
machine learning has made incredible breakthroughs (such as
\href{https://deepmind.com/research/case-studies/alphafold}{AlphaFold}\footnote{\url{https://deepmind.com/research/case-studies/alphafold}}),
therefore applying machine learning to survival analysis is a natural
step in the evolution of an important field.

Survival analysis is the field of Statistics focusing on modelling the
distribution of an event, which may mean the time until the event takes
place, the risk of the event happening, the probability of the event
occurring at a single time, or the event's underlying probability
distribution. Survival analysis (`survival') is a unique field of study
in Statistics as it includes the added difficulty of `censoring'.
Censoring is best described through example: a study is conducted to
determine the mortality rate of a group of patients after diagnoses with
a particular disease. If a patient dies during this study then their
outcome is `death' and their time of death can be recorded. However if a
patient drops-out of the study before they die, then their time of death
(though guaranteed to occur) is unknown and the only available
information is the time at which they left the study. This patient is
now said to be \emph{censored} at the time they drop out. The censoring
mechanism allows as much outcome information (time and event) to be
captured as possible for all patients (observations).

Machine learning (ML) is the field of Statistics primarily concerned
with building models to either predict outputs from inputs or to learn
relationships from data (Hastie, Tibshirani, and Friedman 2001; James et
al. 2013). This thesis is limited to the former case, or more
specifically supervised learning, as this is the field in which the vast
majority of survival problems live. Relative to other areas of
supervised learning, development in survival analysis has been slow --
the majority of developments in machine learning for survival analysis
have only been in the past decade (see chapters
(\textbf{?@sec-review})-(\textbf{?@sec-eval})). This appears to have
resulted in less interest in the development of machine learning
survival models (\textbf{?@sec-review}), less rigour in the evaluation
of such models (\textbf{?@sec-eval}), and fewer off-shelf/open-source
implementations (\textbf{?@sec-tools}). This thesis seeks to set the
foundations for clear workflows, good practice, and precise results for
`machine learning survival analysis'.

Section~\ref{sec-intro-motobj} will elaborate further on the motivation
and objectives behind this PhD; research objectives and contributions
are then presented in Section~\ref{sec-intro-structure}.

\hypertarget{sec-intro-motobj}{%
\section{Motivations and Objectives}\label{sec-intro-motobj}}

Experiments throughout the literature demonstrate that machine learning
survival models often perform worse (or at least no better) than
classical statistical models (Goli et al. 2016; KATTAN 2003;
Ohno-Machado 1997; Puddu and Menotti 2012) (also see
\textbf{?@sec-bench}).\footnote{The distinction between a `classical'
  and `machine learning' model used in this thesis is provided in
  \textbf{?@sec-chap-review}.} This thesis sets out to explore why this
is the case and how this has potential to be improved. The following
questions, based on observations of the field, motivated this thesis:

\hypertarget{why-are-regression-and-classification-more-popular-than-survival-analysis-in-machine-learning}{%
\subsection{Why are regression and classification more popular than
survival analysis in machine
learning?}\label{why-are-regression-and-classification-more-popular-than-survival-analysis-in-machine-learning}}

There is no doubt that this is the case, for example the `bibles of
machine learning' (Bishop 2006; Hastie, Tibshirani, and Friedman 2001;
James et al. 2013) discuss classification and regression in detail but
survival analysis is never discussed. Survival analysis has important
applications in healthcare, finance, engineering and more, all fields
that directly impact upon individual lives on a day-to-day basis, and
should perhaps be considered as important as classification and
regression. The result of this gap in interest, is the erroneous
assumption that one field can be directly applied to another. For
example there is evidence of researchers treating censoring as a
nuisance to be ignored and using regression models instead (Schwarzer,
Vach, and Schumacher 2000). Censoring is indeed a challenge and may
contribute to making survival analysis less accessible than other
fields, but this need not be the case; a clear unification of
terminology and presentation of methods may help make `machine learning
survival analysis' more accessible. Added accessibility could lead to
more academics (and non-academics) engaging with the field and promoting
good standards of practice, as well as developing more novel models and
measures.

\textbf{Why are probabilistic survival predictions important?}

Development of survival models appears to be skewed towards `ranking
models', which predict the relative risk of an event occurring
(\textbf{?@sec-surv-set-types}). In many applications these predictions
are sufficient, for example in randomised control trials if assessing
the increased/decreased risk of an event after treatment. However, there
are many use-cases where predicting an individual's survival probability
distribution is required. Take, for example, an engineer calculating the
lifetime of a plane's engine.\footnote{In this engineering context,
  survival analysis is usually referred to as reliability analysis.}
There are three important reasons to replace a jet engine at the optimal
time:

\begin{itemize}
\tightlist
\item
  financial: jet engines are very expensive and replacing one sooner
  than required is a waste of money;
\item
  environmental: an engine being replaced too early is a waste of
  potential usage;
\item
  safety: if the engine is replaced too late then there is a risk to
  passengers.
\end{itemize}

Now consider examples for the three possible `prediction types' the
engineer can make:

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  A `relative risk prediction': This engine is twice as likely to fail
  as another.
\item
  A `survival time prediction': The engine is expected to fail in 30
  days.
\item
  A `survival distribution prediction': The lifetime of the engine is
  distributed according to the probability distribution \(\zeta\).
\end{enumerate}

The first prediction type is not useful as the underlying relative risk
may be unknown and the engineer is concerned with the individual
lifetime. The second prediction type provides a useful quantity for the
engineer to work with however there is no uncertainty captured in this
prediction. The third prediction type can capture the uncertainty of
failure over the entirety of the positive Reals (though usually only a
small subset is possible and useful). With this final prediction type,
the engineer can create safe decisions: `replace the engine at time
\(\tau\), where \(\tau\) is the time when the predicted probability of
survival drops below 60\%, \(S(\tau) = 0.6\)'. There are ethical,
economic, and environmental reasons for a good survival distribution
prediction and this thesis considers a distribution prediction to be the
most important prediction type.

\textbf{How are survival models evaluated?}

Evaluating predictions from survival models is of the utmost importance.
This is especially important as survival models are often deployed in
the public domain, particularly in healthcare. Physical products in
healthcare, such as new vaccines, undergo rigorous testing and research
in randomised control trials before being publically deployed; the same
level of rigour should be expected for the evaluation of survival models
that are used in life-and-death situations. Evaluation measures for
regression and classification are well-understood with important
properties, however survival measures have not undergone the same
treatment. For example many survival models are still being evaluated
solely with concordance indices that have been repeatedly crticised
(GÃ¶nen and Heller 2005; Rahman et al. 2017; Schmid and Potapov 2012).
This paper argues for the use of scoring rules
(Section~\ref{sec-eval-distr}), which simultaneously assess predictions
of distribution and relative risk.

Motivated by these questions, this thesis attempts to unify the two
fields of machine learning and survival analysis to make the
intersection of the two (`machine learning survival analysis') more
concise and accessible. This aim is guided by three key themes:
Accessibility, Transparency, and Performance. These are now briefly
described to explain why they have been identified as key principles for
this thesis.

\hypertarget{sec-intro-motobj-tap}{%
\subsection{Accessibility, Transparency, and Predictive
Performance}\label{sec-intro-motobj-tap}}

In all critical analyses there must be a metric with which to judge the
surveyed objects. For example, machine learning models may be judged by
predictive performance, i.e.~does one model outperform another? Or
estimators may be judged according to bias and consistency properties.
As this thesis compares multiple different types of objects, a more
universal criteria is applied for the reviews, surveys, and comparisons.
These are: Accessibility, Transparency, and (predictive) Performance. A
model that satisfies all three criteria may be considered APT
(accessible, transparent, performant). These key themes are now briefly
described and then further discussion is given to why all must be
satisfied for this thesis to consider a model or measure to be `good'.
These are primarily explained in terms of a `model', though all extend
naturally to other objects.

A model is termed \emph{accessible} if there either exists an
open-source implementation of the model, or sufficient infrastructure
and published mathematics for the model to be implementable.\footnote{The
  term `accessible' is slightly more general than terms such as
  `off-shelf' as accessibility is defined to include objects that are
  not off-shelf but that can be implemented given information provided
  in the literature.} For example, a novel neural network without an
open-source implementation can still be accessible if the model's
architecture is clearly described and can therefore be implemented with
neural network packages such as TensorFlow (Abadi et al. 2015).

A model is called \emph{transparent} if its properties are
well-understood, its use and manipulation of data is clear, and its
predictions have a precise interpretation. The word `transparent' does
not refer to the inner workings of the model and therefore a transparent
model could still be a `black-box'.\footnote{Therefore the term
  `transparent' here does not refer to the concept of a `glass-box'
  model, which is the opposite of a black-box model.} For example,
random forests (\textbf{?@sec-surv-ml-models-ranfor}) are built of
hundreds or thousands of individual predictive models, thus making it
impossible to fully identify how the final prediction is created.
However the model is considered transparent as it is mathematically
clear and intuitive how it utilises the individual components to produce
its prediction.

A model has good predictive \emph{performance} if its predictions are
notably improved over some baseline model (Gressmann et al. 2018).
Unlike transparency and accessibility, it is possible to quantify
performance and compare this between models (\textbf{?@sec-eval}).
Whilst there is often a trade-off between predictive performance and
model interpretability (e.g.~compare neural networks and linear
regression), this is not the case for predictive performance and
transparency. When considering non-predictive objects, such as measures,
then performance instead refers to verifying other established
performance properties, for example consistency, unbiasedness, and
robustness. An object with good performance is called `performant'.

Performance is traditionally the primary metric by which models (and
measures) are judged, but this thesis only considers a model to be
`good' (or APT) if all three of these themes are satisfied. In fact, it
can be demonstrated that if even one of these conditions is not
satisfied a model can be dishonest or inefficient.

By example, take the model that always predicts the height of a person
as 42cm. This model is very accessible and transparent but has terrible
predictive performance, the model is therefore useless. Now consider a
patented model without open-source implementation that not only makes
perfect predictions but is also clearly described. In this case as no
accessible implementation exists, the model cannot be used and tested by
the community and more importantly cannot be externally validated,
leading to ethical questions about commercial implementation and even
whether the results can be trusted. Finally, in the case of an
accessible model with strong predictive performance but without clear
description in a paper or reader-friendly code/documentation, there can
only be limited trust in the model's performance, especially with
respect to future performance.

\hypertarget{sec-intro-structure}{%
\section{Book Structure}\label{sec-intro-structure}}

\begin{itemize}
\item
  \textbf{?@sec-surv} introduces the survival and machine learning
  settings separately. First a mathematical overview to survival
  analysis is provided (\textbf{?@sec-surv-set}) and then the scope of
  this thesis is identified and justified (\textbf{?@sec-surv-scope}).
  Survival prediction types are then mathematically defined for use
  throughout the thesis (\textbf{?@sec-surv-set-types}). This is then
  mirrored for machine learning by first introducing supervised learning
  and important machine learning methods (\textbf{?@sec-surv-setml}) and
  then defining survival analysis as a machine learning task
  (\textbf{?@sec-surv-setmltask}).
\item
  \textbf{?@sec-review} reviews classical survival models
  (\textbf{?@sec-surv-models}) and surveys machine learning survival
  models ( \textbf{?@sec-surv-ml} - \textbf{?@sec-surv-ml-models-nn}).
  Only a short review is provided for the classical setting as this has
  been covered extensively in the literature over the past few decades.
  This thesis takes a novel approach by focusing the classical review on
  model prediction types, in order to gain clarity in understanding how
  the models can and cannot be utilised. The rest of the chapter
  critically surveys the use of machine learning in survival analysis.
  The survey is first split by machine learning classes, and then
  further categorised again by model prediction types.
\item
  \textbf{?@sec-eval} discusses how to evaluate the models introduced in
  the previous chapter. This starts (Section~\ref{sec-eval-why}) with a
  general discussion about the importance of evaluation and how survival
  measures must be selected to relate to the correct survival task. The
  chapter continues with a full review of the different types of
  survival measures, how these relate, and what properties exist for the
  most common of these. Extensive discussion is given to survival
  scoring rules (Section~\ref{sec-eval-distr}) including introducing and
  completing novel definitions (Section~\ref{sec-eval-distr-score-surv})
  and proofs (Section~\ref{sec-eval-distr-score-proper}).
\item
  \textbf{?@sec-tools} focuses entirely on software engineering and
  introduces the packages that have been published to the
  \emph{Comprehensive R Archive Network}
  (\href{https://cran.r-project.org/}{CRAN}\footnote{\url{https://cran.r-project.org/}}).
  The chapter begins (\textbf{?@sec-tools-intro}) with a general
  overview to the ecosystem that the packages live in, as well as their
  original motivations.
\end{itemize}

\hypertarget{code-and-reproducibility}{%
\subsection{Code and Reproducibility}\label{code-and-reproducibility}}

Finally, some brief words on the programming present in this thesis.

\textbf{Programming Languages} This thesis includes simulations and
figures generated in \(\textsf{R}\) and the benchmark experiments in
\textbf{?@sec-bench} are also conducted in \(\textsf{R}\). Some Python
implementations are considered in \textbf{?@sec-review}. Only
\(\textsf{R}\) and Python are considered as they are the two most
popular open-source programming languages that intersect classical
statistics and machine learning. Further discussion on these languages
is provided in \textbf{?@sec-tools}.

\textbf{Reproducibility} The \(\textsf{R}\) code for any figures or
experiments in this thesis are freely available at
\url{https://github.com/RaphaelS1/MLSA} under an MIT licence, all
content on this website is available under CC BY 4.0. For any code that
requires specific software packages, these are listed when required
alongside version numbers. All \(\textsf{R}\) scripts have set seeds for
reproducibility. The code used in this thesis was run using various
\(\textsf{R}\) versions from 3.6 to 4.0.2 and whilst this should not
affect reproducibility, this cannot be guaranteed.

\bookmarksetup{startatroot}

\hypertarget{statistical-learning}{%
\chapter{Statistical Learning}\label{statistical-learning}}

\section{Machine Learning}
\label{sec:surv_setml}

This section begins with a very brief introduction to machine learning
and a focus on regression and classification; the survival machine
learning task is then introduced \ref{sec:surv_setmltask}. Of the many
fields within machine learning (ML), the scope of this thesis is
narrowed to supervised learning. Supervised learning is the sub-field of
ML in which predictions are made for outcomes based on data with
observed dependent and independent variables. For example predicting
someone's height is a supervised learning problem as data can be
collected for features (independent variables) such as age and sex, and
outcome (dependent variable), which is height. Predictive survival
analysis problems fall naturally in the supervised learning framework as
there are identifiable features and (multiple types of) outcomes.

\subsection{Terminology and Methods}
\label{sec:surv_setml_meth}

Common supervised learning methods are discussed in a simplified setting
with features \(X \ t.v.i. \ \mathcal{X}\) and outcomes
\(Y \ t.v.i. \ \mathcal{Y}\); usually outcomes are referred to as
\texttt{targets\textquotesingle{}\ (a}target for prediction'). Let
\(\mathcal{D}_0 = \{(X_1,Y_1),...,(X_n,Y_n)\}\) be a (training) dataset
where \((X_i, Y_i) \stackrel{i.i.d.}\sim(X, Y)\). The methods below
extend naturally to the survival setting.

\paragraph{Strategies and Models}

In order to clearly separate between similar objects, several terms for
machine learning are now introduced and clearly distinguished.

Let \(g: \mathcal{X}\rightarrow \mathcal{Y}\) be the true (but unknown)
mapping from the features to outcomes, referred to as the
\emph{true prediction functional}. Let \(\mathcal{G}\) be the set of
\emph{prediction functionals} such that
\(\forall \Upsilon \in \mathcal{G}, \Upsilon: \mathcal{X}\rightarrow \mathcal{Y}\).
A \emph{learning} or \emph{fitting algorithm} is defined to be any
function of the form
\(\mathcal{A}: \mathcal{X}^n \times \mathcal{Y}^n \rightarrow \mathcal{G}\).
The goal of supervised learning is to \emph{learn} \(g\) with a learning
algorithm \emph{fit} on (i.e.~the input to the algorithm is) training
data, \(\hat{g}:= \mathcal{A}(\mathcal{D}_0) \in \mathcal{G}\). Note
that \(\hat{g}\) may take hyper-parameters that can be set or tuned (see
below). The learning algorithm is
\texttt{good\textquotesingle{}\ if\ \$\textbackslash{}hatg(X)\ \textbackslash{}approx\ g(X)\$\ (see}Evaluation'
below).

The learning algorithm is determined by the chosen
\emph{learning strategy} and \emph{model}, where a model is a complete
specification of a learning strategy including hyper-parameters. These
terms are more clearly illustrated by example:

\begin{itemize}
\tightlist
\item
  Learning strategy -- simple linear regression
\item
  Model -- \(y = \beta_0 + \beta_1 x\) where \(x \in \mathbb{R}\) is a
  single covariate, \(y \in \mathbb{R}\) is the target, and
  \(\beta_0,\beta_1 \in \mathbb{R}\) are model coefficients.
\item
  Learning algorithm (model fitting) -- Minimise the residual sum of
  squares:
  \((\hat{\beta_0}, \hat{\beta_1}) := \operatornamewithlimits{argmin}_{\beta_0,\beta_1} \{\sum^n_{i=1} (y_i - \beta_0 - \beta_1 x_i)^2\}\)
  for \((x_i,y_i) \in \mathcal{D}_0, i = 1,...,n\).
\item
  Prediction functional --
  \(\hat{g}(x) = \hat{\beta_0} + \hat{\beta_1}x\)
\end{itemize}

To further illustrate the difference between learning strategy and
model, note that the same learning strategy `simple linear regression'
could either utilise the model above or instead a model without
intercept, \(y = \beta x\), in which case the learning algorithm and
prediction functional would also be modified.

The model in (ii) is called \emph{unfitted} as the model coefficients
are unknown and the model cannot be used for prediction. After step
(iii) the model is said to be fit to the training data and therefore the
model is
\emph{fitted}.\footnote{The terms `fitted' and `unfitted' are used instead of `fit' and `unfit' to prevent confusion with words such as `suitable' and `unsuitable'.}
It is common to refer to the learning algorithm (and associated
hyper-parameters) as the unfitted model and to refer to the prediction
functional (and associated hyper-parameters) as the fitted model.

\paragraph{Evaluation}

Models are \emph{evaluated} by evaluation measures called \emph{losses}
or
\emph{scores},\footnote{The term `loss' is usually utilised to refer to evaluation measures to be minimised, whereas `scores' should be maximised, this is returned to in \ref{chap:eval}.}
\(L: \mathcal{Y}\times \mathcal{Y}\rightarrow \bar{\mathbb{R}}\). Let
\((X^*, Y^*) \sim (X,Y)\) be test data (i.e.~independent of
\(\mathcal{D}_0\)) and let
\(\hat{g}: \mathcal{X}\rightarrow \mathcal{Y}\) be a prediction
functional fit on \(\mathcal{D}_0\), then these evaluation measures
determine how closely predictions, \(\hat{g}(X^*)\), relate to the
truth, \(Y^*\), thereby providing a method for determining if a model is
`good'.\footnote{Here evaluation refers specifically to predictive ability; other forms of evaluation and further discussion of the area are provided in \ref{chap:eval}.}

\paragraph{Task}

A machine learning \emph{task} is a simple mechanism to outline the
problem of interest by providing: i) the data specification; ii) the
definition of learning; iii) the definition of success (when is a
prediction
\texttt{good\textquotesingle{}?)\textasciitilde{}\textbackslash{}cite\{Kiraly2021\}.\ All\ tasks\ in\ this\ paper\ have\ the\ same\ definitions\ of\ learning\ and\ success.\ For\ (ii),\ the\ aim\ is\ to\ learn\ the\ true\ prediction\ functional,\ \$g\$,\ by\ fitting\ the\ learning\ algorithm\ on\ training\ data,\ \$\textbackslash{}hatg\ :=\ \textbackslash{}calA(\textbackslash{}calD\_0)\$.\ For\ (iii),\ a\ predicted\ functional\ is\ considered}good'
if the \emph{expected generalization error},
\(\mathbb{E}[L(Y^*, \hat{g}(X^*))]\), is low, where
\((X^*, Y^*) \sim (X,Y)\) is independent of the training data
\(\mathcal{D}_0\), and \(L\) is some loss that is chosen according to
the domain of interest (regression, classification, survival).

\paragraph{Resampling}

Models are \emph{tested} on their ability to make predictions. In order
to avoid
\texttt{optimism\ of\ training\ error\textquotesingle{}\textasciitilde{}\textbackslash{}cite\{Hastie2013\}\ -\/-\ overconfidence\ caused\ by\ testing\ the\ model\ on\ training\ data\ -\/-\ models\ are\ tested\ on\ previously\ unseen\ or}held-out'
data. \emph{Resampling} is the procedure of splitting one dataset into
two or more for separated training and testing. In this paper only two
resampling methods are utilised: \emph{holdout} and
\emph{cross-validation}. Holdout is the process of splitting a primary
dataset into training data for model fitting and testing data for model
predicting. This is an efficient method but may not accurately estimate
the expected generalisation error for future model performance, instead
this is well-estimated by \(K\)-fold cross-validation
(KCV)\textasciitilde{}\cite{Hastie2001}. In KCV, data is split into
\(K \in \mathbb{N}_{> 0}\) `folds' such that \(K-1\) of the folds are
used for model training and the final \(K\)th fold for testing. The
testing fold is iterated over all \(K\) folds, so that each at some
point is used for testing and then training (though never at the same
time). In each iteration the model is fit on the training folds, and
predictions are made and evaluated on the testing fold, giving a loss
\(L_k := L(\hat{g}(X^k), Y^k)\), where \((X^k, Y^k)\) are data from the
\(k\)th fold. A final loss is defined by,
\(L^* := \frac{1}{K} \sum^K_{k = 1} L_k\). Commonly \(K = 5\) or
\(K = 10\)\textasciitilde{}\cite{Breiman1992, Kohavi1995}.

\paragraph{Model Performance Benchmarking}

Whilst \emph{benchmarking} often refers to speed tests, i.e.~the time
taken to complete an operation, it can also refer to any experiment in
which objects (mathematical or computational) are compared. In this
report, a benchmark experiment will either refer to the comparison of
multiple models' predictive abilities, or comparison of computational
speeds and object sizes for model fitting; which of these will be clear
from context.

\paragraph{Model Comparison}

Models can be analytically compared on how well they make predictions
for new data. Model comparison is a complex topic with many open
questions\textasciitilde{}\cite{Demsar2006, Dietterich1998, Nadeau2003}
and as such discussion is limited here. When models are compared on
multiple datasets, there is more of a consensus in how to evaluate
models\textasciitilde{}\cite{Demsar2006} and this is expanded on further
in \ref{chap:bench}. Throughout this thesis there are small simulation
experiments for model comparison on single datasets however as these are
primarily intended to aid exposition and not to generalise results, it
suffices to compare models with the conservative method of constructing
confidence intervals around the sample mean and standard error of the
loss when available\textasciitilde{}\cite{Nadeau2003}.

\paragraph{Hyper-Parameters and Tuning}

A \emph{hyper-parameter} is a model parameter that can be set by the
user, as opposed to coefficients that are estimated as part of model
fitting. A hyper-parameter can be set before training, or it can be
tuned. \emph{Tuning} is the process of choosing the optimal
hyper-parameter value via automation. In the simplest setting, tuning is
performed by selecting a range of values for the hyper-parameter(s) and
treating each choice (combination) as a different model. For example if
tuning the number of trees in a random forest
\ref{sec:surv_ml_models_ranfor}, \(m_r\), then a range of values, say
\(100, 200, 500\) are chosen, and three models
\(m_{r100}, m_{r200}, m_{r500}\) are benchmarked. The optimal
hyper-parameter is given by whichever model is the best performing.
\emph{Nested resampling} is a common method to prevent overfitting that
could occur from using overlapping data for tuning, training, or
testing. Nested resampling is the process of resampling the training set
again for tuning.

\newpage
\subsection{Machine Learning in Classification and Regression}
\label{sec:surv_ml_car}

Before introducing machine learning for survival analysis, which is
considered `non-classical', the more standard classification and
regression set-ups are provided; these are referenced throughout this
thesis.

\subsubsection{Classification}
\label{sec:surv_ml_car_class}

Classification problems make predictions about categorical (or discrete)
events, these may be \emph{deterministic} or \emph{probabilistic}.
Deterministic classification predicts which category an observation
falls into, whereas probabilistic classification predicts the
probability of an observation falling into each category. In this brief
introduction only binary single-label classification is discussed,
though the multi-label case is considered in
\ref{sec:car_reduxes_r7_mlc}. In binary classification, there are two
possible categories an observation can fall into, usually referred to as
the \texttt{positive\textquotesingle{}\ and}negative' class. For example
predicting the probability of death due to a virus is a probabilistic
classification task where the `positive' event is death.

A probabilistic prediction is more informative than a deterministic one
as it encodes uncertainty about the prediction. For example it is
clearly more informative to predict a \(70\%\) chance of rain tomorrow
instead of simply
\texttt{rain\textquotesingle{}.\ Moreover\ the\ latter\ prediction\ implicitly\ contains\ an\ erroneous\ assumption\ of\ certainty,\ e.g.}it
will rain tomorrow'.

\begin{tcolorbox}[enhanced jigsaw, title={Classification Task}, breakable, leftrule=.75mm, rightrule=.15mm, opacityback=0, coltitle=black, colback=white, toptitle=1mm, toprule=.15mm, bottomtitle=1mm, titlerule=0mm, arc=.35mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, left=2mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame]

\leavevmode\vadjust pre{\hypertarget{cnj-task-classif}{}}%
\begin{conjecture}[]\label{cnj-task-classif}

Let \((X,Y)\) be random variables t.v.i.
\(\mathcal{X}\times \mathcal{Y}\) where
\(\mathcal{X}\subseteq \mathbb{R}^p\) and \(\mathcal{Y}= \{0, 1\}\).
Then,

\begin{itemize}
\tightlist
\item
  The \emph{probabilistic classification task} is the problem of
  predicting the probability of a single event taking place and is
  specified by \(g: \mathcal{X}\rightarrow [0, 1]\).
\item
  The \emph{deterministic classification task} is the problem of
  predicting if a single event takes place and is specified by
  \(g: \mathcal{X}\rightarrow \mathcal{Y}\).
\end{itemize}

The estimated prediction functional \(\hat{g}\) is fit on training data
\textbackslash{}\((X_1,Y_1),...,(X_n,Y_n) \stackrel{i.i.d.}\sim(X,Y)\)
and is considered `good' if \(\mathbb{E}[L(Y^*, \hat{g}(X^*))]\) is low,
where \((X^*, Y^*) \sim (X, Y)\) is independent of
\((X_1,Y_1),...,(X_n,Y_n)\) and \(\hat{g}\).

In the probabilistic case, the prediction \(\hat{g}\) maps to the
estimated probability mass function \(\hat{p}_Y\) s.t.
\(\hat{p}_Y(1) = 1 - \hat{p}_Y(0)\).

\end{conjecture}

\end{tcolorbox}

\subsubsection{Regression}
\label{sec:surv_ml_regr}

A regression prediction is one in which the goal is to predict a
continuous outcome from a set of features. For example predicting the
time until an event (without censoring) occurs, is a regression problem.

\begin{tcolorbox}[enhanced jigsaw, title={Regression Task}, breakable, leftrule=.75mm, rightrule=.15mm, opacityback=0, coltitle=black, colback=white, toptitle=1mm, toprule=.15mm, bottomtitle=1mm, titlerule=0mm, arc=.35mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, left=2mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame]

\leavevmode\vadjust pre{\hypertarget{cnj-task-regr}{}}%
\begin{conjecture}[]\label{cnj-task-regr}

Let \((X,Y)\) be random variables t.v.i.
\(\mathcal{X}\times \mathcal{Y}\) where
\(\mathcal{X}\subseteq \mathbb{R}^p\) and
\(\mathcal{Y}\subseteq \mathbb{R}\). Let
\(\mathcal{S}\subset \operatorname{Distr}(\mathcal{Y})\) be a convex set
of distributions on \(\mathcal{Y}\). Then,

\begin{itemize}
\tightlist
\item
  The \emph{probabilistic regression task} is the problem of predicting
  a conditional distribution over the Reals and is specified by
  \(g : \mathcal{X}\rightarrow \mathcal{S}\).
\item
  The \emph{deterministic regression task} is the problem of predicting
  a single continuous value in the Reals and is specified by
  \(g: \mathcal{X}\rightarrow \mathcal{Y}\).
\end{itemize}

The estimated prediction functional \(\hat{g}\) is fit on training data
\textbackslash{}\((X_1,Y_1),...,(X_n,Y_n) \stackrel{i.i.d.}\sim(X,Y)\)
and is considered `good' if \(\mathbb{E}[L(Y^*, \hat{g}(X^*))]\) is low,
where \((X^*, Y^*) \sim (X, Y)\) is independent of
\((X_1,Y_1),...,(X_n,Y_n)\) and \(\hat{g}\).

\end{conjecture}

\end{tcolorbox}

Whilst regression can be either probabilistic or deterministic, the
latter is much more common and therefore in this thesis `regression'
refers to the deterministic case unless otherwise stated.

\section{Survival Analysis Task}
\label{sec:surv_setmltask}

The survival prediction problems identified in \ref{sec:surv_set_types}
are now formalised as machine learning tasks.

\begin{tcolorbox}[enhanced jigsaw, title={Survival Task}, breakable, leftrule=.75mm, rightrule=.15mm, opacityback=0, coltitle=black, colback=white, toptitle=1mm, toprule=.15mm, bottomtitle=1mm, titlerule=0mm, arc=.35mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, left=2mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame]

\leavevmode\vadjust pre{\hypertarget{cnj-task-surv}{}}%
\begin{conjecture}[]\label{cnj-task-surv}

Let \((X,T,\Delta)\) be random variables t.v.i.
\(\mathcal{X}\times \mathcal{T}\times \{0,1\}\) where
\(\mathcal{X}\subseteq \mathbb{R}^p\) and
\(\mathcal{T}\subseteq \mathbb{R}_{\geq 0}\). Let
\(\mathcal{S}\subseteq \ensuremath{\operatorname{Distr}(\mathcal{T})}\)
be a convex set of distributions on \(\mathcal{T}\) and let
\(\mathcal{R}\subseteq \mathbb{R}\). Then,

\begin{itemize}
\tightlist
\item
  The \emph{probabilistic survival task} is the problem of predicting a
  conditional distribution over the positive Reals and is specified by
  \(g: \mathcal{X}\rightarrow \mathcal{S}\).
\item
  The \emph{deterministic survival task} is the problem of predicting a
  continuous value in the positive Reals and is specified by
  \(g: \mathcal{X}\rightarrow \mathcal{T}\).
\item
  The \emph{survival ranking task} is specified by predicting a
  continuous ranking in the Reals and is specified by
  \(g: \mathcal{X}\rightarrow \mathcal{R}\).
\end{itemize}

The estimated prediction functional \(\hat{g}\) is fit on training data
\textbackslash{}\((X_1,T_1,\Delta_1),...,(X_n,T_n,\Delta_n) \stackrel{i.i.d.}\sim(X,T,\Delta)\)
and is considered `good' if
\textbackslash{}\(\mathbb{E}[L(T^*, \Delta^*, \hat{g}(X^*))]\) is low,
where \((X^*, T^*, \Delta^*) \sim (X, T, \Delta)\) is independent of
\((X_1,T_1,\Delta_1),...,(X_n,T_n,\Delta_n)\) and \(\hat{g}\).

\end{conjecture}

\end{tcolorbox}

Any other survival prediction type falls within one of these tasks
above, for example predicting log-survival time is the deterministic
task and predicting prognostic index or linear predictor is the ranking
task. Removing the separation between the prognostic index and ranking
prediction types is due to them both making predictions over the Reals;
their mathematical difference lies in interpretation only. In general,
the survival task will assume that
\(\mathcal{T}\subseteq \mathbb{R}_{\geq 0}\), and the terms
\texttt{discrete\textquotesingle{}\ or}reduced survival task' will refer
to the case when \(\mathcal{T}\subseteq \mathbb{N}_0\). Unless otherwise
specified, the `survival task', will be used to refer to the
probabilistic survival
task.\footnote{These definitions are given in the most general case where the time variable is over $\mathbb{R}_{\geq 0}$. In practice, all models instead assume time is over $\mathbb{R}_{>0}$ and any death at $T_i = 0$ is set to $T_i = \epsilon$ for some very small $\epsilon \in \mathbb{R}_{>0}$. Analogously for the discrete survival task. This assumption may not reflect reality as a patient could die at the study start however models cannot typically include this information in training.}

\paragraph{Survival Analysis and Regression}

Survival and regression tasks are closely related as can be observed
from their respective definitions. Both are specified by
\(g : \mathcal{X}\rightarrow \mathcal{S}\) where for probabilistic
regression \(\mathcal{S}\subseteq \operatorname{Distr}(\mathbb{R})\) and
for survival
\(\mathcal{S}\subseteq \operatorname{Distr}(\mathbb{R}_{\geq 0})\).
Furthermore both settings can be viewed to use the same generative
process. In the survival setting in which there is no censoring then
data is drawn from
\((X,Y) \ t.v.i. \ \mathcal{X}\times \mathcal{T}, \mathcal{T}\subseteq \mathbb{R}_{\geq 0}\)
and in regression from
\((X,Y) \ t.v.i. \ \mathcal{X}\times \mathcal{Y}, \mathcal{Y}\subseteq \mathbb{R}\),
so that the only difference is whether the outcome data ranges over the
Reals or positive Reals.

These closely related tasks are discussed in more detail in
\ref{sec:car_redux}, with a particular focus on how the more popular
regression setting can be used to solve survival tasks. In
\ref{chap:review} the models are first introduced in a regression
setting and then the adaptations to survival are discussed, which is
natural when considering that historically machine learning survival
models have been developed by adapting regression models.

\bookmarksetup{startatroot}

\hypertarget{survival-analysis}{%
\chapter{Survival Analysis}\label{survival-analysis}}

\chapter[Survival Analysis and Machine Learning]{Survival Analysis and Machine\\Learning}
\label{chap:surv}

In their broadest and most basic definitions, survival analysis is the
study of temporal data from a given origin until the occurrence of one
or more events or `end-points'\textasciitilde{}\cite{Collett2014}, and
machine learning is the study of models and algorithms that learn from
data in order to make predictions or find
patterns\textasciitilde{}\cite{Hastie2001}. Reducing either field to
these definitions is ill-advised.

This chapter collects terminology utilised in survival analysis
\ref{sec:surv_set} and machine learning \ref{sec:surv_setml} in order
that this thesis can cleanly discuss
\texttt{machine\ learning\ survival\ analysis\textquotesingle{}\ \textbackslash{}ref\{sec:surv\_setmltask\}.\ Once\ the\ mathematical\ setting\ is\ set\ up,\ the\ thesis\ scope\ is\ fully\ presented\ in\ \textbackslash{}ref\{sec:surv\_scope\}.\ Whilst\ the\ content\ of\ this\ chapter\ is\ not\ novel\ with\ respect\ to\ either\ survival\ analysis\ or\ machine\ learning\ separately,\ this\ does\ appear\ to\ be\ the\ first\ formulation\ of\ the\ survival\ analysis\ machine\ learning}task'\textasciitilde{}\cite{Kiraly2021}.

\section{Survival Analysis}
\label{sec:surv_set}

Survival analysis is the field of Statistics concerned with the analysis
of time-to-event data, which consists of covariates, a categorical
(often binary) outcome, and the time until this outcome takes place (the
`survival time'). As a motivating example of time-to-event data, say 100
patients are admitted to a COVID-19 ward and for each patient the
following covariate data are collected: age, weight and sex;
additionally for each patient the time until death or discharge is
recorded. In the time-to-event dataset, which takes a standard tabular
form, each of the 100 patients is a row, with columns consisting of age,
weight, and sex measurements, as well as the outcome (death or
discharge) and the time to outcome.

Survival analysis is distinct from other areas of Statistics due to the
incorporation of
\texttt{censoring\textquotesingle{},\ a\ mechanism\ for\ capturing\ uncertainty\ around\ when\ an\ event\ occurs\ in\ the\ real-world.\ Continuing\ the\ above\ example,\ if\ a\ patient\ dies\ of\ COVID-19\ five\ dies\ after\ admittance,\ then\ their\ outcome\ is\ exactly\ known:\ they\ \textbackslash{}emph\{died\}\ after\ five\ days.\ Consider\ now\ a\ patient\ who\ is\ discharged\ after\ ten\ days.\ As\ death\ is\ a\ guaranteed\ event\ they\ have\ a\ true\ survival\ time\ but\ this\ may\ be\ decades\ later,\ therefore\ they\ are\ said\ to\ be\ \textbackslash{}emph\{censored\}\ at\ ten\ days.\ This\ is\ a\ convenient\ method\ to\ express\ that\ the\ patient\ survives\ up\ to\ ten\ days\ and\ their\ survival\ status\ at\ any\ time\ after\ this\ point\ is\ unknown.\ Censoring\ is\ a\ unique\ challenge\ to\ survival\ analysis\ that\ attempts\ to\ incorporate\ as\ much\ information\ as\ possible\ without\ knowing\ the\ true\ outcome.\ This\ is\ a}challenge'
as statistical models usually rely on learning from observed,
i.e.~known, outcome data; therefore censoring requires special
treatment.

Whilst survival analysis occurs in many fields, for example as
\texttt{reliability\ analysis\textquotesingle{}\ in\ engineering\ and}duration
analysis' in economics, in this thesis the term
\texttt{survival\textquotesingle{}\ will\ always\ be\ used.\ Moreover\ the\ following\ terminology,\ analogous\ to\ a\ healthcare\ setting,\ are\ employed:\ survival\ analysis\ (or}survival'
for short) refers to the field of study; the event of interest is the
\texttt{event\textquotesingle{},\ or}death'; an observation that has not
experienced an event is \texttt{censored\textquotesingle{}\ or}alive';
and observations are referred to as
\texttt{observations\textquotesingle{},}subjects', or `patients'.

Some of the biggest challenges in survival analysis stem from an unclear
definition of a `survival analysis prediction' and different (sometimes
conflicting) common notations. This thesis attempts to make discussions
around survival analysis clearer and more precise by first describing
the mathematical setting for survival analysis in
\ref{sec:surv_set_math} and only then defining the prediction types to
consider in \ref{sec:surv_set_types}.

\subsection{Survival Data and Definitions}
\label{sec:surv_set_math}

Survival analysis has a more complicated data setting than other fields
as the `true' data generating process is not directly modelled but
instead engineered variables are defined to capture observed
information. Let,

\begin{itemize}
\tightlist
\item
  \(X \ t.v.i. \ \mathcal{X}\subseteq \mathbb{R}^p, p \in \mathbb{N}_{> 0}\)
  be the generative random variable representing the data
  \emph{features}/\emph{covariates}/\emph{independent variables}.
\item
  \(Y \ t.v.i. \ \mathcal{T}\subseteq \mathbb{R}_{\geq 0}\) be the
  (unobservable) \emph{true survival time}.
\item
  \(C \ t.v.i. \ \mathcal{T}\subseteq \mathbb{R}_{\geq 0}\) be the
  (unobservable) \emph{true censoring time}.
\end{itemize}

It is impossible to fully observe both \(Y\) and \(C\). This is clear by
example: if an observation drops out of a study then their censoring
time is observed but their event time is not, whereas if an observation
dies then their true censoring time is unknown. Hence, two engineered
variables are defined to represent observable outcomes. Let,

\begin{itemize}
\tightlist
\item
  \(T := \min\{Y,C\}\) be the \emph{observed outcome time}.
\item
  \(\Delta := \mathbb{I}(Y = T) = \mathbb{I}(Y \leq C)\) be the
  \emph{survival indicator} (also known as the \emph{censoring} or
  \emph{event}
  indicator).\footnote{Indicators are usually named to reflect a positive condition in the function (in this case the event when $Y = T$), but counter to this convention the `censoring indicator' is possibly the most common term.}
\end{itemize}

Together \((T,\Delta)\) is referred to as the \emph{survival outcome} or
\emph{survival tuple} and they form the dependent variables. The
survival outcome provides a concise mechanism for representing the time
of the \emph{observed} outcome and indicating which outcome (death or
censoring) took place.

Now the full generative template for survival analysis is given by
\textbackslash{}
\((X, \Delta, C, Y, T) \ t.v.i. \ \mathcal{X}\times \{0,1\}\times \mathcal{T}\times \mathcal{T}\times \mathcal{T}\)
and with \((X_i, \Delta_i, C_i, Y_i, T_i)\) jointly i.i.d. A
\emph{survival dataset} is defined by
\(\mathcal{D}= \{(X_1,T_1,\Delta_1),...,(X_n,T_n,\Delta_n)\}\) where
\((X_i,T_i,\Delta_i) \stackrel{i.i.d.}\sim(X,T,\Delta)\) and \(X_i\) is
a \(p\)-vector, \(X_i = (X_{i;1},...,X_{i;p})\). Though unobservable,
the true outcome times are defined by \((Y_1,C_1),...,(Y_n,C_n)\) where
\((Y_i,C_i) \stackrel{i.i.d.}\sim(Y,C)\).

\ref{tab:surv_data_abs} exemplifies a random survival dataset with \(n\)
observations (rows) and \(p\) features.

\hypertarget{tbl-surv-data-abs}{}
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1333}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1333}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1333}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1333}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1333}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1333}}@{}}
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
X
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
X
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
X
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
T
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(\Delta\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Y
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
C
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
X
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
X
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
X
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
T
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(\Delta\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Y
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
C
\end{minipage} \\
\midrule()
\endhead
\(X_{11}\) & \(\cdots\) & \(X_{1p}\) & \(T_1\) & \(\Delta_1\) & \(Y_1\)
& \(C_1\) \\
\(\vdots\) & \(\ddots\) & \(\vdots\) & \(\vdots\) & \(\vdots\) &
\(\vdots\) & \(\vdots\) \\
\(X_{n1}\) & \(\cdots\) & \(X_{np}\) & \(T_n\) & \(\Delta_n\) & \(Y_n\)
& \(C_n\) \\
\bottomrule()
\caption{\label{tbl-surv-data-abs}Theoretical time-to-event dataset.
\((Y,C)\) are `hypothetical' as they can never be directly observed.
Rows are individual observations, \(X\) columns are features, \(T\) is
observed time-to-event, \(\Delta\) is the censoring indicator, and
\((Y,C)\) are hypothetical true survival and censoring
times.}\tabularnewline
\end{longtable}

\ref{tab:surv_data_rats} exemplifies an observed survival dataset with a
modified version of the \texttt{rats}
dataset\textasciitilde{}\cite{pkgsurvival}.

\textbf{litter} \((X_{.;1})\) \textbar{} \textbf{rx} \((X_{.;2})\)
\textbar{} \textbf{sexF} \((X_{.;3})\) \textbar{} \textbf{time}
\textbar{} \textbf{status} \textbar{} \textbf{survTime} \textbar{}
\textbf{censTime} \textbar{}\\
X \textbar{} X \textbar{} X \textbar{} T \textbar{} \(\Delta\)
\textbar{} Y \textbar{} C \textbar{}\\
-- \textbar{} -- \textbar{} --- \textbar{} -- \textbar{} --\textbar{} --
\textbar{} -- \textbar{}\\
1 \textbar{} 1 \textbar{} 1 \textbar{} 101 \textbar{} 0 \textbar{} 105
\textbar{} 101 \textbar{}\\
1 \textbar{} 0 \textbar{} 1 \textbar{} 49 \textbar{} 1 \textbar{} 49
\textbar{} 55\textbar{}\\
1 \textbar{} 0 \textbar{} 1 \textbar{} 104 \textbar{} 0 \textbar{} 200
\textbar{} 104 \textbar{}\\
2 \textbar{} 1 \textbar{} 0 \textbar{} 91 \textbar{} 0 \textbar{} 92
\textbar{} 91 \textbar{}\\
2 \textbar{} 0 \textbar{} 0 \textbar{} 104 \textbar{} 1 \textbar{} 104
\textbar{} 104 \textbar{}\\
2 \textbar{} 0 \textbar{} 0 \textbar{} 102 \textbar{} 1 \textbar{} 102
\textbar{} 120 \textbar{}

: \texttt{rats}\textasciitilde{}\cite{pkgsurvival} time-to-event dataset
with added hypothetical columns (\(Y,C\)). Rows are individual
observations, \(X\) columns are features, \(T\) is observed
time-to-event, \(\Delta\) is the censoring indicator, and \((Y,C)\) are
hypothetical (here arbitrary values dependent on \((T,\Delta)\)) true
survival and censoring times. \{\#tbl-surv-data-rats\}

Both datasets includes two extra columns, on the right of the triple
vertical line, which imagine hypothetical data for the unobserved true
survival and censoring times. \textbackslash\textbackslash{} Finally the
following terms are used frequently throughout this report. Let
\((T_i, \Delta_i) \stackrel{i.i.d.}\sim(T,\Delta), i = 1,...,n\), be
random survival outcomes. Then,

\begin{itemize}
\tightlist
\item
  The \emph{set of unique} or \emph{distinct time-points} refers to the
  set of time-points in which at least one observation dies or is
  censored, \(\mathcal{U}_O := \{T_i\}_{i \in \{1,...,n\}}\).
\item
  The \emph{set of unique death times} refers to the set of unique
  time-points in which death (and not censoring) occurred,
  \(\mathcal{U}_D := \{T_i : \Delta_i = 1\}_{i \in \{1,...,n\}}\).
\item
  The \emph{risk set} at a given time-point, \(\tau\), is the set of
  subjects who are known to be alive (not dead or censored) just before
  that time, \(\mathcal{R}_\tau := \{i: T_i \geq \tau\}\) where \(i\) is
  a unique row/subject in the data.
\item
  The \emph{number of observations alive} at \(\tau\) is the cardinality
  of the risk set, \(|\mathcal{R}_\tau|\), and is denoted by
  \(n_\tau := \sum_i \mathbb{I}(T_i \geq \tau)\).
\item
  The \emph{number of observations who die} at \(\tau\) is denoted by
  \(d_\tau := \sum_i \mathbb{I}(T_i = \tau, \Delta_i = 1)\).
\item
  The Kaplan-Meier estimate of the average survival function of the
  training data \emph{survival distribution} is the Kaplan-Meier
  estimator \ref{sec:surv_models_uncond} fit \ref{sec:surv_setml_meth}
  on training data \((T_i, \Delta_i)\) and is denoted by
  \(\hat{S}_{KM}\).
\item
  The Kaplan-Meier estimate of the average survival function of the
  training data \emph{censoring distribution} is the Kaplan-Meier
  estimator fit on training data \((T_i, 1 - \Delta_i)\) and is denoted
  by \(\hat{G}_{KM}\).
\end{itemize}

Notation and definitions will be recapped at the start of each chapter
for convenience.

\subsection{Censoring}
\label{sec:surv_set_cens}

Censoring is now discussed in more detail and important concepts
introduced. Given the survival generating process \((X,T,\Delta)\) with
unobservable \((Y,C)\), the event is experienced if \(Y \leq C\) and
\(\Delta = 1\) or censored if \(\Delta = 0\).

\noindent 

\paragraph{Censoring `Location'}

Right-censoring is the most common form of censoring in survival models
and it occurs either when a patient drops out (but doesn't experience
the event) of the study before the end and thus their outcome is
unknown, or if they experience the event at some unknown point after the
study end. Formally let \([\tau_l, \tau_u]\) be the study period for
some, \(\tau_l,\tau_u \in \mathbb{R}_{\geq 0}\). Then right-censoring
occurs when either \(Y > \tau_u\) or when \(Y \in [\tau_l,\tau_u]\) and
\(C \leq Y\). In the first case \(T = C = \tau_u\) and censoring is due
to the true time of death being unknown as the observation period has
finished. In the latter case, a separate censoring event, such as
drop-out or another competing risk, is observed.

Left-censoring is a rarer form of censoring and occurs when the event
happens at some unknown time before the study start, \(Y < \tau_l\).
Interval-censoring occurs when the event takes place in some interval
within the study period, but the exact time of event is unknown.
\ref{fig:survset_censor} shows a graphical representation of
right-censoring.

\begin{figure}

{\centering \includegraphics{./images/survival/censoring.png}

}

\caption{\label{fig-survset-censor}Dead and censored subjects (y-axis)
over time (x-axis). Black diamonds indicate true death times and white
circles indicate censoring times. Vertical line is the study end time.
Subjects 1 and 2 die in the study time. Subject 3 is censored in the
study and (unknown) dies within the study time. Subject 4 is censored in
the study and (unknown) dies after the study. Subject 5 dies after the
end of the study.}

\end{figure}

\paragraph{Censoring `Dependence'}

Censoring is often defined as \emph{uninformative} if
\(Y \perp \!\!\! \perp C\) and \emph{informative} otherwise however
these definitions can be misleading as the term `uninformative' appears
to be imply that censoring is independent of both \(X\) and \(Y\), and
not just \(Y\). Instead the following more precise definitions are used
in this report.

\leavevmode\vadjust pre{\hypertarget{def-cens}{}}%
\begin{definition}[Censoring]\label{def-cens}

Let \((X,T,\Delta,Y,C)\) be defined as above, then

\begin{itemize}
\tightlist
\item
  If \(C \perp \!\!\! \perp X\), censoring is
  \emph{feature-independent}, otherwise censoring is
  \emph{feature-dependent}.
\item
  If \(C \perp \!\!\! \perp Y\), then censoring is
  \emph{event-independent}, otherwise censoring is
  \emph{event-dependent}.
\item
  If \((C \perp \!\!\! \perp Y) | X\), censoring is conditionally
  independent of the event given covariates, or
  \emph{conditionally event-independent}.
\item
  If \(C \perp \!\!\! \perp(X,Y)\) censoring is \emph{uninformative},
  otherwise censoring is \emph{informative}.
\end{itemize}

\end{definition}

Non-informative censoring can generally be well-handled by models as
true underlying patterns can still be detected and the reason for
censoring does not affect model inference or predictions. However in the
real-world, censoring is rarely non-informative as reasons for drop-out
or missingness in outcomes tend to be related to the study of interest.
Event-dependent censoring is a tricky case that, if not handled
appropriately (by a competing-risks framework), can easily lead to poor
model development; the reason for this can be made clear by example: Say
a study is interested in predicting the time between relapses of stroke
but a patient suffers a brain aneurysm due to some separate neurological
condition, then there is a high possibility that a stroke may have
occurred if the aneurysm had not. Therefore a survival model is unlikely
to distinguish the censoring event (aneurysm) from the event of interest
(stroke) and will confuse predictions. In practice, the majority of
models and measures assume that censoring is conditionally
event-independent and hence censoring can be predicted by the covariates
whilst not directly depending on the event. For example if studying the
survival time of ill pregnant patients in hospital, then dropping out of
the study due to pregnancy is clearly dependent on how many weeks
pregnant the patient is when the study starts (for the sake of argument
assume no early/late pregnancy due to illness).

\paragraph{Type I Censoring}

Type I and Type II censoring are special-cases of right-censoring, only
Type I is discussed in this thesis as it is more common in simulation
experiments. Type I censoring occurs if a study has a set end-date, or
maximum survival time, and a patient survives until the end of the
study. If survival times are dependent on covariates (i.e.~not random)
and the study start date is known (or survival times are shifted to the
same origin) then Type I censoring will usually be informative as
censored patients will be those who survived the longest.

\section{Thesis Scope}
\label{sec:surv_scope}

Now that the mathematical setting has been defined, the thesis scope is
provided. For time and relevance the scope of this thesis is narrowed to
the most parsimonious setting that is genuinely useful in modelling
real-world scenarios. This is the setting that captures all assumptions
made by the majority of proposed survival models and therefore is
practical both theoretically and in application. This setting is defined
by the following assumptions (with justifications):

\begin{itemize}
\tightlist
\item
  Let \(p\) be the proportion of censored observations in the data, then
  \(p \in (0,1)\). This open interval prevents the case when \(p = 0\),
  which is simply a regression problem \ref{sec:surv_ml_regr}, or the
  case when \(p = 1\), in which no useful models exist (as the event
  never occurs).
\item
  Only right-censoring is observed in the data, no left- or
  interval-censoring. This accurately reflects most real-world data in
  which observations that have experienced the event before the study
  start (left-censoring) are usually not of interest, and close
  monitoring of patients means that interval-censoring is unlikely in
  practice. It is acknowledged that left-truncation is a common problem
  in medical datasets though this is often handled not by models but by
  data pre-processing, which is not part of the workflow discussed in
  this thesis.
\item
  There is only one event of interest, an observation that does not
  experience this event is censored. This eliminates the `competing
  risk' setting in which multiple events of interest can be modelled.
\item
  The event can happen at most once. For example the event could be
  death or initial diagnosis of a disease however cannot be recurrent
  such as seizure. In the case where the event could theoretically
  happen multiple times, only the time to one (usually the first)
  occurrence of the event is modelled.
\item
  The event is guaranteed to happen at least once. This is an assumption
  implicitly made by all survival models as predictions are for the time
  until the true event, \(Y\), and not the observed outcome, \(T\).
\end{itemize}

For both the multi-event and recurrent-event cases, simple reductions
exist such that these settings can be handled by the models discussed in
this paper however this is not discussed further here.

No assumptions are made about whether censoring is dependent on the data
but when models and measures make these assumptions, they will be
explicitly discussed. \textbackslash\textbackslash{} The purpose of any
statistical analysis is dependent on the research question. For example
techniques are available for data analysis, imputation, exploration,
prediction, and more. This thesis focuses on the predictive setting;
other objectives, such as model inspection and data exploration can be
achieved post-hoc via interpretable machine learning
techniques\textasciitilde{}\cite{Molnar2019}.
\textbackslash\textbackslash{} Finally, the methods in this thesis are
restricted to frequentist statistics. Bayesian methods are not discussed
as the frequentist setting is usually more parsimonious and additionally
there are comparatively very few off-shelf implementations of Bayesian
survival methods. Despite this, it is noted that Bayesian methods are
particularly relevant to the research in this thesis, which is primarily
concerned with uncertainty estimates and predictions of distributions.
Therefore, a natural extension to the work in this thesis would be to
fully explore the Bayesian setting.

\section{Survival Prediction Problems}
\label{sec:surv_set_types}

This section continues by defining the survival problem narrowed to the
scope described in the previous section. Defining a single
\texttt{survival\ prediction\ problem\textquotesingle{}\ (or}task') is
important mathematically as conflating survival problems could lead to
confused interpretation and evaluation of models. Let \((X,T,\Delta)\)
and \(\mathcal{D}\) be as defined above. A general survival prediction
problem is one in which:

\begin{itemize}
\tightlist
\item
  a survival dataset, \(\mathcal{D}\), is split
  \ref{sec:surv_setml_meth} for training, \(\mathcal{D}_0\), and
  testing, \(\mathcal{D}_1\);
\item
  a survival model is fit on \(\mathcal{D}_0\); and
\item
  the model predicts some representation of the unknown true survival
  time, \(Y\), given \(\mathcal{D}_1\).
\end{itemize}

The process of
\texttt{fitting\textquotesingle{}\ is\ model-dependent,\ and\ can\ range\ from\ simple\ maximum\ likelihood\ estimation\ of\ model\ coefficients,\ to\ complex\ algorithms.\ \ The\ model\ fitting\ process\ is\ discussed\ in\ more\ abstract\ detail\ in\ \textbackslash{}ref\{sec:surv\_setml\}\ and\ then\ concrete\ algorithms\ are\ discussed\ in\ \textbackslash{}ref\{chap:review\}.\ The\ different\ survival\ problems\ are\ separated\ by}prediction
types' or
\texttt{prediction\ problems\textquotesingle{},\ these\ can\ also\ be\ thought\ of\ as\ predictions\ of\ different}representations'
of \(Y\). Four prediction types are discussed in this paper, these may
be the only possible survival prediction types and are certainly the
most common as identified in chapters \ref{chap:review} and
\ref{chap:eval}. They are predicting:

\begin{itemize}
\tightlist
\item
  The \emph{relative risk} of an individual experiencing an event -- A
  single continuous ranking.
\item
  The \emph{time until an event} occurs -- A single continuous value.
\item
  The \emph{prognostic index} for a model -- A single continuous value.
\item
  An individual's \emph{survival distribution} -- A probability
  distribution.
\end{itemize}

The first three of these are referred to as \emph{deterministic}
problems as they predict a single value whereas the fourth is
\emph{probabilistic} and returns a full survival distribution.
Definitions of these are expanded on below.
\textbackslash\textbackslash{} Survival predictions differ from other
fields in two respects. Firstly, the predicted outcome, \(Y\), is a
different object than the outcome used for model training,
\((T, \Delta)\). This differs from, say, regression in which the same
object (a single continuous variable) is used for fitting and
predicting. Secondly, with the exception of the time-to-event
prediction, all other prediction types do not predict \(Y\) but some
other related quantity.

Survival prediction problems must be clearly separated as they are
inherently incompatible. For example it is not meaningful to compare a
relative risk prediction from one observation to a survival distribution
of another. Whilst these prediction types are separated above, they can
be viewed as special cases of each other. Both (1) and (2) may be viewed
as variants of (3); and (1), (2), and (3) can all be derived from (4);
this is elaborated on below.

\paragraph{Relative Risk/Ranking}

This is perhaps the most common survival problem and is defined as
predicting a continuous rank for an individual's
\texttt{relative\ risk\ of\ experiencing\ the\ event\textquotesingle{}.\ For\ example,\ given\ three\ patients,\ \$\textbackslash{}\{i,j,k\textbackslash{}\}\$,\ a\ relative\ risk\ prediction\ may\ predict\ the}risk
of event' as \(\{0.1, 0.5, 10\}\) respectively. From these predictions,
the following types of conclusions can be drawn:

\begin{itemize}
\tightlist
\item
  Conclusions comparing patients. e.g.~\(i\) is at the least risk; the
  risk of \(j\) is only slightly higher than that of \(i\) but the risk
  of \(k\) is considerably higher than \(j\); the corresponding ranks
  for \(i,j,k,\) are \(1,2,3\).
\item
  Conclusions comparing risk groups. e.g.~thresholding risks at \(1.0\)
  places \(i\) and \(j\) in a
  \texttt{low-risk\textquotesingle{}\ group\ and\ \$k\$\ in\ a}high-risk'
  group
\end{itemize}

So whilst many important conclusions can be drawn from these
predictions, the values themselves have no meaning when not compared to
other individuals. Interpretation of these rankings has historically
been conflicting in implementation, with some software having the
interpretation
\texttt{higher\ ranking\ implies\ higher\ risk\textquotesingle{}\ whereas\ others\ may\ indicate}higher
ranking implies lower risk' \ref{sec:tools_mlr3proba_api_learn}. In this
thesis, a higher ranking will always imply a higher risk of event (as in
the example above).

\paragraph{Time to Event}

Predicting a time to event is the problem of predicting the
deterministic survival time of a patient, i.e.~the amount of time for
which they are predicted to be alive after some given start time. Part
of the reason this problem is less common in survival analysis is
because it borders regression -- a single continuous value is predicted
-- and survival -- the handling of censoring is required -- but neither
is designed to solve this problem directly. Time-to-event predictions
can be seen as a special-case of the ranking problem as an individual
with a predicted longer survival time will have a lower overall risk,
i.e.~if \(t_i,t_j\) and \(r_i,r_j\) are survival time and ranking
predictions for patients \(i\) and \(j\) respectively, then
\(t_i > t_j \rightarrow r_i < r_j\).

\paragraph{Prognostic Index}

Given covariates, \(x \in \mathbb{R}^{n \times p}\), and a vector of
model coefficients, \(\beta \in \mathbb{R}^p\), the linear predictor is
defined by \(\eta := x\beta \in \mathbb{R}^n\). The `prognostic index'
is a term that is often used in survival analysis papers that usually
refers to some transformation (possibly identity), \(\phi\), on the
linear predictor, \(\phi(\eta)\). Assuming a predictive function (for
survival time, risk, or distribution defining function (see below)) of
the form \(g(\varphi)\phi(\eta)\), for some function \(g\) and variables
\(\varphi\) where \(g(\varphi)\) is constant for all observations
(e.g.~Cox PH \ref{sec:surv_models_crank}), then predictions of \(\eta\)
are a special case of predicting a relative risk, as are predictions of
\(\phi(\eta)\) if \(\phi\) is rank preserving. A higher prognostic index
may imply a higher or lower risk of event, dependent on the model
structure.

\paragraph{Survival Distribution}

Predicting a survival distribution refers specifically to predicting the
distribution of an individual patient's survival time, i.e.~modelling
the distribution of the event occurring over \(\mathbb{R}_{\geq 0}\).
Therefore this is seen as the probabilistic analogue to the
deterministic time-to-event prediction, these definitions are motivated
by similar terminology in machine learning regression problems
\ref{sec:surv_setml}. The above three prediction types can all be
derived from a probabilistic survival distribution prediction
\ref{sec:car_pipelines}.

A survival distribution is a mathematical object that is estimated by
predicting a \emph{representation} of the distribution. Let \(W\) be a
continuous random variable t.v.i. \(\mathbb{R}_{\geq 0}\) with
probability density function (pdf),
\(f_W: \mathbb{R}_{\geq 0}\rightarrow \mathbb{R}_{\geq 0}\), and
cumulative distribution function (cdf),
\(F_W: \mathbb{R}_{\geq 0}\rightarrow [0,1]; (\tau) \mapsto P(W \leq \tau)\).
The pdf, \(f_W(\tau)\), is the likelihood of an observation dying in a
small interval around time \(\tau\), and
\(F_W(\tau) = \int^\tau_0 f_W(\tau)\) is the probability of an
observation being dead at time \(\tau\) (i.e.~dying at or before
\(\tau\)). In survival analysis, it is generally more interesting to
model the risk of the event taking place or the probability of the
patient being alive, leading to other distribution representations of
interest.

The survival function is defined as \[
S_W: \mathbb{R}_{\geq 0}\rightarrow [0,1]; \quad
(\tau) \mapsto P(W \geq \tau) = \int^\infty_\tau f_W(u) \ du
\] and so \(S_W(\tau) = 1-F_W(\tau)\). This function is known as the
survival function as it can be interpreted as the probability that a
given individual survives until some point \(\tau \geq 0\).

Another common representation is the hazard function, \[
h_W: \mathbb{R}_{\geq 0}\rightarrow \mathbb{R}_{\geq 0}; \quad
(\tau) \mapsto  \frac{f_W(\tau)}{S_W(\tau)}
\] The hazard function is interpreted as the instantaneous risk of death
given that the observation has survived up until that point; note this
is not a probability as \(h_W\) can be greater than one.

The cumulative hazard function (chf) can be derived from the hazard
function by \[
H_W: \mathbb{R}_{\geq 0}\rightarrow \mathbb{R}_{\geq 0}; \quad
(\tau) \mapsto \int^\tau_0 h_W(u) \ du
\]

The cumulative hazard function relates simply to the survival function
by \[
H_W(\tau) = \int^\tau_0 h_W(u) \ du = \int^\tau_0 \frac{f_W(u)}{S_W(u)} \ du = \int^\tau_0 -\frac{S'_W(u)}{S_W(u)} \ du = -\log(S_W(\tau))
\]

Any of these representations may be predicted conditionally on
covariates for an individual by a probabilistic survival distribution
prediction. Once a function has been estimated, predictions can be made
conditional on the given data. For example if \(n\) survival functions
are predicted, \(\hat{S}_1,...,\hat{S}_n\), then \(\hat{S}_i\) is
interpreted as the predicted survival function given covariates of
observation \(i\), and analogously for the other representation
functions.

\bookmarksetup{startatroot}

\hypertarget{survival-models}{%
\chapter{Survival models}\label{survival-models}}

This chapter provides a brief review of classical survival models and
then a critical survey of machine learning survival models. The terms
\texttt{classical\textquotesingle{},}machine learning', and even `model'
have hazy definitions that will be further specified to make clear how
they apply in this paper.

Recall \ref{sec:surv_setml_meth} the separation between the following
terms:

\begin{itemize}
\tightlist
\item
  Learning strategy -- A method for estimating the true prediction
  functional, \(g\)
\item
  Fitting algorithm, \(\mathcal{A}\) -- A function mapping the training
  data, \(\mathcal{D}_0\), to an estimate of the true prediction
  functional, \(\hat{g}:= \mathcal{A}(\mathcal{D}_0)\). The choice of
  fitting algorithm is determined by the learning strategy.
\item
  (Unfitted) Model -- The complete specification of a learning strategy
  with hyper-parameters and any other components such as pre-processing
\item
  Fitted Model/Prediction functional,
  \(\hat{g}: \mathcal{X}\rightarrow \mathcal{Y}\) -- Function, possibly
  with hyper-parameters, for making predictions on unseen data
\end{itemize}

\noindent \texttt{Classical\textquotesingle{}\ models\ are\ defined\ with\ a\ very\ narrow\ scope\ in\ this\ thesis:\ low-complexity\ models\ that\ are\ either\ non-parametric\ or\ have\ parameters\ that\ can\ be\ fit\ with\ maximum\ likelihood\ estimation\ (or\ an\ equivalent\ method).\ In\ contrast,}machine
learning' (ML) models require more intensive model fitting procedures
such as recursion or iteration. The classical models in this paper are
fast to fit and highly interpretable, though can be inflexible and may
make unreasonable assumptions. Whereas the ML models are more flexible
with hyper-parameters however are computationally more intensive (both
in terms of speed and storage), require tuning to produce
\texttt{good\textquotesingle{}\ results,\ and\ are\ often\ a}black-box'
with difficult interpretation.

This chapter investigates models for predictive survival analysis with a
focus on whether a model is APT \ref{sec:intro_motobj_tap}. As classical
survival models have been studied extensively for decades, these are
separated from the ML models in this chapter and reduced to a smaller
literature review in \ref{sec:surv_models}. The rest of this chapter
then surveys each of the primary machine learning classes separately.
The scope of the models discussed in this chapter is limited to the
general thesis scope \ref{sec:surv_scope}, i.e.~single event with
right-censoring and no competing-risks, though in some cases these are
discussed.

Novel adaptations for each of the ML models are suggested at the end of
each section, these primarily serve as interesting avenues to explore
for future research but none have been studied for theoretical
properties or implemented in software packages, though most have been
informally explored to demonstrate some `proof-of-concept'.

\paragraph{Notation and Terminology}

The notation introduced in \ref{chap:surv} is recapped for use in this
chapter: the generative template for the survival setting is given by
\((X,T,\Delta,Y,C) \ t.v.i. \ \mathcal{X}\times \mathcal{T}\times \{0,1\}\times \mathcal{T}\times \mathcal{T}\)
where \(\mathcal{X}\subseteq \mathbb{R}^p\) and
\(\mathcal{T}\subseteq \mathbb{R}_{\geq 0}\), where \(C,Y\) are
unobservable, \(T := \min\{Y,C\}\), and \(\Delta = \mathbb{I}(Y = T)\).
Random survival data is given by
\((X_i,T_i,\Delta_i,Y_i,C_i) \stackrel{i.i.d.}\sim(X,T,\Delta,Y,C)\).
Usually data will instead be presented as a training dataset,
\(\mathcal{D}_0= \{(X_1,T_1,\Delta_1),...,(X_n,T_n,\Delta_n)\}\) where
\((X_i,T_i,\Delta_i) \stackrel{i.i.d.}\sim(X,T,\Delta)\). For simplicity
only a single testing observation needs to be defined to effectively
write about the prediction functional, this test observation is given by
\(\mathcal{D}_1= (X^*, T^*, \Delta^*) \sim (X,T,\Delta)\).

For regression models the generative template is given by \((X,Y)\)
t.v.i. \(\mathcal{X}\subseteq \mathbb{R}^p\) and
\(Y \subseteq \mathbb{R}\). As with the survival setting, a regression
training set is given by \(\{(X_1,Y_1),...,(X_n,Y_n)\}\) where
\((X_i,Y_i) \stackrel{i.i.d.}\sim(X,Y)\) and a testing observation by
\(\mathcal{D}_1= (X^*,Y^*) \sim (X,Y)\).

Finally recall: the set of unique time-points,
\(\mathcal{U}_O := \{T_i\}_{i \in \{1,...,n\}}\), the set of unique
death times,
\(\mathcal{U}_D := \{T_i : \Delta_i = 1\}_{i \in \{1,...,n\}}\), the
risk set at \(\tau\) is \(\mathcal{R}_\tau := \{i: T_i \geq \tau\}\),
the number of observations alive or at risk at \(\tau\) is
\(n_\tau := \sum_i \mathbb{I}(T_i \geq \tau)\), and the number of
observations that die at \(\tau\) is
\(d_\tau := \sum_i \mathbb{I}(T_i = \tau, \Delta_i = 1)\).

\bookmarksetup{startatroot}

\hypertarget{classical-models}{%
\chapter{Classical Models}\label{classical-models}}

\section{A Review of Classical Survival Models}
\label{sec:surv_models}

This section provides a literature review of `classical' models proposed
for survival analysis. There are several possible taxonomies for
categorising statistical models, these include:

\begin{itemize}
\tightlist
\item
  Parametrisation Type: One of non-, semi-, or fully-parametric.
  \textbackslash{} Non-parametric models assume that the data
  distribution cannot be specified with a finite set of parameters. In
  contrast, fully-parametric models assume the distribution can be
  specified with a finite set of parameters. Semi-parametric models are
  a hybrid of the two and are formed of a finite set of parameters
  \emph{and} an infinite-dimensional `nuisance' parameter.
\item
  Conditionality Type: One of unconditional or conditional. A
  conditional prediction is one that makes use of covariates in order to
  condition the prediction on each observation. Unconditional
  predictors, which are referred to below as `estimators', ignore
  covariate data and make the same prediction for all individuals.
\item
  Prediction Type: One of ranking, survival time, or distribution
  \ref{sec:surv_set_types}.
\end{itemize}

\ref{tab:surv_models} summarises the models discussed below into the
taxonomies above for reference. Note that the Cox model is listed as
predicting a continuous ranking, and not a survival distribution, which
may appear inconsistent with other definitions. The reason for this is
elaborated upon in \ref{sec:car_pipelines_distr}. Though the
predict-type taxonomy is favoured throughout this thesis, it is clearer
to review classical models in increasing complexity, beginning with
unconditional estimators before moving onto semi-parametric continuous
ranking predictions, and finally conditional distribution predictors.
The review is brief with mathematics limited to the model fundamentals
but not including methods for parameter estimation. Also the review is
limited to the `basic' model specification and common extensions such as
regularization are not discussed though they do exist for many of these
models.

All classical models are highly transparent and accessible, with decades
of research and many off-shelf implementations. Predictive performance
of each model is briefly discussed as part of the review and then again
in \ref{chap:bench}.

\hypertarget{tbl-surv-models}{}
\begin{longtable}[]{@{}llll@{}}
\toprule()
Model\(^1\) & Parametrisation\(^2\) & Prediction\(^3\) &
Conditionality \\
\midrule()
\endfirsthead
\toprule()
Model\(^1\) & Parametrisation\(^2\) & Prediction\(^3\) &
Conditionality \\
\midrule()
\endhead
Kaplan-Meier & Non & Distr. & Unconditional \\
Nelson-Aalen & Non & Distr. & Unconditional \\
Akritas & Non & Distr. & Conditional \\
Cox PH & Semi & Rank & Conditional \\
Parametric PH & Fully & Distr. & Conditional \\
Accelerated Failure Time & Fully & Distr. & Conditional \\
Proportional Odds & Fully & Distr. & Conditional \\
Flexible Spline & Fully & Distr. & Conditional \\
\bottomrule()
\caption{\label{tbl-surv-models}Table of models discussed in this
literature review, classified by parametrisation, prediction type, and
conditionality.}\tabularnewline
\end{longtable}

* 1. All models are implemented in the \textsf{R} package
\textbf{survival}\textasciitilde{}\cite{pkgsurvival} with the exception
of flexible splines, implemented in
\textbf{flexsurv}\textasciitilde{}\cite{pkgflexsurv}, and the Akritas
estimator in
\textbf{survivalmodels}\textasciitilde{}\cite{pkgsurvivalmodels}. * 2.
Non = non-parametric, Semi = semi-parametric, Fully = fully-parametric.
* 3. Distr. = distribution, Rank = ranking.

\subsection{Non-Parametric Distribution Estimators}
\label{sec:surv_models_uncond}

\paragraph{Unconditional Estimators}

Unconditional non-parametric survival models assume no distribution for
survival times and estimate the survival function using simple
algorithms based on observed outcomes and no covariate data. The two
most common methods are the Kaplan-Meier
estimator\textasciitilde{}\cite{KaplanMeier1958}, which estimates the
average survival function of a training dataset, and the Nelson-Aalen
estimator\textasciitilde{}\cite{Aalen1978, Nelson1972}, which estimates
the average cumulative hazard function of a training dataset.

The Kaplan-Meier estimator of the survival function is given by \[
\label{eq:km}
\hat{S}_{KM}(\tau|\mathcal{D}_0) = \prod_{t \in \mathcal{U}_O, t \leq \tau} \Big(1 - \frac{d_t}{n_t}\Big)
\] As this estimate is so important in survival models, this thesis will
always use the symbol \(\hat{S}_{KM}\) to refer to the Kaplan-Meier
estimate of the average survival function fit on training data
\((T_i, \Delta_i)\). Another valuable function is the Kaplan-Meier
estimate of the average survival function of the \emph{censoring}
distribution, which is the same as above but estimated on
\((T_i, 1 - \Delta_i)\), this will be denoted by \(\hat{G}_{KM}\).

The Nelson-Aalen estimator for the cumulative hazard function is given
by \[
\label{eq:na}
\hat{H}(\tau|\mathcal{D}_0) = \sum_{t \in \mathcal{U}_O, t \leq \tau} \frac{d_t}{n_t}
\]

The primary advantage of these models is that they rely on heuristics
from empirical outcomes only and don't require any assumptions about the
form of the data. To train the models they only require
\((T_i,\Delta_i)\) and both return a prediction of
\(\mathcal{S}\subseteq \operatorname{Distr}(\mathcal{T})\)
\ref{box:task_surv}. In addition, both simply account for censoring and
can be utilised in fitting other models or to estimate unknown censoring
distributions. The Kaplan-Meier and Nelson-Aalen estimators are both
consistent estimators for the survival and cumulative hazard functions
respectively.

Utilising the relationships provided in \ref{sec:surv_set_types}, one
could write the Nelson-Aalen estimator in terms of the survival function
as \(\hat{S}_{NA} = \exp(-\hat{H}(\tau|\mathcal{D}_0))\). It has been
demonstrated that \(\hat{S}_{NA}\) and \(\hat{S}_{KM}\) are
asymptotically equivalent, but that \(\hat{S}_{NA}\) will provide larger
estimates than \(\hat{S}_{KM}\) in smaller
samples\textasciitilde{}\cite{Colosimo2002}. In practice, the
Kaplan-Meier is the most widely utilised non-parametric estimator in
survival analysis and is the simplest estimator that yields consistent
estimation of a survival distribution; it is therefore a natural, and
commonly utilised,
\texttt{baseline\textquotesingle{}\ model\textasciitilde{}\textbackslash{}cite\{Binder2008,\ Herrmann2020,\ Huang2020,\ Wang2017\}:\ estimators\ that\ other\ models\ should\ be}judged'
against to ascertain their overall performance \ref{chap:eval}.

Not only can these estimators be used for analytical comparison, but
they also provide intuitive methods for graphical calibration of models
\ref{sec:eval_distr_calib_prob}. These models are never stuidied for
prognosis directly but as baselines, components of complex models
\ref{sec:car_pipelines_distr}, or graphical
tools\textasciitilde{}\cite{Habibi2018, Jager2008, Moghimi-dehkordi2008}.
The reason for this is due to them having poor predictive performance as
a result of omitting explanatory variables in fitting. Moreover, if the
data follows a particular distribution, parametric methods will be more
efficient\textasciitilde{}\cite{Wang2017}.

\paragraph{Conditional Estimators}

The Kaplan-Meier and Nelson-Aalen estimators are simple to compute and
provide good estimates for the survival time distribution but in many
cases they may be overly-simplistic. Conditional non-parametric
estimators include the advantages described above (no assumptions about
underlying data distribution) but also allow for conditioning the
estimation on the covariates. This is particularly useful when
estimating a censoring distribution that may depend on the data
\ref{chap:eval}. However predictive performance of conditional
non-parametric estimators decreases as the number of covariates
increases, and these models are especially poor when censoring is
feature-dependent\textasciitilde{}\cite{Gerds2006}.

The most widely used conditional non-parametric estimator for survival
analysis is the Akritas estimator\textasciitilde{}\cite{Akritas1994}
defined
by\footnote{Arguments and parameters are separated in function signatures by a pipe, `$|$', where variables to the left are parameters (free variables) and those to the right are arguments (fixed). In this equation, $\tau$ is a parameter to be set by the user, and $X^*, \mathcal{D}_0, \lambda$ are fixed arguments. This could therefore be simplified to $\hat{S}(\tau)$ to only include free variables.}
\[
\hat{S}(\tau|X^*, \mathcal{D}_0, \lambda) = \prod_{j:T_j \leq \tau, \Delta_j = 1} \Big(1 - \frac{K(X^*, X_j|\lambda)}{\sum_{l = 1}^n K(X^*, X_l|\lambda)\mathbb{I}(T_l \geq T_j)}\Big)
\] where \(K\) is a kernel function, usually
\(K(x,y|\lambda) = \mathbb{I}(\lvert \hat{F}_X(x) - \hat{F}_X(y)\rvert < \lambda), \lambda \in (0, 1]\),
\(\hat{F}_X\) is the empirical distribution function of the training
data, \(X_1,...,X_n\), and \(\lambda\) is a hyper-parameter. The
estimator can be interpreted as a conditional Kaplan-Meier estimator
which is computed on a neighbourhood of subjects closest to
\(X^*\)\textasciitilde{}\cite{Blanche2013}. To account for tied survival
times, the following adaptation of the estimator is
utilised\textasciitilde{}\cite{Blanche2013}

\[
\label{eq:akritas}
\hat{S}(\tau|X^*, \mathcal{D}_0, \lambda) = \prod_{t \in \mathcal{U}_O, t \leq \tau} \Big(1 - \frac{\sum^n_{j=1} K(X^*,X_j|\lambda)\mathbb{I}(T_j = t, \Delta_j = 1)}{\sum^n_{j=1} K(X^*,X_j|\lambda)\mathbb{I}(T_j \geq t)}\Big)
\] If \(\lambda = 1\) then \(K(\cdot|\lambda) = 1\) and the estimator is
identical to the Kaplan-Meier estimator.

The non-parametric nature of the model is highlighted in
\ref{eq:akritas}, in which both the fitting and predicting stages are
combined into a single equation. A new observation, \(X^*\), is compared
to its nearest neighbours from a training dataset, \(\mathcal{D}_0\),
without a separated fitting procedure. One could consider splitting
fitting and predicting in order to clearly separate between training and
testing data. In this case, the fitting procedure is the estimation of
\(\hat{F}_X\) on training data and the prediction is given by
\ref{eq:akritas} with \(\hat{F}_X\) as an argument. This separated
fit/predict method is implemented in
\textbf{survivalmodels}\textasciitilde{}\cite{pkgsurvivalmodels}. As
with other non-parametric estimators, the Akritas estimator can still be
considered transparent and accessible. With respect to predictive
performance, the Akritas estimator has more explanatory power than
non-parametric estimators due to conditioning on covariates, however
this is limited to a very small number of variables and therefore this
estimator is still best placed as a conditional baseline.

\subsection{Continuous Ranking and Semi-Parametric Models: Cox PH}
\label{sec:surv_models_crank}

The Cox Proportional Hazards (CPH)\textasciitilde{}\cite{Cox1972}, or
Cox model, is likely the most widely known semi-parametric model and the
most studied survival
model\textasciitilde{}\cite{Habibi2018, Moghimi-dehkordi2008, Reid1994, Wang2017}.
The Cox model assumes that the hazard for a subject is proportionally
related to their explanatory variables, \(X_1,...,X_n\), via some
baseline hazard that all subjects in a given dataset share
(\texttt{the\ PH\ assumption\textquotesingle{}).\ The\ hazard\ function\ in\ the\ Cox\ PH\ model\ is\ defined\ by\ \$\$\ h(\textbackslash{}tau\textbar{}X\_i)=\ h\_0(\textbackslash{}tau)\textbackslash{}exp(X\_i\textbackslash{}beta)\ \$\$\ where\ \$h\_0\$\ is\ the\ non-negative\ \textbackslash{}emph\{baseline\ hazard\ function\}\ and\ \$\textbackslash{}beta\ =\ \textbackslash{}beta\_1,...,\textbackslash{}beta\_p\$\ where\ \$\textbackslash{}beta\_i\ \textbackslash{}in\ \textbackslash{}Reals\$\ are\ coefficients\ to\ be\ fit.\ Note\ the\ proportional\ hazards\ (PH)\ assumption\ can\ be\ seen\ as\ the\ estimated\ hazard,\ \$h(\textbackslash{}tau\textbar{}X\_i)\$,\ is\ directly\ proportional\ to\ the\ model\ covariates\ \$\textbackslash{}exp(X\_i\textbackslash{}beta)\$.\ Whilst\ a\ form\ is\ assumed\ for\ the}risk'
component of the model, \(\exp(X_i\beta)\), no assumptions are made
about the distribution of \(h_0\), hence the model is semi-parametric.

The coefficients, \(\beta\), are estimated by maximum likelihood
estimation of the
\texttt{partial\ likelihood\textquotesingle{}\textasciitilde{}\textbackslash{}cite\{Cox1975\},\ which\ only\ makes\ use\ of\ ordered\ event\ times\ and\ does\ not\ utilise\ all\ data\ available\ (hence\ being}partial').
The partial likelihood allows study of the informative
\(\beta\)-parameters whilst ignoring the nuisance \(h_0\). The predicted
linear predictor, \(\hat{\eta} := X^*\hat{\beta}\), can be computed from
the estimated \(\hat{\beta}\) to provide a ranking prediction.

Inspection of the model is also useful without specifying the full
hazard by interpreting the coefficients as `hazard ratios'. Let
\(p = 1\) and \(\hat{\beta} \in \mathbb{R}\) and let
\(X_i,X_j \in \mathbb{R}\) be the covariates of two training
observations, then the \emph{hazard ratio} for these observations is the
ratio of their hazard functions, \[
\frac{h(\tau|X_i)}{h(\tau|X_j)} = \frac{h_0(\tau)\exp(X_i\hat{\beta})}{h_0(\tau)\exp(X_j\hat{\beta})} =  \exp(\hat{\beta})^{X_i - X_j}
\]

If \(\exp(\hat{\beta}) = 1\) then \(h(\tau|X_i) = h(\tau|X_j)\) and thus
the covariate has no effect on the hazard. If \(\exp(\hat{\beta}) > 1\)
then \(X_i > X_j \rightarrow h(\tau|X_i) > h(\tau|X_i)\) and therefore
the covariate is positively correlated with the hazard (increases risk
of event). Finally if \(\exp(\hat{\beta}) < 1\) then
\(X_i > X_j \rightarrow h(\tau|X_i) < h(\tau|X_i)\) and the covariate is
negatively correlated with the hazard (decreases risk of event).
\textbackslash\textbackslash{} Interpreting hazard ratios is known to be
a challenge, especially by clinicians who require simple statistics to
communicate to
patients\textasciitilde{}\cite{Sashegyi2017, Spruance2004}. For example
the full interpretation of a hazard ratio of
\texttt{2\textquotesingle{}\ for\ binary\ covariate\ \$X\$\ would\ be:}assuming
that the risk of death is constant at all time-points then the
instantaneous risk of death is twice as high in a patient with \(X\)
than without'. Simple conclusions are limited to stating if patients are
at more or less risk than others in their cohort. Further disadvantages
of the model also lie in its lack of real-world interpretabilitity,
these include\textasciitilde{}\cite{Reid1994}:

\begin{itemize}
\tightlist
\item
  the PH assumption may not be realistic and the risk of event may not
  be constant over time;
\item
  the estimated baseline hazard from a non-parametric estimator is a
  discrete step-function resulting in a discrete survival distribution
  prediction despite time being continuous; and
\item
  the estimated baseline hazard will be constant after the last observed
  time-point in the training set\textasciitilde{}\cite{Gelfand2000}.
\end{itemize}

Despite these disadvantages, the model has been demonstrated to have
excellent predictive performance and routinely outperforms (or at least
does not underperform) sophisticated ML
models\textasciitilde{}\cite{Gensheimer2018, Luxhoj1997, VanBelle2011b}
(and \ref{chap:bench}). It's simple form and wide popularity mean that
it is also highly transparent and accessible.

The next class of models address some of the Cox model disadvantages by
making assumptions about the baseline hazard.

\subsection[Conditional Distribution Predictions: Parametric Linear Models]{Conditional Distribution Predictions: Parametric\\Linear Models}
\label{sec:surv_models_param}

\paragraph{Parametric Proportional Hazards}

The CPH model can be extended to a fully parametric PH model by
substituting the unknown baseline hazard, \(h_0\), for a particular
parameterisation. Common choices for distributions are Exponential,
Weibull and Gompertz\textasciitilde{}\cite{Kalbfleisch2011, Wang2017};
their hazard functions are summarised in \ref{tab:survivaldists} along
with the respective parametric PH model. Whilst an Exponential
assumption leads to the simplest hazard function, which is constant over
time, this is often not realistic in real-world applications. As such
the Weibull or Gompertz distributions are often preferred. Moreover,
when the shape parameter, \(\gamma\), is \(1\) in the Weibull
distribution or \(0\) in the Gompertz distribution, their hazards reduce
to a constant risk (\ref{fig:survhazards}). As this model is fully
parametric, the model parameters can be fit with maximum likelihood
estimation, with the likelihood dependent on the chosen distribution.

\hypertarget{tbl-survivaldists}{}
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2857}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2857}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.4286}}@{}}
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
Distribution\(^1\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(h_0(\tau)^2\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(h(\tau|X_i)^3\)
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
Distribution\(^1\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(h_0(\tau)^2\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(h(\tau|X_i)^3\)
\end{minipage} \\
\midrule()
\endhead
\(\operatorname{Exp}(\lambda)\) & \(\lambda\) &
\(\lambda\exp(X_i\beta)\) \\
\(\operatorname{Weibull}(\gamma, \lambda)\) &
\(\lambda\gamma \tau^{\gamma-1}\) &
\(\lambda\gamma \tau^{\gamma-1}\exp(X_i\beta)\) \\
\(\operatorname{Gompertz}(\gamma, \lambda)\) &
\(\lambda \exp(\gamma \tau)\) &
\(\lambda \exp(\gamma \tau)\exp(X_i\beta)\) \\
\bottomrule()
\caption{\label{tbl-survivaldists}Exponential, Weibull, and Gompertz
hazard functions and PH specification.}\tabularnewline
\end{longtable}

* 1. Distribution choices for baseline hazard. \(\gamma,\lambda\) are
shape and scale parameters respectively. * 2. Baseline hazard function,
which is the (unconditional) hazard of the distribution. * 3. PH hazard
function, \(h(\tau|X_i) = h_0(\tau)\exp(X_i\beta)\).

\begin{figure}

{\centering \includegraphics{./images/classical/hazards.png}

}

\caption{\label{fig-survhazards}Comparing the hazard curves under
Weibull and Gompertz distributions for varying values of the shape
parameter; scale parameters are set so that each parametrisation has a
median of 20. x-axes are time and y-axes are Weibull (top) and Gompertz
(bottom) hazards as a function of time.}

\end{figure}

In the literature, the Weibull distribution tends to be favoured as the
initial assumption for the survival
distribution\textasciitilde{}\cite{Gensheimer2018, Habibi2018, Hielscher2010, CoxSnell1968, Rahman2017},
though Gompertz is often tested in death-outcome models for its
foundations in modelling human
mortality\textasciitilde{}\cite{Gompertz1825}. There exist many tests
for checking the goodness-of-model-fit \ref{sec:eval_insample} and the
distribution choice can even be treated as a model hyper-parameter.
Moreover it transpires that model inference and predictions are largely
insensitive to the choice of
distribution\textasciitilde{}\cite{Collett2014, Reid1994}. In contrast
to the Cox model, fully parametric PH models can predict absolutely
continuous survival distributions, they do not treat the baseline hazard
as a nuisance, and in general will result in more precise and
interpretable predictions if the distribution is correctly
specified\textasciitilde{}\cite{Reid1994, RoystonParmar2002}.

Whilst misspecification of the distribution tends not to affect
predictions too greatly, PH models will generally perform worse when the
PH assumption is not valid. PH models can be extended to include
time-varying coefficients or model
stratification\textasciitilde{}\cite{Cox1972} but even with these
adaptations the model may not reflect reality. For example, the
predicted hazard in a PH model will be either monotonically increasing
or decreasing but there are many scenarios where this is not realistic,
such as when recovering from a major operation where risks tends to
increase in the short-term before decreasing. Accelerated failure time
models overcome this disadvantage and allow more flexible modelling,
discussed next.

\paragraph{Accelerated Failure Time}

In contrast to the PH assumption, where a unit increase in a covariate
is a multiplicative increase in the hazard rate, the Accelerated Failure
Time (AFT) assumption means that a unit increase in a covariate results
in an acceleration or deceleration towards death (expanded on below).
The hazard representation of an AFT model demonstrates how the
interpretation of covariates differs from PH models, \[
h(\tau|X_i)= h_0(\exp(-X_i\beta)\tau)\exp(-X_i\beta)
\] where \(\beta = (\beta_1,...,\beta_p)\) are model coefficients. In
contrast to PH models, the
\texttt{risk\textquotesingle{}\ component,\ \$\textbackslash{}exp(-X\_i\textbackslash{}beta)\$,\ is\ the\ exponential\ of\ the\ \textbackslash{}emph\{negative\}\ linear\ predictor\ and\ therefore\ an\ increase\ in\ a\ covariate\ value\ results\ in\ a\ decrease\ of\ the\ predicted\ hazard.\ This\ representation\ also\ highlights\ how\ AFT\ models\ are\ more\ flexible\ than\ PH\ as\ the\ predicted\ hazard\ can\ be\ non-monotonic.\ For\ example\ the\ hazard\ of\ the\ Log-logistic\ distribution\ (\textbackslash{}ref\{fig:litreview\_logloghaz\})\ is\ highly\ flexible\ depending\ on\ chosen\ parameters.\ Not\ only\ can\ the\ AFT\ model\ offer\ a\ wider\ range\ of\ shapes\ for\ the\ hazard\ function\ but\ it\ is\ more\ interpretable.\ Whereas\ covariates\ in\ a\ PH\ model\ act\ on\ the\ hazard,\ in\ an\ AFT\ they\ act\ on\ time,\ which\ is\ most\ clearly\ seen\ in\ the\ log-linear\ representation,\ \$\$\ \textbackslash{}log\ Y\_i\ =\ \textbackslash{}mu\ +\ \textbackslash{}alpha\_1X\_\{i1\}\ +\ \textbackslash{}alpha\_2X\_\{i2\}\ +\ ...\ +\ \textbackslash{}alpha\_pX\_\{ip\}\ +\ \textbackslash{}sigma\textbackslash{}epsilon\_i\ \$\$\ where\ \$\textbackslash{}mu\$\ and\ \$\textbackslash{}sigma\$\ are\ location\ and\ scale\ parameters\ respectively,\ \$\textbackslash{}alpha\_1,...,\textbackslash{}alpha\_p\$\ are\ model\ coefficients,\ and\ \$\textbackslash{}epsilon\_i\$\ is\ a\ random\ error\ term.\ In\ this\ case\ a\ one\ unit\ increase\ in\ covariate\ \$X\_\{ij\}\$\ means\ a\ \$\textbackslash{}alpha\_j\$\ increase\ in\ the\ logarithmic\ survival\ time.\ For\ example\ if\ \$\textbackslash{}exp(X\_i\textbackslash{}alpha)\ =\ 0.5\$\ then\ \$i\$}ages'
at double the baseline
\texttt{speed\textquotesingle{}.\ Or\ less\ abstractly\ if\ studying\ the\ time\ until\ death\ from\ cancer\ then\ \ \$\textbackslash{}exp(X\_i\textbackslash{}alpha)\ =\ 0.5\$\ can\ be\ interpreted\ as}the
entire process from developing tumours to metastasis and eventual death
in subject \(i\) is twice as fast than the normal', where `normal'
refers to the baseline when all covariates are \(0\).

Specifying a particular distribution for \(\epsilon_i\) yields a
fully-parametric AFT model. Common distribution choices include Weibull,
Exponential, Log-logistic, and
Log-Normal\textasciitilde{}\cite{Kalbfleisch2011, Wang2017}. The
Buckley-James estimator\textasciitilde{}\cite{Buckley1979} is a
semi-parametric AFT model that non-parametrically estimates the
distribution of the errors however this model has no theoretical
justification and is rarely fit in
practice\textasciitilde{}\cite{Wei1992}. The fully-parametric model has
theoretical justifications, natural interpretability, and can often
provide a better fit than a PH model, especially when the PH assumption
is violated\textasciitilde{}\cite{Patel2006, Qi2009, Zare2015}.

\begin{figure}

{\centering \includegraphics{./images/classical/llog_hazard.png}

}

\caption{\label{fig-litreview-logloghaz}Log-logistic hazard curves with
a fixed scale parameter of 1 and a changing shape parameter. x-axis is
time and y-axis is the log-logistic hazard as a function of time.}

\end{figure}

\paragraph{Proportional Odds}

Proportional odds (PO) models\textasciitilde{}\cite{Bennett1983} fit a
proportional relationship between covariates and the odds of survival
beyond a time \(\tau\), \[
O_i(\tau) = \frac{S_i(\tau)}{F_i(\tau)} = O_0(\tau)\exp(X_i\beta)
\] where \(O_0\) is the baseline odds.

In this model, a unit increase in a covariate is a multiplicative
increase in the odds of survival after a given time and the model can be
interpreted as estimating the log-odds ratio. There is no simple closed
form expression for the partial likelihood of the PO model and hence in
practice a Log-logistic distribution is usually assumed for the baseline
odds and the model is fit by maximum likelihood estimation on the full
likelihood\textasciitilde{}\cite{Bennett1983}.

Perhaps the most useful feature of the model is convergence of hazard
functions\textasciitilde{}\cite{Kirmani2001}, which states
\(h_i(\tau)/h_0(\tau) \rightarrow 1\) as \(\tau \rightarrow \infty\).
This property accurately reflects real-world scenarios, for example if
comparing chemotherapy treatment on advanced cancer survival rates, then
it is expected that after a long period (say 10 years) the difference in
risk between groups is likely to be negligible. This is in contrast to
the PH model that assumes the hazard ratios are constant over time,
which is rarely a reflection of reality.

In practice, the PO model is harder to fit and is less flexible than PH
and AFT models, both of which can also produce odds ratios. This may be
a reason for the lack of popularity of the PO model, in addition there
is limited off-shelf implementations\textasciitilde{}\cite{Collett2014}.
Despite PO models not being commonly utilised, they have formed useful
components of neural networks \ref{sec:surv_ml_models_nn} and flexible
parametric models (below).

\paragraph{Flexible Parametric Models -- Splines}

Royston-Parmar flexible parametric
models\textasciitilde{}\cite{RoystonParmar2002} extend PH and PO models
by estimating the baseline hazard with natural cubic splines. The model
was designed to keep the form of the PH or PO methods but without the
semi-parametric problem of estimating a baseline hazard that does not
reflect reality (see above), or the parametric problem of misspecifying
the survival distribution.

To provide an interpretable, informative and smooth hazard, natural
cubic splines are fit in place of the baseline hazard. The crux of the
method is to use splines to model time on a log-scale and to either
estimate the log cumulative Hazard for PH models,
\(\log H(\tau|X_i) = \log H_0(\tau) + X_i\beta\), or the log Odds for PO
models, \(\log O(\tau|X_i) = \log O_0(\tau) + X_i\beta\), where
\(\beta\) are model coefficients to fit, \(H_0\) is the baseline
cumulative hazard function and \(O_0\) is the baseline odds function.
For the flexible PH model, a Weibull distribution is the basis for the
baseline distribution and a Log-logistic distribution for the baseline
odds in the flexible PO model. \(\log H_0(\tau)\) and \(\log O_0(\tau)\)
are estimated by natural cubic splines with coefficients fit by maximum
likelihood estimation. The standard full likelihood is optimised, full
details are not provided here. Between one and three internal knots are
recommended for the splines and the placement of knots does not greatly
impact upon the fitted model\textasciitilde{}\cite{RoystonParmar2002}.

Advantages of the model include being: interpretable, flexible, can be
fit with time-dependent covariates, and it returns a continuous
function. Moreover many of the parameters, including the number and
position of knots, are tunable, although Royston and Parmar advised
against tuning and suggest often only one internal knot is
required\textasciitilde{}\cite{RoystonParmar2002}. A recent simulation
study demonstrated that even with an increased number of knots (up to
seven degrees of freedom), there was little bias in estimation of the
survival and hazard functions\textasciitilde{}\cite{Bower2019}. Despite
its advantages, a 2018 review\textasciitilde{}\cite{Ng2018} found only
twelve instances of published flexible parametric models since Royston
and Parmar's 2002 paper, perhaps because it is more complex to train,
has a less intuitive fitting procedure than alternatives, and has
limited off-shelf implementations; i.e.~is less transparent and
accessible than parametric alternatives. \textbackslash\textbackslash{}
The PH and AFT models are both very transparent and accessible, though
require slightly more expert knowledge than the CPH in order to specify
the `correct' underlying probability distribution. Interestingly whilst
there are many papers comparing PH and AFT models to one another using
in-sample metrics \ref{sec:eval_insample} such as
AIC\textasciitilde{}\cite{Georgousopoulou2015,Habibi2018,Moghimi-dehkordi2008,Zare2015},
no benchmark experiments could be found for out-of-sample performance.
PO and spline models are less transparent than PH and AFT models and are
even less accessible, with very few implementations of either. No
conclusions can be drawn about the predictive performance of PO or
spline models due to a lack of suitable benchmark experiments.

\bookmarksetup{startatroot}

\hypertarget{machine-learning-survival-models}{%
\chapter{Machine Learning Survival
Models}\label{machine-learning-survival-models}}

\section{A Survey of Machine Learning Models for Survival Analysis}
\label{sec:surv_ml}

These next sections provide a technical, critical survey of machine
learning models proposed for survival analysis with the focus on the
\texttt{simpler\textquotesingle{}\ setup\ of\ non-competing\ risks.\ Models\ are\ separated\ into\ their\ different}classes'
\ref{tab:surv_ml_returns}, which exists as a natural taxonomy in machine
learning. Each class review is then further separated by first
discussing the simpler and more standard regression setting, before
expanding into their survival framework. The focus is once again on the
different predict types of the model, which enables clear exposition and
discussion around how some areas have successfully dealt with the
survival predictive problem, whereas others have fallen short.

This is not the first survey of machine learning models for survival
analysis. A recent 2017 survey\textasciitilde{}\cite{Wang2017} focused
on covering the breadth of machine learning models for survival analysis
and this survey is recommended to the reader as a strong starting point
to understand which ML models are available for survival analysis.
However whilst this provides a comprehensive review and a `big-picture'
view, there is no discussion about how successful the discussed models
are in solving the survival task.

A comprehensive survey of neural networks was presented by Schwarzer
\textit{et al.}\textsubscript{(2000)}\cite{Schwarzer2000} in which the
authors collected the many ways in which neural networks have been
`misused' in the context of survival analysis. This level of criticism
is vital in the context of survival analysis and healthcare data as
transparency and understanding are often prioritised over predictive
performance. Whilst the survey in this thesis will try not to be as
critical as the Schwarzer review, it will aim to discuss models and how
well they actually solve the survival problem.

In line with the core topic of this thesis, this survey aims to
demonstrate if each model is APT \ref{sec:intro_motobj_tap}.
Historically, surveys have focused primarily on predictive performance,
which is generally preferred for complex classification and regression
tasks. However in the context of survival analysis, transparency is of
the utmost importance and any model that does not solve the task it
claims to, despite strong predictive performance, can be considered
sub-optimal. The survey will also examine the accessibility of survival
models. A model need not be open-source to be accessible, but it should
be `user-friendly' and not require expert cross-domain knowledge. For
example, a neural network may require knowledge of complex model
building, but if set-up correctly could be handled without medical or
survival knowledge. Whereas a Gaussian Process requires knowledge of the
model class, simulation, (usually) Bayesian modelling, and also survival
analysis. \textbackslash\textbackslash{} \ref{tab:surv_ml_returns}
provides information about the models reviewed in this survey, including
a model reference for use in the \ref{chap:bench} benchmark experiment,
the predict types of the model, and in which \textsf{R}{} package it is
implemented.

\hypertarget{tbl-surv-ml-returns}{}
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1538}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1538}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2308}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2308}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2308}}@{}}
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
Class\(^1\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Name\(^2\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Authors (Year)\(^3\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Task\(^4\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Implementation\(^5\)
\end{minipage} \\
\midrule()
\endfirsthead
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
Class\(^1\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Name\(^2\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Authors (Year)\(^3\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Task\(^4\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Implementation\(^5\)
\end{minipage} \\
\midrule()
\endhead
RF & RRT & LeBlanc and Crowley (1992)\textasciitilde{}\cite{LeBlanc1992}
& Rank & \textbf{rpart}\textasciitilde{}\cite{pkgrpart} \\
RF & RSDF-DEV & Hothorn
\textit{et al.}\textsubscript{(2004)}\cite{Hothorn2004} & Prob. &
\textbf{ipred}\textasciitilde{}\cite{pkgipred} \\
RF & RRF & Ishwaran
\textit{et al.}\textsubscript{(2004)}\cite{Ishwaran2004} & Rank & - \\
RF & RSCIFF & Hothorn
\textit{et al.}\textsubscript{(2006)}\cite{Hothorn2005} & Det., Prob. &
\textbf{party}\textasciitilde{}\cite{pkgparty},
\textbf{partykit}\textasciitilde{}\cite{pkgpartykit} \\
RF & RSDF-STAT & Ishwaran
\textit{et al.}\textsubscript{(2008)}\cite{Ishwaran2008} & Prob. &
\textbf{randomForestSRC}\textasciitilde{}\cite{pkgrfsrc},
\textbf{ranger}\textasciitilde{}\cite{pkgranger} \\
GBM & GBM-COX & Ridgeway (1999)\textasciitilde{}\cite{Ridgeway1999} \&
Buhlmann (2007)\textasciitilde{}\cite{Buhlmann2007} & Prob. &
\textbf{mboost}\textasciitilde{}\cite{pkgmboost},
\textbf{xgboost}\textasciitilde{}\cite{pkgxgboost},
\textbf{gbm}\textasciitilde{}\cite{pkggbm} \\
GBM & CoxBoost & Binder \& Schumacher
(2008)\textasciitilde{}\cite{Binder2008} & Prob. &
\textbf{CoxBoost}\textasciitilde{}\cite{pkgcoxboost} \\
GBM & GBM-AFT & Schmid \& Hothorn
(2008)\textasciitilde{}\cite{Schmid2008b} & Det. & \textbf{mboost},
\textbf{xgboost} \\
GBM & GBM-BUJAR & Wang \& Wang (2010)\textasciitilde{}\cite{Wang2010} &
Det. & \textbf{bujar}\textasciitilde{}\cite{pkgbujar} \\
GBM & GBM-GEH & Johnson \& Long
(2011)\textasciitilde{}\cite{Johnson2011} & Det. & \textbf{mboost} \\
GBM & GBM-UNO & Mayr \& Schmid (2014)\textasciitilde{}\cite{Mayr2014} &
Rank & \textbf{mboost} \\
SVM & SVCR & Shivaswamy
\textit{et al.}\textsubscript{(2007)}\cite{Shivaswamy2007} & Det. &
\textbf{survivalsvm}\textasciitilde{}\cite{pkgsurvivalsvm} \\
SVM & SSVM-Rank & Van Belle
\textit{et al.}\textsubscript{(2007)}\cite{VanBelle2007} & Rank &
\textbf{survivalsvm} \\
SVM & SVRc & Khan and Zubek (2008)\textasciitilde{}\cite{Khan2008} &
Det. & - \\
SVM & SSVM-Hybrid & Van Belle
(2011)\textasciitilde{}\cite{VanBelle2011b} & Det. &
\textbf{survivalsvm} \\
SVM & SSVR-MRL & Goli
\textit{et al.}\textsubscript{(2016)}\cite{Goli2016a, Goli2016b} & Det.
& - \\
ANN & ANN-CDP & Liest\o l
\textit{et al.}\textsubscript{(1994)}\cite{Liestol1994} & Prob. & - \\
ANN & ANN-COX & Faraggi and Simon
(1995)\textasciitilde{}\cite{Faraggi1995} & Rank & - \\
ANN & PLANN & Biganzoli
\textit{et al.}\textsubscript{(1998)}\cite{Biganzoli1998} & Prob. & - \\
ANN & COX-NNET & Ching
\textit{et al.}\textsubscript{(2018)}\cite{Ching2018a} & Prob. &
\textbf{cox-nnet}\(^*\)\textasciitilde{}\cite{pkgcoxnnet} \\
ANN & DeepSurv & Katzman
\textit{et al.}\textsubscript{(2018)}\cite{Katzman2018} & Prob. &
\textbf{survivalmodels}\textasciitilde{}\cite{pkgsurvivalmodels} \\
ANN & DeepHit & Lee \textit{et al.}\textsubscript{(2018)}\cite{Lee2018a}
& Prob. & \textbf{survivalmodels} \\
ANN & Nnet-survival & Gensheimer \& Narasimhan
(2019)\textasciitilde{}\cite{Gensheimer2019} & Prob. &
\textbf{survivalmodels} \\
ANN & Cox-Time & Kvamme
\textit{et al.}\textsubscript{(2019)}\cite{Kvamme2019a} & Prob. &
\textbf{survivalmodels} \\
ANN & PC-Hazard & Kvamme \& Borgan
(2019)\textasciitilde{}\cite{Kvamme2019} & Prob. &
\textbf{survivalmodels} \\
ANN & RankDeepSurv & Jing
\textit{et al.}\textsubscript{(2019)}\cite{Jing2019} & Det. &
\textbf{RankDeepSurv}\(^{\ast, \dagger}\)\textasciitilde{}\cite{pkgrankdeepsurv} \\
ANN & DNNSurv & Zhao \& Fend (2020)\textasciitilde{}\cite{Zhao2020} &
Prob. & \textbf{survivalmodels} \\
\bottomrule()
\caption{\label{tbl-surv-ml-returns}Summarising the models discussed in
\ref{sec:surv_ml} by their model class and respective survival
task.}\tabularnewline
\end{longtable}

* 1. Model Class. RSF -- Random Survival Forest; GBM -- Gradient
Boosting Machine; SVM -- Support Vector Machine; ANN -- Artificial
Neural Network. There is some abuse of notation here as some of the RSFs
are actually decision trees and some GBMs do not use gradient boosting.
* 2. Model identifier used in this section and \ref{chap:bench}. * 3.
Authors and year of publication, for RSFs this is the paper most
attributed to the algorithm. * 4. Survival task type: Deterministic
(Det.), Probabilistic (Prob.), Ranking (Rank). * 5. If available in
\textsf{R} then the package in which the model is implemented, otherwise
\texttt{\$\textbackslash{}ast\$\textquotesingle{}\ signifies\ a\ model\ is\ only\ available\ in\ Python.\ With\ the\ exception\ of\ DNNSurv,\ all\ ANNs\ in\ \textbackslash{}pkg\{survivalmodels\}\ are\ implemented\ from\ the\ Python\ package\ \textbackslash{}pkg\{pycox\}\textasciitilde{}\textbackslash{}cite\{pkgpycox\}\ with\ \textbackslash{}pkg\{reticulate\}\textasciitilde{}\textbackslash{}cite\{pkgreticulate\}.\ *\ \$\textbackslash{}dagger\$\ -\/-\ Code\ available\ to\ create\ model\ but\ not\ implemented}off-shelf'.

\bookmarksetup{startatroot}

\hypertarget{tree-based-methods}{%
\chapter{Tree-Based Methods}\label{tree-based-methods}}

\section{Random Forests}
\label{sec:surv_ml_models_ranfor}

\subsection{Random Forests for Regression}

Random forests are a composite algorithm built by fitting many simpler
component models, decision trees, and then averaging the results of
predictions from these trees. Decision trees are first briefly
introduced before the key `bagging' algorithm that composes these trees
to a random forest. Woodland terminology is used throughout this
subsection.

\paragraph{Decision Trees}

Decision trees are a common model class in machine learning and have the
advantage of being (relatively) simple to implement and highly
interpretable. A decision tree takes a set of inputs and a given
\emph{splitting rule} in order to create a series of splits, or
branches, in the tree that culminates in a final \emph{leaf}, or
\emph{terminal node}. Each terminal node has a corresponding prediction,
which for regression is usually the sample mean of the training outcome
data. This is made clearer by example, \ref{fig:surv_ranfor}
demonstrates a decision tree predicting the miles per gallon
(\texttt{mpg}) of a car from the
\texttt{mtcars}\textasciitilde{}\cite{datamtcars} dataset. With this
tree a new prediction is made by feeding the input variables from the
top to the bottom, for example given new data,
\(x = \{\texttt{wt} = 3, \texttt{disp} = 250\}\), then in the first
split the right branch is taken as \texttt{wt} \(= 3 > 2.32\) and in the
second split the left branch is taken as \texttt{disp}
\(= 250 \leq 258\), therefore the new data point `lands' in the final
leaf and is predicted to have an \texttt{mpg} of \(20.8\). This value of
\(20.8\) arises as the sample mean of \texttt{mpg} for the \(11\) (which
can be seen in the box) observations in the training data who were
sorted into this terminal node. Algorithmically, as splits are always
binary, predictions are simply a series of conditional logical
statements.

\begin{figure}

{\centering \includegraphics{./images/forests/iris_tree.png}

}

\caption{\label{fig-surv-ranfor}Demonstrating classification trees using
the \texttt{mtcars}\textasciitilde{}\cite{datamtcars} dataset and the
\textbf{party}\textasciitilde{}\cite{pkgparty} package. Ovals are
leaves, which indicate the variable that is being split. Edges are
branches, which indicate the cut-off at which the variable is split.
Rectangles are terminal nodes and include information about the number
of training observations in the node and the terminal node prediction.}

\end{figure}

\paragraph{Splitting Rules}

Precisely how the splits are derived and which variables are utilised is
determined by the splitting
rule.\footnote{Other methods for growing trees such as pruning are not discussed here as they are less relevant to random forests, which are primarily of interest. Instead see (e.g.) Breiman (1984)~\cite{Breiman1984}.}
In regression, the most common splitting rule is to select the cut-off
for a given variable that minimises the mean squared error in each
hypothetical resultant leaf. The goal is to find the variable and cutoff
that leads to the greatest difference between the two resultant leaves
and thus the maximal homogeneity within each leaf. For all decision tree
and random forest algorithms going forward, let \(L\) denote some leaf,
then let \(L_{xy}, L_x, L_y\) respectively be the set of observations,
features, and outcomes in leaf \(L\). Let \(L_{y;i}\) be the \(i\)th
outcome in \(L_y\) and finally let
\(L_{\bar{y}} = \frac{1}{n} \sum^{n}_{i = 1} L_{y;i}\). To simplify
notation, \(i \in L\) is taken to be equivalent to
\(i \in \{i: X_i \in L_X\}\), i.e.~the indices of the observations in
leaf \(L\).

Let \(c \in \mathbb{R}\) be some cutoff parameter and let
\(L^a_{xy}(j,c) := \{(X_i,Y_i)|X_{ij} < c, i = 1,...,n\}, L^b_{xy}(j,c) = \{(X_i,Y_i)|X_{ij} \geq c, i = 1,...,n\}\)
be the two leaves containing the set of observations resulting from
partitioning variable \(j\) at cutoff \(c\). Then a split is determined
by finding the arguments, \((j^*,c^*)\) that minimise the sum of the
mean squared errors (MSE) in both
leaves\textasciitilde{}\cite{Hastie2013}, \[
(j^*, c^*) = \operatornamewithlimits{argmin}_{j, c} \sum_{y \in L^a_{y}(j,c)} (y - L^a_{\bar{Y}}(j,c))^2 + \sum_{y \in L^b_{y}(j,c)} (y - L^b_{\bar{Y}}(j,c))^2
\label{eq:dt_min}
\] This method is repeated from the first branch of the tree down to the
very last such that observations are included in a given leaf \(L\) if
they satisfy all conditions from all previous branches; features may be
considered multiple times in the growing process. This is an intuitive
method as minimising the above sum results in the set of observations
within each individual leaf being as similar as possible, thus as an
observation is passed down the tree, it becomes more similar to the
subsequent leaves, eventually landing in a leaf containing homogeneous
observations. Controlling how many variables to consider at each split
and how many splits to make are determined by hyper-parameter tuning.

Decision trees are a powerful method for high-dimensional data as only a
small sample of variables will be used for growing a tree, and therefore
they are also useful for variable importance by identifying which
variables were utilised in growth (other importance methods are also
available). Decision trees are also highly interpretable, as
demonstrated by \ref{fig:surv_ranfor}. The recursive pseudo-algorithm in
\ref{alg:dt_fit} demonstrates the simplicity in growing a decision tree
(again methods such as pruning are omitted).

\begin{algorithm}
\caption{Fitting a decision tree. \\
\textbf{Input} Training data, $\mathcal{D}_0$. Splitting rule, $SR$. \\
\textbf{Output} Fitted decision tree, $\hat{g}$.}\label{alg:dt_fit}
\begin{algorithmic}[1]
\State Compute $(j^*, c^*)$ as the optimisers of $SR$ (e.g. \ref{eq:dt_min}) to create the initial leaf and branches.
\State Repeat step 1 on all subsequent branches until a stopping rule is reached.
\State Return the fitted tree, $\hat{g}$, as the series of branches.
\end{algorithmic}
\end{algorithm}

\paragraph{Stopping Rules}

The
\texttt{stopping\ rule\textquotesingle{}\ in\ \textbackslash{}ref\{alg:dt\_fit\}\ is\ usually\ a\ condition\ on\ the\ number\ of\ observations\ in\ each\ leaf\ such\ that\ leaves\ will\ continue\ to\ be\ split\ until\ some\ minimum\ number\ of\ observations\ has\ been\ reached\ in\ a\ leaf.\ Other\ conditions\ may\ be\ on\ the}depth'
of the tree, which corresponds to the number of levels of splitting, for
example the tree in \ref{fig:surv_ranfor} has a depth of \(2\) (the
first level is not counted).

\paragraph{Random Forests}

Despite being more interpretable than other machine learning methods,
decision trees usually have poor predictive performance, high variance
and are not robust to changes in the data. As such,
\emph{random forests} are preferred to improve prediction accuracy and
decrease variance. Random forests utilise bootstrap aggregation, or
\emph{bagging}\textasciitilde{}\cite{Breiman1996a}, to aggregate many
decision trees. A pseudo fitting algorithm is given in
\ref{alg:rsf_fit}.

\begin{algorithm}
\caption{Fitting a random forest. \\
\textbf{Input} Training data, $\mathcal{D}_0$. Total number of trees, $B \in \mathbb{N}_{> 0}$. \\
\textbf{Output} Fitted random forest, $\hat{g}$.}\label{alg:rsf_fit}
\begin{algorithmic}[1]
\For{$b = 1,...,B$}
\State Create a bootstrapped sample of the data, $D_b$.
\State Grow a decision tree, $\hat{g}_b$, on $D_b$ with \ref{alg:dt_fit}.
\EndFor
\State $\hat{g}\gets \{\hat{g}_b\}^B_{b=1}$
\Return $\hat{g}$
\end{algorithmic}
\end{algorithm}

Prediction from a random forest follows by making predictions from the
individual trees and aggregating the results by some function \(\sigma\)
\ref{alg:rsf_pred}; \(\sigma\) is usually the sample mean for
regression,

\[
\hat{g}(X^*) = \sigma(\hat{g}_1(X^*),...,\hat{g}_B(X^*)) = \frac{1}{B} \sum^B_{b=1} \hat{g}_b(X^*)
\]

where \(\hat{g}_b(X^*)\) is the terminal node prediction from the
\(b\)th tree and \(B\) are the total number of grown trees
(\texttt{\$B\$\textquotesingle{}\ is\ commonly\ used\ instead\ of}\(N\)'
to note the relation to bootstrapped data).

\begin{algorithm}
\caption{Predicting from a random forest. \\
\textbf{Input} Testing data $X^* \sim \mathcal{X}$, fitted forest $\hat{g}$ with $B \in \mathbb{N}_{> 0}$ trees, aggregation method $\sigma$. \\
\textbf{Output} Prediction, $\hat{Y}\sim \mathcal{Y}$.}\label{alg:rsf_pred}
\begin{algorithmic}[1]
\For{$b = 1,...,B$}
\State `Drop' $X^*$ down the tree $\hat{g}_b$ individually to return a prediction $\hat{g}_b(X^*)$.
\EndFor
\State $\hat{Y}\gets \sigma(\hat{g}_1(X^*),...,\hat{g}_B(X^*))$
\Return $\hat{Y}$
\end{algorithmic}
\end{algorithm}

Usually many (hundreds or thousands) trees are grown, which makes random
forests robust to changes in data and
\texttt{confident\textquotesingle{}\ about\ individual\ predictions.\ Other\ advantages\ include\ having\ several\ tunable\ hyper-parameters,\ including:\ the\ number\ of\ trees\ to\ grow,\ the\ number\ of\ variables\ to\ include\ in\ a\ single\ tree,\ the\ splitting\ rule,\ and\ the\ minimum\ terminal\ node\ size.\ Machine\ learning\ models\ with\ many\ hyper-parameters,\ tend\ to\ perform\ better\ than\ other\ models\ as\ they\ can\ be\ fine-tuned\ to\ the\ data,\ which\ is\ why\ complex\ deep\ learning\ models\ are\ often\ the\ best\ performing.\ Although\ as\ a\ caveat:\ too\ many\ parameters\ can\ lead\ to\ over-fitting\ and\ tuning\ many\ parameters\ can\ take\ a\ long\ time\ and\ be\ highly\ intensive.\ Random\ forests\ lose\ the\ interpretability\ of\ decision\ trees\ and\ are\ considered}black-box'
models as individual predictions cannot be easily scrutinised.

\subsection{Random Forests for Survival Analysis}

Given time constraints and the scope of this thesis, this survey of
random forests for survival analysis will primarily focus on
`traditional' decision trees and random forests and will not look at
other sub-fields such as causal forests. A comprehensive review of
random survival forests (RSFs) is provided in Bou-Hamad
(2011)\textasciitilde{}\cite{Bou-Hamad2011}, which includes extensions
to time-varying covariates and different censoring types. In order to
prevent overlap, this survey will focus primarily on methods that have
off-shelf implementations, their prediction types, and how successfully
these methods handle the problem of censoring. Random forests and
decision trees for survival are termed from here as Random Survival
Forests (RSFs) and Survival Decision Trees (SDTs) respectively.

Unlike other machine learning methods that may require complex changes
to underlying algorithms, individual components of a random forest can
be adapted without altering the fundamental algorithm. The principle
random forest algorithm is unchanged for RSFs, the difference is in the
choice of splitting rule and terminal node prediction, which both must
be able to handle censoring. Therefore instead of discussing individual
algorithms, the different choices of splitting rules and terminal node
predictions are discussed, then combinations of these are summarised
into five distinct algorithms.

\subsubsection{Splitting Rules}

Survival trees and RSFs have been studied for the past four decades and
whilst the amount of splitting rules to appear could be considered
``numerous'\,'\textasciitilde{}\cite{Bou-Hamad2011}, only two broad
classes are commonly utilised and
implemented\textasciitilde{}\cite{pkgrfsrc, pkgsksurvival, pkgrpart, pkgranger}.
The first class rely on hypothesis tests, and primarily the log-rank
test, to maximise dissimilarity between splits, the second class
utilises likelihood-based measures. The first is discussed in more
detail as this is common in practice and is relatively straightforward
to implement and understand, moreover it has been demonstrated to
outperform other splitting rules\textasciitilde{}\cite{Bou-Hamad2011}.
Likelihood rules are more complex and require assumptions that may not
be realistic, these are discussed briefly.

\paragraph{Hypothesis Tests}

The log-rank test statistic has been widely utilised as the `natural'
splitting-rule for survival
analysis\textasciitilde{}\cite{Ciampi1986, Ishwaran2008, LeBlanc1993, Segal1988}.
The log-rank test compares the survival distributions of two groups and
has the null-hypothesis that both groups have the same underlying risk
of (immediate) death, i.e.~identical hazard functions.

Let \(L^A\) and \(L^B\) be two leaves then using the notation above let
\(h^A,h^B\) be the (true) hazard functions derived from the observations
in the two leaves respectively. The log-rank hypothesis test is given by
\(H_0: h^A = h^B\) with test statistic\textasciitilde{}\cite{Segal1988},
\[
LR(L^A) = \frac{\sum_{\tau \in \mathcal{U}_D} (d^A_{\tau} - e^A_{\tau})}{\sqrt{\sum_{\tau \in \mathcal{U}_D} v_\tau^A}}
\] where \(d^A_{\tau}\) is the observed number of deaths in leaf \(A\)
at \(\tau\), \[
d^A_{\tau} := \sum_{i \in L^A} \mathbb{I}(T_i = \tau, \Delta_i = 1)
\] \(e^A_{\tau}\) is the expected number of deaths in leaf \(A\) at
\(\tau\), \[
e^A_{\tau} := \frac{n_\tau^A d_\tau}{n_\tau}
\] and \(v^A_\tau\) is the variance of the number of deaths in leaf
\(A\) at \(\tau\), \[
v^A_{\tau} := e^A_{\tau} \Big(\frac{n_\tau - d_\tau}{n_\tau}\Big)\Big(\frac{n_\tau - n^A_\tau}{n_\tau - 1}\Big)
\] where \(\mathcal{U}_D\) is the set of unique death times across the
data (in both leaves), \textbackslash{}
\(n_\tau = \sum_i \mathbb{I}(T_i \geq \tau)\) is the number of
observations at risk at \(\tau\) in both leaves, \textbackslash{}
\(n_\tau^A = \sum_{i \in L^A} \mathbb{I}(T_i \geq \tau)\) is the number
of observations at risk at \(\tau\) in leaf A, and \textbackslash{}
\(d_\tau = \sum_i \mathbb{I}(T_i = \tau, \Delta_i = 1)\) is the number
of deaths at \(\tau\) in both leaves.

Intuitively these results follow as the number of deaths in a leaf is
distributed according to
\(\operatorname{Hyper}(n^A_\tau,n_\tau,d_\tau)\). The same statistic
results if \(L^B\) is instead considered. \ref{alg:dt_fit} follows for
fitting decision trees with the log-rank splitting rule, \(SR\), to be
maximised.

The higher the log-rank statistic, the greater the dissimilarity between
the two groups, thereby making it a sensible splitting rule for
survival, moreover it has been shown that it works well for splitting
censored
data\textasciitilde{}\cite{LeBlanc1993}.\footnote{The results of this experiment are actually in LeBlanc's unpublished 1989 PhD thesis and therefore it has to be assumed that LeBlanc is accurately conveying its results in this 1993 paper.}
When censoring is highly dependent on the outcome, the log-rank
statistic does not perform well and is
biased\textasciitilde{}\cite{Bland2004}, which tends to be true of the
majority of survival models. Additionally, the log-rank test requires no
knowledge about the shape of the survival curves or distribution of the
outcomes in either group\textasciitilde{}\cite{Bland2004}, making it
ideal for an automated process that requires no user intervention.

The log-rank \emph{score} rule\textasciitilde{}\cite{Hothorn2003} is a
standardized version of the log-rank rule that could be considered as a
splitting rule, though simulation studies have demonstrated
non-significant predictive performance when comparing the
two\textasciitilde{}\cite{Ishwaran2008}. \textbackslash\textbackslash{}
Alternative dissimiliarity measures and tests have also been suggested
as splitting rules, including modified Kolmogorov-Smirnov test and
Gehan-Wilcoxon tests\textasciitilde{}\cite{Ciampi1988}. Simulation
studies have demonstrated that both of these may have higher power and
produce `better' results than the log-rank
statistic\textasciitilde{}\cite{Fleming1980}. Despite this, these do not
appear to be in common usage and no implementation could be found that
include these.

\noindent 

\paragraph{Likelihood Based Rules}

Likelihood ratio statistics, or deviance based splitting rules, assume a
certain model form and thereby an assumption about the data. This may be
viewed as an advantageous strategy, as it could arguably increase
interpretability, or a disadvantage as it places restrictions on the
data. For survival models, a full-likelihood can be estimated with a Cox
form by estimating the cumulative hazard
function\textasciitilde{}\cite{LeBlanc1992}. LeBlanc and Crowley
(1992)\textasciitilde{}\cite{LeBlanc1992} advocate for selecting the
optimal split by maximising the full PH likelihood, assuming the
cumulative hazard function, \(H\), is known, \[
\mathcal{L}:= \prod_{m = 1}^M \prod_{i \in L^m} h_m(T_i)^{\Delta_i} \exp(-H_m(T_i))
\] where \(M\) is the total number of terminal nodes, \(h_m\) and
\(H_m\) are the (true) hazard and cumulative hazard functions in the
\(m\)th node, and again \(L^m\) is the set of observations in terminal
node \(m\). Estimation of \(h_m\) and \(H_m\) are described with the
associated terminal node prediction below.

The primary advantage of this method is that any off-shelf regression
software with a likelihood splitting rule can be utilised without any
further adaptation to model fitting by supplying this likelihood with
required estimates. However the additional costs of computing these
estimates may outweigh the benefits once the likelihood has been
calculated, and this could be why only one implementation of this method
has been found\textasciitilde{}\cite{Bou-Hamad2011, pkgrpart}.

\paragraph{Other Splitting Rules}

As well as likelihood and log-rank spitting rules, other papers have
studied comparison of residuals\textasciitilde{}\cite{Therneau1990},
scoring rules\textasciitilde{}\cite{pkgrfsrc}, and distance
metrics\textasciitilde{}\cite{Gordon1985}. These splitting rules work
similarly to the mean squared error in the regression setting, in which
the score should be minimised across both leaves. The choice of
splitting rule is usually data-dependent and can be treated as a
hyper-parameter for tuning. However if there is a clear goal in
prediction, then the choice of splitting rule can be informed by the
prediction type. For example, if the goal is to maximise separation,
then a log-rank splitting rule to maximise homogeneity in terminal nodes
is a natural starting point. Whereas if the goal is to estimate the
linear predictor of a Cox PH model, then a likelihood splitting rule
with a Cox form may be more sensible.

\subsubsection{Terminal Node Prediction}
\label{sec:surv_ml_models_ranfor_nodes}

Only two terminal node predictions appear in common usage.

\paragraph{Predict: Ranking}

Terminal node ranking predictions for survival trees and forests have
been limited to those that use a likelihood-based splitting rule and
assume a PH model form\textasciitilde{}\cite{Ishwaran2004, LeBlanc1992}.
In model fitting the likelihood splitting rule model attempts to fit the
(theoretical) PH model \(h_m(\tau) = h_0(\tau)\theta_m\) for
\(m \in 1,...,M\) where \(M\) is the total number of terminal nodes and
\(\theta_m\) is a parameter to estimate. The model returns predictions
for \(\exp(\hat{\theta}_m)\) where \(\hat{\theta}_m\) is the estimate of
\(\theta_m\). This is estimated via an iterative procedure in which in
iteration \(j+1\), \(\hat{\theta}_m^{j+1}\) is estimated by \[
\hat{\theta}_m^{j+1} = \frac{\sum_{i \in L^m} \Delta_i}{\sum_{i \in L^m} \hat{H}^j_0(T_i)}
\] where as before \(L^m\) is the set of observations in leaf \(m\) and
\[
\hat{H}^{j}_0(\tau) = \frac{\sum_{i:T_i \leq \tau} \Delta_i}{\sum_{m = 1}^M\sum_{\{i:i \in \mathcal{R}_\tau \cap L^a\}} \hat{\theta}^{j}_m}
\] which is repeated until some stopping criterion is reached. The same
cumulative hazard is estimated for all nodes however \(\hat{\theta}_m\)
varies across nodes. This method lends itself naturally to a composition
to a full distribution \ref{sec:car_pipelines_distr} as it assumes a PH
form and separately estimates the cumulative hazard and relative risk
\ref{sec:surv_ml_models_ranfor_nov}, though no implementation of this
composition could be found.

\paragraph{Predict: Survival Distribution}

The most common terminal node prediction appears to be predicting the
survival distribution by estimating the survival function, using the
Kaplan-Meier or Nelson-Aalen estimators, on the sample in the terminal
node\textasciitilde{}\cite{Hothorn2004, Ishwaran2008, LeBlanc1993, Segal1988}.
Estimating a survival function by a non-parametric estimator is a
natural choice for terminal node prediction as these are natural
\texttt{baselines\textquotesingle{}\ in\ survival,\ similarly\ to\ taking\ the\ sample\ mean\ in\ regression.\ The\ prediction\ for\ SDTs\ is\ straightforward,\ the\ non-parametric\ estimator\ is\ fit\ on\ all\ observations\ in\ each\ of\ the\ terminal\ nodes.\ This\ is\ adapted\ to\ RSFs\ by\ bagging\ the\ estimator\ across\ all\ decision\ trees\textasciitilde{}\textbackslash{}cite\{Hothorn2004\}.\ Using\ the\ Nelson-Aalen\ estimator\ as\ an\ example,\ let\ \$m\$\ be\ a\ terminal\ node\ in\ an\ SDT,\ then\ the\ terminal\ node\ prediction\ is\ given\ by,\ \$\$\ \textbackslash{}hat\{H\}\_m(\textbackslash{}tau)\ =\ \textbackslash{}sum\_\{\textbackslash{}\{i:\ i\ \textbackslash{}in\ L\^{}m\ \textbackslash{}cap\ T\_i\ \textbackslash{}leq\ \textbackslash{}tau\textbackslash{}\}\}\ \textbackslash{}frac\{d\_i\}\{n\_i\}\ \textbackslash{}label\{eq:surv\_nelson\}\ \$\$\ where\ \$d\_i\$\ and\ \$n\_i\$\ are\ the\ number\ of\ events\ and\ observations\ at\ risk\ at\ time\ \$T\_i\$\ in\ terminal\ node\ \$m\$.\ Ishwaran\textasciitilde{}\textbackslash{}cite\{Ishwaran2008\}\ defined\ the\ bootstrapped\ Nelson-Aalen\ estimator\ as\ \$\$\ \textbackslash{}hat\{H\}\_\{Boot\}(\textbackslash{}tau)\ =\ \textbackslash{}frac\{1\}\{B\}\ \textbackslash{}sum\^{}B\_\{b=1\}\ \textbackslash{}hat\{H\}\_\{m,\ b\}(\textbackslash{}tau),\ \textbackslash{}quad\ m\ \textbackslash{}in\ 1,...,M\ \textbackslash{}label\{eq:surv\_nelson\_boot\}\ \$\$\ where\ \$B\$\ is\ the\ total\ number\ of\ bootstrapped\ estimators,\ \$M\$\ is\ the\ number\ of\ terminal\ nodes,\ and\ \$\textbackslash{}hat\{H\}\_\{m,b\}\$\ is\ the\ cumulative\ hazard\ for\ the\ \$m\$th\ terminal\ node\ in\ the\ \$b\$th\ tree.\ The\ bootstrapped\ Kaplan-Meier\ estimator\ is\ calculated\ analogously.\ More\ generally\ these\ can\ be\ considered\ as\ a\ uniform\ mixture\ of\ \$B\$\ distributions\ \textbackslash{}ref\{sec:car\_pipelines\_avg\}.\ \textbackslash{}\textbackslash{}\textbackslash{}\textbackslash{}\ All\ implemented\ RSFs\ can\ now\ be\ summarised\ into\ the\ following\ five\ algorithms:\ \textbackslash{}\textbackslash{}\textbackslash{}\textbackslash{}\ \textbackslash{}textbf\{RRT\}\textbackslash{}label\{mod:rrt\}\textbackslash{}\textbackslash{}\ LeBlanc\ and\ Crowley\textquotesingle{}s\ (1992)\textasciitilde{}\textbackslash{}cite\{LeBlanc1992\}\ survival\ decision\ tree\ uses\ a\ deviance\ splitting\ rule\ with\ a\ terminal\ node\ ranking\ prediction,\ which\ assumes\ a\ PH\ model\ form.\ These}relative
risk trees' (RRTs) are implemented in the package
\textbf{rpart}\textasciitilde{}\cite{pkgrpart}. This model is considered
the least accessible and transparent of all discussed in this section
as: few implementations exist, it requires assumptions that may not be
realistic, and predictions are harder to interpret than other models.
Predictive performance of the model is expected to be worse than RSFs as
this is a decision tree; this is confirmed in \ref{chap:bench}.
\textbackslash\textbackslash{}
\textbf{RRF}\label{mod:rrf}\textbackslash{} Ishwaran
\textit{et al.}\textsubscript{(2004)}\cite{Ishwaran2004} proposed a
random forest framework for the relative risk trees, which makes a
slight adaptation and applies the iteration of the terminal node
prediction after the tree is grown as opposed to during the growing
process. No implementation for these
\texttt{relative\ risk\ forests\textquotesingle{}\ (RRFs)\ could\ be\ found\ or\ any\ usage\ in\ the\ literature.\ Therefore\ RRFs\ are\ also\ considered\ not\ to\ be\ APT\ for\ the\ same\ reasons\ given\ to\ the\ RRTs,\ except\ that\ in\ this\ case\ the\ predictive\ performance\ of\ RRFs\ is\ simply\ unknown\ (though\ can\ reasonably\ be\ expected\ to\ outperform\ an\ RRT).\ \textbackslash{}\textbackslash{}\textbackslash{}\textbackslash{}\ \textbackslash{}textbf\{RSDF-DEV\}\textbackslash{}label\{mod:rsdfdev\}\textbackslash{}\textbackslash{}\ Hothorn\ \textbackslash{}etal\textasciitilde{}(2004)\textasciitilde{}\textbackslash{}cite\{Hothorn2004\}\ expanded\ upon\ the\ RRT\ by\ introducing\ a\ bagging\ composition\ thus\ creating\ a\ random\ forest\ with\ a\ deviance\ splitting\ rule,\ again\ assuming\ a\ PH\ form.\ However\ the\ ranking\ prediction\ is\ altered\ to\ be\ a\ bootstrapped\ Kaplan-Meier\ prediction\ in\ the\ terminal\ node.\ This\ is\ implemented\ in\ \textbackslash{}pkg\{ipred\}\textasciitilde{}\textbackslash{}cite\{pkgipred\}.\ This\ model\ improves\ upon\ the\ accessibility\ and\ transparency\ of\ the\ RRT\ by\ providing\ a\ more\ straightforward\ and\ interpretable\ terminal\ node\ prediction.\ However,\ as\ this\ is\ a\ decision\ tree,\ predictive\ performance\ is\ again\ expected\ to\ be\ worse\ than\ the\ RSFs.\ \textbackslash{}\textbackslash{}\textbackslash{}\textbackslash{}\ \textbackslash{}textbf\{RSCIFF\}\textbackslash{}label\{mod:rsciff\}\textbackslash{}\textbackslash{}\ Hothorn\ \textbackslash{}etal\textasciitilde{}\textbackslash{}cite\{Hothorn2005\}\ studied\ a\ conditional\ inference\ framework\ in\ order\ to\ predict\ log-survival\ time.\ In\ this\ case\ the\ splitting\ rule\ is\ based\ on\ an\ IPC\ weighted\ loss\ function,\ which\ allows\ implementation\ by\ off-shelf\ classical\ random\ forests.\ The\ terminal\ node\ predictions\ are\ a\ weighted\ average\ of\ the\ log-survival\ times\ in\ the\ node\ where\ weighting\ is\ determined\ by\ the\ Kaplan-Meier\ estimate\ of\ the\ censoring\ distribution.\ This}random
survival conditional inference framework forest' (RSCIFF) is implemented
in \textbf{party}\textasciitilde{}\cite{pkgparty} and
\textbf{partykit}\textasciitilde{}\cite{pkgpartykit}, which additionally
includes a distribution terminal node prediction via the bootstrapped
Kaplan-Meier estimator. The survival tree analogue (SDCIFT) is
implemented in the same packages. Implementation of the RSCIFF is
complex, which is likely why all implementations (in the above packages)
are by the same authors. The complexity of conditional inference forests
may also be the reason why several reviews, including this one, mention
(or completely omit) RSCIFFs but do not include any comprehensive
details that explain the fitting
procedure\textasciitilde{}\cite{Bou-Hamad2011, Wang2017a}. In this
regard, it is hard to claim that RSCIFFs are transparent or accessible.
Moreover the authors of the model state that random conditional
inference forests are for ``expert user{[}s{]} only and {[}their{]}
current state is rather
experimental'\,'\textasciitilde{}\cite{pkgpartykit}. Finally with
respect to model performance, there is evidence that they can outperform
RSDFs (below) dependent on the data
type\textasciitilde{}\cite{Nasejje2017} however no benchmark experiment
could be found that compared them to other models.
\textbackslash\textbackslash{}
\textbf{RSDF-STAT}\label{mod:rsdfstat}\textbackslash{} Finally Ishwaran
\textit{et al.}\textsubscript{(2008)}\cite{Ishwaran2008} proposed the
most general form of RSFs with a choice of hypothesis tests (log-rank
and log-rank score) and survival measure (Brier, concordance) splitting
rules, and a bootstrapped Nelson-Aalen terminal node prediction. These
are implemented in
\textbf{randomForestSRC}\textasciitilde{}\cite{pkgrfsrc} and
\textbf{ranger}\textasciitilde{}\cite{pkgranger}. This final class of
RSFs are likely the only class that can be considered APT. There are
several implementations of these models across programming languages,
and extensive details for the fitting and predicting procedures, which
makes them very accessible. The models utilise a standard random forest
framework, which makes them transparent and familiar to those without
expert Survival knowledge. Moreover they have been proven to perform
well in benchmark experiments, especially on high-dimensional
data\textasciitilde{}\cite{Herrmann2020, Spooner2020}.

\subsection{Novel Adaptations}
\label{sec:surv_ml_models_ranfor_nov}

Based on this survey of RSFs, a couple of novel adaptations may be
considered as natural extensions.

\paragraph{Parametric Terminal Node Predictions}

All probabilistic RSFs make use of a non-parametric estimator for the
terminal node prediction. As an adaptation one could fit a semi- or
fully-parametric model in the terminal nodes. However this could suffer
from the problem of increased complexity/run-time, as well as
overfitting, though is a sensible method worth considering.
Alternatively a random forest for inference could be designed whereby a
theoretical (say Weibull) survival distribution is assumed and the
terminal node predictions are then MLE (or other inference method)
estimates for the distribution parameters.

\paragraph{RRT and RRF Composition}

As discussed above, Ishwaran's Relative Risk Forest makes a relative
risk prediction in each terminal node
\ref{sec:surv_ml_models_ranfor_nodes} by fitting \[
\hat{H}_{h;b}(\tau) = \hat{H}_{0;b}(\tau)\hat{\theta}_h
\] in which \(\hat{H}_{0;b}(\tau)\) and \(\hat{\theta}_h\) are
iteratively updated and the final prediction is \(\hat{\theta}_h\). A
natural alternative would be to return the bootstrapped survival
distribution prediction over \(\hat{H}_{h;b}(\tau)\), instead of only
returning \(\hat{\theta}\). Ishwaran \textit{et al.} allude to this
prediction type in Section 3.2 of the 2004
paper\textasciitilde{}\cite{Ishwaran2004}, however this is not
formalised or implemented. It would be natural to first consider this
for RRTs (before extension to RRFs) and implementation would likely be
straightforward as any software must first estimate
\(\hat{H}_{0;b}(\tau)\) and \(\hat{\theta}_h\).

\subsection{Conclusions}

Random forests are a highly flexible algorithm that allow the various
components to be adapted and altered without major changes to the
underlying algorithm. The result is that relatively few \textsf{R}{}
implementations of RSFs cover almost half a century's worth of
developments. The only algorithm that does not seem to be implemented is
the relative risk forest.

Of the methods reviewed, only one can be considered APT for survival
predictions. A lack of accessibility, transparency, or proven
performance makes RRT and RSDF-DEV a poor choice for model fitting.
RSCIFF is potentially a powerful method with promising results in
benchmark experiments, but even the authors recognise its complexity
prevents it from being accessible. Ishwaran's RSFs on the other hand are
APT and suitable for model fitting and deployment. Simulation studies
have demonstrated that RSFs can perform well even with high levels of
censoring and there is evidence that on some datasets these can
outperform a Cox PH\textasciitilde{}\cite{Ishwaran2008}. Despite only
one of the five models discussed here being APT, Ishwaran's model is
highly flexible, and its implementation in software packages reflects
this. Therefore one can still confidently conclude that random forests
are a powerful algorithm in regression, classification, and survival
analysis.

\bookmarksetup{startatroot}

\hypertarget{support-vector-machines}{%
\chapter{Support Vector Machines}\label{support-vector-machines}}

\section{Support Vector Machines}
\label{sec:surv_ml_models_svm}

\subsection{SVMs for Regression}

In the simplest explanation, support vector machines
(SVMs)\textasciitilde{}\cite{CortesVapnik1995} fit a hyperplane, \(g\),
on given training data and make predictions for new values as
\(\hat{g}(X^*)\) for some testing covariate \(X^*\). One may expect the
hyperplane to be fit so that all training covariates would map perfectly
to the observed labels (a
\texttt{hard-boundary\textquotesingle{})\ however\ this\ would\ result\ in\ overfitting\ and\ instead\ an\ acceptable\ (}soft'-)boundary
of error, the
\texttt{\$\textbackslash{}epsilon\$-tube\textquotesingle{},\ dictates\ how}incorrect'
predictions may be, i.e.~how large an underestimate or overestimate.
\ref{fig:surv_svm} visualises support vector machines for regression
with a linear hyperplane \(g\), and an acceptable boundary of error
within the dashed lines (the \(\epsilon\)-tube). SVMs are not limited to
linear boundaries and \emph{kernel} functions are utilised to specify
more complex hyperplanes. Exact details of the optimization/separating
procedure are not discussed here but many off-shelf `solvers' exist in
different programming languages for fitting SVMs.
\textbackslash\textbackslash{} In the regression setting, the goal of
SVMs is to estimate the function \[
g: \mathbb{R}^p \rightarrow \mathbb{R}; \quad (x) \mapsto x\beta + \beta_0
\label{eq:svm}
\] by estimation of the weights
\(\beta \in \mathbb{R}^p, \beta_0 \in \mathbb{R}\) via the optimisation
problem \[
\begin{aligned}
& \min_{\beta,\beta_0, \xi, \xi^*} \frac{1}{2} \|\beta\|^2 + C \sum^n_{i=1}(\xi_i + \xi_i^*) \\
& \textrm{s.t.}
\begin{dcases}
Y_i - g(X_i) & \leq \epsilon + \xi_i \\
g(X_i) - Y_i & \leq \epsilon + \xi_i^* \\
\xi_i, \xi_i^* & \geq 0, \ i = 1,...,n
\end{dcases}
\end{aligned}
\label{eq:svm_opt}
\] where \(C \in \mathbb{R}\) is the regularization/cost parameter,
\(\xi_i,\xi_i^*\) are slack parameters and \(\epsilon\) is a margin of
error for observations on the wrong side of the hyperplane, and \(g\) is
defined in \ref{eq:svm}. The effect of the slack parameters is seen in
\ref{fig:surv_svm} in which a maximal distance from the
\(\epsilon\)-tube is dictated by the slack variables.

In fitting, the dual of the optimisation is instead solved and
substituting the optimised parameters into \ref{eq:svm} gives the
prediction function, \[
\hat{g}(X^*) = \sum^n_{i=1} (\alpha_i - \alpha_i^*)K(X^*,X_i) + \beta_0
\] where \(\alpha_i, \alpha_i^*\) are Lagrangrian multipliers and \(K\)
is some kernel
function.\footnote{Discussion about the purpose of kernels and sensible choices can be found in~\cite{pkgsurvivalsvm, Hastie2013, Vapnik1998}.}
The Karush-Kuhn-Tucker conditions required to solve the optimisation for
\(\alpha\) result in the key property of SVMs, which is that values
\(\alpha_i = \alpha_i^* = 0\) indicate that observation \(i\) is
\texttt{inside\textquotesingle{}\ the\ \$\textbackslash{}epsilon\$-tube\ and\ if\ \$\textbackslash{}alpha\_i\ \textbackslash{}neq\ 0\$\ or\ \$\textbackslash{}alpha\^{}*\_i\ \textbackslash{}neq\ 0\$\ then\ \$i\$\ is\ outside\ the\ tube\ and\ termed\ a\ \textbackslash{}emph\{support\ vector\}.\ It\ is\ these}support
vectors' that influence the shape of the separating boundary.
\textbackslash\textbackslash{} The choice of kernel and its parameters,
the regularization parameter \(C\), and the acceptable error
\(\epsilon\), are all tunable hyper-parameters, which makes the support
vector machine a highly adaptable and often well-performing machine
learning method. However the parameters \(C\) and \(\epsilon\) often
have no clear apriori meaning (especially true when predicting abstract
rankings) and thus require extensive tuning over a great range of
values; no tuning will result in a very poor model fit.

\begin{figure}

{\centering \includegraphics{./images/svm/svm.png}

}

\caption{\label{fig-surv-svm}Visualising a support vector machine with
an \(\epsilon\)-tube and slack parameters \(\xi\) and \(\xi^*\). Red
circles are values within the \(\epsilon\)-tube and blue diamonds are
values outside the tube. x-axis is single covariate, \(x\), and y-axis
is \(g(x) = x\beta + \beta_0\).}

\end{figure}

\subsection{SVMs for Survival Analysis}
\label{sec:surv_ml_models_svm_surv}

Similarly to random forests, all research for Survival Support Vector
Machines (SSVMs) can be reduced to very few algorithms, in fact only one
unique off-shelf algorithm is identified in this survey. No SSVM for
distribution predictions exist, instead they either predict survival
time, rankings, or a hybrid of the two.

Other reviews and surveys of SSVMs include a short review by Wang
\textit{et al.}\textsubscript{(2017)}\cite{Wang2017} and some benchmark
experiments and short surveys from Van Belle
\textit{et al.}\textsubscript{(2011)}\cite{VanBelle2011b}, Goli
\textit{et al.}\textsubscript{(2016)}\cite{Goli2016a} and Fouodo
\textit{et al.}\textsubscript{(2018)}\cite{pkgsurvivalsvm}. All the
benchmark experiments in these papers indicate that the Cox PH performs
as well as, if not better than, the SSVMs.
\textbackslash\textbackslash{} Initial attempts at developing SSVMs by
Shivaswamy \textit{et al.}\textsubscript{(2007)}\cite{Shivaswamy2007}
took the most `natural' course and attempt to treat the problem as a
regression one with adjustments in the optimisation for censoring. These
methods have a natural interpretation and are intuitive in their
construction. Further development of these by Khan and Zubek
(2008)\textasciitilde{}\cite{Khan2008} and Land
\textit{et al.}\textsubscript{(2011)}\cite{Land2011} focused on
different adjustments for censoring in order to best reflect a realistic
survival data set-up. Simultaneously, ranking models were developed in
order to directly optimise a model's discriminatory power. Developments
started with the work of Evers and Messow
(2008)\textasciitilde{}\cite{Evers2008} but were primarily made by Van
Belle\textsubscript{\textit{et al.} (2007)-(2011)}\cite{VanBelle2010, VanBelle2007, VanBelle2008, VanBelle2011a}.
These lack the survival time interpretation but are less restrictive in
the optimisation constraints. Finally a hybrid of the two followed
naturally from Van
Belle\textsubscript{\textit{et al.} (2011)}\cite{VanBelle2011b} by
combining the constraints from both the regression and ranking tasks.
This hybrid method allows a survival time interpretation whilst still
optimising discrimination. These hybrid models have become increasingly
popular in not only SSVMs, but also neural networks
\ref{sec:surv_ml_models_nn}. Instead of presenting these models
chronologically, the final hybrid model is defined and then other
developments can be more simply presented as components of this hybrid.
One model with an entirely different formulation is considered after the
hybrid.

For all SSVMs defined in this section let: \(\xi_i,\xi_i^*,\xi_i'\) be
slack variables; \(\beta,\beta_0\) be model weights in \(\mathbb{R}\);
\(C, \mu\) be regularisation hyper-parameters in \(\mathbb{R}\);
\((X_i, T_i, \Delta_i) \stackrel{i.i.d.}\sim(X,T,\Delta)\) be the usual
training data; and \(g(x) = x\beta + \beta_0\).

\paragraph{SSVM-Hybrid}\label{mod:ssvmhybrid}

Van Belle \textit{et al.} published several papers developing SSVMs,
which culminate in the hybrid model here termed
`SSVM-Hybrid'\textasciitilde{}\cite{VanBelle2011b}. The model is defined
by the optimisation problem, \textbackslash\textbackslash{}
\textbf{SSVM-Hybrid}\textbackslash{} \[
\begin{aligned}
& \min_{\beta, \beta_0, \xi, \xi', \xi^*} \frac{1}{2}\|\beta\|^2 + C\sum_{i =1}^n \xi_i + \mu \sum^n_{i=1}(\xi_i' + \xi_i^*) \\
& \textrm{s.t.}
\begin{dcases}
& g(X_i) - g(X_{j(i)}) \geq T_i - T_{j(i)} - \xi_i, \\
& \Delta_i(g(X_i) - T_i) \leq \xi^*_i \\
& T_i - g(X_i) \leq \xi'_i \\
& \xi_i, \xi_i', \xi_i^* \geq 0, \quad \forall i = 1,...,n \\
\end{dcases}
\end{aligned}
\label{eq:surv_ssvmvb2}
\]

where
\(j(i) := \operatornamewithlimits{argmax}_{j \in 1,...n} \{T_j : T_j < T_i\}\)
is an index discussed further below. A prediction for test data is given
by,

\[
\hat{g}(X^*) = \sum^n_{i=1} \alpha_i(K(X_i, X^*) - K(X_{j(i)}, X^*)) + \alpha^*_i K(X_i, X^*) - \Delta_i\alpha_i'K(X_i, X^*) + \beta_0
\]

where \(\alpha_i, \alpha_i^*, \alpha_i'\) are Lagrange multipliers and
\(K\) is a chosen kernel function, which may have hyper-parameters to
select or tune.

\paragraph{SVCR (Regression)}

Examining the components of the SSVM-Hybrid model will help identify its
relation to previously published SSVMs. First note the model's
connection to the regression setting when on setting \(C = 0\), removing
the associated first constraint and ignoring \(\Delta\) in the second
constraint, the regression setting is exactly recovered:

\[
\begin{aligned}
& \min_{\beta, \beta_0, \xi, \xi'} \frac{1}{2}\|\beta\|^2 + \mu \sum^n_{i=1}(\xi_i + \xi_i') \\
& \textrm{s.t.}
\begin{dcases}
& g(X_i) - T_i \leq \xi_i \\
& T_i - g(X_i) \leq \xi'_i \\
& \xi_i, \xi_i' \geq 0, \quad \forall i = 1,...,n \\
\end{dcases}
\end{aligned}
\]

Note a slight difference in the formulation of this optimisation to the
original regression problem, here no error component \(\epsilon\) is
directly included, instead this is part of the optimisation and
considered as part of the slack parameters \(\xi_i, \xi'_i\);
effectively this is the same as setting \(\epsilon = 0\). This
formulation removes the \(\epsilon\)-tube symmetry seen previously and
therefore distinguishes more clearly between overestimates and
underestimates, with each being penalised differently. Removing the
\(\epsilon\) parameter can lead to model overfitting as all points
become support vectors, however careful tuning of other hyper-parameters
can effectively control for this.

This formulation allows for clearer control over left-, right-, and
un-censored observations. Clearly if an observation is uncensored then
the true value is known and should be predicted exactly, hence under-
and over-estimates are equally problematic and should be penalised the
same. If an observation is right-censored then the true death time is
greater than the observed time and therefore overestimates should not be
heavily penalised but underestimates should be; conversely for
left-censored observations.

This leads to the first SSVM for regression from Shivaswamy
\textit{et al.}\textsubscript{(2007)}\cite{Shivaswamy2007}.
\textbackslash\textbackslash{} \textbf{SVCR}\label{mod:svcr} \[
\begin{aligned}
& \min_{\beta, \beta_0, \xi, \xi^*} \frac{1}{2}\|\beta\|^2 + \mu\Big(\sum_{i \in R} \xi_i + \sum_{i \in L} \xi_i^*\Big) \\
& \textrm{s.t.}
\begin{dcases}
& g(X_i) - T_i \leq \xi^*_i, \quad \forall i \in R \\
& T_i - g(X_i) \leq \xi_i, \quad \forall i \in L \\
& \xi_i \geq 0, \forall i\in R; \xi^*_i \geq 0, \forall i \in L
\end{dcases}
\end{aligned}
\]

where \(L\) is the set of observations who are either left- or
un-censored, and \(R\) is the set of observations who are either right-
or un-censored. Hence an uncensored observation is constrained on both
sides as their true survival time is known, whereas a left-censored
observation is constrained in the amount of
\texttt{over-prediction\textquotesingle{}\ and\ a\ right-censored\ observation\ is\ constrained\ by}under-prediction'.
This is intuitive as the only known for these censoring types are the
lower and upper bounds of the actual survival time respectively.

Reducing this to the thesis scope of right-censoring only results in the
optimisation:

\[
\begin{aligned}
& \min_{\beta, \beta_0, \xi, \xi^*} \frac{1}{2}\|\beta\|^2 + \mu\Big(\sum_{i = 1}^n \xi_i + \xi_i^*\Big) \\
& \textrm{s.t.}
\begin{dcases}
& \Delta_i(g(X_i) - T_i) \leq \xi_i \\
& T_i - g(X_i) \leq \xi^*_i \\
& \xi_i, \xi_i^* \geq 0 \\
& \forall i\in 1,...,n
\end{dcases}
\end{aligned}
\] which can be seen to be identical to SSVM-Hybrid when \(C=0\) and the
first constraint is removed. Predictions are found by,

\[
\hat{g}(X^*) = \sum^n_{i=1} \alpha^*_i K(X_i, X^*) - \Delta_i\alpha_i'K(X_i, X^*) + \beta_0
\] \textbackslash\textbackslash{} The advantage of this algorithm is its
simplicity. Clearly if no-one is censored then the optimisation is
identical to the regression optimisation in \ref{eq:svm_opt}. As there
is no \(\epsilon\) hyper-parameter, the run-time complexity is the same
as, if not quicker than, a regression SVM. Both left- and
right-censoring are handled and no assumptions are made about
independent censoring. With respect to performance, benchmark
experiments\textasciitilde{}\cite{pkgsurvivalsvm} indicate that the SVCR
does not outperform a na"ive SVR (i.e.~censoring ignored). The SVCR is
implemented in the \textsf{R}{} package
\textbf{survivalsvm}\textasciitilde{}\cite{pkgsurvivalsvm} and is
referred to as `regression'. \textbackslash\textbackslash{} As
discussed, the error margin for left- and right- censoring should not
necessarily be equal and the penalty for each should not necessarily be
equal either. Hence a natural extension to SVCR is to add further
parameters to better separate the different censoring types, which gives
rise to the SVRc\textasciitilde{}\cite{Khan2008}. However this model is
only briefly discussed as left-censoring is out of scope of this thesis
and also the model is patented and therefore not easily accessible. The
model is given by the optimisation, \textbackslash\textbackslash{}
\textbf{SVRc}\label{mod:svrc} \[
\begin{aligned}
& \min_{\beta, \beta_0, \xi, \xi^*} \frac{1}{2}\|\beta\|^2 + \sum^n_{i=1} C_i\xi_i + C^*_i\xi'_i \\
& \textrm{s.t.}
\begin{dcases}
& g(X_i) - T_i \leq \epsilon'_i + \xi'_i \\
& T_i - g(X_i) \leq \epsilon_i + \xi_i \\
& \xi_i, \xi_i' \geq 0, \quad \forall i = 1,...,n \\
\end{dcases}
\end{aligned}
\]

Where
\(C_i = \Delta_iC_c + (1-\Delta_i)C_n, \epsilon_i = \Delta_i\epsilon_c + (1-\Delta_i)\epsilon_n\)
and analogously for \(C^*_i, C_C^*, \epsilon^*,...\). The new
hyper-parameters \(C_c, C_n, \epsilon_c, \epsilon_n\) are the penalty
for errors in censored predictions (c) and uncensored predictions (n)
for left and right (*) censoring, and the acceptable margin of errors
respectively. The rationale behind this algorithm is clear, by having
asymmetric error margins the algorithm can penalise predictions that are
clearly wrong whilst allowing predictions that may be correct (but
ultimately unknown due to censoring). Experiments indicate the model may
have superior discrimination than the Cox
PH\textasciitilde{}\cite{Khan2008} and
SVCR\textasciitilde{}\cite{Du2011}. However these conclusions are weak
as independent experiments do not have access to the patented model.

The largest drawback of the algorithm is a need to tune eight
parameters. As the number of hyper-parameters to tune increases, so too
does model fitting time as well as the risk of overfitting. The problem
of extra hyper-parameters is the most common disadvantage of the model
given in the literature\textasciitilde{}\cite{pkgsurvivalsvm, Land2011}.
Land \textit{et al.}\textsubscript{(2011)}\cite{Land2011} present an
adaptation to the SVRc to improve model fitting time, termed the
EP-SVRc, which uses Evolutionary Programming to determine the optimal
values for the parameters. No specific model or algorithm is described,
nor any quantitative results presented. No evidence can be found for
this method being used since publication. The number of hyper-parameters
in the SVRc, coupled with its lack of accessibility, outweigh the
benefits of the claimed predictive performance and is therefore clearly
not APT and will not be considered further.

\paragraph{SSVM-Rank}\label{mod:svmem}

The regression components of SSVM-Hybrid (\ref{eq:surv_ssvmvb2}) have
been fully examined, now turning to the ranking components and setting
\(\mu = 0\). In this case the model reduces to
\textbackslash\textbackslash{}
\textbf{SSVM-Rank}\label{mod:ranksvmc}\label{mod:ssvmvb1} \[
\begin{aligned}
& \min_{\beta, \beta_0, \xi} \frac{1}{2}\|\beta\|^2 + C\sum_{i =1}^n \xi_i \\
& \textrm{s.t.}
\begin{dcases}
& g(X_i) - g(X_{j(i)}) \geq T_i - T_{j(i)} - \xi_i, \\
& \xi_i \geq 0, \quad \forall i = 1,...,n \\
\end{dcases}
\end{aligned}
\]

with predictions

\[
\hat{g}(X^*) = \sum^n_{i=1} \alpha_i(K(X_i, X^*) - K(X_{j(i)}, X^*))
\]

This formulation, termed here
\texttt{SSVM-Rank\textquotesingle{},\ has\ been\ considered\ by\ numerous\ authors\ in\ different\ forms,\ including\ Evers\ and\ Messow\textasciitilde{}\textbackslash{}cite\{Evers2008\}\ and\ Van\ Belle\ \textbackslash{}etal\textasciitilde{}\textbackslash{}cite\{VanBelle2007,\ VanBelle2008,\ VanBelle2011b\}.\ The\ primary\ differences\ between\ the\ various\ models\ are\ in\ which\ observations\ are\ compared\ in\ order\ to\ optimise\ discrimination;\ to\ motivate\ why\ this\ matters,\ first\ observe\ the\ intuitive\ nature\ of\ the\ optimisation\ constraints.\ By\ example,\ define\ \$k\ :=\ T\_i\ -\ T\_\{j(i)\}\$\ and\ say\ \$T\_i\ \textgreater{}\ T\_\{j(i)\}\$.\ Then,\ in\ the\ first\ constraint,\ \$g(X\_i)\ -\ g(X\_\{j(i)\})\ \textbackslash{}geq\ k\ -\ \textbackslash{}xi\_i\$.\ As\ \$k\ \textgreater{}\ 0\$\ and\ \$\textbackslash{}xi\_i\ \textbackslash{}geq\ 0\$,\ it\ follows\ that\ \$g(X\_i)\ \textgreater{}\ g(X\_\{j(i)\})\$,\ hence\ creating\ a\ concordant\ ranking\textbackslash{}footnote\{Note\ this\ ranking\ has\ the\ interpretation}higher
rank equals lower risk'.\} which is the opposite to the between
observations \(i\) (ranked higher) and \(j(i)\); illustrating why this
optimisation results in a ranking model.

This choice of comparing observations \(i\) and \(j(i)\) (defined below)
stems from a few years of research in an attempt to optimise the
algorithm with respect to both speed and predictive performance. In the
original formulation, RANKSVMC\textasciitilde{}\cite{VanBelle2007}, the
model ranks all possible pairs of observations. This is clearly
infeasible as it increases the problem to a \(\mathcal{O}(qn^2/2)\)
runtime where \(q\) is the proportion of non-censored observations out
of a total sample size \(n\)\textasciitilde{}\cite{VanBelle2008}. The
problem was reduced by taking a nearest neighbours approach and only
considering the \(k\)th closest
observations\textasciitilde{}\cite{VanBelle2008}. Simulation experiments
determined that the single nearest neighbour was sufficient, thus
arriving at \(j(i)\), the observation with the largest observed survival
time smaller than \(T_i\), \[
j(i) := \operatornamewithlimits{argmax}_{j \in 1,...n} \{T_j : T_j < T_i\}
\]

This requires that the first observation is taken to be an event, even
if it is actually censored. In practice, sorting observations by
survival time then greatly speeds up the model
run-time\textasciitilde{}\cite{pkgsurvivalsvm}. The RANKSVMC and
SSVM-RANK are implemented in
\textbf{survivalsvm}\textasciitilde{}\cite{pkgsurvivalsvm} and referred
to as \texttt{vanbelle1\textquotesingle{}\ and}vanbelle2' respectively.

The hybrid model is repeated below with the ranking components in blue,
the regression components in red, and the common components in black,
clearly highlighting the composite nature of the model.

\[
\begin{aligned}
& \min_{\beta, \beta_0, \xi, \xi', \xi^*} \frac{1}{2}\|\beta\|^2 + \textcolor{blue}{C\sum_{i =1}^n \xi_i} + \textcolor{red}{\mu \sum^n_{i=1}(\xi_i' + \xi_i^*)} \\
& \textrm{s.t.}
\begin{dcases}
& \textcolor{blue}{g(X_i) - g(X_{j(i)}) \geq T_i - T_{j(i)} - \xi_i} \\
& \textcolor{red}{\Delta_i(g(X_i) - T_i) \leq \xi^*_i} \\
& \textcolor{red}{T_i - g(X_i) \leq \xi'_i} \\
& \textcolor{blue}{\xi_i}, \textcolor{red}{\xi_i', \xi_i^*} \geq 0, \quad \forall i = 1,...,n \\
\end{dcases}
\end{aligned}
\]

and predictions are made with,

\[
\hat{g}(X^*) = \sum^n_{i=1} \textcolor{blue}{\alpha_i(K(X_i, X^*) - K(X_{j(i)}, X^*))} + \textcolor{red}{\alpha^*_i K(X_i, X^*) - \Delta_i\alpha_i'K(X_i, X^*)} + \beta_0
\]

The regularizer hyper-parameters \(C\) and \(\mu\) now have a clear
interpretation. \(C\) is the penalty associated with the regression
method and \(\mu\) is the penalty associated with the ranking method. By
always fitting the hybrid models and tuning these two parameters, there
is never a requirement to separately fit the regression or ranking
methods as these would be automatically identified as superior in the
tuning procedure. Moreover, the hybrid model retains the
interpretability of the regression method and predictions can be
interpreted as survival times. The hybrid method is implemented in
\textbf{survivalsvm} as `hybrid'. By Van Belle's own simulation studies,
these models do not outperform the Cox PH with respect to Harrell's C.

\newpage
\paragraph{SSVR-MRL}

Not all SSVMs can be considered a variant of the SSVM-Hybrid, though all
prominent and commonly utilised suggestions do seem to have this
formulation. One other algorithm of note is termed here the
`SSVM-MRL'\textasciitilde{}\cite{Goli2016a, Goli2016b}, which is a
regression SSVM. The algorithm is identical to SVCR with one additional
constraint. \textbackslash\textbackslash{}
\textbf{SSVR-MRL}\label{mod:ssvrmrl}\textbackslash{} \[
\begin{aligned}
& \min_{\beta, \beta_0, \xi, \xi^*,\xi'} \frac{1}{2}\|\beta\|^2 + C\sum^n_{i=1} (\xi_i + \xi_i^*) + C^*\sum^n_{i=1} \xi_i' \\
& \textrm{s.t.}
\begin{dcases}
& T_i - g(X_i) \leq \xi_i \\
& \Delta_i(g(X_i) - T_i) \leq \xi_i^* \\
& (1 - \Delta_i)(g(X_i) - T_i - MRL(T_i|\hat{S})) \leq \xi_i' \\
& \xi_i, \xi_i^*, \xi_i' \geq 0 \\
& \forall i = 1,...,n
\end{dcases}
\end{aligned}
\]

where \(MRL(T_i|\hat{S})\) is the `mean residual lifetime'
function\textasciitilde{}\cite{Klein2003} \[
MRL(\tau|\hat{S}) = \frac{\int^\infty_\tau \hat{S}(u) du}{\hat{S}(\tau)}
\] which is the area under the estimated survival curve (say by Kaplan
Meier), \(\hat{S}\), from point \(\tau\), weighted by the probability of
being alive at point \(\tau\). This is interpreted as the expected
remaining lifetime from point \(\tau\). On setting \(C^* = 0\) and
removing associated constraint three, this reduces exactly to the SVCR
and similarly if there's no censoring then the standard regression
setting is recovered. Unlike other strategies, no new hyper-parameters
are introduced and Kaplan-Meier estimation should not noticeably impact
run-time. There is no evidence of this model being used in practice, nor
of any off-shelf implementation. Theoretically, the hybrid model could
be expanded to include this extra penalty term and constraint (discussed
below).

\subsection{Novel Adaptations}

Based on the above survey, one novel adaptation is proposed to merge the
SSVM-Hybrid with SSVR-MRL. This is a simple addition in which one extra
constraint (and associated penalty and slack parameter) is added in
order to control for right-censored observations. The SSVM-Hybrid
becomes, \textbackslash\textbackslash{} \[
\begin{aligned}
& \min_{\beta, \beta_0, \xi, \xi', \xi'', \xi^*} \frac{1}{2}\|\beta\|^2 + \textcolor{blue}{C\sum_{i =1}^n \xi_i} + \textcolor{red}{\mu \sum^n_{i=1}(\xi_i' + \xi_i^*)} +
\textcolor{magenta}{\gamma\sum^n_{i=1} \xi_i''} \\
& \textrm{s.t.}
\begin{dcases}
& \textcolor{blue}{g(X_i) - g(X_{j(i)}) \geq T_i - T_{j(i)} - \xi_i} \\
& \textcolor{magenta}{(1 - \Delta_i)(g(X_i) - T_i - MRL(T_i|\hat{S})) \leq \xi_i''} \\
& \textcolor{red}{\Delta_i(g(X_i) - T_i) \leq \xi^*_i} \\
& \textcolor{red}{T_i - g(X_i) \leq \xi'_i} \\
& \textcolor{blue}{\xi_i}, \textcolor{red}{\xi_i', \xi_i^*}, \textcolor{magenta}{\xi_i''} \geq 0, \quad \forall i = 1,...,n \\
\end{dcases}
\end{aligned}
\]

Where the ranking (blue) and regression (red) components are unchanged
but the additional MRL (magenta) constraint is added for censored
observations. One additional parameter should not impact upon fitting
time or overfitting too greatly, though this should be tested on large
datasets. As with the combination of hybrid and ranking models, the
additional constraint can be automatically `tuned out' of the model, or
just manually removed, by setting \(\gamma = 0\).

\subsection{Conclusions}

Several SSVMs have been proposed for survival analysis. These can
generally be categorised into
\texttt{regression\textquotesingle{}\ models\ that\ adapt\ SVMs\ to\ account\ for\ censoring\ and\ predict\ a\ survival\ time,}ranking'
models that predict a relative ranking in order to optimise measures of
discrimination, and `hybrid' models that optimise measures of
discrimination but make survival time predictions. Other SSVMs that lie
outside of these groupings are not able to solve the survival task
(e.g.\textasciitilde{}\cite{Shiao2013}). Other SVM-type approaches could
be considered, including relevance vector machines and import vector
machines, however less work has been developed in these areas and
further consideration is beyond the scope of this thesis.

The models that have received the most attention are SVCR, SSVM-Rank,
and SSVM-Hybrid; the first two are special cases of SSVM-Hybrid. Judging
if SSVM-Hybrid (and by extension SVCR and SSVM-Rank) is APT is not
straightforward. On the one hand it could be considered transparent as
SVMs have been studied for decades and the literature for SSVMs,
especially from Van Belle, is extensive. On the other hand, the
predictions from SSVM-Hybrid should be interpretable as survival times
but first hand experience indicates that this is not the case (though
this may be due to implementation), which calls into question whether
the interpretation they claim to have is actually correct. For
accessibility, there appears to be only one implementation of SSVMs in
\textsf{R}\textasciitilde{}\cite{pkgsurvivalsvm}, and also only one in
Python\textasciitilde{}\cite{pkgsksurvival}, which may be due to SSVMs
being difficult to implement, even when several optimisation solvers
exist off-shelf. Finally, there is no evidence that SSVMs outperform the
Cox PH or baseline models and moreover they often perform
worse\textasciitilde{}\cite{pkgsurvivalsvm, VanBelle2011b}, which is
also seen in \ref{chap:bench}. Yet one cannot dismiss SSVMs outright as
they often require extensive tuning to perform well, even in
classification settings, and no benchmark experiment has yet to emerge
for testing SSVMs with the required
set-up.\footnote{Though one is in progress as a result of the work in \ref{chap:bench}.}
Therefore SSVMs may not be APT for now but future developments will be
worth paying attention to.

\bookmarksetup{startatroot}

\hypertarget{boosting-methods}{%
\chapter{Boosting Methods}\label{boosting-methods}}

\section{Gradient Boosting Machines}
\label{sec:surv_ml_models_boost}

\subsection{Gradient Boosting Machines for Regression}
\label{sec:surv_ml_models_boost_regr}

Boosting is a machine learning strategy that can be applied to any model
class. Similarly to random forests, boosting is an
\texttt{ensemble\textquotesingle{}\ method\ that\ creates\ a\ model\ from\ a}committee'
of learners. The committee is formed of
\texttt{weak\textquotesingle{}\ learners\ that\ make\ poor\ predictions\ individually,\ which\ creates\ a}slow
learning' approach (as opposed to `greedy') that requires many
iterations for a model to be a good fit to the data. Boosting models are
similar to random forests in that both make predictions from a large
committee of learners. However the two differ in how this committee is
combined to a prediction. In random forest algorithms, each decision
tree is grown independently and their predictions are combined by a
simple mean calculation. In contrast, weak learners in a boosting model
are fit sequentially and predictions are made by a linear combination of
predictions from each learner. With respect to transparency, it is
simpler to inspect 100 trees in a random forest, than it is to inspect
100 weak learners in a boosted model, though both are considered
black-box models.

The best known boosting algorithm is likely
AdaBoost\textasciitilde{}\cite{Freund1996}, which is more generally a
Forward Stagewise Additive Model (FSAM) with an exponential
loss\textasciitilde{}\cite{Hastie2001}. Today, the most widely used
boosting model is the Gradient Boosting Machine
(GBM)\textasciitilde{}\cite{Friedman2001}.

\paragraph{Training a GBM}

Pseudo-code for training a componentwise GBM is presented in
\ref{alg:surv_gbm}. The term `componentwise' is explained fully below,
only this variation of GBM is presented as it is the most common in
implementation\textasciitilde{}\cite{pkggbm, pkgmboost}. Line 1: the
initial function is initialized as
\(g_0 = 0\);\footnote{Some algorithms may instead initialize $g_0$ by finding the value that minimises the given loss function, however setting $g_0 = 0$ appears to be the most common practice for componentwise GBMs.}
Line 2: iterate over boosting steps \(m = 1,...,M\) and; Line 3:
randomly sample the training data, \(\mathcal{D}_0\), to a smaller
sample, \(\mathcal{D}_0^*\), this may be ignored if \(\phi = 1\); Line
4: for all training observations in the reduced dataset,
\(i \in \{i:X_i \in \mathcal{D}_0^*\}\), compute the negative gradient,
\(r_{im}\), of the differentiable loss function, \(L\), with respect to
predictions from the previous iteration, \(g_{m-1}(X_i)\); Line 5: fit
one weak learner for each feature, \(j = 1,...,p\), in the training
data, where the feature, \(X_{;j}\), is the single covariate and
\(r_{im}\) are the labels; Line 6: select the optimal weak learner as
the one that minimises the squared error between the prediction and the
true gradient; Line 7: update the fitted model by adding the optimal
weak learner with a shrinkage penalty, \(\nu\); Line 9: return the model
updated in the final iteration as the fitted GBM.

\begin{algorithm}[H]
\caption{Training a componentwise Gradient Boosting Machine. \\
\textbf{Input} Training data, $\mathcal{D}_0= \{(X_1,Y_1),...,(X_n,Y_n)\}$, where $(X_i,Y_i) \stackrel{i.i.d.}\sim(X,Y)$. Differentiable loss, $L$. Hyper-parameters: sampling fraction, $\phi \in (0,1]$; step-size, $\nu \in  (0,1]$; number of iterations, $M \in \mathbb{R}_{>0}$. \\
\textbf{Output} Boosted model, $\hat{g}$.}\label{alg:surv_gbm}
\begin{algorithmic}[1]
\State Initialize $g_0 \gets 0$
\For{$m = 1,...,M$}
\State $\mathcal{D}_0^* \gets $ Randomly sample $\mathcal{D}_0$ w.p. $\phi$
\State $r_{im} \gets -[\frac{\partial L(y_i, g_{m-1}(X_i))}{\partial g_{m-1}(X_i)}], i \in \{i: X_i \in \mathcal{D}_0^*\}$
\State Fit $p$ weak learners, $w_j$ to $(X_i, r_{im}), j = 1,..,p$
\State $j^* \gets \operatornamewithlimits{argmin}_{j = 1,..,p} \sum_{i \in \{i: X_i \in \mathcal{D}_0^*\}}
(r_{im} - w_j(X_i))^2$
\State $g_m \gets g_{m-1} + \nu w_{j^*}$
\EndFor
\State $\hat{g}\gets g_M$
\Return $\hat{g}$
\end{algorithmic}
\end{algorithm}

\paragraph{Predicting with a GBM}

In general, predictions from a trained GBM are simple to compute as the
fitted model (and all individual weak learners) take the same inputs,
which are passed sequentially to each of the weak learners. In
\ref{alg:surv_gbm}, the fitted GBM is a single model, which is a linear
combination of weak learners. Instead one could think of the returned
model as a collection of the optimal weak learners, i.e.~let
\(w_{m;j^*}\) be the optimal weak learner from iteration \(m\) and let
the fitted GBM (Line 9 \ref{alg:surv_gbm}) be
\(\hat{g}:= \{w_{m;j^*}\}^M_{m=1}\).\footnote{This formulation is computationally and mathematically identical to the formulation in \ref{alg:surv_gbm} and is practically more convenient for implementation, indeed this is the implementation in \textbf{mboost}~\cite{pkgmboost}. Despite this, the formulation in \ref{alg:surv_gbm} is common in the literature, which often conflates model training and predicting.}
With this formulation, making predictions from the GBM can be
demonstrated simply in \ref{alg:surv_gbm_pred}.

\begin{algorithm}[H]
\caption{Predicting from a Gradient Boosting Machine. \\
\textbf{Input} Fitted GBM, $\hat{g}:= \{w_{m;j^*}\}^M_{m=1}$, trained with step-size $\nu$. Testing data $X^* \sim \mathcal{X}$. \\
\textbf{Output} Prediction, $\hat{Y}\sim \mathcal{Y}$.}\label{alg:surv_gbm_pred}
\begin{algorithmic}[1]
\State Initialize $\hat{Y}= 0$
\For{$m = 1,...,M$}
\State $\hat{Y}\gets \hat{Y}+ \nu w_{m;j^*}(X^*)$
\EndFor
\Return $\hat{Y}$
\end{algorithmic}
\end{algorithm}

The biggest advantages of boosting are firstly relatively few
hyper-parameters, which all have a meaningful and intuitive
interpretation, and secondly its modular nature means that, like random
forests, relatively few parts need to be updated to derive a novel
model. First the model components will be discussed and then the
hyper-parameters. Once this has been established, deriving survival
variants can be simply presented.

\subsubsection{Losses and Learners}

\paragraph{Losses}

Building a GBM requires selection of the loss to minimise, \(L\),
selection of weak learners, \(w_j\), and a method to compare the weak
learners to the loss gradient. The only constraint in selecting a loss,
\(L\), is that it must be differentiable w.r.t.
\(g(X)\)\textasciitilde{}\cite{Hastie2001}. Of course a sensible loss
should be chosen (a classification loss should not be used for
regression) and different choices of losses will optimise different
tasks. \(L_2\)-losses have been demonstrated to be effective for
regression boosting, especially with high-dimensional
data\textasciitilde{}\cite{Buhlmann2003}; this is referred to as
\(L_2\)-boosting.

\paragraph{Weak Learners}

\ref{alg:surv_gbm} is specifically a \emph{componentwise}
GBM\textasciitilde{}\cite{Buhlmann2003}, which means that each of the
\(p\) weak learners is fit on a single covariate from the data. This
method simplifies selecting the possible choices for the weak learners
to selecting the class of weak learner (below). Additionally,
componentwise GBMs provide a natural and interpretable feature selection
method as selecting the optimal learner (\ref{alg:surv_gbm}, line 6)
corresponds to selecting the feature that minimises the chosen loss in
iteration \(m\).

Only three weak, or `base', learner classes are commonly used in
componentwise GBMs\textasciitilde{}\cite{pkgmboost, Wang2010}. These are
linear least squares\textasciitilde{}\cite{Friedman2001}, smoothing
splines\textasciitilde{}\cite{Buhlmann2003}, and decision
stumps\textasciitilde{}\cite{Buhlmann2003, Friedman2001}. Let \(L\) be a
loss with negative gradient for observation \(i\) in the \(m\)th
iteration, \(r_{im}\), and let \(\mathcal{D}_0\) be the usual training
data. For linear least squares, an individual weak learner is fit
by\textasciitilde{}\cite{Friedman2001,Wang2010}, \[
w_j(\mathcal{D}_0) = X_{;j}\frac{\sum^n_{i=1} X_{ij}r_{im}}{\sum^n_{i=1} (X_{ij})^2}
\] For smoothing splines, usually cubic splines are implemented, these
fit weak learners as the minimisers of the
equation\textasciitilde{}\cite{Buhlmann2003}, \[
w_j := \operatornamewithlimits{argmin}_{g \in \mathcal{G}} \frac{1}{n} \sum^{n}_{i = 1} (r_{im} - g(X_{ij}))^2 + \lambda \int (g''(u))^2 du
\] where \(g''\) is the second derivative of \(g\), \(\mathcal{G}\) is
the set of functions, \textbackslash{}
\(\mathcal{G}:= \{g: g \text{ is twice continuously differentiable and } \int (g''(x))^2 dx < \infty\}\),
and \(\lambda\) is a hyper-parameter usually chosen so that the number
of degrees of freedom, df, is small, with df \(\approx 4\)
suggested\textasciitilde{}\cite{Buhlmann2003, Schmid2008a, Wang2010}.

Finally for decision stumps (\ref{fig:surv_stump}), a decision tree,
\(w_j\), is grown (\ref{alg:dt_fit}) on \((X_{;j}, r_m)\) to depth one
(equivalently to two terminal nodes) for each of the \(j = 1,...,p\)
covariates\textasciitilde{}\cite{Friedman2001}.

\subsubsection{Hyper-Parameters}

The hyper-parameters in \ref{alg:surv_gbm} are the `step-size', \(\nu\),
the sampling fraction, \(\phi\), and the number of iterations, \(M\).

\paragraph{Number of iterations, $M$}

The number of iterations is often claimed to be the most important
hyper-parameter in GBMs and it has been demonstrated that as the number
of iterations increases, so too does the model performance (with respect
to a given loss on test data) up to a certain point of
overfitting\textasciitilde{}\cite{Buhlmann2006, Hastie2001, Schmid2008a}.
This is an intuitive result as the foundation of boosting rests on the
idea that weak learners can slowly be combined to form a single powerful
model. This is especially true in componentwise GBMs as time is required
to learn which features are important. Finding the optimal value of
\(M\) is critical as a value too small will result in poor predictions,
whilst a value too large will result in model overfitting. Two primary
methods have been suggested for finding the optimal value of \(M\). The
first is to find the \(M \in \mathbb{N}_{> 0}\) that minimises a given
measure based on the AIC\textasciitilde{}\cite{Akaike1974}, the second
is the `usual' empirical selection by nested cross-validation. In
practice the latter method is usually employed.

\paragraph{Step-size, $\nu$}

The step-size parameter (\ref{alg:surv_gbm}, line 7), \(\nu\), is a
shrinkage parameter that controls the contribution of each weak learner
at each iteration. Several studies have demonstrated that GBMs perform
better when shrinkage is applied and a value of \(\nu = 0.1\) is often
suggested\textasciitilde{}\cite{Buhlmann2007, Hastie2001, Friedman2001, Lee2018, Schmid2008a}.
The optimal values of \(\nu\) and \(M\) depend on each other, such that
smaller values of \(\nu\) require larger values of \(M\), and vice
versa. This is intuitive as smaller \(\nu\) results in a slower learning
algorithm and therefore more iterations are required to fit the model.
Accurately selecting the \(M\) parameter is generally considered to be
of more importance, and therefore a value of \(\nu\) is often chosen
heuristically (e.g.~the common value of \(0.1\)) and then \(M\) is tuned
by cross-validation and/or early-stopping.

\paragraph{Sampling Fraction, $\phi$}

Motivated by the success of bagging in random forests, stochastic
gradient boosting\textasciitilde{}\cite{Friedman1999} randomly samples
the data in each iteration. It appears that subsampling performs best
when also combined with shrinkage\textasciitilde{}\cite{Hastie2001} and
as with the other hyper-parameters, selection of \(\phi\) is usually
performed by nested cross-validation.

\subsection{Gradient Boosting Machines for Survival Analysis}
\label{sec:surv_ml_models_boost_surv}

In a componentwise GBM framework, adapting boosting to survival analysis
requires only selecting a sensible choice of loss function \(L\).
Therefore fitting and predicting algorithms for componentwise survival
GBMs are not discussed as these are fully described in algorithms
\ref{alg:surv_gbm} and \ref{alg:surv_gbm_pred} respectively. However,
some GBMs in this section are not componentwise and therefore require
some more detailed consideration. Interestingly, unlike other machine
learning algorithms that historically ignored survival analysis, early
GBM papers considered boosting in a survival
context\textasciitilde{}\cite{Ridgeway1999}; though there appears to be
a decade gap before further considerations were made in the survival
setting. After that period, several developments by Binder, Schmid, and
Hothorn, adapted componentwise GBMs to a framework suitable for survival
analysis. Their developments are covered exhaustively in the R packages
\textbf{gbm}\textasciitilde{}\cite{pkggbm} and
\textbf{mboost}\textasciitilde{}\cite{pkgmboost}. This survey continues
with the predict type taxonomy.

\subsubsection{Cox Survival Models}

All survival GBMs make ranking predictions and none are able to directly
predict survival distributions. However, the GBMs discussed in this
section all have natural compositions to distributions as they are
modelled in the semi-parametric proportional hazards framework
\ref{sec:car_pipelines_distr}. The models discussed in the next section
can also be composed to distributions though the choice of composition
is less clear and therefore they are listed as pure
\texttt{ranking\textquotesingle{}\ models.\ \textbackslash{}\textbackslash{}\textbackslash{}\textbackslash{}\ \textbackslash{}textbf\{GBM-COX\}\textbackslash{}label\{mod:gdcox\}\textbackslash{}label\{mod:gbmcox\}\textbackslash{}\textbackslash{}\ The}GBM-COX'
aims to predict the distribution of data following the PH assumption by
estimating the coefficients of a Cox model in a boosting
framework\textasciitilde{}\cite{Ridgeway1999}. The model attempts to
predict \(\hat{g}(X^*) = \hat{\eta} := X^*\hat{\beta}\), by minimising a
suitable loss function. As the model assumes a PH specification, the
natural loss to optimise is the Cox partial
likelihood\textasciitilde{}\cite{Cox1972, Cox1975}, more specifically to
minimise the negative partial log-likelihood, \(-l\), where

\[
l(\beta) = \sum^n_{i=1} \Delta_i \Big[\eta_i \ - \ \log\Big(\sum^n_{j \in \mathcal{R}_{t_i}} \exp(\eta_i)\Big)\Big]
\label{eq:surv_logpartial}
\] where \(\mathcal{R}_{t_i}\) is the set of patients at risk at time
\(t_i\) and \(\eta_i = X_i\beta\). The gradient of \(-l(\beta)\) at
iteration \(m\) is \[
r_{im} := \Delta_i - \sum^n_{j=1} \Delta_j \frac{\mathbb{I}(T_i \geq T_j) \exp(g_{m-1}(X_i))}{\sum_{k \in \mathcal{R}_{t_j}} \exp(g_{m-1}(X_k))}
\label{eq:surv_partialgrad}
\] where \(g_{m-1}(X_i) = X_i\beta_{m-1}\).

\ref{alg:surv_gbm} now follows with the loss
\(L := -l(\beta)\).\footnote{Early implementations and publications of the GBM algorithm~\cite{Friedman1999, Friedman2001} included an additional step to the algorithm in which a step size is estimated by line search. More recent research has determined that this additional step is unneccesary~\cite{Buhlmann2007} and the line search method does not appear to be used in practice.}

The GBM-COX is implemented in
\textbf{mboost}\textasciitilde{}\cite{pkgmboost} and has been
demonstrated to perform well even when the data violates the PH
assumption\textasciitilde{}\cite{Johnson2011}. Despite being a
black-box, GBMs are well-understood and individual weak learners are
highly interpretable, thus making GBMs highly transparent. Several
well-established software packages implement GBM-COX and those that do
not tend to be very flexible with respect to custom implementations.
GBM-COX is therefore considered an APT survival model.
\textbackslash\textbackslash{}
\noindent \textbf{CoxBoost}\label{mod:coxboost}\textbackslash{} The
CoxBoost algorithm boosts the Cox PH by optimising the penalized
partial-log likelihood; additionally the algorithm allows for mandatory
(or `forced') covariates\textasciitilde{}\cite{Binder2008}. In medical
domains the inclusion of mandatory covariates may be essential, either
for model interpretability, or due to prior expert knowledge. This is
not a feature usually supported by boosting. CoxBoost deviates from
\ref{alg:surv_gbm} by instead using an offset-based approach for
generalized linear models\textasciitilde{}\cite{Tutz2007}. This model
has a non-componentwise and componentwise framework but only the latter
is implemented by the authors\textasciitilde{}\cite{pkgcoxboost} and
discussed here. Let \(\mathcal{I}_{mand}\) be the indices of the
mandatory covariates to be included in all iterations, \(m = 1,...,M\),
then for an iteration \(m\) the indices to consider for fitting are the
set \[
 I_m = \{\{1\} \cup \mathcal{I}_{mand},...,\{p\} \cup \mathcal{I}_{mand}\} / \{\{j\} \cup \mathcal{I}_{mand} : j \in \mathcal{I}_{mand}\}
\] i.e.~in each iteration the algorithm fits a weak learner on the
mandatory covariates and one additional (non-mandatory) covariate (hence
still being componentwise).

In addition, a penalty matrix \(\mathbf{P} \in \mathbb{R}^{p \times p}\)
is considered such that \(P_{ii} > 0\) implies that covariate \(i\) is
penalized and \(P_{ii} = 0\) means no penalization. In practice this is
usually a diagonal matrix\textasciitilde{}\cite{Binder2008} and by
setting \(P_{ii} = 0, i \in I_{mand}\) and
\(P_{ii} > 0, i \not\in I_{mand}\), only optional (non-mandatory)
covariates are penalized. The penalty matrix can be allowed to vary with
each iteration, which allows for a highly flexible approach, however in
implementation a simpler approach is to either select a single penalty
to be applied in each iteration step or to have a single penalty
matrix\textasciitilde{}\cite{pkgcoxboost}.

At the \(m\)th iteration and the \(k\)th set of indices to consider
(\(k = 1,...,p\)), the loss to optimize is the penalized partial-log
likelihood given by \[
\begin{split}
&l_{pen}(\gamma_{mk}) = \sum^n_{i=1} \Delta_i \Big[\eta_{i,m-1} + X_{i,\mathcal{I}_{mk}}\gamma^T_{mk}\Big] - \\
&\quad\Delta_i\log\Big(\sum^n_{j = 1} \mathbb{I}(T_j \leq T_i) \exp(\eta_{i,{m-1}} + X_{i, \mathcal{I}_{mk}}\gamma^T_{mk}\Big) - \lambda\gamma_{mk}\mathbf{P}_{mk}\gamma^T_{mk}
\end{split}
\]

where \(\eta_{i,m} = X_i\beta_m\), \(\gamma_{mk}\) are the coefficients
corresponding to the covariates in \(\mathcal{I}_{mk}\) which is the
possible set of candidates for a subset of total candidates
\(k = 1,...,p\), \(\mathbf{P}_{mk}\) is the penalty matrix, and
\(\lambda\) is a penalty hyper-parameter to be tuned or
selected.\footnote{On notation, note that $\mathbf{P}_{ij}$ refers to the penalty matrix in the $i$th iteration for the $j$th set of indices, whereas $P_{ij}$ is the $(i,j)$th element in the matrix $\mathbf{P}$.}
\textbackslash\textbackslash{} In each iteration, all potential
candidate sets (the union of mandatory covariates and one other
covariate) are updated by \[
\hat{\gamma}_{mk} = \mathbf{I}^{-1}_{pen}(0)U(0)
\] where \(U(\gamma) = \partial l / \partial \gamma (\gamma)\) and
\(\mathbf{I}^{-1}_{pen} = \partial^2 l/\partial\gamma\partial\gamma^T (\gamma + \lambda\mathbf{P}_{mk})\)
are the first and second derivatives of the unpenalized
partial-log-likelihood. The optimal set is then found as \[
k^* := \operatornamewithlimits{argmax}_k l_{pen}(\gamma_{mk})
\] and the estimated coefficients are updated with \[
\hat{\beta}_m = \hat{\beta}_{m-1} + \gamma_{mk^*}, \quad k^* \in \mathcal{I}_{mk}
\] The step size, \(\nu\), is then one, but this could potentially be
altered. \textbackslash\textbackslash{} The algorithm deviates from
\ref{alg:surv_gbm} as \(l_{pen}\) is directly optimised and not its
gradient, additionally model coefficients are iteratively updated
instead of a more general model form. The algorithm is implemented in
\textbf{CoxBoost}\textasciitilde{}\cite{pkgcoxboost}. Experiments
suggest that including the `correct' mandatory covariates may increase
predictive performance\textasciitilde{}\cite{Binder2008}. CoxBoost is
less accessible than other boosting methods as it requires a unique
boosting algorithm, as such only one off-shelf implementation appears to
exist and even this implementation has been removed from CRAN as of
2020-11-11. CoxBoost is also less transparent as the underlying
algorithm is more complex, though is well-explained by the
authors\textasciitilde{}\cite{Binder2008}. There is good indication that
CoxBoost is performant, which is seen in \ref{chap:bench}. In a
non-medical domain, where performance may be the most important metric,
then perhaps CoxBoost can be recommended as a powerful model. However,
when sensitive predictions are required, CoxBoost is currently not APT.
Further papers studying the model and more off-shelf implementations
could change this in the future.

\subsubsection{Ranking Survival Models}

The ranking survival models in this section are all unified as they make
predictions of the linear predictor,
\(\hat{g}(X^*) = X^*\hat{\beta}\).\footnote{This is commonly referred to as a `linear predictor' as it directly relates to the boosted linear model (e.g. Cox PH), however it is more accurately a `prognostic index' as the final prediction is not the true linear predictor.}
\textbackslash\textbackslash{}
\textbf{GBM-AFT}\label{mod:gbmaft}\textbackslash{} Schmid and Hothorn
(2008)\textasciitilde{}\cite{Schmid2008b} published a GBM for
accelerated failure time models in response to PH-boosted models that
may not be suitable for non-PH data. Their model fits into the GBM
framework by assuming a fully-parametric AFT and simultaneously
estimating the linear predictor, \(\hat{g}(X_i) =\hat{\eta}\), and the
scale parameter, \(\hat{\sigma}\), controlling the amount of noise in
the distribution. The (fully-parametric) AFT is defined by \[
\log Y = \eta + \sigma W
\] where \(W\) is a random variable independent of the covariates that
follows a given distribution and controls the noise in the model. By
assuming a distribution on \(W\), a distribution is assumed for the full
parametric model. The full likelihood, \(\mathcal{L}\), is given by \[
\mathcal{L}(\mathcal{D}_0|\mu, \sigma, W) = \prod^n_{i=1} \Big[\frac{1}{\sigma} f_W\Big(\frac{\log(T_i) - \mu}{\sigma}\Big)\Big]^{\Delta_i}\Big[S_W\Big(\frac{\log(T_i) - \mu}{\sigma}\Big)\Big]^{(1-\Delta_i)}
\label{eq:surv_aft_like}
\] where \(f_W, S_W\) is the pdf and survival function of \(W\) for a
given distribution. By setting \(\mu := g(X_i)\), \(\sigma\) is then
rescaled according to known results depending on the
distribution\textasciitilde{}\cite{Klein2003}. The gradient of the
negative log-likelihood, \(-l\), is minimised in the \(m\)th iteration
where \[
\begin{split}
l(\mathcal{D}_0|\hat{g}, \hat{\sigma},W) = \sum^n_{i=1} \Delta_i\Big[- \log\sigma + \log f_W\Big(\frac{\log(T_i) - \hat{g}_{m-1}(X_i)}{\hat{\sigma}_{m-1}}\Big)\Big] + \\
(1-\Delta_i)\Big[\log S_W\Big(\frac{\log(T_i) - \hat{g}_{m-1}(X_i)}{\hat{\sigma}_{m-1}}\Big)\Big]
\end{split}
\] where \(\hat{g}_{m-1}, \hat{\sigma}_{m-1}\) are the location-scale
parameters estimated in the previous iteration. Note this key difference
to other GBM methods in which two estimates are made in each iteration
step. In order to allow for this, \ref{alg:surv_gbm} is run as normal
but in addition, after updating \(\hat{g}_m\), one then updates
\(\hat{\sigma}_m\) as \[
\hat{\sigma}_m := \operatornamewithlimits{argmin}_\sigma -l(\mathcal{D}_0|g_m,\sigma, W)
\] \(\sigma_0\) is initialized at the start of the algorithm with
\(\sigma_0 = 1\) suggested\textasciitilde{}\cite{Schmid2008b}.
\textbackslash\textbackslash{} This algorithm provides a ranking
prediction without enforcing an often-unrealistic PH assumption on the
data. This model is implemented in \textbf{mboost} and \textbf{xgboost}.
Experiments indicate that this may outperform the Cox
PH\textasciitilde{}\cite{Schmid2008b}. Moreover the model has the same
transparency and accessibility as the GBM-COX and is therefore also
considered APT. \textbackslash\textbackslash{}
\textbf{GBM-GEH}\label{mod:gbmgeh}\textbackslash{} The concordance index
is likely the most popular measure of discrimination, this in part due
to the fact that it makes little-to-no assumptions about the data
\ref{sec:eval_crank}. A less common measure is the Gehan loss, motivated
by the semi-parametric AFT. Johnson and Long proposed the GBM with Gehan
loss, here termed GBM-GEH, to optimise separation within an AFT
framework\textasciitilde{}\cite{Johnson2011}.

The semi-parametric AFT is defined by the linear model, \[
\log Y = \eta + \epsilon
\] for some error term, \(\epsilon\).

The D-dimensional Gehan loss to minimise is given by, \[
G_D(\mathcal{D}_0, \hat{g}) = -\frac{1}{n^2} \sum^n_{i=1}\sum^n_{j=1} \Delta_i (\hat{e}_i - \hat{e}_j)\mathbb{I}(\hat{e}_i \leq \hat{e}_j)
\] where \(\hat{e}_i = \log T_i - \hat{g}(X_i)\). The negative gradient
of the loss is, \[
r_{im} := \frac{\sum^n_{j=1} \Delta_j \mathbb{I}(\hat{e}_{m-1,i} \geq \hat{e}_{m-1,j}) -\Delta_i\mathbb{I}(\hat{e}_{m-1,i} \leq \hat{e}_{m-1,j})}{n}
\] where \(\hat{e}_{m-1,i} = \log T_i - \hat{g}_{m-1}(X_i)\).
\textbackslash\textbackslash{} \ref{alg:surv_gbm} then follows naturally
substituting the loss and gradient above. The algorithm is implemented
in \textbf{mboost}. Simulation studies on the performance of the model
are inconclusive\textasciitilde{}\cite{Johnson2011} however the results
in \ref{chap:bench} indicate strong predictive performance. Therefore
this can tentatively be considered APT but further benchmark experiments
would be preferred. \textbackslash\textbackslash{}
\textbf{GBM-BUJAR}\label{mod:gbmbujar}\textbackslash{} GBM-BUJAR is
another boosted semi-parametric AFT. However the algorithm introduced by
Wang and Wang (2010)\textasciitilde{}\cite{Wang2010} uses Buckley-James
imputation and minimisation. This algorithm is almost identical to a
regression GBM (i.e.~using squared loss or similar for \(L\)), except
with one additional step to iteratively impute censored survival times.
Assuming a semi-parametric AFT model, the GBM-BUJAR algorithm
iteratively updates imputed outcomes with the Buckley-James
estimator\textasciitilde{}\cite{Buckley1979}, \[
T^*_{m, i} := \hat{g}_{m-1}(X_i) + e_{m-1, i}\Delta_i + (1-\Delta_i)\Big[\hat{S}_{KM}(e_{m-1, i})^{-1}\sum_{e_{m-1, j} > e_{m-1, i}} e_{m-1, j}\Delta_j \hat{p}_{KM}(e_{m-1, j})\Big]
\] where \(\hat{g}_{m-1}(X_i) = \hat{\eta}_{m-1}\), and
\(\hat{S}_{KM}, \hat{p}_{KM}\) are Kaplan-Meier estimates of the
survival and probability mass functions respectively fit on some
training data, and \(e_{m-1,i} := \log(T_i) - g_{m-1}(X_i)\). Once
\(T^*_{m, i}\) has been updated, \ref{alg:surv_gbm} continues from with
least squares as with any regression model.
\textbackslash\textbackslash{} GBM-BUJAR is implemented in
\textbf{bujar}\textasciitilde{}\cite{pkgbujar} though without a
separated fit/predict interface, its accessibility is therefore limited.
There is no evidence of wide usage of this algorithm nor simulation
studies demonstrating its predictive ability. Finally, there are many
known problems with semi-parametric AFT models and the Buckey-James
procedure\textasciitilde{}\cite{Wei1992}, hence GBM-BUJAR is also not
transparent. \textbackslash\textbackslash{}
\textbf{GBM-UNO}\label{mod:gbmuno}\textbackslash{} Instead of optimising
models based on a given model form, Chen
\textit{et al.}\textasciitilde{}\cite{Chen2013} studied direct
optimisation of discrimination by Harrell's C whereas Mayr and
Schmid\textasciitilde{}\cite{Mayr2014} focused instead on Uno's C. Only
an implementation of the Uno's C method could be found, this is
therefore discussed here and termed `GBM-UNO'.
\textbackslash\textbackslash{} The GBM-UNO attempts to predict
\(\hat{g}(X^*) := \hat{\eta}\) by optimising Uno's C
\ref{sec:eval_crank_disc_conc}, \[
C_U(\hat{g}, \mathcal{D}_0) = \frac{\sum_{i \neq j}\Delta_i\{\hat{G}_{KM}(T_i)\}^{-2}\mathbb{I}(T_i < T_j)\mathbb{I}(\hat{g}(X_i) >\hat{g}(X_j))}{\sum_{i \neq j}\Delta_i\{\hat{G}_{KM}(T_i)\}^{-2}\mathbb{I}(T_i < T_j)}
\]

The GBM algorithm requires that the chosen loss, here \(C_U\), be
differentiable w.r.t. \(\hat{g}(X)\), which is not the case here due to
the indicator term, \(\mathbb{I}(\hat{g}(X_i) > \hat{g}(X_j))\).
Therefore a smoothed version is instead considered where the indicator
is approximated by the sigmoid function\textasciitilde{}\cite{Ma2006},

\[
K(u|\sigma) = (1 + \exp(-u/\sigma))^{-1}
\]

where \(\sigma\) is a hyper-parameter controlling the smoothness of the
approximation. The measure to optimise is then,

\[
C_{USmooth}(\mathcal{D}_0|\sigma) = \sum_{i \neq j} \frac{k_{ij}}{1 + \exp\big[(\hat{g}(X_j) - \hat{g}(X_i))/\sigma)\big]}
\label{eq:surv_gbm_cus}
\]

with

\[
k_{ij} = \frac{\Delta_i (\hat{G}_{KM}(T_i))^{-2}\mathbb{I}(T_i < T_j)}{\sum^n_{i \neq j} \Delta_i(\hat{G}_{KM}(T_i))^{-2}\mathbb{I}(T_i < T_j)}
\]

The negative gradient at iteration \(m\) for observation \(i\) can then
be found,

\[
r_{im} := - \sum^n_{j = 1} k_{ij} \frac{-\exp(\frac{\hat{g}_{m-1}(X_j) - \hat{g}_{m-1}(X_i)}{\sigma})}{\sigma(1 + \exp(\frac{\hat{g}_{m-1}(X_j) - \hat{g}_{m-1}(X_i)}{\sigma}))}
\label{eq:surv_gbm_cus_grad}
\]

\ref{alg:surv_gbm} can then be followed exactly by substituting this
loss and gradient; this is implemented in \textbf{mboost}. One
disadvantage of GBM-UNO is that C-index boosting is more insensitive to
overfitting than other methods\textasciitilde{}\cite{Mayr2016},
therefore stability selection\textasciitilde{}\cite{Meinshausen2010} can
be considered for variable selection; this is possible with
\textbf{mboost}. Despite directly optimising discrimination, simulation
studies do not indicate that this model has better separation than other
boosted or lasso models\textasciitilde{}\cite{Mayr2014}. GBM-UNO has the
same accessibility, transparency, and performance \ref{chap:bench} as
previous APT boosting models and is therefore also considered APT.

\subsection{Novel Adaptations}

A clear theme emerging throughout this survey is a historical focus on
predicting survival time or ranking, with less interest in direct
optimisation of distributional predictions, which may be due to less
off-shelf software for the task. Optimisation of a distribution is
possible by considering a scoring rule \ref{sec:eval_distr} as the GBM
loss. The integrated Graf score (IGS) is discussed below but others are
also possible.

The Integrated Graf Score (IGS) is given by, \[
L_{IGS}(t,\delta,\hat{S}|\tau^*) = \int^{\tau^*}_0 \frac{\hat{S}(\tau)^2 \mathbb{I}(t \leq \tau, \delta=1)}{\hat{G}_{KM}(t)} + \frac{\hat{F}(\tau)^2 \mathbb{I}(t > \tau)}{\hat{G}_{KM}(\tau)} \ d\tau
\] where \(\tau^*\) is a threshold cut-off but in this case it is
assumed \(\tau^* = \max\{T_i: i = 1,..,n\}\). Differentiating with
respect to \(\hat{S}(\tau)\), the negative gradient in the \(m\)th
iteration is given by \[
r_{im} := \int^{\tau^*}_0 2\hat{f}(\tau)\Big[\frac{\hat{F}(\tau)\mathbb{I}(t_i > \tau)}{\hat{G}_{KM}(\tau)} - \frac{\hat{S}(\tau)\mathbb{I}(t_i \leq \tau, \delta_i = 1)}{\hat{G}_{KM}(t_i)}\Big] \ d\tau
\label{eq:surv_igsgrad}
\] where \(\hat{f}\) is the estimated probability density function.

\ref{alg:surv_gbm} follows with these equations. The package
\textbf{mboost} can be utilised to test these equations as a `custom
family'.

\subsection{Conclusions}

Componentwise gradient boosting machines are a highly flexible and
powerful machine learning tool. They have proven particularly useful in
survival analysis as minimal adjustments are required to make use of
off-shelf software. The flexibility of the algorithm allows all the
models above to be implemented in very few \textsf{R} (and other
programming languages) packages.

Boosting is a method that often relies on intensive computing power and
therefore dedicated packages, such as
\textbf{xgboost}\textasciitilde{}\cite{pkgxgboost}, exist to push
CPU/GPUs to their limits in order to optimise predictive performance.
This can be viewed as a strong advantage though one should be careful
not to focus too much on predictive performance to the detriment of
accessibility and transparency.

Boosting, especially with tree learners, is viewed as a black-box model
that is increasingly difficult to interpret as the number of iterations
increase. However, there are several methods for increasing
interpretability, such as variable importance and
SHAPs\textasciitilde{}\cite{Lundberg2017}. There is also evidence that
boosting models can outperform the Cox
PH\textasciitilde{}\cite{Schmid2008b} (not something all ML models can
claim) and in general survival GBMs are considered APT.

\bookmarksetup{startatroot}

\hypertarget{neural-networks}{%
\chapter{Neural Networks}\label{neural-networks}}

\section{Neural Networks}
\label{sec:surv_ml_models_nn}

Before starting the survey on neural networks, first a comment about
their transparency and accessibility. Neural networks are infamously
difficult to interpret and train, with some calling building and
training neural networks an
\texttt{art\textquotesingle{}\textasciitilde{}\textbackslash{}cite\{Hastie2001\}.\ As\ discussed\ in\ the\ introduction\ of\ this\ thesis,\ whilst\ neural\ networks\ are\ not\ transparent\ with\ respect\ to\ their\ predictions,\ they\ are\ transparent\ with\ respect\ to\ implementation.\ In\ fact\ the\ simplest\ form\ of\ neural\ network,\ as\ seen\ below,\ is\ no\ more\ complex\ than\ a\ simple\ linear\ model.\ With\ regard\ to\ accessibility,\ whilst\ it\ is\ true\ that\ defining\ a\ custom\ neural\ network\ architecture\ is\ complex\ and\ highly\ subjective,\ established\ models\ are\ implemented\ with\ a\ default\ architecture\ and\ are\ therefore\ accessible}off-shelf'.

\subsection{Neural Networks for Regression}

(Artificial) Neural networks (ANNs) are a class of model that fall
within the greater paradigm of \emph{deep learning}. The simplest form
of ANN, a feed-forward single-hidden-layer network, is a relatively
simple algorithm that relies on linear models, basic activation
functions, and simple derivatives. A short introduction to feed-forward
regression ANNs is provided to motivate the survival models. This
focuses on single-hidden-layer models and increasing this to multiple
hidden layers follows relatively simply. \textbackslash\textbackslash{}
The single hidden-layer network is defined through three equations
\begin{align}
& Z_m = \sigma(\alpha_{0m} + \alpha^T_mX_i), \quad m = 1,...,M \\
& T = \beta_{0k} + \beta_k^TZ, \quad k = 1,..,K \\
& g_k(X_i) = \phi_k(T)
\end{align}

where \((X_1,...,X_n) \stackrel{i.i.d.}\sim X\) are the usual training
data, \(\alpha_{0m}, \beta_0\) are bias parameters, and
\(\theta = \{\alpha_m, \beta\}\) (\(m = 1,..,,M\)) are model weights
where \(M\) is the number of hidden units. \(K\) is the number of
classes in the output, which for regression is usually \(K = 1\). The
function \(\phi\) is a \texttt{link\textquotesingle{}\ or}activation
function', which transforms the predictions in order to provide an
outcome of the correct return type; usually in regression,
\(\phi(x) = x\). \(\sigma\) is the
\texttt{activation\ function\textquotesingle{},\ which\ transforms\ outputs\ from\ each\ layer.\ The\ \$\textbackslash{}alpha\_m\$\ parameters\ are\ often\ referred\ to\ as}activations'.
Different activation functions may be used in each layer or the same
used throughout, the choice is down to expert knowledge. Common
activation functions seen in this section include the sigmoid function,
\[
\sigma(v) = (1 + \exp(-v))^{-1}
\] tanh function, \[
\sigma(v) = \frac{\exp(v) - \exp(-v)}{\exp(v) + \exp(-v)}
\label{eq:surv_tanh}
\] and ReLU\textasciitilde{}\cite{Nair2010} \[
\sigma(v) = \max(0, v)
\label{eq:surv_relu}
\]

A single-hidden-layer model can also be expressed in a single equation,
which highlights the relative simplicity of what may appear a complex
algorithm.

\[
g_k(X_i) = \sigma_0(\beta_{k0} + \sum_{h=1}^H (\beta_{kh}\sigma_h (\beta_{h0} + \sum^M_{m=1} \beta_{hm}X_{i;m}))
\label{eq:surv_nnet}
\] where \(H\) are the number of hidden units, \(\beta\) are the model
weights, \(\sigma_h\) is the activation function in unit \(h\), also
\(\sigma_0\) is the output unit activation, and \(X_{i;m}\) is the
\(i\)th observation features in the \(m\)th hidden unit.

An example feed-forward single-hidden-layer regression ANN is displayed
in \ref{fig:surv_ann}. This model has 10 input units, 13 hidden units,
and one output unit; two bias parameters are fit. The model is described
as `feed-forward' as there are no cycles in the node and information is
passed forward from the input nodes (left) to the output node (right).

\begin{figure}

{\centering \includegraphics{./images/neuralnetworks/ann.png}

}

\caption{\label{fig-surv-ann}Single-hidden-layer artificial neural
network with 13 hidden units fit on the
\texttt{mtcars}\textasciitilde{}\cite{datamtcars} dataset using the
\textbf{nnet}\textasciitilde{}\cite{pkgnnet} package, and
\textbf{gamlss.add}\textasciitilde{}\cite{pkggamlssadd} for plotting.
Left column are input variables, I1-I10, second column are 13 hidden
units, H1-H13, right column is single output variable, O1. B1 and B2 are
bias parameters.}

\end{figure}

\paragraph{Back-Propagation}

The model weights, \(\theta\), in this section are commonly fit by
`back-propagation' although this method is often considered inefficient
compared to more recent advances. A brief pseudo-algorithm for the
process is provided below.

Let \(L\) be a chosen loss function for model fitting, let
\(\theta = (\alpha, \beta)\) be model weights, and let
\(J \in \mathbb{N}_{> 0}\) be the number of iterations to train the
model over. Then the back-propagation method is given by,

\begin{itemize}
\tightlist
\item
  \textbf{For} \(j = 1,...,J\): \emph{{[}{]} \emph{Forward Pass}
  }{[}i.{]} Fix weights \(\theta^{(j-1)}\). \emph{{[}ii.{]} Compute
  predictions \(\hat{Y} := \hat{g}^{(j)}_k(X_i|\theta^{(j-1)})\) with
  \ref{eq:surv_nnet}. }{[}{]} \emph{Backward Pass} \emph{{[}iii.{]}
  Calculate the gradients of the loss \(L(\hat{Y}|\mathcal{D}_0)\).
  }{[}{]} \emph{Update} *{[}iv.{]} Update \(\alpha^{(r)}, \beta^{(r)}\)
  with gradient descent.
\item
  \textbf{End For}
\end{itemize}

In regression, a common choice for \(L\) is the squared loss, \[
L(\hat{g}, \theta|\mathcal{D}_0) = \sum_{i=1}^n (Y_i - \hat{g}(X_i|\theta))^2
\] which may help illustrate how the training outcome,
\((Y_1,...,Y_n) \stackrel{i.i.d.}\sim Y\), is utilised for model
fitting.

\paragraph{Making Predictions}

Once the model is fitted, predictions for new data follow by passing the
testing data as inputs to the model with fitted weights,

\[
g_k(X^*) = \sigma_0(\hat{\beta}_{k0} + \sum_{h=1}^H (\hat{\beta}_{kh}\sigma_h (\hat{\beta}_{h0} + \sum^M_{m=1} \hat{\beta}_{hm}X^*_m))
\]

\paragraph{Hyper-Parameters}

In practice, a regularization parameter, \(\lambda\), is usually added
to the loss function in order to help avoid overfitting. This parameter
has the effect of shrinking model weights towards zero and hence in the
context of ANNs regularization is usually referred to as `weight decay'.
The value of \(\lambda\) is one of three important hyper-parameters in
all ANNs, the other two are: the range of values to simulate initial
weights from, and the number of hidden units, \(M\).

The range of values for initial weights is usually not tuned but instead
a consistent range is specified and the neural network is trained
multiple times to account for randomness in initialization.

The regularization parameter and number of hidden units, \(M\), depend
on each other and have a similar relationship to the learning rate and
number of iterations in the GBMs \ref{sec:surv_ml_models_boost}. Like
the GBMs, it is simplest to set a high number of hidden units and then
tune the regularization
parameter\textasciitilde{}\cite{Bishop2006, Hastie2001}. Determining how
many hidden layers to include, and how to connect them, is informed by
expert knowledge and well beyond the scope of this thesis; decades of
research has been required to derive sensible new configurations.

\paragraph{Training Batches}

ANNs can either be trained using complete data, in batches, or online.
This decision is usually data-driven and will affect the maximum number
of iterations used to train the algorithm; as such this will also often
be chosen by expert-knowledge and not empirical methods such as
cross-validation.

\paragraph{Neural Terminology}

Neural network terminology often reflects the structures of the brain.
Therefore ANN units are referred to as nodes or neurons and sometimes
the connections between neurons are referred to as synapses. Neurons are
said to be \texttt{fired\textquotesingle{}\ if\ they\ are}activated'.
The simplest example of activating a neuron is with the Heaviside
activation function with a threshold of \(0\):
\(\sigma(v) = \mathbb{I}(v \geq 0)\). Then a node is activated and
passes its output to the next layer if its value is positive, otherwise
it contributes no value to the next layer.

\subsection{Neural Networks for Survival Analysis}

Surveying neural networks is a non-trivial task as there has been a long
history in machine learning of publishing very specific data-driven
neural networks with limited applications; this is also true in survival
analysis. This does mean however that where limited developments for
survival were made in other machine learning classes, ANN survival
adaptations have been around for several decades. A review in 2000 by
Schwarzer \textit{et al.}{} surveyed 43 ANNs for diagnosis and prognosis
published in the first half of the 90s, however only up to ten of these
are specifically for survival
data.\footnote{Schwarzer conflates the prognosis and survival task, therefore it is not clear if all 10 of these are for time-to-event data (at least five definitely are).}
Of those, Schwarzer \textit{et al.}{} deemed three to be `na"ive
applications to survival data', and recommended for future research
models developed by Liest\o l
\textit{et al.}\textsubscript{(1994)}\cite{Liestol1994}, Faraggi and
Simon (1995)\textasciitilde{}\cite{Faraggi1995}, and Biganzoli
\textit{et al.}\textsubscript{(1998)}\cite{Biganzoli1998}.

This survey will not be as comprehensive as the 2000 survey, and nor has
any survey since, although there have been several ANN
reviews\textasciitilde{}\cite{Ripley2001, Huang2020a, Ohno-Machado1996, Yang2010, Zhu2020}.
ANNs are considered to be a black-box model, with interpretability
decreasing steeply as the number of hidden layers and nodes increases.
In terms of accessibility there have been relatively few open-source
packages developed for survival ANNs; where these are available the
focus has historically been in Python, with no
\textsf{R} implementations. The new
\textbf{survivalmodels}\textasciitilde{}\cite{pkgsurvivalmodels}
package,\footnote{Created in order to run the experiments in \ref{chap:bench}.}
implements these Python models via
\textbf{reticulate}\textasciitilde{}\cite{pkgreticulate}. No recurrent
neural netwoks are included in this survey though the survival models
SRN\textasciitilde{}\cite{Oh2018} and
RNN-Surv\textasciitilde{}\cite{Giunchiglia2018} are acknowledged.
\textbackslash\textbackslash{} This survey is made slightly more
difficult as neural networks are often proposed for many different
tasks, which are not necessarily clearly advertised in a paper's title
or abstract. For example, many papers claim to use neural networks for
survival analysis and make comparisons to Cox models, whereas the task
tends to be death at a particular (usually 5-year) time-point
(classification)\textasciitilde{}\cite{Han2018, Lundin1999, Ripley2001, Ripley1998, Seker2002},
which is often not made clear until mid-way through the paper. Reviews
and surveys have also conflated these different tasks, for example a
very recent review concluded superior performance of ANNs over Cox
models, when in fact this is only in
classification\textasciitilde{}\cite{Huang2020} (RM2)
\{sec:car\_reduxstrats\_mistakes\}. To clarify, this form of
classification task does fall into the general \emph{field} of survival
analysis, but not the survival \emph{task} \ref{box:task_surv}.
Therefore this is not a comment on the classification task but a reason
for omitting these models from this survey.

Using ANNs for feature selection (often in gene expression data) and
computer vision is also very common in survival analysis, and indeed it
is in this area that most success has been
seen\textasciitilde{}\cite{Bello2019, Chen2014, Cui2020, Lao2017, McKinney2020, Rietschel2018, Seker2002a, Zhang2020, Zhu2016},
but these are again beyond the scope of this survey.
\textbackslash\textbackslash{} The key difference between neural
networks is in their output layer, required data transformations, the
model prediction, and the loss function used to fit the model. Therefore
the following are discussed for each of the surveyed models: the loss
function for training, \(L\), the model prediction type, \(\hat{g}\),
and any required data transformation. Notation is continued from the
previous surveys with the addition of \(\theta\) denoting model weights
(which will be different for each model).

\subsubsection{Probabilistic Survival Models}

Unlike other classes of machine learning models, the focus in ANNs has
been on probabilistic models. The vast majority make these predictions
via reduction to binary classification \ref{sec:car_reduxes_r7}. Whilst
almost all of these networks implicitly reduce the problem to
classification, most are not transparent in exactly how they do so and
none provide clear or detailed interface points in implementation
allowing for control over this reduction. Most importantly, the majority
of these models do not detail how valid survival predictions are derived
from the binary
setting,\footnote{One could assume they use procedures such as those described in Tutz and Schmid (2016)~\cite{Tutz2016} but there is rarely transparent writing to confirm this.}
which is not just a theoretical problem as some implementations, such as
the Logistic-Hazard model in
\textbf{pycox}\textasciitilde{}\cite{pkgpycox}, have been observed to
make survival predictions outside the range \([0,1]\). This is not a
statement about the performance of models in this section but a remark
about the lack of transparency across all probabilistic ANNs.
\textbackslash\textbackslash{} Many of these algorithms use an approach
that formulate the Cox PH as a non-linear model and minimise the partial
likelihood. These are referred to as
\texttt{neural-Cox\textquotesingle{}\ models\ and\ the\ earliest\ appears\ to\ have\ been\ developed\ by\ Faraggi\ and\ Simon\textasciitilde{}\textbackslash{}cite\{Faraggi1995\}.\ All\ these\ models\ are\ technically\ composites\ that\ first\ predict\ a\ ranking,\ however\ they\ assume\ a\ PH\ form\ and\ in\ implementation\ they\ all\ appear\ to\ return\ a\ probabilistic\ prediction.\ \textbackslash{}\textbackslash{}\textbackslash{}\textbackslash{}\ \textbackslash{}textbf\{ANN-COX\}\textbackslash{}label\{mod:anncox\}\textbackslash{}\textbackslash{}\ Faraggi\ and\ Simon\textasciitilde{}\textbackslash{}cite\{Faraggi1995\}\ proposed\ a\ non-linear\ PH\ model\ \$\$\ h(\textbackslash{}tau\textbar{}X\_i,\textbackslash{}theta)\ =\ h\_0(\textbackslash{}tau)\textbackslash{}exp(\textbackslash{}phi(X\_i\textbackslash{}beta))\ \textbackslash{}label\{eq:surv\_farsim\}\ \$\$\ where\ \$\textbackslash{}phi\$\ is\ the\ sigmoid\ function\ and\ \$\textbackslash{}theta\ =\ \textbackslash{}\{\textbackslash{}beta\textbackslash{}\}\$\ are\ model\ weights.\ This\ model,}ANN-COX',
estimates the prediction functional,
\(\hat{g}(X^*) = \phi(X^*\hat{\beta})\). The model is trained with the
partial-likelihood function \[
L(\hat{g}, \theta|\mathcal{D}_0) = \prod_{i = 1}^n \frac{\exp(\sum^M_{m=1} \alpha_m\hat{g}_m(X^*))}{\sum_{j \in \mathcal{R}_{t_i}} \exp(\sum^M_{m=1} \alpha_m\hat{g}_m(X^*))}
\] where \(\mathcal{R}_{t_i}\) is the risk group alive at \(t_i\); \(M\)
is the number of hidden units;
\(\hat{g}_m(X^*) = (1 + \exp(-X^*\hat{\beta}_m))^{-1}\); and
\(\theta = \{\beta, \alpha\}\) are model weights.

The authors proposed a single hidden layer network, trained using
back-propagation and weight optimisation with Newton-Raphson. This
architecture did not outerperform a Cox
PH\textasciitilde{}\cite{Faraggi1995}. Further adjustments including
(now standard) pre-processing and hyper-parameter tuning did not improve
the model performance\textasciitilde{}\cite{Mariani1997}. Further
independent studies demonstrated worse performance than the Cox
model\textasciitilde{}\cite{Faraggi1995, Xiang2000}.
\textbackslash\textbackslash{}
\textbf{COX-NNET}\label{mod:coxnnet}\textbackslash{}
COX-NNET\textasciitilde{}\cite{Ching2018a} updates the ANN-COX by
instead maximising the regularized partial log-likelihood \[
L(\hat{g}, \theta|\mathcal{D}_0, \lambda) = \sum^n_{i=1} \Delta_i \Big[\hat{g}(X_i) \ - \ \log\Big(\sum_{j \in \mathcal{R}_{t_i}} \exp(\hat{g}(X_j))\Big)\Big] + \lambda(\|\beta\|_2 + \|w\|_2)
\] with weights \(\theta = (\beta, w)\) and where
\(\hat{g}(X_i) = \sigma(wX_i + b)^T\beta\) for bias term \(b\), and
activation function \(\sigma\); \(\sigma\) is chosen to be the tanh
function (\ref{eq:surv_tanh}). In addition to weight decay,
dropout\textasciitilde{}\cite{Srivastava2014} is employed to prevent
overfitting. Dropout can be thought of as a similar concept to the
variable selection in random forests, as each node is randomly
deactivated with probability \(p\), where \(p\) is a hyper-parameter to
be tuned.

Independent simulation studies suggest that COX-NNET does not outperform
the Cox PH\textasciitilde{}\cite{Gensheimer2019}.
\textbackslash\textbackslash{}
\textbf{DeepSurv}\label{mod:deepsurv}\textbackslash{}
DeepSurv\textasciitilde{}\cite{Katzman2018} extends these models to deep
learning with multiple hidden layers. The chosen error function is the
average negative log-partial-likelihood with weight decay \[
L(\hat{g}, \theta|\mathcal{D}_0, \lambda) = -\frac{1}{n^*} \sum_{i = 1}^n \Delta_i \Big[ \Big(\hat{g}(X_i) - \log \sum_{j \in \mathcal{R}_{t_i})} \exp(\hat{g}(X_j)\Big)\Big] + \lambda\|\theta\|^2_2
\] where \(n^* := \sum^n_{i=1} \mathbb{I}(\Delta_i = 1)\) is the number
of uncensored observations and \(\hat{g}(X_i) = \phi(X_i|\theta)\) is
the same prediction object as the ANN-COX. State-of-the-art methods are
used for data pre-processing and model training. The model architecture
uses a combination of fully-connected and dropout layers. Benchmark
experiments by the authors indicate that DeepSurv can outperform the Cox
PH in ranking tasks\textasciitilde{}\cite{Katzman2016, Katzman2018}
although independent experiments do not confirm
this\textasciitilde{}\cite{Zhao2020}.

\newpage

\noindent\textbf{Cox-Time}\label{mod:coxtime}\textbackslash{} Kvamme
\textit{et al.}{}\textasciitilde{}\cite{Kvamme2019a} build on these
models by allowing time-varying effects. The loss function to minimise,
with regularization, is given by \[
L(\hat{g}, \theta|\mathcal{D}_0, \lambda) = \frac{1}{n} \sum_{i:\Delta_i = 1} \log\Big(\sum_{j \in \mathcal{R}_{t_i}} \exp[\hat{g}(X_j,T_i) - \hat{g}(X_i, T_i)]\Big) + \lambda \sum_{i:\Delta_i=1}\sum_{j \in \mathcal{R}_{t_i}} |\hat{g}(X_j,T_i)|
\] where \(\hat{g}= \hat{g}_1,...,\hat{g}_n\) is the same non-linear
predictor but with a time interaction and \(\lambda\) is the
regularization parameter. The model is trained with stochastic gradient
descent and the risk set, \(\mathcal{R}_{t_i}\), in the equation above
is instead reduced to batches, as opposed to the complete dataset. ReLU
activations\textasciitilde{}\cite{Nair2010} and dropout are employed in
training. Benchmark experiments indicate good performance of Cox-Time,
though no formal statistical comparisons are provided and hence no
comment about general performance can be made.
\textbackslash\textbackslash{}
\textbf{ANN-CDP}\label{mod:anncdp}\textbackslash{} One of the earliest
ANNs that was noted by Schwarzer
\textit{et al.}\textasciitilde{}\cite{Schwarzer2000} was developed by
Liest\o l \textit{et al.}\textasciitilde{}\cite{Liestol1994} and
predicts conditional death probabilities (hence `ANN-CDP'). The model
first partitions the continuous survival times into disjoint intervals
\(\mathcal{I}_k, k = 1,...,m\) such that \(\mathcal{I}_k\) is the
interval \((t_{k-1}, t_k]\). The model then studies the logistic Cox
model (proportional odds)\textasciitilde{}\cite{Cox1972} given by \[
\frac{p_k(\mathbf{x})}{q_k(\mathbf{x})} = \exp(\eta + \theta_k)
\] where \(p_k = 1-q_k\), \(\theta_k = \log(p_k(0)/q_k(0))\) for some
baseline probability of survival, \(q_k(0)\), to be estimated; \(\eta\)
is the usual linear predictor, and
\(q_k = P(T \geq T_k | T \geq T_{k-1})\) is the conditional survival
probability at time \(T_k\) given survival at time \(T_{k-1}\) for
\(k = 1,...,K\) total time intervals. A logistic activation function is
used to predict \(\hat{g}(X^*) = \phi(\eta + \theta_k)\), which provides
an estimate for \(\hat{p}_k\).

The model is trained on discrete censoring indicators \(D_{ki}\) such
that \(D_{ki} = 1\) if individual \(i\) dies in interval
\(\mathcal{I}_k\) and \(0\) otherwise. Then with \(K\) output nodes and
maximum likelihood estimation to find the model parameters,
\(\hat{\eta}\), the final prediction provides an estimate for the
conditional death probabilities \(\hat{p}_k\). The negative
log-likelihood to optimise is given by \[
L(\hat{g}, \theta|\mathcal{D}_0) = \sum^n_{i=1}\sum^{m_i}_{k=1} [D_{ki}\log(\hat{p}_k(X_i)) + (1-D_{ki})\log(\hat{q}_k(X_i))]
\] where \(m_i\) is the number of intervals in which observation \(i\)
is not censored.

Liest\o l \textit{et al.}{} discuss different weighting options and how
they correspond to the PH assumption. In the most generalised case, a
weight-decay type regularization is applied to the model weights given
by \[
\alpha \sum_l \sum_k (w_{kl} - w_{k-1,l})^2
\] where \(w\) are weights, and \(\alpha\) is a hyper-parameter to be
tuned, which can be used alongside standard weight decay. This
corresponds to penalizing deviations from proportionality thus creating
a model with approximate proportionality. The authors also suggest the
possibility of fixing the weights to be equal in some nodes and
different in others; equal weights strictly enforces the proportionality
assumption. Their simulations found that removing the proportionality
assumption completely, or strictly enforcing it, gave inferior results.
Comparing their model to a standard Cox PH resulted in a
\texttt{better\textquotesingle{}\ negative\ log-likelihood,\ however\ this\ is\ not\ a\ precise\ evaluation\ metric\ and\ an\ independent\ simulation\ would\ be\ preferred.\ Finally\ List\textbackslash{}o\ l\ \textbackslash{}etal\{\}\ included\ a\ warning\ \textasciigrave{}\textasciigrave{}The\ flexibility\ is,\ however,\ obtained\ at\ unquestionable\ costs:\ many\ parameters,\ difficult\ interpretation\ of\ the\ parameters\ and\ a\ slow\ numerical\ procedure\textquotesingle{}\textquotesingle{}\textasciitilde{}\textbackslash{}cite\{Liestol1994\}.\ \textbackslash{}\textbackslash{}\textbackslash{}\textbackslash{}\ \textbackslash{}textbf\{PLANN\}\textbackslash{}label\{mod:plann\}\textbackslash{}\textbackslash{}\ Biganzoli\ \textbackslash{}etal\textasciitilde{}(1998)\textasciitilde{}\textbackslash{}cite\{Biganzoli1998\}\ studied\ the\ same\ proportional-odds\ model\ as\ the\ ANN-CDP\textasciitilde{}\textbackslash{}cite\{Liestol1994\}.\ Their\ model\ utilises\ partial\ logistic\ regression\textasciitilde{}\textbackslash{}cite\{Efron1988\}\ with\ added\ hidden\ nodes,\ hence}PLANN'.
Unlike ANN-CDP, PLANN predicts a smoothed hazard function by using
smoothing splines. The continuous time outcome is again discretised into
disjoint intervals \(t_m, m = 1,...,M\). At each time-interval, \(t_m\),
the number of events, \(d_m\), and number of subjects at risk, \(n_m\),
can be used to calculate the discrete hazard
function,\footnote{Derivation of this as a `hazard' estimator follows trivially by comparison to the Nelson-Aalen estimator.}
\[
\label{eq:surv_dischaz}
\hat{h}_m = \frac{d_m}{n_m}, m = 1,...,M
\] This quantity is used as the target to train the neural network. The
survival function is then estimated by the Kaplan-Meier type estimator,
\[
\label{eq:surv_discreteKM}
\hat{S}(\tau) = \prod_{m:t_m \leq \tau} (1 - \hat{h}_m)
\]

The model is fit by employing one of the more `usual' survival reduction
strategies in which an observation's survival time is treated as a
covariate in the model\textasciitilde{}\cite{Tutz2016}. As this model
uses discrete time, the survival time is discretised into one of the
\(M\) intervals. This approach removes the proportional odds constraint
as interaction effects between time and covariates can be modelled (as
time-updated covariates). Again the model makes predictions at a given
time \(m\), \(\phi(\theta_m + \eta)\), where \(\eta\) is the usual
linear predictor, \(\theta\) is the baseline proportional odds hazard
\(\theta_m = \log(h_m(0)/(1-h_m(0))\). The logistic activation provides
estimates for the discrete hazard, \[
h_m(X_i) = \frac{\exp(\theta_m + \hat{\eta})}{1 + \exp(\theta_m + \hat{\eta})}
\] which is smoothed with cubic splines\textasciitilde{}\cite{Efron1988}
that require tuning.

A cross-entropy error function is used for training \[
L(\hat{h}, \theta|\mathcal{D}_0, a) = - \sum^M_{m = 1} \Big[\hat{h}_m \log \Big(\frac{h_l(X_i, a_l)}{\hat{h}_m}\Big) + (1 - \hat{h}_m) \log \Big(\frac{1 - h_l(X_i, a_l)}{1 - \hat{h}_m}\Big)\Big]n_m
\] where \(h_l(X_i, a_l)\) is the discrete hazard \(h_l\) with smoothing
at mid-points \(a_l\). Weight decay can be applied and the authors
suggest
\(\lambda \approx 0.01-0.1\)\textasciitilde{}\cite{Biganzoli1998},
though they make use of an AIC type criterion instead of
cross-validation.

This model makes smoothed hazard predictions at a given time-point,
\(\tau\), by including \(\tau\) in the input covariates \(X_i\).
Therefore the model first requires transformation of the input data by
replicating all observations and replacing the single survival indicator
\(\Delta_i\), with a time-dependent indicator \(D_{ik}\), the same
approach as in ANN-CDP. Further developments have extended the PLANN to
Bayesian modelling, and for competing
risks\textasciitilde{}\cite{Biganzoli2009}.

No formal comparison is made to simpler model classes. The authors
recommend ANNs primarily for exploration, feature selection, and
understanding underlying patterns in the
data\textasciitilde{}\cite{Biganzoli2009}.
\textbackslash\textbackslash{}
\textbf{Nnet-survival}\label{mod:nnetsurvival}\textbackslash{} Aspects
of the PLANN algorithm have been generalised into discrete-time survival
algorithms in several
papers\textasciitilde{}\cite{Gensheimer2019, Kvamme2019, Mani1999, Street1998}.
Various estimates have been derived for transforming the input data to a
discrete hazard or survival function. Though only one is considered here
as it is the most modern and has a natural interpretation as the `usual'
Kaplan-Meier estimator for the survival function. Others by Street
(1998)\textasciitilde{}\cite{Street1998} and Mani
(1999)\textasciitilde{}\cite{Mani1999} are acknowledged. The discrete
hazard estimator \ref{eq:surv_dischaz}, \(\hat{h}\), is estimated and
these values are used as the targets for the ANN. For the error
function, the mean negative log-likelihood for discrete
time\textasciitilde{}\cite{Kvamme2019} is minimised to estimate
\(\hat{h}\), \[
\begin{split}
L(\hat{h}, \theta|\mathcal{D}_0) = -\frac{1}{n} \sum^n_{i=1}\sum^{k(T_i)}_{j=1} (\mathbb{I}(T_i = \tau_j, \Delta_i = 1) \log[\hat{h}_i(\tau_j)] \ + \\
 (1-\mathbb{I}(T_i = \tau_j, \Delta_i = 1))\log(1 - \hat{h}_i(\tau_j)))
\end{split}
\] where \(k(T_i)\) is the time-interval index in which observation
\(i\) dies/is censored, \(\tau_j\) is the \(j\)th discrete
time-interval, and the prediction of \(\hat{h}\) is obtained via \[
\hat{h}(\tau_j|\mathcal{D}_0) = [1 + \exp(-\hat{g}_j(\mathcal{D}_0))]^{-1}
\] where \(\hat{g}_j\) is the \(j\)th output for \(j = 1,...,m\)
discrete time intervals. The number of units in the output layer for
these models corresponds to the number of discrete-time intervals.
Deciding the width of the time-intervals is an additional
hyper-parameter to consider.

Gensheimer and Narasimhan's
\texttt{Nnet-survival\textquotesingle{}\textasciitilde{}\textbackslash{}cite\{Gensheimer2019\}\ has\ two\ different\ implementations.\ The\ first\ assumes\ a\ PH\ form\ and\ predicts\ the\ linear\ predictor\ in\ the\ final\ layer,\ which\ can\ then\ be\ composed\ to\ a\ distribution.\ Their\ second}flexible'
approach instead predicts the log-odds of survival in each node, which
are then converted to a conditional probability of survival,
\(1 - h_j\), in a given interval using the sigmoid activation function.
The full survival function can be derived with \ref{eq:surv_discreteKM}.
The model has been demonstrated not to outperform the Cox PH w.r.t.
Harrell's C or the Graf (Brier)
score\textasciitilde{}\cite{Gensheimer2019}.
\textbackslash\textbackslash{}
\textbf{PC-Hazard}\label{mod:pchazard}\textbackslash{} Kvamme and Borgan
deviate from nnet-survival in their
\texttt{PC-Hazard\textquotesingle{}\textasciitilde{}\textbackslash{}cite\{Kvamme2019\}\ by\ first\ considering\ a\ discrete-time\ approach\ with\ a\ softmax\ activation\ function\ influenced\ by\ multi-class\ classification.\ They\ expand\ upon\ this\ by\ studying\ a\ piecewise\ constant\ hazard\ function\ in\ continuous\ time\ and\ defining\ the\ mean\ negative\ log-likelihood\ as\ \$\$\ L(\textbackslash{}hatg,\ \textbackslash{}theta\textbar{}\textbackslash{}dtrain)\ =\ -\textbackslash{}frac\{1\}\{n\}\ \textbackslash{}sum\^{}n\_\{i=1\}\ \textbackslash{}Big(\textbackslash{}Delta\_i\ X\_i\textbackslash{}log\textbackslash{}tilde\{\textbackslash{}eta\}\_\{k(T\_i)\}\ -\ X\_i\textbackslash{}tilde\{\textbackslash{}eta\}\_\{k(T\_i)\}\textbackslash{}rho(T\_i)\ -\ \textbackslash{}sum\^{}\{k(T\_i)-1\}\_\{j=1\}\ \textbackslash{}tilde\{\textbackslash{}eta\}\_jX\_i\textbackslash{}Big)\ \$\$\ where\ \$k(T\_i)\$\ and\ \$\textbackslash{}tau\_i\$\ is\ the\ same\ as\ defined\ above,\ \$\textbackslash{}rho(t)\ =\ \textbackslash{}frac\{t\ -\ \textbackslash{}tau\_\{k(t)-1\}\}\{\textbackslash{}Delta\textbackslash{}tau\_\{k(t)\}\}\$,\ \$\textbackslash{}Delta\textbackslash{}tau\_j\ =\ \textbackslash{}tau\_j\ -\ \textbackslash{}tau\_\{j-1\}\$,\ and\ \$\textbackslash{}tilde\{\textbackslash{}eta\}\_j\ :=\ \textbackslash{}log(1\ +\ \textbackslash{}exp(\textbackslash{}hatg\_j(X\_i))\$\ where\ again\ \$\textbackslash{}hatg\_j\$\ is\ the\ \$j\$th\ output\ for\ \$j\ =\ 1,...,m\$\ discrete\ time\ intervals.\ Once\ the\ weights\ have\ been\ estimated,\ the\ predicted\ survival\ function\ is\ given\ by\ \$\$\ \textbackslash{}hatS(\textbackslash{}tau,\ X\^{}*\textbar{}\textbackslash{}dtrain)\ =\ \textbackslash{}exp(-X\^{}*\textbackslash{}tilde\{\textbackslash{}eta\}\_\{k(\textbackslash{}tau)\}\textbackslash{}rho(\textbackslash{}tau))\ \textbackslash{}prod\^{}\{k(\textbackslash{}tau)-1\}\_\{j=1\}\ \textbackslash{}exp(-\textbackslash{}tilde\{\textbackslash{}eta\}\_j(X\^{}*))\ \$\$\ Benchmark\ experiments\ indicate\ similar\ performance\ to\ nnet-survival\textasciitilde{}\textbackslash{}cite\{Kvamme2019\},\ an\ unsurprising\ result\ given\ their\ implementations\ are\ identical\ with\ the\ exception\ of\ the\ loss\ function\textasciitilde{}\textbackslash{}cite\{Kvamme2019\},\ which\ is\ also\ similar\ for\ both\ models.\ A\ key\ result\ found\ that\ varying\ values\ for\ interval\ width\ lead\ to\ significant\ differences\ and\ therefore\ should\ be\ carefully\ tuned.\ \textbackslash{}\textbackslash{}\textbackslash{}\textbackslash{}\ \textbackslash{}textbf\{DNNSurv\}\textbackslash{}label\{mod:dnnsurv\}\textbackslash{}\textbackslash{}\ A\ very\ recent\ (pre-print)\ approach\textasciitilde{}\textbackslash{}cite\{Zhao2020\}\ instead\ first\ computes}pseudo-survival
probabilities' and uses these to train a regression ANN with sigmoid
activation and squared error loss. These pseudo-probabilities are
computed using a jackknife-style estimator given by \[
\tilde{S}_{ij}(T_{j+1}, \mathcal{R}_{t_j}) = n_j\hat{S}(T_{j+1}|\mathcal{R}_{t_j}) - (n_j - 1)\hat{S}^{-i}(T_{j+1}|\mathcal{R}_{t_j})
\] where \(\hat{S}\) is the IPCW weighted Kaplan-Meier estimator
(defined below) for risk set \(\mathcal{R}_{t_j}\), \(\hat{S}^{-i}\) is
the Kaplan-Meier estimator for all observations in \(\mathcal{R}_{t_j}\)
excluding observation \(i\), and \(n_j := |\mathcal{R}_{t_j}|\). The
IPCW weighted KM estimate is found via the IPCW Nelson-Aalen estimator,
\[
\hat{H}(\tau|\mathcal{D}_0) = \sum^n_{i=1} \int^\tau_0 \frac{\mathbb{I}(T_i \leq u, \Delta_i = 1)\hat{W}_i(u)}{\sum^n_{j=1} \mathbb{I}(T_j \geq u) \hat{W}_j(u)} \ du
\] where \(\hat{W}_i,\hat{W}_j\) are subject specific IPC weights.

In their simulation studies, they found no improvement over other
proposed neural networks. Arguably the most interesting outcome of their
paper are comparisons of multiple survival ANNs at specific time-points,
evaluated with C-index and Brier score. Their results indicate identical
performance from all models. They also provide further evidence of
neural networks not outperforming a Cox PH when the PH assumption is
valid. However, in their non-PH dataset, DNNSurv appears to outperform
the Cox model (no formal tests are provided). Data is replicated
similarly to previous models except that no special indicator separates
censoring and death, this is assumed to be handled by the IPCW pseudo
probabilities. \textbackslash\textbackslash{}
\%\textbf{RNN-SURV}\label{mod:rnnsurv}\textbackslash{}
\%\textbf{\textcolor{red}{consider deleting this model}}
\%RNN-SURV\textasciitilde{}\cite{Giunchiglia2018} again uses a reduction
to binary classification approach though makes use of recurrent layers
to incorporate the sequential nature of survival data and time-variant
features. The final layer in the model consists of \(K\) nodes, which
correspond with individual survival probability predictions for interval
\(k\), \(\hat{S}(\tau_k|X)\), where \(\tau_k, k = 1,...,K,\) are \(K\)
discrete time-intervals
\(\{(\tau_0, \tau_1],...,(\tau_{K-1}, \tau_K)]\}\). The model assumes
constant hazards within each time interval. These estimates can be
linearly combined to predict a single risk score for each observation,
\(\hat{r}_i = \sum^K_{k=1} \theta_k\hat{S}_i(\tau_k)\) where
\(\theta_k\) are the weights from the final model layer. In order to
accommodate these predictions the data is again first transformed to
consist of vectors of covariates with their corresponding time interval.
The model uses a composite loss built from a linear combination of two
individual losses with weight decay, \%\[
%L(\hatS, t, \delta|\theta, \alpha, \gamma) = \alpha L_1(\hatS, t, \delta|\theta) + \gamma L_2(\hatS, t,\delta|\theta) + \lambda\|\theta\|^2_2
%
\] \%where \(\alpha, \beta, \gamma\) are hyper-parameters to tune,
\(\theta\) are the model weights, and \%\[
%L_1(\hatS, t,\delta| \theta) = -\sum^K_{k=1}\sum_{i \in U_k} [\II(t_i > \tau_k)\log(\hatS_i(\tau_k)) + (1-\II(t_i > \tau_k))\log(1-\hatS_i(\tau_k)]
%\label{eq:surv_rnnsurv_cross}
%
\] \%where
\(U_i = \{i : \delta_i = 1 \cup \delta_i = 0 \cap T_i > \tau_k\}\) is
the set of observations who are either alive, dead, or not-yet-censored.
\(L_1\) can be recognised as a cross-entropy
loss\textasciitilde{}\cite{Graf1999}. \(L_2\) is an upper bound of the
negative C-index\textasciitilde{}\cite{Steck2008}, \%\[
%L_2(\theta) = -\frac{1}{|\calC|}\sum_{(i,j)\in\calC} \Big[1 + \Big(\frac{\log \ \sigma(\hat{r}_j-\hat{r}_i)}{\log \ 2}\Big)\Big]
%
\] \%where \(\mathcal{C}= \{(i,j) : \delta_i = 1 \cap t_i \leq t_j\}\).
The ReLU activation function is used for the feed-forward layers, long
short-term memory (LSTM)\textasciitilde{}\cite{Hochreiter1997} cells in
the recurrent layers, and the sigmoid function in the final layer.
Dropout is again employed. The model demonstrates good sepration ability
w.r.t. Harrell's C and is shown to significantly outperform Cox PH,
RSFs\textasciitilde{}\cite{Ishwaran2008}, and
DeepSurv\textasciitilde{}\cite{Katzman2018}. No experiments are
performed to assess the predictive performance of the predicted survival
distributions. No explicit methodology is provided for enforcing a
decreasing monotonic prediction for the discrete survival distribution,
which is a general problem that is discussed further in
\ref{sec:car_redux}. No off-shelf implementation is available.
\%\textbackslash\textbackslash{}
\textbf{DeepHit}\label{mod:deephit}\textbackslash{}
DeepHit\textasciitilde{}\cite{Lee2018a} was originally built to
accommodate competing risks, but only the non-competing case is
discussed here\textasciitilde{}\cite{Kvamme2019a}. The model builds on
previous approaches by discretising the continuous time outcome, and
makes use of a composite loss. It has the advantage of making no
parametric assumptions and directly predicts the probability of failure
in each time-interval (which again correspond to different terminal
nodes),
i.e.~\(\hat{g}(\tau_k|\mathcal{D}_1) = \hat{P}(T^* = \tau_k|X^*)\) where
again \(\tau_k, k = 1,...,K\) are the distinct time intervals. The
estimated survival function is found with
\(\hat{S}(\tau_K|X^*) = 1 - \sum^K_{k = 1} \hat{g}_i(\tau_k|X^*)\). ReLU
activations were used in all fully connected layers and a softmax
activation in the final layer. The losses in the composite error
function are given by \[
L_1(\hat{g}, \theta|\mathcal{D}_0) = -\sum^N_{i=1} [\Delta_i \log(\hat{g}_i(T_i)) + (1-\Delta_i)\log(\hat{S}_i(T_i))]
\] and \[
L_2(\hat{g}, \theta|\mathcal{D}_0, \sigma) = \sum_{i \neq j} \Delta_i \mathbb{I}(T_i < T_j) \sigma(\hat{S}_i(T_i), \hat{S}_j(T_i))
\] for some convex loss function \(\sigma\) and where
\(\hat{g}_i(t) = \hat{g}(t|X_i)\). Again these can be seen to be a
cross-entropy loss and a ranking loss. Benchmark experiments demonstrate
the model outperforming the Cox PH and
RSFs\textasciitilde{}\cite{Lee2018a} with respect to separation, and an
independent experiment supports these
findings\textasciitilde{}\cite{Kvamme2019a}. However, the same
independent study demonstrated worse performance than a Cox PH w.r.t.
the integrated Brier score\textasciitilde{}\cite{Graf1999}.

\subsubsection{Deterministic Survival Models}

Whilst the vast majority of survival ANNs have focused on probabilistic
predictions (often via ranking), a few have also tackled the
deterministic or
\texttt{hybrid\textquotesingle{}\ problem.\ \textbackslash{}\textbackslash{}\textbackslash{}\textbackslash{}\ \textbackslash{}textbf\{RankDeepSurv\}\textbackslash{}label\{mod:rankdeepsurv\}\textbackslash{}\textbackslash{}\ Jing\ \textbackslash{}etal\textasciitilde{}\textbackslash{}cite\{Jing2019\}\ observed\ the\ past\ two\ decades\ of\ research\ in\ survival\ ANNs\ and\ then\ published\ a\ completely\ novel\ solution,\ RankDeepSurv,\ which\ makes\ predictions\ for\ the\ survival\ time\ \$\textbackslash{}hat\{T\}\ =\ (\textbackslash{}hat\{T\}\_1,...,\textbackslash{}hat\{T\}\_n)\$.\ They\ proposed\ a\ composite\ loss\ function\ \$\$\ L(\textbackslash{}hatT,\ \textbackslash{}theta\textbar{}\textbackslash{}dtrain,\ \textbackslash{}alpha,\textbackslash{}gamma,\textbackslash{}lambda)\ =\ \textbackslash{}alpha\ L\_1(\textbackslash{}hat\{T\},T,\textbackslash{}Delta)\ +\ \textbackslash{}gamma\ L\_2(\textbackslash{}hat\{T\},T,\textbackslash{}Delta)\ +\ \textbackslash{}lambda\textbackslash{}\textbar{}\textbackslash{}theta\textbackslash{}\textbar{}\^{}2\_2\ \$\$\ where\ \$\textbackslash{}theta\$\ are\ the\ model\ weights,\ \$\textbackslash{}alpha,\textbackslash{}gamma\ \textbackslash{}in\ \textbackslash{}PReals\$,\ \$\textbackslash{}lambda\$\ is\ the\ shrinkage\ parameter,\ by\ a\ slight\ abuse\ of\ notation\ \$T\ =\ (T\_1,...,T\_n)\$\ and\ \$\textbackslash{}Delta\ =\ (\textbackslash{}Delta\_1,...,\textbackslash{}Delta\_n)\$,\ and\ \$\$\ L\_1(\textbackslash{}hatT,\ \textbackslash{}theta\textbar{}\textbackslash{}dtrain)\ =\ \textbackslash{}frac\{1\}\{n\}\ \textbackslash{}sum\_\{\textbackslash{}\{i:\ I(i)\ =\ 1\textbackslash{}\}\}\ (\textbackslash{}hat\{T\}\_i\ -\ T\_i)\^{}2;\ \textbackslash{}quad\ I(i)\ =\ \textbackslash{}begin\{cases\}\ 1,\ \&\ \textbackslash{}Delta\_i\ =\ 1\ \textbackslash{}cup\ (\textbackslash{}Delta\_i\ =\ 0\ \textbackslash{}cap\ \textbackslash{}hat\{T\}\_i\ \textbackslash{}leq\ T\_i)\ \textbackslash{}\textbackslash{}\ 0,\ \&\ \textbackslash{}otherw\ \textbackslash{}end\{cases\}\ \$\$\ \$\$\ L\_2(\textbackslash{}hatT,\ \textbackslash{}theta\textbar{}\textbackslash{}dtrain)\ =\ \textbackslash{}frac\{1\}\{n\}\textbackslash{}sum\^{}n\_\{\textbackslash{}\{i,j\ :\ I(i,j)\ =\ 1\textbackslash{}\}\}\ {[}(T\_j\ -\ T\_i)\ -\ (\textbackslash{}hat\{T\}\_j\ -\ \textbackslash{}hat\{T\}\_i){]}\^{}2;\ \textbackslash{}quad\ I(i,j)\ =\ \textbackslash{}begin\{cases\}\ 1,\ \&\ T\_j\ -\ T\_i\ \textgreater{}\ \textbackslash{}hat\{T\}\_j\ -\ \textbackslash{}hat\{T\}\_i\ \textbackslash{}\textbackslash{}\ 0,\ \&\ \textbackslash{}otherw\ \textbackslash{}end\{cases\}\ \$\$\ where\ \$\textbackslash{}hat\{T\}\_i\$\ is\ the\ predicted\ survival\ time\ for\ observation\ \$i\$.\ A\ clear\ contrast\ can\ be\ made\ between\ these\ loss\ functions\ and\ the\ constraints\ used\ in\ SSVM-Hybrid\textasciitilde{}\textbackslash{}cite\{VanBelle2011b\}\ \textbackslash{}ref\{sec:surv\_ml\_models\_svm\_surv\}.\ \$L\_1\$\ is\ the\ squared\ second\ constraint\ in\ \textbackslash{}ref\{eq:surv\_ssvmvb2\}\ and\ \$L\_2\$\ is\ the\ squared\ first\ constraint\ in\ \textbackslash{}ref\{eq:surv\_ssvmvb2\}.\ However\ \$L\_1\$\ in\ RankDeepSurv\ discards\ the\ squared\ error\ difference\ for\ all\ censored\ observations\ when\ the\ prediction\ is\ lower\ than\ the\ observed\ survival\ time;\ which\ is\ problematic\ as\ if\ someone\ is\ censored\ at\ time\ \$T\_i\$\ then\ it\ is\ guaranteed\ that\ their\ true\ survival\ time\ is\ greater\ than\ \$T\_i\$\ (this\ constraint\ may\ be\ more\ sensible\ if\ the\ inequality\ were\ reversed).\ An\ advantage\ to\ this\ loss\ is,\ like\ the\ SSVM-Hybrid,\ it\ enables\ a\ survival\ time\ interpretation\ for\ a\ ranking\ optimised\ model;\ however\ these}survival
times' should be interpreted with care.

The authors propose a model architecture with several fully connected
layers with the ELU\textasciitilde{}\cite{Clevert2015} activation
function and a single dropout layer. Determining the success of this
model is not straightforward. The authors claim superiority of
RankDeepSurv over Cox PH, DeepSurv, and RSFs however this is an unclear
comparison (RM2) \{sec:car\_reduxstrats\_mistakes\} that requires
independent study.

\subsection{Novel Adaptations}
\label{sec:surv_ml_models_nn_nov}

In stark contrast to other model classes, the vast majority of survival
ANNs have focused on optimising probabilistic predictions and not
relative risks. There does not appear to a model that directly optimises
separation via some concordance measure. One simple method could
consider RankDeepSurv\textasciitilde{}\cite{Jing2019} without \(L_1\).
Interestingly, Jing \textit{et al.}\textasciitilde{}\cite{Jing2019}
compare RankDeepSurv to a model using \(L_1\) only but not to a model
using \(L_2\) only, which would be similar to
SSVM-Rank\textasciitilde{}\cite{VanBelle2011b}
\ref{sec:surv_ml_models_svm_surv}. RankDeepSurv also likely suffers from
the same computational problems as
RANKSVMC\textasciitilde{}\cite{VanBelle2007}. However this could be
resolved by employing the same nearest-neighbours
methodology\textasciitilde{}\cite{VanBelle2008} as in SSVM-Rank. A
disadvantage of RankDeepSurv is that the loss does not compare
right-censored observations to possibly-correct predictions. Two
possible methods to resolve this are either to include a hyper-parameter
for `mean time alive from censoring', \(\epsilon\), or an MRL imputation
method, similarly to SSVR-MRL\textasciitilde{}\cite{Goli2016a}
\ref{sec:surv_ml_models_svm_surv}. With these adaptations, \(L_1\) is
given by \[
L_1(\hat{T}, \theta|\mathcal{D}_0, \epsilon) = \frac{1}{n} \sum^n_{i=1} \Delta_i(\hat{T}_i - T_i)^2 + (1-\Delta_i)(\hat{T}_i - T_i - \epsilon_i)^2
\] where either \(\epsilon_i\) are hyper-parameters for tuning (all
could be set equal to prevent overfitting) or \(\epsilon_i = MRL(T_i)\).
\(L_2\) is given by, \[
\begin{split}
&L_2(\hat{T}, \theta|\mathcal{D}_0) = \frac{1}{n}\sum^n_{\{i : I(i) = 1\}} [(T_i - T_{j(i)}) - (\hat{T}_i - \hat{T}_{j(i)})]^2; \\
&I(i) =
\begin{cases}
1, & T_i - T_{j(i)} > \hat{T}_i - \hat{T}_{j(i)} \\
0, & \text{otherwise}
\end{cases}
\end{split}
\] where \(T_{j(i)}\) is the survival time of the nearest non-censored
neighbour with the largest survival time smaller than \(T_i\), the same
definition as given by Van Belle
\textit{et al.}\textasciitilde{}\cite{VanBelle2011b}. The adaptation to
\(L_1\) prevents predictions from being discarded in the loss and
simultaneously increases penalization applied to under-predictions. The
adapted \(L_2\) should also have a faster run-time.

\subsection{Conclusions}

There have been many advances in neural networks for survival analysis.
It is not possible to review all proposed survival neural networks
without diverting too far from the thesis scope. This survey of ANNs
should demonstrate two points: firstly that the vast majority (if not
all) of survival ANNs are reduction models that either find a way around
censoring via imputation or discretisation of time-intervals, or by
focusing on partial likelihoods only; secondly that no survival ANN is
APT. \textbackslash\textbackslash{} Despite ANNs being highly performant
in other areas of supervised learning, there is strong evidence that the
survival ANNs above are inferior to a Cox PH when the data follows the
PH assumption or when variables are linearly
related\textasciitilde{}\cite{Gensheimer2018, Luxhoj1997, Ohno-Machado1997, Puddu2012, Xiang2000, Yang2010, Yasodhara2018, Zhao2020}.
There are not enough experiments to make conclusions in the case when
the data is non-PH. Experiments in \ref{chap:bench} support the finding
that survival ANNs are not performant.

There is evidence that many papers introducing neural networks do not
utilise proper methods of comparison or
evaluation\textasciitilde{}\cite{Kiraly2018d} and in conducting this
survey, these findings are further supported. Many papers made claims of
being `superior' to the Cox model based on unfair comparisons
(RM2)\{sec:car\_reduxstrats\_mistakes\} or miscommunicating (or
misinterpreting) results (e.g.\textasciitilde{}\cite{Fotso2018}). At
this stage, it does not seem possible to make any conclusions about the
effectiveness of neural networks in survival analysis. Moreover, even
the authors of these models have pointed out problems with
transparency\textasciitilde{}\cite{Biganzoli2009, Liestol1994}, which
was further highlighted by Schwarzer
\textit{et al.}\textasciitilde{}\cite{Schwarzer2000}.

Finally, accessibility of neural networks is also problematic. Many
papers do not release their code and instead just state their networks
architecture and available packages. In theory, this is enough to build
the models however this does not guarantee the reproducibility that is
usually expected. For users with a technical background and good coding
ability, many of the models above could be implemented in one of the
neural network packages in \textsf{R}, such as
\textbf{nnet}\textasciitilde{}\cite{pkgnnet} and
\textbf{neuralnet}\textasciitilde{}\cite{pkgneuralnet}; though in
practice the only package that does contain these models,
\textbf{survivalmodels}, does not directly implement the models in
\textsf{R} (which is much slower than Python) but provides a method for
interfacing the Python implementations in
\textbf{pycox}\textasciitilde{}\cite{pkgpycox}.

\bookmarksetup{startatroot}

\hypertarget{evaluation}{%
\chapter{Evaluation}\label{evaluation}}

This chapter studies how to evaluate the predictions arising from the
surveyed models in the previous chapter. `Model evaluation' is as vague
a phrase as `human evaluation'. A human could be evaluated by a series
of exams, physical or neurological tests, aesthetics, etc. Likewise a
model could be evaluated according to how well it fits to training data,
the quality of predictions on new data, the average prediction, and many
more methods. This chapter aims to provide a nuanced approach to
defining, understanding, and examining model evaluation. Evaluation is
defined in further detail in Section~\ref{sec-eval-why} and throughout
this chapter the definition will continue to be refined and specialised
to specific sub-types of evaluation, including discrimination
(Section~\ref{sec-eval-crank}), calibration
(Section~\ref{sec-eval-distr-calib}), and overall predictive performance
(Section~\ref{sec-eval-distr}).

Evaluation is a surprising source of disagreement in the literature with
some arguing that the process can often be ignored completely (Laan,
Polley, and Hubbard 2007; Wolpert 1992). There is a larger divide in
survival analysis as many believe that the primary (possibly only) goal
is risk prediction (Chen et al. 2012; Newson 1983; Pencina, D'Agostino,
and Song 2012) and thus other forms of evaluation are not required.
These strict views can undermine an integral part of the model building
and deployment process, and create more division than necessary. This
thesis advocates for strict implementation of model evaluation as a
critical part of the model building process as well as in continuous
monitoring of deployed models. Without rigorous evaluation, a model
cannot be `trusted' to perform well and could be as useless as making
random guesses for all predictions. This is critical in survival
analysis, which has important applications in healthcare and finance, in
these sectors models that have not been evaluated are potentially
dangerous.

An infamous example of evaluation going wrong is the
\href{https://www.google.org/flutrends/about/}{Google Flu Trends (GFT)
model}\footnote{\url{https://www.google.org/flutrends/about/}}, which
claimed to accurately predict future flu trends but was in fact deemed
by many a complete failure as it significantly overestimated all
predictions, in some cases doubling the true figures (Lazer et al.
2014). The GFT model was never utilised (at least openly) in policy and
as such no lasting harm was created. However it is not hard to imagine
the problems that would be caused by such a model if it was utilised and
trusted during the time of COVID-19. On a more individual level, as
machine learning is increasingly deployed in public sectors, major
decisions for patients could become increasingly automated (or at least
machine-assisted). Patients should expect their models to be as trained
and tested as their doctors.

This chapter attempts to highlight the purpose and need of evaluation in
survival analysis by first giving a high-level overview to evaluation as
a concept, then providing a brief review of commonly-used survival
measures and finally extensive treatment to scoring rules for evaluation
of probabilistic predictions, including novel definitions and proofs for
properness of scoring rules. The term \emph{measure} will be used
throughout this chapter to refer to functions or `metrics' that quantify
some aspect of model evaluation, this should not be confused with a
mathematical measure.

The APT criteria will be utilised to survey these measures. For
transparency and accessibility, these are straightforward to apply to
measures with the same definitions as for models. For predictive
performance this is more complicated as it depends on the model class.
Therefore optimal measure performance definitions will be covered within
each section.

\hypertarget{notation-and-terminology}{%
\subsubsection*{Notation and
Terminology}\label{notation-and-terminology}}

The notation introduced in (\textbf{chap-surv?}) is recapped for use in
this chapter. The generative template is given by
\((X,T,\Delta,Y,C) \ t.v.i. \ \mathcal{X}\times \mathcal{T}\times \{0,1\}\times \mathcal{T}\times \mathcal{T}\)
where \(\mathcal{X}\subseteq \mathbb{R}^p\) and
\(\mathcal{T}\subseteq \mathbb{R}_{\geq 0}\), where \(C,Y\) are
unobservable, \(T := \min\{Y,C\}\), and \(\Delta = \mathbb{I}(Y = T)\).
Specific survival data is given by training data,
\(\mathcal{D}_0= \{(X_1,T_1,\Delta_1),...,(X_n,T_n,\Delta_n)\}\) where
\((X_i,T_i,\Delta_i) \stackrel{i.i.d.}\sim(X,T,\Delta)\), and test data,
\(\mathcal{D}_1= \{(X^*_1,T^*_1,\Delta^*_1),...,(X^*_m,T^*_m,\Delta^*_m)\}\)
where \((X^*_i,T^*_i,\Delta^*_i) \stackrel{i.i.d.}\sim(X,T,\Delta)\).

\hypertarget{sec-eval-why}{%
\section{Evaluation Overview}\label{sec-eval-why}}

\hypertarget{sec-eval-why-what}{%
\subsection{What is Evaluation?}\label{sec-eval-why-what}}

Evaluation is the process of examining a model's relationship to data,
which may refer to the model's relationship to training data, i.e.~how
well the model is `fit' to this data, or the relationship to testing
data, i.e.~how `good' are the predictions from the model. In this
thesis, only three types of evaluation measure are considered and
qualitative definitions of these are given here; more precise
definitions appear later in the chapter.

\begin{itemize}
\tightlist
\item
  Discrimination -- A model's discriminatory power refers to how well it
  separates observations that are at a higher or lower risk of event.
  Therefore discrimination is also sometimes referred to as
  \emph{separation}. For example, a model with good discrimination will
  predict that (at a given time) a dead patient has a higher probability
  of being dead than an alive patient. These measures are the most
  common in survival and assess relative risk or rank predictions.
\item
  Calibration -- There is no single agreed upon definition of model
  calibration, with definitions varying from paper to paper (Collins et
  al. 2014; F. E. Harrell, Lee, and Mark 1996; Rahman et al. 2017; Van
  Houwelingen 2000). Generally, a model is said to be well-calibrated if
  the average predicted values from the model are in some `agreement'
  (which is specified by the chosen measure) with the average true
  observed values.
\item
  Predictive Performance -- A model is said to have good predictive
  performance (or sometimes `predictive accuracy') if its predictions
  for new data are `close to' the truth.
\end{itemize}

These are referred to as measures of predictive ability as they draw
conclusions about the ability of the model to make
predictions.\footnote{Measures of predictive ability measure a model's
  \emph{ability} to make any form of prediction. Measures of predictive
  performance measure the \emph{performance} of the predictions. In this
  section a model's predictive ability refers to all three of
  discrimination, calibration, and predictive performance.}

Using these definitions as a primary taxonomy for survival measures is
problematic as without clear definitions there can be significant
overlap between model `classes'. Instead this thesis advocates for the
same taxonomy as in the previous chapter and categorises measures by the
return type that they evaluate: survival time, ranking, or survival
distribution.

Goodness-of-fit measures are very briefly discussed in
Section~\ref{sec-eval-insample} for completeness, however these are
generally out of scope in this thesis as the vast majority (if any)
cannot evaluate machine learning models.

\hypertarget{sec-eval-why-why}{%
\section{Why are Models Evaluated?}\label{sec-eval-why-why}}

A key element of the scientific method is experiments and validation. In
the usual workflow of the scientific method:

\begin{itemize}
\tightlist
\item
  a hypothesis is proposed;
\item
  predictions are made; and
\item
  experiments are performed to test the hypothesis based on these
  predictions.
\end{itemize}

For statistical models the same principles are upheld:

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  a model is proposed (by manual or automated selection with possible
  tuning);
\item
  predictions are made either internally (cross-validation) or
  externally (held-out data); and
\item
  validation is performed on these predictions in order to infer
  something about the model's performance.
\end{enumerate}

The model can then be considered `good' or `bad' and either deployed,
adjusted, or discarded. As these are models that are run on a computer
(as opposed to experiments in the real-world), the process from fitting
to validating is relatively quick and as such multiple proposed models
can be evaluated and compared at the same time. This provides two key
use-cases for evaluation:

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  demonstrating model performance; and
\item
  model comparison/selection.
\end{enumerate}

Resistance to model evaluation can be found in the machine learning
community. One such example are proponents of inhomogeneous ensemble
methods, which combine predictions from multiple different models into a
single prediction. The arguments for these models are that:

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  model evaluation can never be precise enough, or strong enough
  guarantees cannot be given (Jiao and Du 2016); and
\item
  ensemble methods can guarantee a better performance than the
  individual component models and therefore evaluation of the components
  is not required.
\end{enumerate}

For example, `super learners' (Laan, Polley, and Hubbard 2007) are a
class of such model and claim\footnote{Testing this claim is tangential
  so for now will be assumed true.} to guarantee that a super learner
will always perform as well as, if not better, than its component
models: '\,'\ldots the super learner framework allows a researcher to
try many prediction algorithms\ldots knowing that the final combined
super learner fit will either be the best fit or near the best fit''
(Polley and Van Der Laan 2010). This has three problems, it:

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  assumes that researchers will only fit sensible prediction algorithms;
\item
  advocates for complex ensemble models instead of transparent and
  parsimonious ones; and
\item
  assumes that a super learner is guaranteed to be the (near) `best
  fit', which actively discourages simpler models being tested
  separately.
\end{enumerate}

Each of these problems can be resolved by researchers only fitting
sensible models and opting for an Occam's Razor approach where
inhomogeneous ensemble methods are used only if they outperform simpler
models, thus requiring validation to test this.

By the parsimony principle, if two models have the same predictive
performance (within some degree of confidence), then the simpler and
more transparent model is preferred. Even a very slight gain in
predictive performance could be outweighed by a large increase to
complexity. All models, whether simple or complex, should be critically
compared to many alternatives. At the very least a model should be
compared to a baseline (Section~\ref{sec-eval-distr-score-base-base}) as
many performance measures are uninterpretable without a point of
comparison (Gressmann et al. 2018).

\hypertarget{how-are-models-evaluated}{%
\subsection{How are Models Evaluated?}\label{how-are-models-evaluated}}

The process of evaluation in machine learning is briefly given as a key
method in \textbf{?@sec-surv-setml} and relevant parts are repeated
here. The evaluation process itself is a simple application of a
suitable mathematical function to predictions and true data. Let \(L\)
be some evaluation measure and for now assume \(L\) is a measure
evaluating deterministic predictions (the following generalises to other
types trivially). A model will either be evaluated on each prediction
separately, in which case
\(L: \mathbb{R}\times \mathbb{R}\rightarrow \bar{\mathbb{R}}\) or the
measure is calculated for all predictions simultaneously, in which case
\(L: \mathbb{R}^m \times \mathbb{R}^m \rightarrow \bar{\mathbb{R}}\).
Specifically the loss parameters are observed (true) outcomes, \(Y\),
and predictions of this outcome, \(\hat{Y}\). \(L\) is usually referred
to as a \emph{loss} when \(L\) should be minimised for optimal
prediction, whereas a \emph{score} is the term given when \(L\) should
be maximised.

All evaluation measures discussed in this thesis are out-of-sample
measures and therefore evaluation takes place after the model makes
predictions on held-out test data.

Specific choices for \(L\) are now reviewed.

\hypertarget{sec-eval-insample}{%
\section{In-Sample Measures}\label{sec-eval-insample}}

In-sample measures are not examined in this thesis as no in-sample
measures could be found that are applicable to all machine learning
methods and therefore are out of scope for this thesis. Instead, the
interested reader is referred to the papers and references listed below:

\hypertarget{residuals}{%
\subsubsection*{Residuals}\label{residuals}}

For discussion about model residuals, refer to texts on survival
modelling fitting and goodness-of-fit such as:

\begin{itemize}
\tightlist
\item
  Collett (2014)
\item
  Hosmer Jr, Lemeshow, and May (2011)
\end{itemize}

Both provide a comprehensive overview to model residuals for semi- and
fully-parametric low-complexity survival models.

\hypertarget{r2-measures}{%
\subsubsection*{\texorpdfstring{\(R^2\)
measures}{R\^{}2 measures}}\label{r2-measures}}

\(R^2\) type measures have been the focus of several reviews and
surveys, in particular the following are recommended:

\begin{itemize}
\tightlist
\item
  Choodari-Oskooei, Royston, and Parmar (2012a) --- For a comprehensive
  review and simulation study of \(R^2\) type measures
\item
  Kent and O'Quigley (1988) --- Defines the commonly utilised Kent and
  O'Quigley \(R^2\) measure
\item
  Royston and Sauerbrei (2004) --- Defines the commonly utilised Royston
  and Sauerbrei \(R^2\) measure
\end{itemize}

\hypertarget{likelihood-and-information-criteria}{%
\subsubsection*{Likelihood and Information
Criteria}\label{likelihood-and-information-criteria}}

Measures of likelihood and information criteria (e.g.~AIC, BIC) are
commonly utilised in in-sample model comparison of low-complexity
survival models though in general are harder (if not impossible) to
compute on ML alternatives.

These criterion are originally defined in:

\begin{itemize}
\tightlist
\item
  Akaike (1974) --- For the introduction of the AIC
\item
  Schwarz (1978) --- For the introduction of the BIC
\end{itemize}

These are discussed for survival analysis in:

\begin{itemize}
\tightlist
\item
  Volinsky and Raftery (2000) --- For discussion on the BIC for survival
  models.
\item
  HURVICH and TSAI (1989) --- Definition of corrected \(AIC\) for
  survival models, \(AIC_C\)
\item
  Liang and Zou (2008) --- `Improved' AIC for survival models.
\end{itemize}

\hypertarget{sec-eval-det}{%
\section{Evaluating Survival Time}\label{sec-eval-det}}

There appears to be little research into measures for evaluating
survival time predictions, which is likely due to this task usually
being of less interest than the others (\textbf{?@sec-surv-set-types}).
Common measures in survival analysis for survival time predictions are
the same as regression measures but with an additional indicator
variable to remove censoring. Three common regression measures are the
mean absolute error (MAE), mean squared error (MSE), and root mean
squared error (RMSE). These are respectively defined for survival
analysis as

\leavevmode\vadjust pre{\hypertarget{def-survivaltime}{}}%
\begin{definition}[Survival time measures]\label{def-survivaltime}

Let \(\mathcal{T}^m \subseteq \mathbb{R}_{>0}^m\),
\(\hat{t}= \hat{t}_1,...,\hat{t}_m, t = t_1,...,t_m\),
\(\delta = \delta_1,...,\delta_m\), and \(d := \sum^m_{i=1} \delta_i\),
then

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  The \emph{censoring-adjusted mean absolute error}, \(MAE_C\) is
  defined by
\end{enumerate}

\[
MAE_C: \mathcal{T}^m \times \mathcal{T}^m \times \{0,1\}^m \rightarrow \mathbb{R}_{\geq 0}; (\hat{t}, t, \delta) \mapsto \frac{1}{d} \sum^m_{i=1} \delta_i|t_i - \hat{t_i}|
\] i. The \emph{censoring-adjusted mean squared error}, \(MSE_C\) is
defined by

\[
MSE_C: \mathcal{T}^m \times \mathcal{T}^m \times \{0,1\}^m \rightarrow \mathbb{R}_{\geq 0}; (\hat{t}, t, \delta) \mapsto \frac{1}{d}\sum^m_{i=1}\delta_i(t_i - \hat{t}_i)^2
\] i. The \emph{censoring-adjusted root mean squared error}, \(RMSE_C\)
is defined by

\[
RMSE_C: \mathcal{T}^m \times \mathcal{T}^m \times \{0,1\}^m \rightarrow \mathbb{R}_{\geq 0}; (\hat{t}, t, \delta) \mapsto \sqrt{MSE_C(t, \hat{t}, \delta)}
\]

\end{definition}

These are referred to as `distance' measures as they measure the
distance between the true, \((t, \delta)\), and predicted, \(\hat{t}\),
values. This approach is not ideal as the removal of censored
observations results in increased bias as the proportion of censoring
increases (Section~\ref{sec-eval-crank-disc-conc}). Furthermore these
measures make some assumptions that are likely not valid in a survival
setting. For example these metrics assume that an over-prediction should
be penalised equally as much as an under-prediction, whereas in survival
data it is likely that a model should be overly-cautious and
under-predict survival times, i.e.~it is safer to predict a patient is
more at risk and will die sooner rather than less risk and die later.

These measures are clearly transparent and accessible as off-shelf
implementation is straightforward, though \(\textbf{mlr3proba}\)
(Sonabend et al. 2021) was the only \(\textsf{R}\) package found to
implement these. For performance, no conclusions can be drawn as no
research could be found into the theoretical properties of these losses;
despite this there is evidence of them being utilised in the literature
(Wang, Li, and Reddy 2017).

\hypertarget{sec-eval-crank}{%
\section{Evaluating Continuous Rankings}\label{sec-eval-crank}}

The next category of survival measures assess predictive performance via
discrimination for the evaluation of continuous ranking predictions.
Assessment of continuous rankings are also possible by measures of
calibration however few methods could be found that generalised to all
(not just PH) model forms. Therefore this section exclusively discusses
measures of discrimination. First time-independent concordance indices
(Section~\ref{sec-eval-crank-disc-conc}) are discussed and then
time-dependent AUCs (Section~\ref{sec-eval-crank-disc-auc}).

Measures of discrimination identify how well a model can separate
patients into different risk groups. A model has perfect discrimination
if it correctly predicts that patient \(i\) is at higher risk of death
than patient \(j\) if patient \(i\) dies first. This risk of death is
derived from the ranking prediction type. All discrimination measures
are ranking measures, which means that the exact predicted value is
irrelevant, only its relative ordering is required. For example given
predictions \(\{100,2,299.3\}\), only their rankings, \(\{2,1,3\}\), are
used by measures of discrimination.

\hypertarget{sec-eval-crank-disc-conc}{%
\subsection{Concordance Indices}\label{sec-eval-crank-disc-conc}}

The simplest form of discrimination measures are concordance indices,
which in general measure the proportion of cases in which the model
correctly separates a pair of observations into `low' and `high' risk.

\leavevmode\vadjust pre{\hypertarget{def-concordance}{}}%
\begin{definition}[Concordance]\label{def-concordance}

Let \((i,j)\) be a pair of observations with outcomes\textbackslash{}
\(\{(t_i,\delta_i),(t_j,\delta_j)\} \stackrel{i.i.d.}\sim(T,\Delta)\)
and let \(y_i,y_j \in \mathbb{R}\) be their respective risk predictions.
Then \((i,j)\) are called (F. E. J. Harrell et al. 1984; F. E. Harrell,
Califf, and Pryor 1982):

\begin{itemize}
\tightlist
\item
  \emph{Comparable} if \(t_i < t_j\) and \(\delta_i = 1\);
\item
  \emph{Concordant} if \(y_i > y_j\).\footnote{Recall
    (\textbf{?@sec-surv-set-types}) this thesis defines the risk ranking
    such that a higher value implies higher risk of death and so a pair
    is concordant if \(\mathbb{I}(t_i < t_j, y_i > y_j)\), whereas this
    would be \(\mathbb{I}(t_i < t_j, y_i < y_j)\) if a higher value
    implied a lower risk of death.}
\end{itemize}

\end{definition}

A concordance index (C-index) is a weighted proportion of the number of
concordant pairs over the number of comparable pairs. As such, a C-index
value is between \([0, 1]\) with \(1\) indicating perfect separation,
\(0.5\) indicating no separation, and \(0\) being separation in the
`wrong direction', i.e.~all high risk patients being ranked lower than
all low risk patients. Concordance measures may either be reported as a
value in \([0,1]\), a percentage, or as `discriminatory power'.
Discriminatory power refers to the percentage improvement of a model's
discrimination above the baseline value of \(0.5\). For example if a
model has a concordance of \(0.8\) then its discriminatory power is
\((0.8-0.5)/0.5 = 60\%\). This representation of discrimination provides
more information by encoding the model's improvement over some baseline
although is often confused with reporting concordance as a percentage
(e.g.~reporting a concordance of 0.8 as 80\%).

The most common concordance indices can be expressed as a general
measure.

\leavevmode\vadjust pre{\hypertarget{def-cindex}{}}%
\begin{definition}[C-index]\label{def-cindex}

Let \(\mathcal{T}^m \subseteq \mathbb{R}_{>0}^m\),
\(y = y_1,...,y_m, t = t_1,...,t_m\),
\(\delta = \delta_1,...,\delta_m\), and let \(W\) be a weighting
function. Then, the \emph{survival concordance index} is defined by,

\[
\begin{split}
&C: \mathbb{R}^m \times \mathcal{T}^m \times \{0,1\}^m \times \mathbb{R}_{\geq 0}\rightarrow [0,1]; \\
&(y, t, \delta|\tau) \mapsto \frac{\sum_{i\neq j} W(t_i)\mathbb{I}(t_i < t_j, y_i > y_j, t_i < \tau)\delta_i}{\sum_{i\neq j}W(t_i)\mathbb{I}(t_i < t_j, t_i < \tau)\delta_i}
\end{split}
\] for some cut-off time \(\tau\).

\end{definition}

The choice of \(W\) specifies a particular evaluation measure (see
below). To evaluate the discrimination of a prediction functional,
\(\hat{g}\), with predicted rankings from the model,
\(r = r_1,...,r_m\), the concordance is calculated as
\textbackslash{}\(C(r, (T^*_1,...,T^*_m), (\Delta^*_1,...,\Delta^*_m)|\tau)\)
for some choice of \(\tau \in \mathbb{R}_{\geq 0}\). The use of the
cut-off \(\tau\) mitigates against decreased sample size over time due
to the removal of censored observations. There are multiple methods for
dealing with tied times but in practice a value of \(0.5\) is usually
taken when \(t_i = t_j\) (Therneau and Atkinson 2020). The following
weights have been proposed for the concordance index (Therneau and
Atkinson 2020):

\begin{itemize}
\tightlist
\item
  \(W(t_i) = 1\) -- This is Harrell's concordance index, \(C_H\) (F. E.
  J. Harrell et al. 1984; F. E. Harrell, Califf, and Pryor 1982), which
  is widely accepted to be the most common survival measure (Collins et
  al. 2014; GÃ¶nen and Heller 2005; Rahman et al. 2017). There is no
  cut-off in the original definition of \(C_H\) (\(\tau = \infty\)).
\item
  \(W(t_i) = [\hat{G}_{KM}(t_i)]^{-2}\) -- This is Uno's C, \(C_U\) (Uno
  et al. 2011). \(\hat{G}_{KM}\) is the Kaplan-Meier estimate of the
  survival function of the censoring distribution fit on training data.
  This is referred to as an Inverse Probability of Censoring Weighted
  (IPCW) measure as the estimated censoring distribution is utilised to
  weight the measure in order to compensate for removed censored
  observations.
\item
  \(W(t_i) = [\hat{G}_{KM}(t_i)]^{-1}\)
\item
  \(W(t_i) = \hat{S}_{KM}(t_i)\). \(\hat{S}_{KM}\) is the Kaplan-Meier
  estimator of the survival distribution.
\item
  \(W(t_i) = \hat{S}_{KM}(t_i)/\hat{G}_{KM}(t_i)\)
\end{itemize}

All methods assume that censoring is conditionally-independent of the
event given the features (\textbf{?@sec-surv-set-cens}), otherwise
weighting by \(\hat{S}_{KM}\) or \(\hat{G}_{KM}\) would not be
applicable. It is assumed here that \(\hat{S}_{KM}\) and
\(\hat{G}_{KM}\) are estimated on the training data and not the testing
data (though the latter is often seen in implementation (Therneau
2015)).

With respect to being APT, all concordance indices are highly
transparent and accessible, with many off-shelf implementations. With
respect to performance, Choodari-Oskooei \textit{et al.} (2012)
(Choodari-Oskooei, Royston, and Parmar 2012a) define a measure as
performant if it is:\footnote{This paper refers specifically to measures
  of explained variation and therefore only the properties that
  generalise to all measures are included here.}

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  independent of censoring;
\item
  interpretable; and
\item
  robust against outliers.
\end{enumerate}

This second property is already covered by `transparency'. The third
property is guaranteed for all measures of concordance, which are
ranking measures; all outliers are removed once ranks are applied to
predictions. Therefore the first property, `'a measure that is the least
affected by the amount of censoring is generally preferred''
(Choodari-Oskooei, Royston, and Parmar 2012a), is now considered.

Several papers have shown that \(C_H\) is affected by the precense of
censoring (Koziol and Jia 2009; Pencina, D'Agostino, and Song 2012;
Royston and Altman 2013; Uno et al. 2011) as the measure ignores pairs
in which the shorter survival time is censored. Despite this, \(C_H\) is
still the most widely utilised measure and moreover if a suitable cut-of
\(\tau\) is chosen, then all these weightings perform very similarly
(Rahman et al. 2017; Schmid and Potapov 2012).

Measures that utilise other weightings have been demonstrated to be less
affected by censoring than \(C_H\) (Rahman et al. 2017). However if a
poor choice is selected for \(\tau\) then IPCW measures (which include
\(\hat{G}_{KM}\) in the weighting) can be highly unstable (Rahman et al.
2017). For example, the variance of \(C_U\) has been shown to
drastically increase more than other measures with increased censoring
(Schmid and Potapov 2012).

None of these measures are perfect and all have been shown to be
affected to some extent by censoring (Schmid and Potapov 2012), which
can lead to both under-confidence and over-confidence in the model's
discriminatory ability. For example, \(C_U\) has been observed to report
values as low as 0.2 when the `true estimate' was 0.6 (Schmid and
Potapov 2012). Therefore interpreting a value from these measures can be
very difficult, for example naively reporting a concordance of 60\% when
\(C_H = 0.6\) would be incorrect as this value may mean very different
things for different amounts of censoring. Whilst intepreting these
measures may be difficult, it is not impossible as all these estimators
tend to produce values around a similar range (Rahman et al. 2017;
Schmid and Potapov 2012). Therefore this thesis advocates for multiple
concordance indices being reported alongside expert interpretation that
takes into account sample size and censoring proportions (Schmid and
Potapov 2012) as well as `risk profiles' (how at risk patients are)
(Rahman et al. 2017).

For within-study model comparison, instability from censoring is not of
concern as the measure will be affected equally across all models;
though interpretation remains difficult. However a concordance from one
study cannot be compared to that from another if the datasets differ
greatly in the proportion of censoring. Future research could consider
more robust concordance indices that can provide greater ease of
interpretation.

As well as the concordance indices discussed here, another promiment
alterntive was derived by G"onen and Heller (2005) (GÃ¶nen and Heller
2005). However as this is only applicable to the Cox PH it is out of
scope for this thesis, which is primarily concerned with generalisable
measures for model comparison.

In simulation experiments, the concordance indices that tended to
perform `better' were those based on AUC-type measures, these are now
discussed.

\hypertarget{sec-eval-crank-disc-auc}{%
\subsection{AUC Measures}\label{sec-eval-crank-disc-auc}}

AUC, or AUROC, measures calculate the Area Under the Receiver Operating
Characteristic (ROC) Curve, which is a plot of the \emph{sensitivity}
(or true positive rate (TPR)) against \$1 - \$\emph{specificity} (or
true negative rate (TNR)) at varying thresholds (described below) for
the predicted probability (or risk) of event. Figure~\ref{fig-eval-rocs}
visualises ROC curves for two classification models. The blue line is a
featureless baseline that has no discrimination. The red line is a
decision tree with better discrimination as it comes closer to the
top-left corner.

\begin{figure}

{\centering \includegraphics{./images/evaluation/rocs.png}

}

\caption{\label{fig-eval-rocs}ROC Curves for a classification example.
Red is a decision tree with good discrimination as it `hugs' the
top-left corner. Blue is a featureless baseline with no discrimination
as it sits on \(y = x\).}

\end{figure}

In a classification setting with no censoring, the AUC has the same
interpretation as Harrell's C (Uno et al. 2011). AUC measures for
survival analysis have been developed in order to provide a
time-dependent measure of discriminatory ability (Patrick J. Heagerty,
Lumley, and Pepe 2000). The proposed concordance indices described above
are time-independent, which is useful for producing a single statistic.
However, in a survival setting it can reasonably be expected for a model
to perform differently over time and therefore time-dependent measures
are advantageous. First discussion around computation of TPR and TNR are
provided and then how these are incorporated into the AUC equation.

The AUC, TPR, and TNR are derived from the \emph{confusion matrix} in a
binary classification setting. Let \(b,\hat{b} \in \{0, 1\}\) be the
true and predicted binary outcomes respectively. The confusion matrix is

\begin{longtable}[]{@{}lll@{}}
\toprule()
\endhead
& \(b = 1\) & \(b = 0\) \\
\(\hat{b} = 1\) & TP & FP \\
\(\hat{b} = 0\) & FN & TN \\
\bottomrule()
\end{longtable}

where \(TN := \sum_i \mathbb{I}(b = 0, \hat{b}= 0)\) is the number of
(\#) true negatives, \(TP := \sum_i \mathbb{I}(b = 1, \hat{b}= 1)\) is
\# true positives, \(FP := \sum_i \mathbb{I}(b = 0, \hat{b}= 1)\) is \#
false positives, and \(FN := \sum_i \mathbb{I}(b = 1, \hat{b}= 0)\) is
\# false negatives. From these are derived \begin{align}
& TPR := \frac{TP}{TP + FN} \\
& TNR := \frac{TN}{TN + FP}
\end{align}

In classification, a probabilistic prediction of an event can simply be
\emph{thresholded} (or `binarised') to obtain a deterministic
prediction. For a predicted \(\hat{p} := \hat{P}(b = 1)\), and threshold
\(\alpha\), the thresholded binary prediction is given by
\(\hat{b} := \mathbb{I}(\hat{p} > \alpha)\). In survival analysis, this
is complicated as either models only predict a continuous ranking (and
not a probability of death), or a full survival distribution, which
implies that the probability of death changes over time; it is the first
of these that is utilised in AUC measures. Two primary methods for doing
so have emerged, the first is to use an IPCW method to weight the
thresholded linear predictor by an estimated censoring distribution at a
given time, the second is to first classify cases and controls then
compute estimators based on these classes. All measures of TPR, TNR and
AUC are in the range \([0,1]\) with larger values preferred.

Weighting the linear predictor was proposed by Uno
\textit{et al.} (2007) (Uno et al. 2007) and provides a method for
estimating TPR and TNR via

\[
\begin{split}
&TPR_U: \mathbb{R}^m \times \mathbb{R}_{\geq 0}^m \times \{0,1\}^m \times \mathbb{R}_{\geq 0}\times \mathbb{R}\rightarrow [0,1]; \\
&(\hat{\eta}, t, \delta | \tau, \alpha) \mapsto  \frac{\sum^m_{i=1} \delta_i \mathbb{I}(k(\hat{\eta}_i) > \alpha, t_i \leq \tau)[\hat{G}_{KM}(t_i)]^{-1}}{\sum^m_{i=1}\delta_i\mathbb{I}(t_i \leq \tau)[\hat{G}_{KM}(t_i)]^{-1}}
\end{split}
\] and

\[
\begin{split}
&TNR_U: \mathbb{R}^m \times \mathbb{R}_{\geq 0}^m \times \mathbb{R}_{\geq 0}\times \mathbb{R}\rightarrow [0,1]; \\
&(\hat{\eta}, t | \tau, \alpha) \mapsto \frac{\sum^m_{i=1} \mathbb{I}(k(\hat{\eta}_i) \leq \alpha, t_i > \tau)}{\sum^m_{i=1}\mathbb{I}(t_i > \tau)}
\end{split}
\] where \(\tau\) is the time at which to evaluate the measure,
\(\alpha\) is a cut-off for the linear predictor, and \(k\) is a known,
strictly increasing, differentiable function. \(k\) is chosen depending
on the model choice, for example if the fitted model is PH then
\(k(x) = 1 - \exp(-\exp(x))\) (Uno et al. 2007). Similarities can be
drawn between these equations and Uno's concordance index, in particular
the use of IPCW. Censoring is again assumed to be at least random once
conditioned on features. Plotting \(TPR_U\) against \(1 - TNR_U\) for
varying values of \(\alpha\) provides the ROC.

The second method, which appears to be more prominent in the literature,
is derived from Heagerty and Zheng (2005) (Patrick J. Heagerty and Zheng
2005). They define four distinct classes, in which observations are
split into controls and cases.

An observation is a \emph{case} at a given time-point if they are dead,
otherwise they are a \emph{control}. These definitions imply that all
observations begin as controls and (hypothetically) become cases over
time. Cases are then split into \emph{incident} or \emph{cumulative} and
controls are split into \emph{static} or \emph{dynamic}. The choice
between modelling static or dynamic controls is dependent on the
question of interest. Modelling static controls implies that a `subject
does not change disease status' (Patrick J. Heagerty and Zheng 2005),
and few methods have been developed for this setting (Kamarudin, Cox,
and Kolamunnage-Dona 2017), as such the focus here is on \emph{dynamic}
controls. The incident/cumulative cases choice is discussed in more
detail below.\footnote{All measures discussed in this section evaluate
  model discrimination from `markers', which may be a \emph{predictive}
  marker (model predictions) or a \emph{prognostic} marker (a single
  covariate). This section always defines a marker as a ranking
  prediction, which is valid for all measures discussed here with the
  exception of one given at the end.}

The TNR for dynamic cases is defined as

\[
TNR_D(y, N | \alpha, \tau) = P(y_i \leq \alpha | N_i(\tau) = 0)
\] where \(y = (y_1,...,y_n)\) is some deterministic prediction and
\(N(\tau)\) is a count of the number of events in \([0,\tau)\). Heagerty
and Zheng further specify \(y\) to be the predicted linear predictor
\(\hat{\eta}\). Cumulative/dynamic and incident/dynamic measures are
available in software packages `off-shelf', these are respectively
defined by

\[
TPR_C(y, N | \alpha, \tau) = P(y_i > \alpha | N_i(\tau) = 1)
\] and

\[
TPR_I(y, N | \alpha, \tau) = P(y_i > \alpha | dN_i(\tau) = 1)
\] where \(dN_i(\tau) = N_i(\tau) - N_i(\tau-)\). Practical estimation
of these quantities is not discussed here.

The choice between the incident/dynamic (I/D) and cumulative/dynamic
(C/D) measures primarily relates to the use-case. The C/D measures are
preferred if a specific time-point is of interest (Patrick J. Heagerty
and Zheng 2005) and is implemented in several applications for this
purpose (Kamarudin, Cox, and Kolamunnage-Dona 2017). The I/D measures
are preferred when the true survival time is known and discrimination is
desired at the given event time (Patrick J. Heagerty and Zheng 2005).

Defining a time-specific AUC is now possible with

\[
AUC(y, N | \tau) = \int^1_0 TPR(y, N | 1 - TNR^{-1}(p|\tau), \tau) \ dp
\]

Finally, integrating over all time-points produces a time-dependent AUC
and as usual a cut-off is applied for the upper limit,

\[
AUC^*(y,N|\tau^*) = \int^{\tau^*}_0 AUC(y,N|\tau)\frac{2\hat{p}_{KM}(\tau)\hat{S}_{KM}(\tau)}{1 - \hat{S}_{KM}^2(\tau^*)} \ d\tau
\] where \(\hat{S}_{KM},\hat{p}_{KM}\) are survival and mass functions
estimated with a Kaplan-Meier model on training data.

Since Heagerty and Zheng's paper, other methods for calculating the
time-dependent AUC have been devised, including by Chambless and Diao
(Chambless and Diao 2006), Song and Zhou (Song and Zhou 2008), and Hung
and Chiang (Hung and Chiang 2010). These either stem from the Heagerty
and Zheng paper or ignore the case/control distinction and derive the
AUC via different estimation methods of TPR and TNR. Blanche
\textit{et al.} (2012) (Blanche, Latouche, and Viallon 2012) surveyed
these and concluded `'regarding the choice of the retained definition
for cases and controls, no clear guidance has really emerged in the
literature'`, but agree with Heagerty and Zeng on the use of C/D for
clinical trials and I/D for 'pure' evaluation of the marker. Blanche
\textit{et al.} (2013) (Blanche, Dartigues, and Jacqmin-Gadda 2013)
published a survey of C/D AUC measures with an emphasis on
non-parametric estimators with marker-dependent censoring, including
their own Conditional IPCW (CIPCW) AUC,

\[
AUC_B(y, t, \delta, \hat{G}|\tau) = \frac{\sum_{i \neq j} \mathbb{I}(y_i > y_j)\mathbb{I}(t_i \leq \tau, t_j > \tau)\frac{\delta_i}{m^2\hat{G}(t_i|y_i)\hat{G}(\tau|y_j)}}{\Big(\sum^m_{i=1}\mathbb{I}(t_i \leq \tau)\frac{\delta_i}{m\hat{G}(t_i|y_i)}\Big)\Big(\sum^m_{j=1}\mathbb{I}(t_j>\tau)\frac{1}{m\hat{G}(\tau|y_j)}\Big)}
\] where \(t = (t_1,...,t_m)\), and \(\hat{G}\) is the Akritas (Akritas
1994) estimator of the censoring distribution
(\textbf{?@sec-surv-models-uncond}). It can be shown that setting the
\(\lambda\) parameter of the Akritas estimator to \(1\) results in the
IPCW estimators (Blanche, Dartigues, and Jacqmin-Gadda 2013). However
unlike the previous measures in which a deterministic prediction can be
substituted for the marker, this is not valid for this estimator and as
such this cannot be used for predictions. This is clear from the
weights, \(\hat{G}(t|y)\), in the equation which are dependent on the
prediction itself. The purpose of the CIPCW method is to adapt the IPCW
weights to be conditioned on the data covariates, which is not the case
when \(y\) is a predictive marker. Hence the following adaptation is
considered instead,

\[
AUC^*_B(y, x, t, \delta, \hat{G}|\tau) = \frac{\sum_{i \neq j} \mathbb{I}(y_i > y_j)\mathbb{I}(t_i \leq \tau, t_j > \tau)\frac{\delta_i}{m^2\hat{G}(t_i|x_i)\hat{G}(\tau|x_j)}}{\Big(\sum^m_{i=1}\mathbb{I}(t_i \leq \tau)\frac{\delta_i}{m\hat{G}(t_i|x_i)}\Big)\Big(\sum^m_{j=1}\mathbb{I}(t_j>\tau)\frac{1}{m\hat{G}(\tau|x_j)}\Big)}
\] where \(x\) are random covariates (possibly from a separate training
dataset).

AUC measures are less transparent and less accessible than the simpler
time-independent concordance indices, only the \textbf{survAUC}
(Potapov, Adler, and Schmid 2012) package could be found that implements
these measures. For performance, reviews of these measures have produced
(sometimes markedly) different results (Blanche, Latouche, and Viallon
2012; Li, Greene, and Hu 2018; Kamarudin, Cox, and Kolamunnage-Dona
2017) with no clear consensus on how and when these measures should be
used. The primary advantage of these measures is to extend
discrimination metrics to be time-dependent. However it is unclear how
to interpret a threshold of a linear predictor and moreover if this is
even the `correct' quantity to threshold, especially when survival
distribution predictions are the more natural object to evaluate over
time. Methods for evaluating these distribution predictions are now
discussed.

\hypertarget{sec-eval-distr-calib}{%
\section{Evaluating Distributions by
Calibration}\label{sec-eval-distr-calib}}

The final discussed measures are for evaluating survival distributions.
First measures of calibration are briefly discussed in this section and
then extensive treatment is given to scoring rules
(Section~\ref{sec-eval-distr}).

\hypertarget{random-variable-and-distribution-notation}{%
\subsubsection*{Random Variable and Distribution
Notation}\label{random-variable-and-distribution-notation}}

Throughout these next two sections, two different notations are utilised
for random variables and distributions. The first is the `standard'
notation, for example if \(\zeta\) is a continuous probability
distribution and \(X \sim \zeta\) is a random variable, then \(f_X\) is
the probability density function of \(X\). The second notation
associates distribution functions directly with the distribution and not
the variable. For example if \(\zeta\) is a continuous probability
distribution then \(\zeta.f\) is the probability density function of
\(\zeta\). Analogously for the probability mass, cumulative
distribution, hazard, cumulative hazard, and survival functions of
\(X \sim \zeta\),
\(p_X/\zeta.p, F_X/\zeta.F, h_X/\zeta.h, H_X/\zeta.H, S_X/\zeta.S\).
This notation (fully described and motivated in
\textbf{?@sec-tools-distr6-intro}) provides a clearer separation of
probability distributions and random variables, which in turn allows for
cleaner proofs involving probability distributions.

\hypertarget{measures-of-calibration}{%
\subsubsection*{Measures of Calibration}\label{measures-of-calibration}}

Few measures of calibration exist in survival analysis (Rahman et al.
2017) and this is likely due to the meaning of calibration being unclear
in this context (Van Houwelingen 2000). This is compounded by the fact
that calibration is often evaluated graphically, which can leave room
for high subjectivity and thus may be restricted to expert
interpretation. For these reasons, measures of calibration are only
considered in this thesis with respect to accessibility and transparency
as there is no clear meaning for what makes a calibration measure
performant. Many methods of calibration are restricted to calibration
and re-calibration of PH models (Demler, Paynter, and Cook 2015; Van
Houwelingen 2000), none of these are considered here as they do not
generalise to all (or at least many) survival models.

\hypertarget{point-and-probabilistic-calibration}{%
\subsubsection*{Point and Probabilistic
Calibration}\label{point-and-probabilistic-calibration}}

Andres \textit{et al.} (2018) (Andres et al. 2018) derived a taxonomy
for calibration measures to separate measures that only evaluate
distributions at a single time-point (`1-Calibration') and measures that
evaluate distributions at all time-points
(`distributional-calibration'). This section will use the same taxonomy
but in keeping with machine learning terminology will refer to
`1-Calibration' as `Point Calibration' and `distributional-calibration'
as `Probabilistic Calibration'.

All measures considered previously can be viewed as `point' measures as
they evaluate predictions at a single point, specifically comparing the
predicted linear predictor (more generally relative risk) or survival
time to the true time of death. However calibration measures and scoring
rules instead evaluate predicted distributions and specifically
functions that vary over time, hence it is often of more interest to
evaluate these functions at multiple (all if discrete) time-points in
order to derive a metric that captures changes over time. For example
one may expect probabilistic predictions to be more accurate in the
near-future and to steadily worsen as uncertainty increases over time
(both mathematical (censoring) and real-world uncertainty), and
therefore a measure that only evaluates distributions at a single
(possibly early) time-point cannot assess the true variation in the
prediction.

Mathematically this difference in measures may be considered as follows:
Let \(\mathcal{P}\) be a set of distributions over
\(\mathcal{T}\subseteq \mathbb{R}_{>0}\), then a point measure for
evaluating distributions is given by,

\[
L_1: \mathcal{P}\times \mathcal{T}\times \{0,1\}\times \mathcal{T}\rightarrow \bar{\mathbb{R}}; \quad
(\zeta, t, \delta|\tau) \mapsto g_1(\zeta.\rho(\tau), t, \delta)
\] and a probabilistic measure is given by,

\[
L_P: \mathcal{P}\times \mathcal{T}\times \{0,1\}\times \mathbb{R}_{>0}\rightarrow \bar{\mathbb{R}}; \quad
(\zeta, t, \delta|\tau^*) \mapsto \int_0^{\tau^*} g_P(\zeta.\rho(\tau), t, \delta) \ d\tau
\] or

\[
L_P: \mathcal{P}\times \mathcal{T}\times \{0,1\}\times \mathbb{R}_{>0}\rightarrow \bar{\mathbb{R}}; \quad
(\zeta, t, \delta|\tau^*) \mapsto \sum_{\tau = 0}^{\tau^*} g_P(\zeta.\rho(\tau), t, \delta)
\] where \(\tau^*\) is some cut-off for the measure to control
uncertainty increasing over time, \(\rho\) is usually the survival
function but may be any distribution-defining function, and \(g_1,g_P\)
are functions corresponding to specific measures (some examples in next
two sections). Note that \(\tau\) is an argument (not a free variable)
of \(L_1\) as the fixed choice of \(\tau\) is measure-dependent; usually
\(\tau = t\).

Less abstractly, a point-calibration measure will evaluate a function of
the predicted distribution at a single time-point whereas a
probabilistic measure evaluates the distribution over a range of
time-points; in both cases the evaluated quantity is compared to the
observed outcome, \((T^*, \Delta^*)\).

\hypertarget{sec-eval-distr-calib-point}{%
\subsection{Point Calibration}\label{sec-eval-distr-calib-point}}

Point calibration measures can be further divided into metrics that
evaluate calibration at a single time-point (by reduction) and measures
that evaluate an entire distribution by only considering the event time.
The subtle difference significantly affects conclusions that can be
drawn. In the first case, a calibration measure can only draw
conclusions at that one time-point, whereas the second case can draw
conclusions about the calibration of the entire distribution.

\hypertarget{calibration-by-reduction}{%
\subsubsection{Calibration by
Reduction}\label{calibration-by-reduction}}

Point calibration measures are implicitly reduction methods as they
attempt to evaluate a full distribution based on a single point only.
For example given a predicted survival function \(\zeta.S\), then one
could select a time-point \(\tau^*\) and calculate the survival function
at this time, \(\zeta.S(\tau^*)\), probabilistic classification
calibration measures can then be utilised. Using this approach one may
employ common calibration methods such as the Hosmer--Lemeshow test
(Hosmer and Lemeshow 1980). Calibration at a single point in this manner
is not particularly useful as a model may be well-calibrated at one
time-point and then poorly calibrated at all others (Haider et al.
2020). To overcome this one could perform the Hosmer--Lemeshow test (or
any other applicable test) multiple times at different values of
\(\tau^* \in \mathbb{R}_{\geq 0}\). However doing so is inefficient and
can lead to problems with `multiple testing'; hence these single-point
methods are not considered further.

\hypertarget{houwelingens-alpha}{%
\subsubsection{\texorpdfstring{Houwelingen's
\(\alpha\)}{Houwelingen's \textbackslash alpha}}\label{houwelingens-alpha}}

Methods that evaluate entire distributions based on a single point may
be more useful as conclusions can be drawn at the distribution level.
One such method is termed here `Houwelingen's \(\alpha\)'. van
Houwelingen proposed several measures (Van Houwelingen 2000) for
calibration but only one generalises to all probabilistic survival
models. This method evaluates the predicted cumulative hazard function,
\(\zeta_i.H\) (for some predicted distribution \(\zeta_i\)), by
comparing \(\zeta_i.H\) to the `true' hypothetical cumulative hazard,
\(H\). The test statistic, \(H_\alpha\), is defined by

\[
H_\alpha := \frac{\sum_i H_i(T^*_i)}{\sum_i \zeta_i.H(T^*_i)} \approx \frac{\sum_i \Delta^*_i}{\sum_i \zeta_i.H(T^*_i)}
\] where \(\zeta = (\zeta_1,...,\zeta_m)\) are predicted distributions
and
\(\{(T_1^*,\Delta_1^*),...,(T_m^*,\Delta_m^*)\} \stackrel{i.i.d.}\sim(T, \Delta)\)
is some test data. The model is therefore well-calibrated if
\(H_\alpha = 1\). This has standard error
\(SE(H_\alpha) = \exp(1/\sqrt{(\sum_i \Delta^*_i)})\).

The approximate equality is motivated by formulating survival data as a
counting process and noting that in this setting the cumulative hazard
function can estimate the number of events in a time-period (Hosmer Jr,
Lemeshow, and May 2011). No study could be found that utilised
\(H_\alpha\) for model comparison, possibly because graphical methods
are favoured. This method can infer results about the calibration of an
entire model and not just at a single point because the measure is
calculated at a meaningful time (the event time) and utilises known
results from counting processes to verify if the expected number of
deaths equals the observed number of deaths.

However, as with the reduction method, the statistic is derived from a
single point (the observed event time) for each individual and thus it
is possible that the model is well-calibrated only for making
predictions at the event time, but not over the full \(\mathbb{R}_{>0}\)
range.

\hypertarget{sec-eval-distr-calib-prob}{%
\subsection{Probabilistic Calibration}\label{sec-eval-distr-calib-prob}}

Unlike other areas of evaluation, graphical methods are favoured in
calibration and possibly more so than numerical ones. Graphical methods
compare the average predicted distribution to the expected distribution.
As the expected distribution is itself unknown, this is often estimated
with the Kaplan-Meier curve.

\hypertarget{kaplan-meier-comparison}{%
\subsubsection{Kaplan-Meier Comparison}\label{kaplan-meier-comparison}}

The simplest graphical comparison compares the average predicted
survival curve to the Kaplan-Meier curve estimated on the testing data.
Formally, let \textbackslash{} \(\zeta_1.S,...,\zeta_m.S\) be predicted
survival functions, then the average predicted survival function is a
mixture of these distributions,
\(\frac{1}{m} \sum^{m}_{i = 1} \zeta_i.S(\tau)\). Plotting this mixture
and the Kaplan-Meier on \(\tau\) vs \(S(\tau)\) allows a visual
comparison of how closely these curves align. An example is given in
Figure~\ref{fig-eval-calib-km}, the Cox model (CPH) is well-calibrated
as it almost perfectly overlaps the Kaplan-Meier estimator, whereas
predictions from the poorly-calibrated support vector machine (SVM) are
far from this line.

\begin{figure}

{\centering \includegraphics{./images/evaluation/calib_km.png}

}

\caption{\label{fig-eval-calib-km}Assessing the calibration of a Cox PH
(CPH) and SVM (with distribution composition by PH form and Kaplan-Meier
(\textbf{?@sec-car-pipelines-distr})) by comparing the average survival
prediction to a Kaplan-Meier (KM) estimate on the testing dataset.
x-axis is time and y-axis is the predicted survival functions evaluated
over time. The CPH (red line) is said to be well-calibrated as it almost
perfectly overlaps the Kaplan-Meier (green line), whereas the SVM (blue
line) is far from this line. Models trained and tested on randomly
simulated data from the
\href{https://cran.r-project.org/package=simsurv}{\texttt{simsurv}}
(Brilleman 2019) package in \(\textbf{mlr3proba}\)
(\textbf{?@sec-tools-mlr3proba}).}

\end{figure}

This approach is both simple and interpretable. In the example above one
can conclude: on average, the trained Cox PH predicts a distribution
just as well as (or very close to) an unconditional estimator using the
real test data. A major caveat is that conclusions are at an average
\emph{population} level with no individual-level measurement.

In order to capture finer information on a level closer to inidivduals,
calibration can be applied to the predicted relative risks or linear
predictor. One such approach is to bin the predictions to create
different `risk groups' from low-to-high risk (Royston and Altman 2013).
These groups are then plotted against a stratified Kaplan-Meier
estimator. This allows for a more nuanced approach to calibration and
can simultaneously visualise a model's discrimination. However this
method is far less transparent as it adds even more subjectivity around
how many risk groups to create and how to create them (Royston and
Altman 2013).

\hypertarget{d-calibration}{%
\subsubsection{D-Calibration}\label{d-calibration}}

D-Calibration (Andres et al. 2018; Haider et al. 2020) is a very recent
method that aims to evaluate a model's calibration at all time-points in
a predicted survival distribution. The D-calibration measure is
identical to the \(\chi^2\) test-statistic, which is usually written as
follows

\[
\chi^2 := \sum_{i=1}^n \frac{(O_i - E_i)^2}{E_i}
\] where \(O_1,...,O_n\) is the observed number of events in \(n\)
groups and \(E_1,...,E_n\) is the expected number of events. The
statistic is utilised to determine if the underlying distribution of the
observed events follows a theoretical/expected distribution.

The D-Calibration measure tests if predictions (observations) from the
survival functions of predicted distributions,
\(\zeta_1.S,...,\zeta_m.S\), follow the uniform distribution as
expected. The following lemma motivates this test.

\leavevmode\vadjust pre{\hypertarget{lem}{}}%
\label{lem:uniform_surv} Let \(\zeta\) be a continuous probability
distribution and let \(X \sim \zeta\) be a random variable. Let \(S_X\)
be the survival function of \(X\). Then
\(S_X(X) \sim \mathcal{U}(0, 1)\).

In order to utilise the \(\chi^2\) test (for categorical variables), the
\([0,1]\) codomain of \(\zeta_i.S\) is cut into \(B\) disjoint
contiguous intervals (`bins') over the full range \([0,1]\). Let \(m\)
be the total number of observations in the test data. Then assuming a
discrete uniform distribution as the theoretical distribution, the
expected number of events is \(m/B\).

The observed number of events in bin \(i\), \(O_i\), is defined as
follows: Define \(b_i\) as the set of observations that die in the
\(i\)th bin, formally defined by
\(b_i := \{j \in 1,...,m : \lceil \zeta_j.S(T^*_j)B \rceil = i\}\),
where \(j = 1,...,m\) are the indices of the test observations and
\(\zeta = (\zeta_1,...,\zeta_m)\) are predicted
distributions.\footnote{This is a slightly simplified procedure which
  omits handling of censoring, but this is easily extended in the full
  algorithm, see Algorithm 2 of Haider \textit{et al.} (2020) (Haider et
  al. 2020).} Then, \(O_i = |b_i|, \forall i \in 1,...,B\).

The D-Calibration measure, or \(\chi^2\) statistic, is now defined by,

\[
D_{\chi^2}(\zeta, T^*) :=  \frac{\sum^B_{i = 1} (O_i - \frac{m}{B})^2}{m/B}
\]

This measure has several useful properties. Firstly, a \(p\)-value can
be derived from \(\chi^2_{B-1}\) to hypothesis test if a single model is
`D-calibrated'. Secondly, as a model is increasingly well-calibrated it
holds that \(D_{\chi^2} \rightarrow 0\) (as the number of observed
events approach expected events), which motivates utilising the test for
model comparison. Thirdly, the theory lends itself very nicely to an
intuitive graphical calibration method:

If a model is D-calibrated, i.e.~predicted distributions from the model
result in a low D-calibration, then one expects,

\[
\label{eq:eval_dcalib}
p = \frac{\sum_i \mathbb{I}(T^*_i \leq \zeta_i.F^{-1}(p))}{|T^*|}
\] where \(p \in [0,1]\) and \(\zeta_i.F^{-1}\) is the inverse
cumulative distribution function of the \(i\)th predicted distribution.
In words, if a model is D-calibrated then the number of deaths occurring
at or before each quantile should be equal to the quantile itself, for
example 50\% of deaths should occur before their predicted median
survival time. Therefore one can graphically test for D-calibration by
plotting \(p\) on the x-axis and the RHS of \textbf{?@eq-eval-dcalib} on
the y-axis. A D-calibrated model should result in a straight line on
\(x = y\). This is visualised in Figure~\ref{fig-eval-dcalib} for the
same models as in Figure~\ref{fig-eval-calib-km}. Again the SVM is
terribly-calibrated but the CPH is better calibrated. In this case it is
clearer that the D-calibration of the CPH is not perfect, especially at
higher quantiles. Comparison to \(\chi^2_9\) indicates the CPH is
D-calibrated whereas the SVM is not.

\begin{figure}

{\centering \includegraphics{./images/evaluation/dcalib.png}

}

\caption{\label{fig-eval-dcalib}Assessing the D-calibration of the Cox
PH (CPH) and SVM from the same data as Figure~\ref{fig-eval-calib-km}:
models trained and tested on randomly simulated data from the
\href{https://cran.r-project.org/package=simsurv}{\texttt{simsurv}}
(Brilleman 2019) package in \(\textbf{mlr3proba}\)
(\textbf{?@sec-tools-mlr3proba}). x-axis are quantiles in \([0,1]\) and
y-axis are predicted quantiles from the models. The dashed line is
\(y = x\). Again the SVM is terribly calibrated and the CPH is better
calibrated as it is closer to \(y = x\).}

\end{figure}

\hypertarget{transparency-and-accessibility}{%
\subsubsection{Transparency and
Accessibility}\label{transparency-and-accessibility}}

It has already been stated that performance cannot be considered for
calibration measures however it is unclear if any of these measures are
even accessible or transparent as they often require expert
interpretation to prevent erroneous conclusions. This is demonstrated by
example using the same data and models as in
Figure~\ref{fig-eval-dcalib}. The predictions from these models are
evaluated with Harrell's C (Section~\ref{sec-eval-crank-disc-conc}), the
Integrated Graf Score (Section~\ref{sec-eval-distr-commonsurv}),
D-Calibration, and Houwelingen's \(\alpha\)
(Table~\ref{tbl-eval-calib}). All measures agree that the SVM performs
poorly. In contrast, whilst the Cox PH (CPH) is well-calibrated
according to both measures, its concordance is quite bad (barely above
baseline). Haider \textit{et al.}[@Haider2020] claimed that if a model
is D-Calibrated then a `patient should believe the prediction from the
survival curve', these results clearly demonstrate otherwise. Measures
of calibration alone are clearly not sufficient to determine if a
survival curve prediction should be `believed' and should therefore be
computed alongside measures of discrimination or scoring rules,
discussed next.

\hypertarget{tbl-eval-calib}{}
\begin{longtable}[]{@{}llll@{}}
\toprule()
Model & KM & CPH & SVM \\
\midrule()
\endfirsthead
\toprule()
Model & KM & CPH & SVM \\
\midrule()
\endhead
\(C_H^1\) & 0.5 & 0.52 & 0.45 \\
\(L_{IGS}^2\) & 0.18 & 0.18 & 0.52 \\
\(H_\alpha^3\) & 0.99 & 1.00 & 15.42 \\
\(D_{\chi^2}^4\) & 2.23\(^*\) & 7.03\(^*\) & \(1.02\times10^{10}\) \\
\bottomrule()
\caption{\label{tbl-eval-calib}Comparison of numerical calibration
metrics. Same models and data as in Figure~\ref{fig-eval-calib-km}:
models trained and tested on randomly simulated data from the
\href{https://cran.r-project.org/package=simsurv}{\texttt{simsurv}}
(Brilleman 2019) package in \(\textbf{mlr3proba}\).}\tabularnewline
\end{longtable}

1. Harrell's C (Section~\ref{sec-eval-crank-disc-conc}). 2. Integrated
Graf Score (Section~\ref{sec-eval-distr-commonsurv}). 3. Houwelingen's
\(\alpha\) (Section~\ref{sec-eval-distr-calib-point}). 4. D-Calibration
statistic. A \('*'\) indicates the model is D-Calibrated according to a
\(\chi^2_9\) test.

\hypertarget{sec-eval-distr}{%
\section{Evaluating Distributions by Scoring
Rules}\label{sec-eval-distr}}

Scoring rules evaluate probabilistic predictions and (attempt to)
measure the overall predictive ability of a model, i.e.~both calibration
and discrimination (Gneiting and Raftery 2007; Murphy 1973). Scoring
rules have been gaining in popularity for the past couple of decades
since probabilistic forecasts were recognised to be superior than
deterministic predictions for capturing uncertainity in predictions (A.
P. Dawid 1984; A. Philip Dawid 1986). Formalisation and development of
scoring rules has primarily been due to Dawid (A. P. Dawid 1984; A.
Philip Dawid 1986; A. Philip Dawid and Musio 2014) and Gneiting and
Raftery (Gneiting and Raftery 2007); though the earliest measures
promoting `'rational'' and `'honest'' decision making date back to the
1950s (Brier 1950; Good 1952). Whilst several scoring rules have been
proposed for classification problems, fewer exist for probabilistic
regression predictions (Gneiting and Raftery 2007) and even fewer for
survival analysis. In practice, only three continuous scoring rules for
regression are employed (though the last two of these are often
conflated), the integrated Brier score (Brier 1950), the log loss (Good
1952), and the integrated log loss.\footnote{These often appear under
  many different names. The Brier score is often referred to as the
  `squared-error loss', or `quadratic score', and the log loss often
  appears as the `log score', `logarithmic loss', `cross-entropy loss',
  or `negative log-likelihood'.} In survival analysis only one scoring
rule was found to be routinely employed. In fact, there is no recognised
definition of a scoring rule in survival analysis, nor definitions for
the fundamental scoring rule properties of (strict) properness. This
section attempts to fill these gaps and to explore the proposed scoring
rules for survival analysis.\footnote{In this section a `scoring rule'
  refers to the general class of measures that evaluate a probabilistic
  prediction and a `loss' refers to the specific function to be
  minimised. As all scoring rules are optimally minimised in this
  survey, the terms are used interchangeably.}

This survey of survival scoring rules covers:

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  basic definitions for scoring rules and properties;
\item
  proposed scoring rules for survival analysis;
\item
  proofs for (strict) properness; and
\item
  baselines and standard errors for scoring rules.
\end{enumerate}

Key contributions include demonstrating that no commonly-utilised
survival scoring rule is proper and deriving a class of strictly proper
outcome-independent scoring rules with strict assumptions (see
Section~\ref{sec-eval-distr-score-surv} for definitions and
Section~\ref{sec-eval-distr-score-proper} for proofs).

Each of these subsections is built up in complexity, starting with
binary classification, then probabilistic regression, and finally
survival. This is required to demonstrate how the survival setting makes
use of the other two for scoring rules.

To recap the notation from (\textbf{chap-surv?}), the three mathematical
settings are defined by the generative processes:

\begin{itemize}
\tightlist
\item
  Regression: \((X,Y) \ t.v.i. \ \mathcal{X}\times \mathcal{Y}\) where
  \(\mathcal{X}\subseteq \mathbb{R}^p\) and
  \(\mathcal{Y}\subseteq \mathbb{R}\).
\item
  Classification: \((X,Y) \ t.v.i. \ \mathcal{X}\times \mathcal{Y}\)
  where \(\mathcal{X}\subseteq \mathbb{R}^p\) and
  \(\mathcal{Y}= \{0,1\}\).
\item
  Survival:
  \((X,T,\Delta,Y,C) \ t.v.i. \ \mathcal{X}\times \mathcal{T}\times \{0,1\}\times \mathcal{T}\times \mathcal{T}\)
  where \(X \subseteq \mathbb{R}^p\) and
  \(\mathcal{T}\subseteq \mathbb{R}_{\geq 0}\), where \(C,Y\) are
  unobservable, \(T := \min\{Y,C\}\), and
  \(\Delta = \mathbb{I}(Y = T)\).
\end{itemize}

As the sections are clearly separated, the overloaded notation will be
clear from context.

\hypertarget{sec-eval-distr-score-reg}{%
\subsection{Classification and Regression Scoring
Rules}\label{sec-eval-distr-score-reg}}

Definitions and losses in the classification setting are first discussed
and then the same in the regression setting.

\hypertarget{classification}{%
\subsubsection{Classification}\label{classification}}

All scoring rules were initially derived from the binary classification
setting, in this case scoring rules are considered to have the form in
Box~\ref{cnj-loss-classif}.

\begin{tcolorbox}[enhanced jigsaw, title={Binary classification loss}, breakable, leftrule=.75mm, rightrule=.15mm, opacityback=0, coltitle=black, colback=white, toptitle=1mm, toprule=.15mm, bottomtitle=1mm, titlerule=0mm, arc=.35mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, left=2mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame]

\leavevmode\vadjust pre{\hypertarget{cnj-loss-classif}{}}%
\begin{conjecture}[]\label{cnj-loss-classif}

Let \(\mathcal{P}\) be some family of distributions over
\(\mathcal{Y}= \{0,1\}\) containing at least two elements. Then for a
predicted distribution in \(\mathcal{P}\), any real-valued function with
the signature
\(L: \mathcal{P}\times \mathcal{Y}\rightarrow \bar{\mathbb{R}}\) will be
considered as a \emph{binary classification loss}.

\end{conjecture}

\end{tcolorbox}

Any arbitrary function can be a binary classification loss as long as it
satisfies the conditions in Box~\ref{cnj-loss-classif}, for example
\(L(\zeta, y) = 0\) is a valid loss for all \(\zeta \in \mathcal{P}\)
and all \(y \in \mathcal{Y}\). Therefore a scoring rule is generally
only considered useful if it satisfies the properties below (Gneiting
and Raftery 2007).

\leavevmode\vadjust pre{\hypertarget{def-classif-proper}{}}%
\begin{definition}[Classification loss
properness]\label{def-classif-proper}

A classification loss
\(L: \mathcal{P}\times \mathcal{Y}\rightarrow \bar{\mathbb{R}}\) is
called:

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  \emph{Proper} if: for any distributions \(p_Y,p\) in \(\mathcal{P}\)
  and for any random variables \(Y \sim p_Y\), it holds that
\end{enumerate}

\[
\mathbb{E}[L(p_Y, Y)] \leq \mathbb{E}[L(p, Y)]
\] i. \emph{Strictly proper} if in addition to being proper it holds,
for the same quantification of variables, that

\[
\mathbb{E}[L(p_Y, Y)] = \mathbb{E}[L(p, Y)] \Leftrightarrow p = p_Y
\]

\end{definition}

Proper scoring rules provide a method of model comparison as, by
definition, predictions closest to the true distribution will result in
lower expected losses.\footnote{Further details for model comparison are
  not provided here as the topic is complex and with many open
  questions, see e.g. (DemÅ¡ar 2006; Dietterich 1998; Nadeau and Bengio
  2003).} On the other hand, if a scoring rule is not proper (`improper'
(Gneiting and Raftery 2007)) then it has no meaningful comparison as it
is unknown if the optimal model would have a lower or higher loss than
any sub-optimal one. A strictly proper scoring rule has additional
important uses such as in model optimisation, i.e.~if a loss is strictly
proper then minimisation of the loss will result in the `optimum score
estimator based on the scoring rule' (Gneiting and Raftery 2007). Whilst
properness is usually a minimal acceptable property for a scoring rule,
it is generally not sufficient on its own. For example, take the
following classification loss,

\[
L: \mathcal{P}\times \mathcal{Y}\rightarrow \bar{\mathbb{R}};
\quad (\zeta, y) \mapsto 42
\] This is proper as the loss, \(L\), is always equal to \(42\) and
therefore is minimised by the true distribution of \(Y\) but the loss is
clearly useless. Properness and strict properness properties are
utilised to determine if a scoring rule is performant and will be stated
(if previously proved/disproved) or proved/disproved for all losses
going forward.

\hypertarget{losses}{%
\subsubsection*{Losses}\label{losses}}

The two most widely used scoring rules for classification are the Brier
score (Brier 1950) and log loss (Good 1952).\footnote{Despite being
  called a `score', the Brier score is in fact a loss to be minimised.}

The (binary classification) log loss is defined by

\[
\begin{split}
&L_{LL}:\mathcal{P}\times \mathcal{Y}\rightarrow \mathbb{R}_{\geq 0}; \\
&(\zeta, y) \mapsto -\mathbb{I}(y = 1)\log(\zeta.p(1)) - \mathbb{I}(y = 0)\log(\zeta.p(0))
\end{split}
\] or more simply

\[
(\zeta, y) \mapsto -\log \zeta.p(y)
\]

The (binary classification) Brier score is defined by

\[
L_{BS}:\mathcal{P}\times \mathcal{Y}\rightarrow [0,1]; \quad
(\zeta, y) \mapsto (y - \zeta.p(y))^2
\]

These are both strictly proper scoring rules (A. Philip Dawid and Musio
2014) and are visualised in Figure~\ref{fig-eval-brierlog} to
demonstrate their properties. The figure highlights the `honesty'
property of the scoring rules (i.e.~their strict properness) as both
losses are shown to be minimised when the true prediction is made. The
plot also demonstrates baselines for interpretability
(Section~\ref{sec-eval-distr-score-base-base}). For the Brier score and
log loss, any result below 0.25 and 0.693 respectively indicates a
prediction better than a constant uninformed prediction of
\(\zeta.p(1) = 0.5\). Therefore classification scoring rules provide a
method to simultaneously encourage honest predictions and have in-built
informative baselines for external reference.

\begin{figure}

{\centering \includegraphics{./images/evaluation/brier_logloss.png}

}

\caption{\label{fig-eval-brierlog}Brier and log loss scoring rules for a
binary outcome and varying probabilistic predictions. x-axis is a
probabilistic prediction in \([0,1]\), y-axis is Brier score (left) and
log loss (right). Blue lines are varying Brier score/log loss over
different predicted probabilities when the true outcome is 1. Red lines
are varying Brier score/log loss over different predicted probabilities
when the true outcome is 0. Both losses are minimised with the correct
prediction, i.e.~if \(\zeta.p(1) = 1\) when \(y = 1\) and
\(\zeta.p(1) = 0\) when \(y = 0\) for a predicted discrete distribution
\(\zeta\).}

\end{figure}

\hypertarget{sec-eval-distr-score-reg-reg}{%
\subsubsection{Regression}\label{sec-eval-distr-score-reg-reg}}

The definition of a probabilistic regression scoring rule follows
similarly to the classification setting after a re-specification of the
target domain.

\begin{tcolorbox}[enhanced jigsaw, title={Probabilistic regression loss}, breakable, leftrule=.75mm, rightrule=.15mm, opacityback=0, coltitle=black, colback=white, toptitle=1mm, toprule=.15mm, bottomtitle=1mm, titlerule=0mm, arc=.35mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, left=2mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame]

\leavevmode\vadjust pre{\hypertarget{cnj-loss-regr}{}}%
\begin{conjecture}[]\label{cnj-loss-regr}

Let \(\mathcal{P}\) be some family of distributions over
\(\mathcal{Y}\subseteq \mathbb{R}\) containing at least two elements.
Then for a predicted distribution in \(\mathcal{P}\), any real-valued
function with the signature
\(L: \mathcal{P}\times \mathcal{Y}\rightarrow \bar{\mathbb{R}}\) will be
considered as a \emph{probabilistic regression loss}.

\end{conjecture}

\end{tcolorbox}

\leavevmode\vadjust pre{\hypertarget{def-regr-proper}{}}%
\begin{definition}[Regression loss properness]\label{def-regr-proper}

A probabilistic regression loss
\(L: \mathcal{P}\times \mathcal{Y}\rightarrow \bar{\mathbb{R}}\) is
called:

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  \emph{Proper} if: for any distributions \(p_Y,p\) in \(\mathcal{P}\)
  and for any random variables \(Y \sim p_Y\), it holds that
\end{enumerate}

\[
\mathbb{E}[L(p_Y, Y)] \leq \mathbb{E}[L(p, Y)]
\] i. \emph{Strictly proper} if in addition to being proper it holds,
for the same quantification of variables, that

\[
\mathbb{E}[L(p_Y, Y)] = \mathbb{E}[L(p, Y)] \Leftrightarrow p = p_Y
\]

\end{definition}

\hypertarget{losses-1}{%
\subsubsection*{Losses}\label{losses-1}}

In the regression setting, classification scoring rules are extended by
instead considering distribution functions and integrating these over
\(\mathcal{Y}\subseteq \mathbb{R}\).

The Integrated Brier Score (IBS) is defined by,\footnote{also known as
  the Continuous Ranked Probability Score (CRPS).}

\begin{equation}\protect\hypertarget{eq-ibs}{}{
L_{IBS}:\mathcal{P}\times \mathcal{Y}\rightarrow [0,1]; \quad
(\zeta, y) \mapsto \int_{\mathcal{Y}} (\mathbb{I}(y \leq \tau) - \zeta.F(\tau))^2 \ d\tau
}\label{eq-ibs}\end{equation}

The extension from the classification Brier score is intuitive, instead
of evaluating if the predicted pmf is `correct' at a single point, the
predicted cumulative distribution function is compared with the true
event status over the entire distribution.

The log loss has two adaptations for continuous predictions. The first
is analogous to the IBS and is termed the Integrated Log Loss (ILL)

\[
\begin{split}
&L_{ILL}:\mathcal{P}\times \mathcal{Y}\rightarrow \mathbb{R}_{\geq 0}; \\
&(\zeta, y) \mapsto - \int_{\mathcal{Y}} \mathbb{I}(y \leq \tau)\log[\zeta.F(\tau)] + \mathbb{I}(y > \tau)\log[\zeta.S(\tau)] \ d\tau
\end{split}
\]

This follows the `longer' form of the binary classification log loss and
considers the cumulative probability of events over all time-points. A
second adaptation to the log loss instead considers the `simpler' form
and replaces the probability mass function with the probability density
function. Again this measure is intuitive as a perfect distributional
prediction will assign the highest point of density to the point at
which the event occurs. This variant of the log loss does not have a
specific name but it is termed here the `density log loss', \(L_{DLL}\),
and is formally defined by,

\[
L_{DLL}:\mathcal{P}\times \mathcal{Y}\rightarrow \mathbb{R}_{\geq 0}; \quad
(\zeta, y) \mapsto - \log[\zeta.f(y)]
\label{eq:density_logloss}
\] where \(\mathcal{P}\) is a family of absolutely continuous
distributions over \(\mathcal{Y}\) with defined density functions.

All three of these losses are strictly proper (Gneiting and Raftery
2007; Gressmann et al. 2018).

\hypertarget{sec-eval-distr-score-surv}{%
\subsection{Survival Scoring Rule
Definitions}\label{sec-eval-distr-score-surv}}

Losses in the survival setting compare predicted survival distributions
to the observed outcome tuple (time and censoring). A large class of
survival losses additionally incorporate an estimator of the unknown
censoring distribution, in order to attempt meaningful comparison. This
second group of losses are termed here as `approximate' losses as the
true censoring distribution is never known and hence an estimate of the
loss is approximate at best.

\begin{tcolorbox}[enhanced jigsaw, title={Survival loss}, breakable, leftrule=.75mm, rightrule=.15mm, opacityback=0, coltitle=black, colback=white, toptitle=1mm, toprule=.15mm, bottomtitle=1mm, titlerule=0mm, arc=.35mm, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, left=2mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame]

\leavevmode\vadjust pre{\hypertarget{cnj-loss-surv}{}}%
\begin{conjecture}[]\label{cnj-loss-surv}

Let \(\mathcal{T}\subseteq \mathbb{R}_{\geq 0}\) and let
\(\mathcal{C}, \mathcal{P}\) be any two distinct families of
distributions over \(\mathcal{T}\), containing at least two elements.
Then,

\begin{itemize}
\tightlist
\item
  Any real-valued function with the signature
  \(L: \mathcal{P}\times \mathcal{T}\times \{0,1\}\rightarrow \bar{\mathbb{R}}\)
  will be considered as a \emph{survival loss}.
\item
  Any real-valued function with the signature
  \(L: \mathcal{P}\times \mathcal{T}\times \{0,1\}\times \mathcal{C}\rightarrow \bar{\mathbb{R}}\)
  will be considered as an \emph{approximate survival loss}.
\end{itemize}

\end{conjecture}

\end{tcolorbox}

Two separate novel definitions for (strict) properness are provided: the
first captures the general case in which no assumptions are made about
the censoring distribution; the second assumes that censoring is
conditionally event-independent.

\leavevmode\vadjust pre{\hypertarget{def-surv-proper}{}}%
\begin{definition}[Survival loss properness]\label{def-surv-proper}

A survival loss
\(L: \mathcal{P}\times \mathcal{T}\times \{0,1\}\rightarrow \bar{\mathbb{R}}\)
is called:

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  \emph{Proper} if: for any distributions \(p_Y, p\) in \(\mathcal{P}\);
  and for any random variables \(Y \sim p_Y\), and \(C\) t.v.i.
  \(\mathcal{T}\); with \(T := \min\{Y,C\}\) and
  \(\Delta := \mathbb{I}(T=Y)\); it holds that,
\end{enumerate}

\[
\mathbb{E}[L(p_Y, T, \Delta)] \leq \mathbb{E}[L(p, T, \Delta)]
\] i. \emph{Strictly proper} if in addition to being proper it holds,
for the same quantification of variables, that

\[
\mathbb{E}[L(p_Y, T, \Delta)] = \mathbb{E}[L(p, T, \Delta)] \Leftrightarrow p = p_Y
\] i. \emph{Outcome-independent proper} if: for any distributions
\(p_Y, p\) in \(\mathcal{P}\); and for any random variables
\(Y \sim p_Y\), and \(C\) t.v.i. \(\mathcal{T}\), where
\(C \perp \!\!\! \perp Y\); with \(T := \min\{Y,C\}\) and
\(\Delta := \mathbb{I}(T=Y)\); it holds that,

\[
\mathbb{E}[L(p_Y, T, \Delta)] \leq \mathbb{E}[L(p, T, \Delta)]
\] i. \emph{Outcome-independent strictly proper} if in addition to being
outcome-independent proper it holds, for the same quantification of
variables, that

\[
\mathbb{E}[L(p_Y, T, \Delta)] = \mathbb{E}[L(p, T, \Delta)] \Leftrightarrow p = p_Y
\]

\end{definition}

These final two definitions are `weaker' but provide a term for losses
that are improper in general but are (strictly) proper under common
(though possibly strict) assumptions about the censoring distribution.
Note by definition that if a loss is:

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  (strictly) proper then it is also outcome-independent (strictly)
  proper;
\item
  (outcome-independent) strictly proper then it is also
  (outcome-independent) proper
\end{enumerate}

Analogous definitions are now provided for approximate survival losses.

\leavevmode\vadjust pre{\hypertarget{def-surv-approx-proper}{}}%
\begin{definition}[Survival approximate loss
properness]\label{def-surv-approx-proper}

An approximate survival loss
\(L: \mathcal{P}\times \mathcal{T}\times \{0,1\}\times \mathcal{C}\rightarrow \bar{\mathbb{R}}\)
is called:

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  \emph{Proper} if: for any distributions \(p_Y, p\) in \(\mathcal{P}\)
  and \(c \in \mathcal{C}\); and for any random variables \(Y \sim p_Y\)
  and \(C \sim c\); with \(T := \min\{Y,C\}\) and
  \(\Delta := \mathbb{I}(T=Y)\); it holds that,
\end{enumerate}

\[
\mathbb{E}[L(p_Y, T, \Delta|c)] \leq \mathbb{E}[L(p, T, \Delta|c)]
\] i. \emph{Strictly proper} if in addition to being proper it holds,
for the same quantification of variables, that

\[
\mathbb{E}[L(p_Y, T, \Delta|c)] = \mathbb{E}[L(p, T, \Delta|c)] \Leftrightarrow p = p_Y
\] i. \emph{Outcome-independent proper} if: for any distributions
\(p_Y, p\) in \(\mathcal{P}\) and \(c \in \mathcal{C}\); and for any
random variables \(Y \sim p_Y\) and \(C \sim c\), where
\(C \perp \!\!\! \perp Y\); with \(T := \min\{Y,C\}\) and
\(\Delta := \mathbb{I}(T=Y)\); it holds that,

\[
\mathbb{E}[L(p_Y, T, \Delta|c)] \leq \mathbb{E}[L(p, T, \Delta|c)]
\] i. \emph{Outcome-independent strictly proper} if in addition to being
outcome-independent proper it holds, for the same quantification of
variables, that

\[
\mathbb{E}[L(p_Y, T, \Delta|c)] = \mathbb{E}[L(p, T, \Delta|c)] \Leftrightarrow p = p_Y
\]

\end{definition}

As the true censoring distribution, \(c\), can never be known exactly,
this definition allows for approximate losses to be proper in the
asymptotic (with infinite training data) if they include estimators of
\(c\) that are convergent in distribution. Proper approximate losses are
therefore useful in modern predictive settings in which `big data' is
very common and thus estimators, such as the Kaplan-Meier, can converge
to the true censoring distribution. However approximate losses may
provide misleading results when the sample size is small; future
research should ascertain what `small' means for individual losses.

\hypertarget{sec-eval-distr-commonsurv}{%
\subsection{Common Survival Scoring
Rules}\label{sec-eval-distr-commonsurv}}

The IBS, ILL, and DLL are now extended to the survival setting by
suitably incorporating censoring and their properness properties are
then discussed in Section~\ref{sec-eval-distr-score-proper}. Measures
are split into `classes', which represent the basic form of the measure.

\hypertarget{squared-survival-losses}{%
\subsubsection{Squared Survival Losses}\label{squared-survival-losses}}

The analogue to the IBS for survival analysis is termed here as the
Integrated Graf Score (IGS) as it was extensively discussed and promoted
by Graf (Graf and Schumacher 1995; Graf et al. 1999).

\leavevmode\vadjust pre{\hypertarget{def-igs}{}}%
\begin{definition}[Integrated Graf score (IGS)]\label{def-igs}

\[
\begin{split}
&L_{IGS}: \mathcal{P}\times \mathcal{T}\times \{0,1\}\times \mathcal{C}\rightarrow [0,1]; \\
&(\zeta, t, \delta|\hat{G}_{KM}) \mapsto \int^{\tau^*}_0  \frac{\zeta.S^2(\tau) \mathbb{I}(t \leq \tau, \delta=1)}{\hat{G}_{KM}(t)} + \frac{\zeta.F^2(\tau) \mathbb{I}(t > \tau)}{\hat{G}_{KM}(\tau)} \ d\tau
\end{split}
\label{eq:igs}
\] where \(\zeta.S^2(\tau) = (\zeta.S(\tau))^2\), analogously for
\(\zeta.F^2\), and \(\tau^* \in \mathcal{T}\) is an upper threshold to
compute the loss up to.

\end{definition}

The IGS consistently estimates the mean square error
\(L(t, S|\tau^*) = \int^{\tau^*}_0 [\mathbb{I}(t > \tau) - S(\tau)]^2 d\tau\),
where \(S\) is the correctly specified survival function, when censoring
is uninformative only (Gerds and Schumacher 2006). This is intuitive as
the IGS utilises the marginal Kaplan-Meier estimator to estimate the
censoring distribution. Therefore CIPCW estimates such as the Cox model
or Akritas estimator could instead be considered for \(\hat{G}_{KM}\)
and these have been demonstrated to have less bias when censoring is
informative (Gerds and Schumacher 2006). However this raises concerns as
now separate models have to be trained and predicted, which could need
validation themselves, and therefore the final measure is even more
difficult to interpret. Graf claimed that the IGS is strictly proper
(Graf et al. 1999) however as no definition of properness was provided
this claim cannot be validated. With the definition of properness
provided in this thesis (Definition~\ref{def-surv-approx-proper}), the
IGS is not even proper
(Section~\ref{sec-eval-distr-score-proper-nonapprox}).

One could instead consider extending the IBS by weighting by
\(\hat{G}_{KM}(t)\) only, giving the following loss.

\leavevmode\vadjust pre{\hypertarget{def-rigs}{}}%
\begin{definition}[Reweighted Integrated Graf score
(IGS\(^*\))]\label{def-rigs}

Let \(\mathcal{P}\) be a family of absolutely continuous distributions
over \(\mathcal{T}\) with defined density functions. Then the
\emph{reweighted Integrated Graf score} (IGS\(^*\)) is defined by

\[\label{eq:wsbs}
\begin{split}
&L_{IGS^*}: \mathcal{P}\times \mathcal{T}\times \{0,1\}\times \mathcal{C}\rightarrow \mathbb{R}_{\geq 0}; \\
&(\zeta, t, \delta|\hat{G}_{KM}) \mapsto \frac{\delta \int_{\mathcal{T}} (\mathbb{I}(t \leq \tau) - \zeta.F(\tau))^2 \ d\tau}{\hat{G}_{KM}(t)}
\end{split}
\]

\end{definition}

IGS\(^*\) is outcome-independent strictly proper
(Section~\ref{sec-eval-distr-score-proper-strict}).

\hypertarget{log-survival-losses}{%
\subsubsection{Log Survival Losses}\label{log-survival-losses}}

The ILL is similarly extended to the Integrated Survival Log Loss (ISLL)
(Graf et al. 1999).

\leavevmode\vadjust pre{\hypertarget{def-isll}{}}%
\begin{definition}[Integrated survival log loss (ISLL)]\label{def-isll}

The \emph{integrated survival log loss} (ISLL) is defined by
\begin{align*}
& L_{ISLL}: \mathcal{P}\times \mathcal{T}\times \{0,1\}\times \mathcal{C}\rightarrow \mathbb{R}_{\geq 0}; \\
& (\zeta,t,\delta|\hat{G}_{KM}) \mapsto -\int^{\tau^*}_0  \frac{\log[\zeta.F(\tau)] \mathbb{I}(t \leq \tau, \delta=1)}{\hat{G}_{KM}(t)} + \frac{\log[\zeta.S(\tau)] \mathbb{I}(t > \tau)}{\hat{G}_{KM}(\tau)} \ d\tau
\label{eq:isll}
\end{align*}

where \(\tau^* \in \mathcal{T}\) is an upper threshold to compute the
loss up to.

\end{definition}

The ISLL is not a proper approximate survival loss
(Section~\ref{sec-eval-distr-score-proper-nonapprox}). Again one could
instead a different weighting in the denominator of the measure to give
the following loss.

\leavevmode\vadjust pre{\hypertarget{def-risll}{}}%
\begin{definition}[Reweighted integrated survival log loss
(ISLL\(^*\))]\label{def-risll}

Let \(\mathcal{P}\) be a family of absolutely continuous distributions
over \(\mathcal{T}\) with defined density functions. Then the
\emph{reweighted integrated survival log loss} (ISLL\(^*\)) is defined
by

\[\label{eq:wsill}
\begin{split}
&L_{ISLL^*}: \mathcal{P}\times \mathcal{T}\times \{0,1\}\times \mathcal{C}\rightarrow \mathbb{R}_{\geq 0};\\
&(\zeta, t, \delta|\hat{G}_{KM}) \mapsto -\frac{\delta \int_{\mathcal{T}} \mathbb{I}(t \leq \tau)\log[\zeta.F(\tau)] + \mathbb{I}(t > \tau)\log[\zeta.S(\tau)] \ d\tau}{\hat{G}_{KM}(t)}
\end{split}
\]

\end{definition}

ISLL\(^*\) is an outcome-independent strictly proper scoring rule
(Section~\ref{sec-eval-distr-score-proper-strict}).

The DLL can be extended in one of two ways, the first simply removes all
censored observations.

\leavevmode\vadjust pre{\hypertarget{def-sdll}{}}%
\begin{definition}[Survival density log loss (SDLL)]\label{def-sdll}

Let \(\mathcal{P}\) be a family of absolutely continuous distributions
over \(\mathcal{T}\) with defined density functions. Then the
\emph{survival density log loss} (SDLL) is defined by

\[
L_{SDLL}: \mathcal{P}\times \mathcal{T}\times \{0,1\}\rightarrow \mathbb{R}_{\geq 0}; \quad (\zeta, t, \delta) \mapsto - \delta \log[\zeta.f(t)]
\label{eq:sdll}
\]

\end{definition}

The SDLL is not a proper scoring rule
(Section~\ref{sec-eval-distr-score-proper-nostrict}). The second
extension to DLL adds the same IPC weighting as IGS\(^*\) and
ISLL\(^*\).

\leavevmode\vadjust pre{\hypertarget{def-wsdll}{}}%
\begin{definition}[Weighted survival density log loss
(SDLL\(^*\))]\label{def-wsdll}

Let \(\mathcal{P}\) be a family of absolutely continuous distributions
over \(\mathcal{T}\) with defined density functions. Then the
\emph{weighted survival density log loss} (SDLL\(^*\)) is defined by

\[\label{eq:wsdll}
L_{SDLL^*}: \mathcal{P}\times \mathcal{T}\times \{0,1\}\times \mathcal{C}\rightarrow \mathbb{R}_{\geq 0}; \quad (\zeta, t, \delta|\hat{G}_{KM}) \mapsto - \frac{\delta \log[\zeta.f(t)]}{\hat{G}_{KM}(t)}
\]

\end{definition}

SDLL\(^*\) is outcome-independent strictly proper
(Section~\ref{sec-eval-distr-score-proper-strict}).

\hypertarget{absolute-survival-losses}{%
\subsubsection{Absolute Survival
Losses}\label{absolute-survival-losses}}

Whilst the IGS and ISLL appear to be the most common losses in the
literature, there is one other class to briefly mention that is based on
absolute error functions. For example, the `absolute Brier score'
proposed by Schemper and Henderson (Schemper and Henderson 2000) which
is based on the mean absolute error. This takes a similar approach to
the IGS and weights the loss at different time-points according to
whether an observation is censored. Studies of this loss have
demonstrated that it depends heavily on correct model specification and
is biased when this is not the case (Choodari-Oskooei, Royston, and
Parmar 2012b; Schmid et al. 2011). To prevent this bias, Schmid
\textit{et al.}[@Schmid2011] proposed the following robust approximate
loss, termed here the `Schmid score',

\[
L(\zeta, t, \delta|\hat{G}_{KM}) = \int^{\tau^*}_0 \frac{\zeta.S(\tau)\mathbb{I}(t \leq \tau, \delta = 1)}{\hat{G}_{KM}(t)} + \frac{\zeta.F(\tau)\mathbb{I}(t > \tau)}{\hat{G}_{KM}(\tau)} \ d\tau
\] where \(\hat{G}_{KM}\) and \(\tau^*\) are as defined above.
Analogously to the IGS, the Schmid score consistently estimates the mean
absolute error when censoring is uninformative (Schmid et al. 2011).
Both scores tend to yield similar results (Schmid et al. 2011).

\hypertarget{comparing-weighting-methods}{%
\subsubsection{Comparing Weighting
Methods}\label{comparing-weighting-methods}}

The IGS and ISLL are well-established survival losses however no
discussion about IGS\(^*\) and ISLL\(^*\) could be found in the
literature. On the surface these measures may look very similar but
there are two important differences, which are illustrated below with
the ISLL and ISLL\(^*\), recall these are defined as:

\[
\begin{split}
&L_{ISLL^*}(\zeta, t, \delta|\hat{G}_{KM}) = -\int^{\tau^*}_0  \frac{\log[\zeta.F(\tau)]\mathbb{I}(t \leq \tau, \delta = 1)}{\hat{G}_{KM}(t)} + \frac{\log[\zeta.S(\tau)]\mathbb{I}(t > \tau, \delta = 1)}{\hat{G}_{KM}(t)} \ d\tau \\
&L_{ISLL}(\zeta,t,\delta|\hat{G}_{KM}) = -\int^{\tau^*}_0  \frac{\log[\zeta.F(\tau)] \mathbb{I}(t \leq \tau, \delta=1)}{\hat{G}_{KM}(t)} + \frac{\log[\zeta.S(\tau)] \mathbb{I}(t > \tau)}{\hat{G}_{KM}(\tau)} \ d\tau
\end{split}
\]

The primary differences are (RHS of equations):

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  Always removing censored observations from \(L_{ISLL^*}\) (even when
  alive) whereas \(L_{ISLL}\) includes all observations when alive.
\item
  \(L_{ISLL^*}\) weights alive and dead observations by
  \(\hat{G}_{KM}(t)\) whereas \(L_{ISLL}\) weights dead observations by
  \(\hat{G}_{KM}(t)\) and alive observations by \(\hat{G}_{KM}(\tau)\)
\end{enumerate}

Analytically the difference between these weighting results has major
implications as \(L_{ISLL^*}\) (and \(L_{IGS^*}\)) is
outcome-independent strictly proper
(Section~\ref{sec-eval-distr-score-proper-strict}) whereas \(L_{ISLL}\)
(and \(L_{IGS}\)) is not even proper
(Section~\ref{sec-eval-distr-score-proper-nonapprox}). However whilst it
has been demonstrated that the IGS consistently estimates the mean
squared error (Gerds and Schumacher 2006), no theory exists for
IGS\(^*\). Similarly no study has been made on ISLL\(^*\) and
SDLL\(^*\).

\hypertarget{pecs}{%
\subsubsection{PECs}\label{pecs}}

As well as evaluating probabilistic outcomes with integrated scoring
rules, non-integrated scoring rules can also be utilised for evaluating
distributions at a single point. For example, instead of evaluating a
probabilistic prediction with the IGS over \(\mathbb{R}_{\geq 0}\),
instead one could compute the IGS at a single time-point,
\(\tau \in \mathbb{R}_{\geq 0}\), only. Plotting these for varying
values of \(\tau\) results in `prediction error curves' (PECs), which
provide a simple visualisation for how predictions vary over the
outcome. PECs are especially useful for survival predictions as they can
visualise the prediction `over time'. PECs should only be used as a
graphical guide and never for model comparison as they only provide
information at a limited number of points. An example is provided in
\textbf{?@fig-eval-pecs} for the IGS; the CPH is consistently better
performing than the SVM.

\begin{figure}

{\centering \includegraphics{./images/evaluation/pecs.png}

}

\caption{\label{fig-eval-eval-pecs}Prediction error curves for the CPH
and SVM models from Section~\ref{sec-eval-distr-calib}. x-axis is time
and y-axis is the IGS computed at different time-points. The CPH (red)
performs better than the SVM (blue) as it scores consistently lower.
Trained and tested on randomly simulated data from
\(\textbf{mlr3proba}\).}

\end{figure}

\hypertarget{sec-eval-distr-score-proper}{%
\subsection{Properness of Survival Scoring
Rules}\label{sec-eval-distr-score-proper}}

As the IBS, ILL, and DLL are all strictly proper regression losses, one
may assume the analogous survival losses are also strictly proper. No
arguments could be found proving/disproving properness of the survival
losses, which may be due to researchers assuming properness followed
from the regression setting. Despite these estimators being demonstrated
to have useful properties and to `perform well' in simulation
experiments (Choodari-Oskooei, Royston, and Parmar 2012a, 2012b; Gerds
and Schumacher 2006), it transpires that none are proper. Key results in
this section are collected in the following summary theorem.

\leavevmode\vadjust pre{\hypertarget{thm}{}}%
Let \(\mathcal{T}\subseteq \mathbb{R}_{>0}\) and let
\(\mathcal{C},\mathcal{P}\) be two distinct families of distributions
over \(\mathcal{T}\) containing at least two elements and let
\(L_R: \mathcal{P}\times \mathcal{T}\rightarrow \bar{\mathbb{R}}\) be a
regression scoring rule. Then the following statements are true:

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  \(L_{SDLL}\) is not: a) outcome-independent proper; b)
  outcome-independent strictly proper; c) proper; d) strictly proper
  ((\textbf{prop-sdll-proper?})).
\item
  Define the approximate survival loss,
\end{enumerate}

\[
L_S: \mathcal{P}\times \mathcal{T}\times \{0,1\}\times \mathcal{C}\rightarrow \bar{\mathbb{R}}; \quad
(\zeta, t, \delta|\hat{G}_{KM}) \mapsto \frac{\delta L_R(\zeta, t)}{\hat{G}_{KM}(t)}
\]

Then \(L_S\) is outcome-independent strictly proper if and only if
\(L_R\) is strictly proper (\textbf{?@thm-surv-regr-proper}). i.
\(L_{SDLL^*}, L_{IGS^*}, L_{ISLL^*}\) are all outcome-independent
strictly proper ((\textbf{prop-approx-proper-losses?})). i. \(L_{IGS}\)
is not: a) outcome-independent proper; b) outcome-independent strictly
proper; c) proper; d) strictly proper ((\textbf{prop-eval-igs?})). i.
\(L_{ISLL}\) is not: a) outcome-independent proper; b)
outcome-independent strictly proper; c) proper; d) strictly proper
((\textbf{prop-eval-isll?})).

The following conjectures are also made:

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  No survival loss,
  \(L: \mathcal{P}\times \mathcal{T}\times \{0,1\}\rightarrow \bar{\mathbb{R}}\),
  is: a) outcome-independent strictly proper; b) strictly proper
  ((\textbf{conj-no-proper-loss?})).
\item
  No approximate survival loss,
  \(L: \mathcal{P}\times \mathcal{T}\times \{0,1\}\times \mathcal{C}\rightarrow \bar{\mathbb{R}}\),
  is strictly proper ((\textbf{conj-approx-strictly?})).
\end{enumerate}

\hypertarget{definitions-and-lemmas}{%
\subsubsection{Definitions and Lemmas}\label{definitions-and-lemmas}}

Important proofs in this subsection follow after these definitions and
lemmas.

\leavevmode\vadjust pre{\hypertarget{lem}{}}%
\label{lem:proper_relate} Let
\(L: \mathcal{P}\times \mathcal{T}\times \{0,1\}\rightarrow \bar{\mathbb{R}}\)
be a survival loss. Let \(p_Y \in \mathcal{P}\), let \(Y \sim p_Y\) and
\(C \ t.v.i. \ \mathcal{T}\) be random variables where
\(C \perp \!\!\! \perp Y\). Let \(T := \min\{Y,C\}\) and
\(\Delta := \mathbb{I}(T=Y)\). Then if
\(\exists p \in \mathcal{P}, p \neq p_Y\), such that

\[
\mathbb{E}[L(p_Y, T, \Delta)] > \mathbb{E}[L(p, T, \Delta)]
\] Then, \(L\) is not:

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  outcome-independent proper;
\item
  outcome-independent strictly proper;
\item
  proper;
\item
  strictly proper.
\end{enumerate}

\leavevmode\vadjust pre{\hypertarget{lem}{}}%
\label{lem:approx_proper_relate} Let
\(L: \mathcal{P}\times \mathcal{T}\times \{0,1\}\times \mathcal{C}\rightarrow \bar{\mathbb{R}}\)
be an approximate survival loss. Let \(p_Y \in \mathcal{P}\) and let
\(c \in \mathcal{C}\). Let \(Y \sim p_Y\) and \(C t.v.i. \mathcal{T}\)
be random variables. Let \(T := min\{Y,C\}\) and
\(\Delta := \mathbb{I}(T=Y)\). Then if
\(\exists p \in \mathcal{P}, p \neq p_Y\), such that

\[
\mathbb{E}[L(p_Y, T, \Delta|c)] > \mathbb{E}[L(p, T, \Delta|c)]
\]\mbox{} Then: \(L\) is not,

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  proper;
\item
  strictly proper.
\end{enumerate}

\leavevmode\vadjust pre{\hypertarget{def-proper-terms}{}}%
\begin{definition}[Properness terminology]\label{def-proper-terms}

Let
\(L: \mathcal{P}\times \mathcal{T}\times \{0,1\}\rightarrow \bar{\mathbb{R}}\)
be a proper scoring rule and let \(p,p_Y\) be distributions in
\(\mathcal{P}\). Let \(Y \sim p_Y\) and \(C\) t.v.i. \(\mathcal{T}\) be
random variables and let \(T := \min\{Y,C\}\) and
\(\Delta := \mathbb{I}(T=Y)\). Then, (Gneiting and Raftery 2007)

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  \(S_L(p_Y, p) := \mathbb{E}[L(p, T, \Delta)]\) is defined as the
  \emph{expected penalty}.
\item
  \(H_L(p_Y) := S_L(p_Y, p_Y)\) is defined as the \emph{(generalised)
  entropy of} \(p_Y \in \mathcal{P}\).
\item
  \(D_L(p_Y, p) := S_L(p_Y, p) - H_L(p_Y)\) is defined as the
  \emph{discrepancy} or \emph{divergence} of \(p \in \mathcal{P}\) from
  \(p_Y \in \mathcal{P}\).
\end{enumerate}

\end{definition}

Similar definitions follow for the expected penalty, entropy, and
divergence for an approximate survival loss
\(L: \mathcal{P}\times \mathcal{T}\times \{0,1\}\times \mathcal{C}\rightarrow \bar{\mathbb{R}}\).

\leavevmode\vadjust pre{\hypertarget{lem}{}}%
\label{lem:divergence} Let
\(L: \mathcal{P}\times \mathcal{T}\times \{0,1\}\rightarrow \bar{\mathbb{R}}\)
be a survival loss and let \(p_Y\) be a distribution in \(\mathcal{P}\).
Let \(Y \sim p_Y\) and \(C\) t.v.i. \(\mathcal{T}\) be random variables
and let \(T := \min\{Y,C\}\) and \(\Delta := \mathbb{I}(T=Y)\). Then,

\begin{itemize}
\tightlist
\item
  \(D_L(p_Y, p) \geq 0\) for all \(p \in \mathcal{P}\) if \(L\) is
  proper
\item
  \(D_L(p_Y, p) > 0\) iff \(L\) is strictly proper and \(p \neq p_Y\)
\end{itemize}

\leavevmode\vadjust pre{\hypertarget{def-joints}{}}%
\begin{definition}[Joint density]\label{def-joints}

Let \(X\) be an absolutely continuous random variable and let \(Y\) be a
discrete random variable. Then,

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  The \emph{mixed joint density} of \((X,Y)\) is defined by
\end{enumerate}

\[
f_{X,Y}(x,y) = f_{X|Y}(x|y)P(Y = y)
\] where \(f_{X|Y}(x|y)\) is the conditional probability density
function of \(X\) given \(Y = y\). i. The \emph{mixed joint cumulative
distribution function} of \((X,Y)\) is given by

\[
F_{X,Y}(x,y) =  \sum_{z \leq y} \int_{u=-\infty}^x f_{X,Y}(u, z) \ du
\]

\end{definition}

\leavevmode\vadjust pre{\hypertarget{lem}{}}%
\label{lem:joints} Let \(X,Y\) be jointly absolutely continuous random
variables supported on the Reals with joint density function
\(f_{X,Y}(x,y)\) and let \(Z = \mathbb{I}(X \leq Y)\), then the mixed
joint density of \((X,Z)\) is given by

\[
f_{X,Z}(x,z) =
\begin{cases}
\int^\infty_x \ f_{X,Y}(x,y) \ dy, & z = 1 \\
\int^x_{-\infty} f_{X,Y}(x,y) \ dy, & z = 0
\end{cases} \\
\]

\leavevmode\vadjust pre{\hypertarget{cor}{}}%
\label{cor:joints} Let \(X,Y\) be jointly absolutely continuous random
variables supported on the Reals with joint density function
\(f_{X,Y}(x,y)\) and let \(Z = \mathbb{I}(X \leq Y)\). As a direct
corollary to \textbf{?@lem-joints}, if \(X\) and \(Y\) are independent
then the mixed joint density of \((X,Z)\) is given by

\[
f_{X,Z}(x,z) =
\begin{cases}
f_X(x)S_Y(x), & z = 1 \\
f_X(x)F_Y(x), & z = 0
\end{cases}
\]

\leavevmode\vadjust pre{\hypertarget{lem}{}}%
\label{lem:joints_rev} Let \(X,Y\) be jointly absolutely continuous
random variables supported on the Reals with joint density function
\(f_{X,Y}(x,y)\) and let \(Z = \mathbb{I}(X \leq Y)\), then the mixed
joint density of \((Y,Z)\) is given by

\[
f_{Y,Z}(y,z) =
\begin{cases}
\int^y_{-\infty} f_{X,Y}(x,y) \ dx, & z = 1\\
\int^\infty_y \ f_{X,Y}(x,y) \ dx, & z = 0
\end{cases} \\
\]

In addition if \(X \perp \!\!\! \perp Y\), then

\[
f_{Y,Z}(y,z) =
\begin{cases}
f_Y(y)F_X(y), & z = 1\\
f_Y(y)S_X(y), & z = 0
\end{cases} \\
\]

\hypertarget{sec-eval-distr-score-proper-nostrict}{%
\subsubsection{No Strictly Proper Survival
Loss}\label{sec-eval-distr-score-proper-nostrict}}

First it is proved that the survival density log loss is not
outcome-independent proper and then a conjecture is made on the strict
properness of all non-approximate losses.

\leavevmode\vadjust pre{\hypertarget{prp}{}}%
\label{prop:sdll_proper} The survival density log loss is not:

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  outcome-independent proper
\item
  outcome-independent strictly proper
\item
  proper
\item
  strictly proper
\end{enumerate}

Not only is the \(L_{SDLL}\) not outcome-independent proper but the
counter-example in the proof is not even a rare edge case. Accounting
for the censoring distribution is attempted by approximate losses, which
are explored after the following conjecture.

\leavevmode\vadjust pre{\hypertarget{cnj}{}}%
\label{conj:no_proper_loss} Let
\(L: \mathcal{P}\times \mathcal{T}\times \{0,1\}\rightarrow \bar{\mathbb{R}}\)
be a survival loss, then \(L\) is not:

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  outcome-independent strictly proper;
\item
  strictly proper;
\end{enumerate}

This conjecture is motivated by identifying that as the true censoring
distribution is always unknown, a counter-example can likely always be
identified to contradict the loss being strictly proper.\footnote{This
  conjecture is being explored as part of a theorem in a paper with
  external collaborators.}

\hypertarget{sec-eval-distr-score-proper-strict}{%
\subsubsection{Strictly Proper Approximate Survival
Losses}\label{sec-eval-distr-score-proper-strict}}

By making strict assumptions about the data, some survival scoring rules
can still be useful, these assumptions are:

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  survival times and censoring times are independent;
\item
  the training dataset is large enough to approximate the censoring
  distribution
\end{enumerate}

With these assumptions, a large class of approximate losses can be
outcome-independent strictly proper.

\leavevmode\vadjust pre{\hypertarget{thm}{}}%
\label{thm:surv_regr_proper} Let
\(L_R: \mathcal{P}\times \mathcal{T}\rightarrow \bar{\mathbb{R}}\) be a
regression loss and define the approximate survival loss

\[
L_S: \mathcal{P}\times \mathcal{T}\times \{0,1\}\times \mathcal{C}\rightarrow \bar{\mathbb{R}}; \quad
(\zeta, t, \delta|\hat{G}_{KM}) \mapsto \frac{\delta L_R(\zeta, t)}{\hat{G}_{KM}(t)}
\] Then \(L_S\) is outcome-independent strictly proper if and only if
\(L_R\) is strictly proper.

\leavevmode\vadjust pre{\hypertarget{prp}{}}%
\label{prop:approx_proper_losses} The following approximate survival
losses are outcome-independent strictly proper:

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  \(L_{SDLL^*}\) -- \textbf{?@eq-wsdll}
\item
  \(L_{IGS^*}\) -- \textbf{?@eq-wsbs}
\item
  \(L_{ISLL^*}\) -- \textbf{?@eq-wsill}
\end{enumerate}

\hypertarget{sec-eval-distr-score-proper-nonapprox}{%
\subsubsection{Non-Proper Approximate Survival
Losses}\label{sec-eval-distr-score-proper-nonapprox}}

From the previous proofs, it would be natural to assume that \(L_{IGS}\)
and \(L_{ISLL}\) are also outcome-independent strictly proper, however
this is not the case.

\leavevmode\vadjust pre{\hypertarget{prp}{}}%
\label{prop:eval_igs} The integrated Graf score, \(L_{IGS}\), is not:

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  outcome-independent proper
\item
  outcome-independent strictly proper
\item
  proper
\item
  strictly proper
\end{enumerate}

Whilst in this counter-example the value of \(D_{IGS}(\xi, \zeta)\) is
very close to zero, there will be other counter-examples with a more
pronounced difference, though this is not required for the proof. Also
note that again this is not a rare edge case, practically this example
is reflected in any real-world scenario in which the prediction is close
to the truth and when the censoring and survival times follow the same
distribution.

\leavevmode\vadjust pre{\hypertarget{prp}{}}%
\label{prop:eval_isll} The integrated survival log-loss, \(L_{ISLL}\),
is not:

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  outcome-independent proper
\item
  outcome-independent strictly proper
\item
  proper
\item
  strictly proper
\end{enumerate}

Proof is not provided but follows with the same argumentation as the
previous proposition and noting that a counter-example can always be
found as \(C\) is unknown and cannot be removed from the equation.

\leavevmode\vadjust pre{\hypertarget{cnj}{}}%
\label{conj:approx_strictly} Let
\(L: \mathcal{P}\times \mathcal{T}\times \{0,1\}\times \mathcal{C}\rightarrow \bar{\mathbb{R}}\)
be an approximate survival loss, then \(L\) is not strictly proper.

This conjecture is motivated by noting that the joint distribution of
\((Y,C)\) is always unknown and thus a suitable counter-example to
strict-properness can likely always be derived.\footnote{This conjecture
  is being explored as part of a theorem in a paper with external
  collaborators.}

\hypertarget{sec-eval-distr-score-base}{%
\subsection{Baselines and ERV}\label{sec-eval-distr-score-base}}

A common criticism of scoring rules is a lack of interpretability,
e.g.~without context an IGS of 0.5 or 0.0005 have no meaning. The final
part of this section very briefly looks at two methods that help
increase the interpretability of scoring rules. Scoring rules may
already be considered less transparent than, say, concordance indices,
as the underlying mathematics is more abstract, and therefore
interpretability of the measure can play a large role in increasing
transparency.

\hypertarget{sec-eval-distr-score-base-base}{%
\subsubsection{Baselines}\label{sec-eval-distr-score-base-base}}

A baseline is either a model or a value that can be utilised to provide
a reference value for a scoring rule, they provide a universal method to
judge all models of the same class by (Gressmann et al. 2018).

In classification, an analytical baseline value can be derived for
measures, i.e.~a baseline model does not actually need to be fit to know
what a `good' value for the loss is. For example it is generally known
that a Brier score is considered `good' if it is below 0.25 or a log
loss if it is below 0.693 (Section~\ref{sec-eval-distr-score-reg}).
Unfortunately simple analytical expressions are not possible in survival
analysis as the losses are dependent on the distributions of both the
survival and censoring time. Therefore all experiments in survival
analysis must include a baseline model that can produce a reference
value in order to derive meaningful results.

There is a clear consensus that the Kaplan-Meier estimator is the most
sensible baseline model for survival modelling (Graf and Schumacher
1995; Lawless and Yuan 2010; Royston and Altman 2013) as it is the
simplest model that can consistently estimate the true survival
function. One could also consider the Akritas estimator as a tunable
conditional baseline (\textbf{?@sec-surv-models-uncond}).

Baseline models are often ignored in experiments when there is
overconfidence in a particular model class, this is frequently the case
in survival analysis in which a novel model class may only be compared
to a Cox PH. This has practical and ethical implications. The
calibration example in Section~\ref{sec-eval-distr-calib-point}
demonstrates how one sophisticated model (CPH) may outperform another
(SVM) and still perform worse than the Kaplan-Meier. Not including
Kaplan-Meier in every experiment could lead to over-confidence in a
novel model that is no better than an unconditional estimator (with no
individual predictive ability).

\hypertarget{sec-eval-distr-score-base-erv}{%
\subsubsection{Explained Residual
Variation}\label{sec-eval-distr-score-base-erv}}

Baseline models can also be utilised to derive a potentially more useful
representation of scoring rules. Any scoring rule can be utilised to
derive a measure of explained residual variation (ERV) (Edward L. Korn
and Simon 1990; Edward L. Korn and Simon 1991) by standardising the loss
with respect to a baseline, say Kaplan-Meier. For any survival loss
\(L\) (analogously for an approximate survival loss), the ERV is,

\[
\label{eq:eval_erv}
\begin{split}
&R_L: \mathcal{P}\times \mathcal{P}\times \mathbb{R}_{\geq 0}^m \times \{0,1\}^m \rightarrow [0,1]; \\
&(\zeta,\xi_0,t,\delta) \mapsto 1 - \frac{\frac{1}{m} \sum^{m}_{i = 1} L(\zeta,t_i,\delta_i)}{\frac{1}{m} \sum^{m}_{i = 1} L(\xi_0,t_i,\delta_i)}
\end{split}
\] where \(t = t_1,...,t_m, \delta = \delta_1,...,\delta_m\) and
\(\zeta\) should be a predicted distribution from a sophisticated
(non-baseline) model and \(\xi_0\) is a prediction from the Kaplan-Meier
estimator.\footnote{\textbf{?@eq-eval-erv} assumes the numerator is
  always less than the denominator or more specifically that the
  sophisticated model is `better' than the baseline; if this is not the
  case then \(R_L^2 < 0\). Therefore this representation should only be
  utilised when the model outperforms the baseline.}

Representing a scoring rule in this manner improves interpretability by
allowing for model comparison whilst simultaneously capturing the
improvement from a baseline. Therefore instead of reporting some
arbitrary loss value, say \(L = 0.1\), one can instead report
\(R_L = 70\%\) which demonstrates a clear improvement (of 70\%) over the
baseline.

\hypertarget{sec-eval-conc}{%
\section{Conclusions}\label{sec-eval-conc}}

This chapter briefly reviewed different classes of survival measures
before focusing on the application of scoring rules to survival
analysis.

One finding of note from the review of survival measures is the
possibility that research and debate has become too focused on measures
of discrimination. For example, many papers state the flaws of Harrell's
C index (GÃ¶nen and Heller 2005; Rahman et al. 2017; Schmid and Potapov
2012; Uno et al. 2007) however few acknowledge that simulation
experiments have demonstrated that common alternatives yield very
similar results to Harrell's C (Rahman et al. 2017; Therneau and
Atkinson 2020) and moreover some promimnent alternatives, such as Uno's
C (Uno et al. 2007), are actually harder to interpret due to very high
variance (Rahman et al. 2017; Schmid and Potapov 2012). Whilst all
concordance indices may be considered accessible and transparent, there
is considerable doubt over their performance due to influence from
censoring.

Focus on discrimination could be the reason for less development in
survival time and calibration measures. There is evidence (Wang, Li, and
Reddy 2017) of the censoring-adjusted RMSE, MAE, and MSE
(Section~\ref{sec-eval-det}) being used in evaluation but without any
theoretical justification, which may lead to questionable results. Less
development in calibration measures is likely due to these measures
being more widely utilised for re-calibration of models and not in model
comparison. The new D-Calibration measure (Andres et al. 2018; Haider et
al. 2020) could prove useful for model comparison however independent
simulation experiments and theoretical studies of the measure's
properties would first be required. No calibration measures can be
considered performant due to a lack of clear definition of a calibration
measure for survival, moreover the reviewed measures may not even be
transparent and accessible due to requiring expert interpretation.

The most problematic findings in this chapter lie in the survival
scoring rules. Section~\ref{sec-eval-distr-score-proper} proved that no
commonly used scoring rule is proper, which means that any results
regarding model comparison based on these measures are thrown into
question. It is also conjectured that no approximate survival loss can
be strictly proper (in general), which is due to the joint distribution
of the censoring and survival distribution always being unknown and
impossible to estimate (though the marginal censoring distribution can
be estimated). As demonstrated in
Section~\ref{sec-eval-distr-score-reg}, a proper scoring rule is not
necessarily a useful one and therefore is not enough for robust model
validation.

As an important caveat to the findings in this chapter, this thesis
presents one particular definition of properness for survival scoring
rules. This definition is partially subjective and other definitions
could instead be considered. Therefore these losses should not be
immediately dismissed outright. As well as deriving new losses that are
(strictly) proper with respect to the definitions provided here,
research may also be directed towards finding other sensible definitions
of properness, or in confirming that the definition here is the only
sensible option. As these are open research questions, the scoring rules
discussed in this chapter are still utilised in evaluation for the
benchmark experiment in (\textbf{chap-bench?}).

This chapter demonstrates that no survival measure on its own can
capture enough information to fully evaluate a survival prediction. No
measure is satisfactorily APT. This is a serious problem that will
either lead (or already is leading) to less interest and uptake in
survival modelling, or misunderstanding and deployment of sub-optimal
models. Evaluation of survival models is still possible but currently
requires expert interpretation to prevent misleading results. If the aim
of a study is solely in assessing a model's discriminatory power, then
measures of discrimination alone are sufficient, otherwise a range of
classes should be included to capture all aspects of model performance.
This thesis advocates reporting \emph{all} of the below to evaluate
model performance:

\begin{itemize}
\tightlist
\item
  \textbf{Calibration}: Houwelingen's \(\alpha\) and (Van Houwelingen
  2007) \emph{and} D-calibration (Haider et al. 2020).
\item
  \textbf{Discrimination}: Harrell's (F. E. J. Harrell et al. 1984)
  \emph{and} Uno's (Uno et al. 2011) C. By including two (or even more)
  measures of concordance, one can determine a feasible range for the
  `true' discriminatory ability of the model instead of basing results
  on a single measure. Time-dependent AUCs can also be considered but
  these may require expert-interpretation and may only be advisable for
  discrimination-specific studies.
\item
  \textbf{Scoring Rules}: When censoring is outcome-independent and a
  large enough training dataset is available, then the re-weighted
  integrated Graf score and re-weighted integrated survival log-loss
  (Section~\ref{sec-eval-distr-commonsurv}). Otherwise the IGS
  \emph{and} ISLL (Graf et al. 1999) which should be interpreted
  together to ensure consistency in results.
\end{itemize}

If survival time prediction is the primary goal then RMSE\(_C\) and
MAE\(_C\) can be included in the analysis however these should not form
the primary conclusions due to a lack of theoretical justification.
Instead, scoring rules should be utilised as a distributional prediction
can always be composed into a survival time prediction
(\textbf{?@sec-car-pipelines-crank}).

All measures discussed in this chapter, with the exception of the
Blanche AUC, have been implemented in \(\textbf{mlr3proba}\)
((\textbf{chap-tools?})). The listed measures above are utilised in the
benchmark experiment in (\textbf{chap-bench?}).

\bookmarksetup{startatroot}

\hypertarget{alternative-methods}{%
\chapter{Alternative Methods}\label{alternative-methods}}

This survey has focused on reviewing machine learning models according
to the three key themes of this thesis \ref{sec:intro_motobj_tap} and
within the thesis scope \ref{sec:surv_scope}. Therefore this survey has
not exhaustively covered all machine learning models and entire model
classes have been omitted; this short section briefly discusses these
classes.

\paragraph{Bayesian Models}

As stated in the thesis scope, only frequentist frameworks are
considered in this thesis. In terms of accessibility, many more
off-shelf survival model implementations exist in the frequentist
framework. Despite this, there is good evidence that Bayesian survival
models, such as Bayesian neural
networks\textasciitilde{}\cite{Bakker2004, Faraggi1997}, can perform
well\textasciitilde{}\cite{Bishop2006} and a survey of these models may
be explored in future work.

\paragraph{Gaussian Processes}

Gaussian Processes (GPs) are a class of model that naturally fit the
survival paradigm as they model the joint distribution of random
variables over some continuous domain, often time. The simplest
extension from a standard Cox model to GP is given by the non-linear
hazard \[
h(\tau|X_i) = h_0(\tau)\phi(g(\tau|X_i)); \quad g(\cdot) \sim \mathcal{G}\mathcal{P}(0, k)
\] where \(\phi\) is a non-negative link function,
\(\mathcal{G}\mathcal{P}\) is a Gaussian
process\textasciitilde{}\cite{Rasmussen2004}, and \(k\) is a kernel
function with parameters to be estimated\textasciitilde{}\cite{Kim2018}.
Hyper-parameters are learnt by evaluating the likelihood
function\textasciitilde{}\cite{Bishop2006} and in the context of
survival analysis this is commonly performed by assuming an
inhomogeneous Poisson
process\textasciitilde{}\cite{Fernandez2016a, Saul2016, Vehtari2013}.
For a comprehensive survey of GPs for survival, see Saul
(2016)\textasciitilde{}\cite{Saul2016}. There is evidence of GPs
outperforming Cox and ML models\textasciitilde{}\cite{Fernandez2016a}.
GPs are excluded from this survey due to lack of implementation (thus
accessibility) and poorer transparency. Future research could look at
increasing off-shelf accessibility of these models.

\paragraph{Non-Supervised Learning}

As well as pure supervised learning, there are also survival models that
use active learning\textasciitilde{}\cite{Nezhad2019}, transfer
learning, or treat survival analysis as a Markov process. As with GPs,
none of these are currently available off-shelf and all require expert
knowledge to be useful. These are not discussed in detail here but a
very brief introduction to the Markov Process (MP) set-up is provided to
motivate further consideration for the area.

\ref{fig:surv_mcsurv} visualises the survival set-up as a Markov chain.
In each discrete time-point \(t_1,...,t_{K-1}\), an individual can
either move to the next time-point (and therefore be alive at that
time-point), or move to one of the absorbing states
(\texttt{Dead\textquotesingle{}\ and}Censored'). The final time-point,
\(t_K\), is never visited as an individual must be dead or censored at
the end of a study, and hence are last seen alive at \(t_{K-1}\). In
this set-up, data is assumed sequential and the time of death or
censoring is determined by the last state at which the individual was
seen to be alive, plus one, i.e.~if an individual transitions from
\(t_k\) to
\texttt{Death\textquotesingle{},\ then\ they\ died\ at\ \$t\_\{k+1\}\$.\ This\ setting\ assumes\ the\ Markov\ property,\ so\ that\ the\ probability\ of\ moving\ to\ the}next'
state only depends on the current one. This method lends itself
naturally to competing risks, which would extend the `Dead' state to
multiple absorbing states for each risk. Additionally, left-censoring
can be naturally incorporated without further
assumptions\textasciitilde{}\cite{Abner2013}.

This set-up has been considered in survival both for Markov models and
in the context of reinforcement
learning\textasciitilde{}\cite{Turing2020}, though the latter case is
underdeveloped and future research could pursue this further.

\bookmarksetup{startatroot}

\hypertarget{survival-software}{%
\chapter{Survival Software}\label{survival-software}}

\bookmarksetup{startatroot}

\hypertarget{conclusions}{%
\chapter{Conclusions}\label{conclusions}}

\bookmarksetup{startatroot}

\hypertarget{references}{%
\chapter*{References}\label{references}}
\addcontentsline{toc}{chapter}{References}

\markboth{References}{References}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-pkgtensorflow}{}}%
Abadi, MartÃ­n, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen,
Craig Citro, Greg S. Corrado, et al. 2015. {``{TensorFlow: Large-Scale
Machine Learning on Heterogeneous Systems}.''}
\url{https://www.tensorflow.org/}.

\leavevmode\vadjust pre{\hypertarget{ref-Akaike1974}{}}%
Akaike, Hirotugu. 1974. {``{A New Look at the Statistical Model
Identification}.''} \emph{IEEE Transactions on Automatic Control} 19
(6): 716--23. \url{https://doi.org/10.1093/ietfec/e90-a.12.2762}.

\leavevmode\vadjust pre{\hypertarget{ref-Akritas1994}{}}%
Akritas, Michael G. 1994. {``{Nearest Neighbor Estimation of a Bivariate
Distribution Under Random Censoring}.''} \emph{Ann. Statist.} 22 (3):
1299--1327. \url{https://doi.org/10.1214/aos/1176325630}.

\leavevmode\vadjust pre{\hypertarget{ref-Andres2018}{}}%
Andres, Axel, Aldo Montano-Loza, Russell Greiner, Max Uhlich, Ping Jin,
Bret Hoehn, David Bigam, James Andrew Mark Shapiro, and Norman Mark
Kneteman. 2018. {``{A novel learning algorithm to predict individual
survival after liver transplantation for primary sclerosing
cholangitis}.''} \emph{PLOS ONE} 13 (3): e0193523.
\url{https://doi.org/10.1371/journal.pone.0193523}.

\leavevmode\vadjust pre{\hypertarget{ref-Bishop2006}{}}%
Bishop, Christopher M. 2006. \emph{{Pattern recognition and machine
learning}}. springer.

\leavevmode\vadjust pre{\hypertarget{ref-Blanche2013}{}}%
Blanche, Paul, Jean-FranÃ§ois Dartigues, and HÃ©lÃ¨ne Jacqmin-Gadda. 2013.
{``{Review and comparison of ROC curve estimators for a time-dependent
outcome with marker-dependent censoring}.''} \emph{Biometrical Journal}
55 (5): 687--704. \url{https://doi.org/10.1002/bimj.201200045}.

\leavevmode\vadjust pre{\hypertarget{ref-Blanche2012}{}}%
Blanche, Paul, AurÃ©lien Latouche, and Vivian Viallon. 2012.
{``{Time-dependent AUC with right-censored data: a survey study},''}
October. \url{https://doi.org/10.1007/978-1-4614-8981-8_11}.

\leavevmode\vadjust pre{\hypertarget{ref-Brier1950}{}}%
Brier, Glenn. 1950. {``{Verification of forecasts expressed in terms of
probability}.''} \emph{Monthly Weather Review} 78 (1): 1--3.

\leavevmode\vadjust pre{\hypertarget{ref-pkgsimsurv}{}}%
Brilleman, Sam. 2019. {``{simsurv: Simulate Survival Data}.''} CRAN.
\url{https://cran.r-project.org/package=simsurv}.

\leavevmode\vadjust pre{\hypertarget{ref-Chambless2006}{}}%
Chambless, Lloyd E, and Guoqing Diao. 2006. {``{Estimation of
time-dependent area under the ROC curve for long-term risk
prediction}.''} \emph{Statistics in Medicine} 25 (20): 3474--86.
\url{https://doi.org/10.1002/sim.2299}.

\leavevmode\vadjust pre{\hypertarget{ref-Chen2012}{}}%
Chen, Hung Chia, Ralph L. Kodell, Kuang Fu Cheng, and James J. Chen.
2012. {``{Assessment of performance of survival prediction models for
cancer prognosis}.''} \emph{BMC Medical Research Methodology} 12.
\url{https://doi.org/10.1186/1471-2288-12-102}.

\leavevmode\vadjust pre{\hypertarget{ref-Choodari2012a}{}}%
Choodari-Oskooei, Babak, Patrick Royston, and Mahesh K. B. Parmar.
2012a. {``{A simulation study of predictive ability measures in a
survival model I: Explained variation measures}.''} \emph{Statistics in
Medicine} 31 (23): 2627--43. \url{https://doi.org/10.1002/sim.4242}.

\leavevmode\vadjust pre{\hypertarget{ref-Choodari2012b}{}}%
---------. 2012b. {``{A simulation study of predictive ability measures
in a survival model II: explained randomness and predictive
accuracy}.''} \emph{Statistics in Medicine} 31 (23): 2644--59.
\url{https://doi.org/10.1002/sim.4242}.

\leavevmode\vadjust pre{\hypertarget{ref-Collett2014}{}}%
Collett, David. 2014. \emph{{Modelling Survival Data in Medical
Research}}. 3rd ed. CRC.

\leavevmode\vadjust pre{\hypertarget{ref-Collins2014}{}}%
Collins, Gary S., Joris A. De Groot, Susan Dutton, Omar Omar, Milensu
Shanyinde, Abdelouahid Tajar, Merryn Voysey, et al. 2014. {``{External
validation of multivariable prediction models: A systematic review of
methodological conduct and reporting}.''} \emph{BMC Medical Research
Methodology} 14 (1): 1--11.
\url{https://doi.org/10.1186/1471-2288-14-40}.

\leavevmode\vadjust pre{\hypertarget{ref-Turing2020}{}}%
Data Study Group Team. 2020. {``{Data Study Group Final Report: Great
Ormond Street Hospital.}''}
\url{https://doi.org/10.5281/zenodo.3670726}.

\leavevmode\vadjust pre{\hypertarget{ref-Dawid1984}{}}%
Dawid, A P. 1984. {``{Present Position and Potential Developments: Some
Personal Views: Statistical Theory: The Prequential Approach}.''}
\emph{Journal of the Royal Statistical Society. Series A (General)} 147
(2): 278--92. \url{https://doi.org/10.2307/2981683}.

\leavevmode\vadjust pre{\hypertarget{ref-Dawid1986}{}}%
Dawid, A Philip. 1986. {``{Probability Forecasting}.''}
\emph{Encyclopedia of Statistical Sciences} 7: 210-----218.

\leavevmode\vadjust pre{\hypertarget{ref-Dawid2014}{}}%
Dawid, A Philip, and Monica Musio. 2014. {``{Theory and Applications of
Proper Scoring Rules}.''} \emph{Metron} 72 (2): 169--83.
\url{https://arxiv.org/abs/arXiv:1401.0398v1}.

\leavevmode\vadjust pre{\hypertarget{ref-Demler2015}{}}%
Demler, Olga V, Nina P Paynter, and Nancy R Cook. 2015. {``{Tests of
calibration and goodness-of-fit in the survival setting}.''}
\emph{Statistics in Medicine} 34 (10): 1659--80.
\url{https://doi.org/10.1002/sim.6428}.

\leavevmode\vadjust pre{\hypertarget{ref-Demsar2006}{}}%
DemÅ¡ar, Janez. 2006. {``{Statistical comparisons of classifiers over
multiple data sets}.''} \emph{Journal of Machine Learning Research} 7
(Jan): 1--30.

\leavevmode\vadjust pre{\hypertarget{ref-Dietterich1998}{}}%
Dietterich, Thomas G. 1998. {``{Approximate Statistical Tests for
Comparing Supervised Classification Learning Algorithms}.''}
\emph{Neural Computation} 10 (7): 1895--1923.
\url{https://doi.org/10.1162/089976698300017197}.

\leavevmode\vadjust pre{\hypertarget{ref-Gerds2006}{}}%
Gerds, Thomas A, and Martin Schumacher. 2006. {``{Consistent Estimation
of the Expected Brier Score in General Survival Models with
Right-Censored Event Times}.''} \emph{Biometrical Journal} 48 (6):
1029--40. \url{https://doi.org/10.1002/bimj.200610301}.

\leavevmode\vadjust pre{\hypertarget{ref-Gneiting2007}{}}%
Gneiting, Tilmann, and Adrian E Raftery. 2007. {``{Strictly Proper
Scoring Rules, Prediction, and Estimation}.''} \emph{American
Statistical Association} 102 (477).
\url{https://doi.org/10.1198/016214506000001437}.

\leavevmode\vadjust pre{\hypertarget{ref-Goli2016a}{}}%
Goli, Shahrbanoo, Hossein Mahjub, Javad Faradmal, and Ali-Reza
Soltanian. 2016. {``{Performance Evaluation of Support Vector Regression
Models for Survival Analysis: A Simulation Study}.''}
\emph{International Journal of Advanced Computer Science and
Applications} 7 (June).
\url{https://doi.org/10.14569/IJACSA.2016.070650}.

\leavevmode\vadjust pre{\hypertarget{ref-GonenHeller2005}{}}%
GÃ¶nen, Mithat, and Glenn Heller. 2005. {``{Concordance Probability and
Discriminatory Power in Proportional Hazards Regression}.''}
\emph{Biometrika} 92 (4): 965--70.

\leavevmode\vadjust pre{\hypertarget{ref-Good1952}{}}%
Good, I J. 1952. {``{Rational Decisions}.''} \emph{Journal of the Royal
Statistical Society. Series B (Methodological)} 14 (1): 107--14.
\url{http://www.jstor.org/stable/2984087}.

\leavevmode\vadjust pre{\hypertarget{ref-Graf1999}{}}%
Graf, Erika, Claudia Schmoor, Willi Sauerbrei, and Martin Schumacher.
1999. {``{Assessment and comparison of prognostic classification schemes
for survival data}.''} \emph{Statistics in Medicine} 18 (17-18):
2529--45.
\url{https://doi.org/10.1002/(SICI)1097-0258(19990915/30)18:17/18\%3C2529::AID-SIM274\%3E3.0.CO;2-5}.

\leavevmode\vadjust pre{\hypertarget{ref-Graf1995}{}}%
Graf, Erika, and Martin Schumacher. 1995. {``{An Investigation on
Measures of Explained Variation in Survival Analysis}.''} \emph{Journal
of the Royal Statistical Society. Series D (The Statistician)} 44 (4):
497--507. \url{https://doi.org/10.2307/2348898}.

\leavevmode\vadjust pre{\hypertarget{ref-Gressmann2018}{}}%
Gressmann, Frithjof, Franz J. KirÃ¡ly, Bilal Mateen, and Harald
Oberhauser. 2018. {``{Probabilistic supervised learning}.''}
\url{https://doi.org/10.1002/iub.552}.

\leavevmode\vadjust pre{\hypertarget{ref-Haider2020}{}}%
Haider, Humza, Bret Hoehn, Sarah Davis, and Russell Greiner. 2020.
{``{Effective ways to build and evaluate individual survival
distributions}.''} \emph{Journal of Machine Learning Research} 21 (85):
1--63.

\leavevmode\vadjust pre{\hypertarget{ref-Harrell1984}{}}%
Harrell, F E Jr, K L Lee, R M Califf, D B Pryor, and R A Rosati. 1984.
{``{Regression modelling strategies for improved prognostic
prediction.}''} \emph{Statistics in Medicine} 3 (2): 143--52.
\url{https://doi.org/10.1002/sim.4780030207}.

\leavevmode\vadjust pre{\hypertarget{ref-Harrell1982}{}}%
Harrell, Frank E., Robert M. Califf, and David B. Pryor. 1982.
{``{Evaluating the yield of medical tests}.''} \emph{JAMA} 247 (18):
2543--46. \url{http://dx.doi.org/10.1001/jama.1982.03320430047030}.

\leavevmode\vadjust pre{\hypertarget{ref-Harrell1996}{}}%
Harrell, Frank E., Kerry L. Lee, and Daniel B. Mark. 1996.
{``{Multivariable Prognostic Models: Issues in Developing Models,
Evaluating Assumptions and Adequacy, and Measuring and Reducing
Errors}.''} \emph{Statistics in Medicine} 15: 361--87.
\url{https://doi.org/10.1002/0470023678.ch2b(i)}.

\leavevmode\vadjust pre{\hypertarget{ref-Hastie2001}{}}%
Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2001. \emph{{The
Elements of Statistical Learning}}. Springer New York Inc.

\leavevmode\vadjust pre{\hypertarget{ref-Heagerty2000}{}}%
Heagerty, Patrick J., Thomas Lumley, and Margaret S. Pepe. 2000.
{``{Time-Dependent ROC Curves for Censored Survival Data and a
Diagnostic Marker}.''} \emph{Biometrics} 56 (2): 337--44.
\url{https://doi.org/10.1111/j.0006-341X.2000.00337.x}.

\leavevmode\vadjust pre{\hypertarget{ref-Heagerty2005}{}}%
Heagerty, Patrick J, and Yingye Zheng. 2005. {``{Survival Model
Predictive Accuracy and ROC Curves Patrick}.''} \emph{Biometrics} 61:
92--105.

\leavevmode\vadjust pre{\hypertarget{ref-Hosmer1980}{}}%
Hosmer, David W, and Stanley Lemeshow. 1980. {``{Goodness of fit tests
for the multiple logistic regression model}.''} \emph{Communications in
Statistics-Theory and Methods} 9 (10): 1043--69.

\leavevmode\vadjust pre{\hypertarget{ref-dataapplied}{}}%
Hosmer Jr, David W, Stanley Lemeshow, and Susanne May. 2011.
\emph{{Applied survival analysis: regression modeling of time-to-event
data}}. Vol. 618. John Wiley {\&} Sons.

\leavevmode\vadjust pre{\hypertarget{ref-Hung2010}{}}%
Hung, Hung, and Chin-Tsang Chiang. 2010. {``{Estimation methods for
time-dependent AUC models with survival data}.''} \emph{The Canadian
Journal of Statistics / La Revue Canadienne de Statistique} 38 (1):
8--26. \url{http://www.jstor.org/stable/27805213}.

\leavevmode\vadjust pre{\hypertarget{ref-HURVICH1989}{}}%
HURVICH, CLIFFORD M, and CHIH-LING TSAI. 1989. {``{Regression and time
series model selection in small samples}.''} \emph{Biometrika} 76 (2):
297--307. \url{https://doi.org/10.1093/biomet/76.2.297}.

\leavevmode\vadjust pre{\hypertarget{ref-Hastie2013}{}}%
James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani.
2013. \emph{{An introduction to statistical learning}}. Vol. 112. New
York: Springer.

\leavevmode\vadjust pre{\hypertarget{ref-Jiao2016}{}}%
Jiao, Yasen, and Pufeng Du. 2016. {``{Performance measures in evaluating
machine learning based bioinformatics predictors for
classifications}.''} \emph{Quantitative Biology} 4 (4): 320--30.

\leavevmode\vadjust pre{\hypertarget{ref-Kamarudin2017}{}}%
Kamarudin, Adina Najwa, Trevor Cox, and Ruwanthi Kolamunnage-Dona. 2017.
{``{Time-dependent ROC curve analysis in medical research: Current
methods and applications}.''} \emph{BMC Medical Research Methodology} 17
(1): 1--19. \url{https://doi.org/10.1186/s12874-017-0332-6}.

\leavevmode\vadjust pre{\hypertarget{ref-KATTAN2003}{}}%
KATTAN, MICHAEL W. 2003. {``{Comparison of Cox Regression With Other
Methods for Determining Prediction Models and Nomograms}.''}
\emph{Journal of Urology} 170 (6S): S6--10.
\url{https://doi.org/10.1097/01.ju.0000094764.56269.2d}.

\leavevmode\vadjust pre{\hypertarget{ref-Kent1988}{}}%
Kent, John T., and John O'Quigley. 1988. {``{Measures of dependence for
censored survival data}.''} \emph{Biometrika} 75 (3): 525--34.
\url{https://doi.org/10.1093/biomet/75.3.525}.

\leavevmode\vadjust pre{\hypertarget{ref-Korn1990}{}}%
Korn, Edward L., and Richard Simon. 1990. {``{Measures of explained
variation for survival data}.''} \emph{Statistics in Medicine} 9 (5):
487--503. \url{https://doi.org/10.1002/sim.4780090503}.

\leavevmode\vadjust pre{\hypertarget{ref-Korn1991}{}}%
Korn, Edward L, and Richard Simon. 1991. {``{Explained Residual
Variation, Explained Risk, and Goodness of Fit}.''} \emph{The American
Statistician} 45 (3): 201--6. \url{https://doi.org/10.2307/2684290}.

\leavevmode\vadjust pre{\hypertarget{ref-Koziol2009}{}}%
Koziol, James A., and Zhenyu Jia. 2009. {``{The concordance index C and
the Mann-Whitney parameter Pr(X{\textgreater{}}Y) with randomly censored
data}.''} \emph{Biometrical Journal} 51 (3): 467--74.
\url{https://doi.org/10.1002/bimj.200800228}.

\leavevmode\vadjust pre{\hypertarget{ref-vanderLaan2007}{}}%
Laan, Mark K van der, Eric C Polley, and Alan E Hubbard. 2007. {``{Super
Learner}.''} \emph{Statistical Applications in Genetics and Molecular
Biology} 6 (1). \url{https://doi.org/10.2202/1544-6115.1309}.

\leavevmode\vadjust pre{\hypertarget{ref-Lawless2010}{}}%
Lawless, Jerald F, and Yan Yuan. 2010. {``{Estimation of prediction
error for survival models}.''} \emph{Statistics in Medicine} 29 (2):
262--74. \url{https://doi.org/10.1002/sim.3758}.

\leavevmode\vadjust pre{\hypertarget{ref-Lazer2014}{}}%
Lazer, David, Ryan Kennedy, Gary King, and Alessandro Vespignani. 2014.
{``{The Parable of Google Flu: Traps in Big Data Analysis}.''}
\emph{Science} 343 (6176): 1203 LP--1205.
\url{https://doi.org/10.1126/science.1248506}.

\leavevmode\vadjust pre{\hypertarget{ref-Li2018}{}}%
Li, Liang, Tom Greene, and Bo Hu. 2018. {``{A simple method to estimate
the time-dependent receiver operating characteristic curve and the area
under the curve with right censored data}.''} \emph{Statistical Methods
in Medical Research} 27 (8): 2264--78.
\url{https://doi.org/10.1177/0962280216680239}.

\leavevmode\vadjust pre{\hypertarget{ref-Liang2008}{}}%
Liang, Hua, and Guohua Zou. 2008. {``{Improved AIC Selection Strategy
for Survival Analysis}.''} \emph{Computational Statistics {\&} Data
Analysis} 52 (5): 2538--48.
\url{https://doi.org/10.1016/j.csda.2007.09.003}.

\leavevmode\vadjust pre{\hypertarget{ref-Murphy1973}{}}%
Murphy, Allan H. 1973. {``{A New Vector Partition of the Probability
Score}.''} \emph{Journal of Applied Meteorology and Climatology} 12 (4):
595--600.
\url{https://doi.org/10.1175/1520-0450(1973)012\%3C0595:ANVPOT\%3E2.0.CO;2}.

\leavevmode\vadjust pre{\hypertarget{ref-Nadeau2003}{}}%
Nadeau, Claude, and Yoshua Bengio. 2003. {``{Inference for the
Generalization Error}.''} \emph{Machine Learning} 52 (3): 239--81.
\url{https://doi.org/10.1023/A:1024068626366}.

\leavevmode\vadjust pre{\hypertarget{ref-Newson1983}{}}%
Newson, Roger B. 1983. {``{Comparing the predictive power of survival
models using Harrell's c or Somers' D}.''} \emph{The Stata Journal}, no.
ii: 1--19.

\leavevmode\vadjust pre{\hypertarget{ref-Ohno-Machado1997}{}}%
Ohno-Machado, Lucila. 1997. {``{A COMPARISON OF COX PROPORTIONAL HAZARDS
AND ARTIFICIAL NEURAL NETWORK MODELS FOR MEDICAL PROGNOSIS The
theoretical advantages and disadvantages of using different methods for
predicting survival have seldom been tested in real data sets {[} 1 , 2
{]}. Althou}.''} \emph{Comput. Biol. Med} 27 (1): 55--65.

\leavevmode\vadjust pre{\hypertarget{ref-Pencina2012}{}}%
Pencina, Michael J., Ralph B. D'Agostino, and Linye Song. 2012.
{``{Quantifying discrimination of Framingham risk functions with
different survival C statistics}.''} \emph{Statistics in Medicine} 31
(15): 1543--53. \url{https://doi.org/10.1002/sim.4508}.

\leavevmode\vadjust pre{\hypertarget{ref-Polley2010}{}}%
Polley, Eric C, and Mark J Van Der Laan. 2010. {``{Super learner in
prediction}.''}

\leavevmode\vadjust pre{\hypertarget{ref-pkgsurvauc}{}}%
Potapov, Sergej, Werner Adler, and Matthias Schmid. 2012. {``{survAUC:
Estimators of prediction accuracy for time-to-event data.}''}

\leavevmode\vadjust pre{\hypertarget{ref-Puddu2012}{}}%
Puddu, Paolo Emilio, and Alessandro Menotti. 2012. {``{Artificial neural
networks versus proportional hazards Cox models to predict 45-year
all-cause mortality in the Italian Rural Areas of the Seven Countries
Study}.''} \emph{BMC Medical Research Methodology} 12 (1): 100.
\url{https://doi.org/10.1186/1471-2288-12-100}.

\leavevmode\vadjust pre{\hypertarget{ref-Rahman2017}{}}%
Rahman, M. Shafiqur, Gareth Ambler, Babak Choodari-Oskooei, and Rumana
Z. Omar. 2017. {``{Review and evaluation of performance measures for
survival prediction models in external validation settings}.''}
\emph{BMC Medical Research Methodology} 17 (1): 1--15.
\url{https://doi.org/10.1186/s12874-017-0336-2}.

\leavevmode\vadjust pre{\hypertarget{ref-Royston2013}{}}%
Royston, Patrick, and Douglas G. Altman. 2013. {``{External validation
of a Cox prognostic model: Principles and methods}.''} \emph{BMC Medical
Research Methodology} 13 (1).
\url{https://doi.org/10.1186/1471-2288-13-33}.

\leavevmode\vadjust pre{\hypertarget{ref-Royston2004}{}}%
Royston, Patrick, and Willi Sauerbrei. 2004. {``{A new measure of
prognostic separation in survival data}.''} \emph{Statistics in
Medicine} 23 (5): 723--48. \url{https://doi.org/10.1002/sim.1621}.

\leavevmode\vadjust pre{\hypertarget{ref-Schemper2000}{}}%
Schemper, Michael, and Robin Henderson. 2000. {``{Predictive Accuracy
and Explained Variation in Cox Regression}.''} \emph{Biometrics} 56:
249--55. \url{https://doi.org/10.1002/sim.1486}.

\leavevmode\vadjust pre{\hypertarget{ref-Schmid2011}{}}%
Schmid, Matthias, Thomas Hielscher, Thomas Augustin, and Olaf Gefeller.
2011. {``{A Robust Alternative to the Schemper-Henderson Estimator of
Prediction Error}.''} \emph{Biometrics} 67 (2): 524--35.
\url{https://doi.org/10.1111/j.1541-0420.2010.01459.x}.

\leavevmode\vadjust pre{\hypertarget{ref-Schmid2012}{}}%
Schmid, Matthias, and Sergej Potapov. 2012. {``{A comparison of
estimators to evaluate the discriminatory power of time-to-event
models}.''} \emph{Statistics in Medicine} 31 (23): 2588--2609.
\url{https://doi.org/10.1002/sim.5464}.

\leavevmode\vadjust pre{\hypertarget{ref-Schwarz1978}{}}%
Schwarz, Gideon. 1978. {``{Estimating the Dimension of a Model}.''}
\emph{The Annals of Statistics} 6 (2): 461--64.
\url{https://doi.org/10.1214/aos/1176344136}.

\leavevmode\vadjust pre{\hypertarget{ref-Schwarzer2000}{}}%
Schwarzer, Guido, Werner Vach, and Martin Schumacher. 2000. {``{On the
misuses of artificial neural networks for prognostic and diagnostic
classification in oncology}.''} \emph{Statistics in Medicine} 19 (4):
541--61.
\url{https://doi.org/10.1002/(SICI)1097-0258(20000229)19:4\%3C541::AID-SIM355\%3E3.0.CO;2-V}.

\leavevmode\vadjust pre{\hypertarget{ref-pkgmlr3proba}{}}%
Sonabend, Raphael, Franz J KirÃ¡ly, Andreas Bender, Bernd Bischl, and
Michel Lang. 2021. {``{mlr3proba: An R Package for Machine Learning in
Survival Analysis}.''} \emph{Bioinformatics}, February.
\url{https://doi.org/10.1093/bioinformatics/btab039}.

\leavevmode\vadjust pre{\hypertarget{ref-Song2008}{}}%
Song, Xiao, and Xiao-Hua Zhou. 2008. {``{A semiparametric approach for
the covariate specific ROC curve with survival outcome}.''}
\emph{Statistica Sinica} 18 (July): 947--65.

\leavevmode\vadjust pre{\hypertarget{ref-pkgsurvival}{}}%
Therneau, Terry M. 2015. {``{A Package for Survival Analysis in S}.''}
\url{https://cran.r-project.org/package=survival}.

\leavevmode\vadjust pre{\hypertarget{ref-Therneau2020}{}}%
Therneau, Terry M., and Elizabeth Atkinson. 2020. {``{Concordance}.''}
\url{https://cran.r-project.org/web/packages/survival/vignettes/concordance.pdf}.

\leavevmode\vadjust pre{\hypertarget{ref-Uno2011}{}}%
Uno, Hajime, Tianxi Cai, Michael J. Pencina, Ralph B. D'Agostino, and L
J Wei. 2011. {``{On the C-statistics for Evaluating Overall Adequacy of
Risk Prediction Procedures with Censored Survival Data}.''}
\emph{Statistics in Medicine} 30 (10): 1105--17.
\url{https://doi.org/10.1002/sim.4154}.

\leavevmode\vadjust pre{\hypertarget{ref-Uno2007}{}}%
Uno, Hajime, Tianxi Cai, Lu Tian, and L J Wei. 2007. {``{Evaluating
Prediction Rules for t-Year Survivors with Censored Regression
Models}.''} \emph{Journal of the American Statistical Association} 102
(478): 527--37. \url{http://www.jstor.org/stable/27639883}.

\leavevmode\vadjust pre{\hypertarget{ref-VanHouwelingen2000}{}}%
Van Houwelingen, Hans C. 2000. {``{Validation, calibration, revision and
combination of prognostic survival models}.''} \emph{Statistics in
Medicine} 19 (24): 3401--15.
\url{https://doi.org/10.1002/1097-0258(20001230)19:24\%3C3401::AID-SIM554\%3E3.0.CO;2-2}.

\leavevmode\vadjust pre{\hypertarget{ref-VanHouwelingen2007}{}}%
---------. 2007. {``{Dynamic prediction by landmarking in event history
analysis}.''} \emph{Scandinavian Journal of Statistics} 34 (1): 70--85.
\url{https://doi.org/10.1111/j.1467-9469.2006.00529.x}.

\leavevmode\vadjust pre{\hypertarget{ref-VolinskyRaftery2000}{}}%
Volinsky, Chris T, and Adrian E Raftery. 2000. {``{Bayesian Information
Criterion for Censored Survival Models}.''} \emph{International
Biometric Society} 56 (1): 256--62.

\leavevmode\vadjust pre{\hypertarget{ref-Wang2017}{}}%
Wang, Ping, Yan Li, and Chandan K. Reddy. 2017. {``{Machine Learning for
Survival Analysis: A Survey}.''} \emph{ACM Computing Surveys} 1 (1).
\url{https://arxiv.org/abs/arXiv:1708.04649v1}.

\leavevmode\vadjust pre{\hypertarget{ref-Wolpert1992}{}}%
Wolpert, David H. 1992. {``{Stacked generalization}.''} \emph{Neural
Networks} 5 (2): 241--59.
https://doi.org/\url{https://doi.org/10.1016/S0893-6080(05)80023-1}.

\end{CSLReferences}

\appendix
\addcontentsline{toc}{part}{Appendices}

\hypertarget{section}{%
\chapter{}\label{section}}


\backmatter

\printindex

\end{document}
