{{< include _setup.qmd >}}

# Alternative Methods

This survey has focused on reviewing machine learning models according to the three key themes of this thesis (@sec-intro-motobj-tap) and within the thesis scope (@sec-surv-scope). Therefore this survey has not exhaustively covered all machine learning models and entire model classes have been omitted; this short section briefly discusses these classes.

\paragraph{Bayesian Models}
As stated in the thesis scope, only frequentist frameworks are considered in this thesis. In terms of accessibility, many more off-shelf survival model implementations exist in the frequentist framework. Despite this, there is good evidence that Bayesian survival models, such as Bayesian neural networks  [@Bakker2004; @Faraggi1997], can perform well  [@Bishop2006] and a survey of these models may be explored in future work.

\paragraph{Gaussian Processes}
Gaussian Processes (GPs) are a class of model that naturally fit the survival paradigm as they model the joint distribution of random variables over some continuous domain, often time. The simplest extension from a standard Cox model to GP is given by the non-linear hazard
$$
h(\tau|X_i) = h_0(\tau)\phi(g(\tau|X_i)); \quad g(\cdot) \sim \calG\calP(0, k)
$$
where $\phi$ is a non-negative link function, $\calG\calP$ is a Gaussian process  [@Rasmussen2004], and $k$ is a kernel function with parameters to be estimated  [@Kim2018]. Hyper-parameters are learnt by evaluating the likelihood function  [@Bishop2006] and in the context of survival analysis this is commonly performed by assuming an inhomogeneous Poisson process  [@Fernandez2016a; @Saul2016; @Vehtari2013]. For a comprehensive survey of GPs for survival, see Saul (2016)  [@Saul2016]. There is evidence of GPs outperforming Cox and ML models  [@Fernandez2016a]. GPs are excluded from this survey due to lack of implementation (thus accessibility) and poorer transparency. Future research could look at increasing off-shelf accessibility of these models.

\paragraph{Non-Supervised Learning}
As well as pure supervised learning, there are also survival models that use active learning  [@Nezhad2019], transfer learning, or treat survival analysis as a Markov process. As with GPs, none of these are currently available off-shelf and all require expert knowledge to be useful. These are not discussed in detail here but a very brief introduction to the Markov Process (MP) set-up is provided to motivate further consideration for the area.

(@fig-surv-mcsurv) visualises the survival set-up as a Markov chain. In each discrete time-point $t_1,...,t_{K-1}$, an individual can either move to the next time-point (and therefore be alive at that time-point), or move to one of the absorbing states ('Dead' and 'Censored'). The final time-point, $t_K$, is never visited as an individual must be dead or censored at the end of a study, and hence are last seen alive at $t_{K-1}$. In this set-up, data is assumed sequential and the time of death or censoring is determined by the last state at which the individual was seen to be alive, plus one, i.e. if an individual transitions from $t_k$ to 'Death', then they died at $t_{k+1}$. This setting assumes the Markov property, so that the probability of moving to the 'next' state only depends on the current one. This method lends itself naturally to competing risks, which would extend the 'Dead' state to multiple absorbing states for each risk. Additionally, left-censoring can be naturally incorporated without further assumptions  [@Abner2013].

This set-up has been considered in survival both for Markov models and in the context of reinforcement learning  [@Turing2020], though the latter case is underdeveloped and future research could pursue this further.

<!-- \begin{figure}
\centering
\begin{tikzpicture}
\node (t0) [state] {$t_1$};
\node (t1) [state, right=of t0] {$t_2$};
\node (t2) [state, right=of t1] {$...$};
\node (t3) [state, right=of t2] {$t_k$};
\node (t7) [state, right=of t3] {$...$};
\node (t8) [state, right=of t7] {$t_{K-1}$};
\node (t4) [state, right=of t8] {$t_K$};
\node (t5) [state, above=of t3] {Dead};
\node (t6) [state, below=of t3] {Censored};

\path[->]
   (t0)  edge (t1)
   (t1)  edge (t2)
   (t2)  edge (t3)
   (t3)  edge (t7)
   (t7)  edge (t8)

   (t0)  edge (t5)
   (t1)  edge (t5)
   (t3)  edge (t5)
   (t8)  edge (t5)

   (t0)  edge (t6)
   (t1)  edge (t6)
   (t3)  edge (t6)
   (t8)  edge (t6)

   (t5) edge [loop above] (t5)
   (t6) edge [loop below] (t6);
\end{tikzpicture}
\caption[Markov survival process]{Markov survival process with probabilities suppressed. $t_1,...,t_K$ are states representing time, 'Censored' and 'Death' are absorbing states corresponding to observed censoring indicator.} {#fig-surv-mcsurv}
\end{figure} -->
