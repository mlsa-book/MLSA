---
abstract: "This chapter introduces the different survival problems and formalizes them as survival tasks. There are four prediction types in survival analysis: relative risks - predicting the risk of an event compared to others in the sample, survival times - predicting the time until an event happens, prognostic index - predicting a linear predictor to assess outcomes based on risk factors, and survival distributions - predicting the probability of an event taking place over time. These reduce to three formal survival tasks: deterministic (survival time), ranking (risks and prognostic index), and probabilistic (distribution). This separation of tasks helps create a taxonomy of survival models and losses that is used throughout the book." 
---

::: {.content-visible when-format="html"}
{{< include _macros.tex >}}
:::

# Survival Task {#sec-survtsk}

{{< include _wip_minor.qmd >}}

A machine learning task specifies a mathematical problem to be solved by an algorithm (@sec-ml-tasks).
Formally, a task is a mapping $f: \calX \rightarrow \calY$ with three components: a description of the input space $\calX$, a description of the target space $\calY$, and a description of the estimation procedure that learns $f$ from data.
A _survival task_ is a machine learning task in which the target space $\calY_S$ corresponds to a _survival prediction type_ (@sec-surv-tsk-predicts), and the learning algorithm $f_S$ is designed to handle censoring and/or truncation while targeting that prediction type (as in the methods introduced in Part III).

Throughout this chapter let  $\calX \subseteq \Reals^{n \times p}$ be a set representing the covariate matrix.
The censoring mechanism does not affect the definition of the prediction types, hence this chapter does not distinguish between right-, left-, or interval-censoring when defining $\calY_S$.

## Survival prediction types {#sec-surv-tsk-predicts}

Survival prediction types describe the codomain $\calY_S$, four are commonly defined:

1. Survival distribution: Probability of the event occurring over time;
2. Relative risk: A scalar quantity representing the risk of event that is meaningful only in comparison to other individuals in the sample;
3. Survival time or time-to-event: A point prediction of the time at which the event of interest will occur;
4. Prognostic index: A risk score usually based on a linear predictor.

Survival distribution predictions are _probabilistic_ as they return a full distribution over time.
Survival time predictions are _deterministic_ point predictions in the sense that they return a single scalar value, though uncertainty remains due to underlying variance.
Relative risk and prognostic index predictions do not directly predict when or if the event of interest will occur, instead they produce scores that can be used to rank or compare an individual's risk to others in the same cohort.

To distinguish the types of 'risk', it may be helpful to view survival distribution predictions as a form of _absolute risk_ prediction: the output has a direct probabilistic interpretation without requiring comparison to other predictions to be meaningfully understood.
By contrast, the other prediction types are _relative risk_ predictions: their scale is directly tied to others in the sample and are most (in some cases _only_) interpretable through comparisons.

These prediction types are closely related.
Relative risks and survival time predictions can be derived from a predicted survival distribution, though the reverse does not hold in general as a single survival time or risk score does not uniquely determine a probability distribution.
Both prognostic index and time-to-event predictions can usually be interpreted as a type of relative risk prediction.
Under (often strict) assumptions, prediction types can be converted between each other.
In fact, many algorithms target a single prediction type but internally compute another as an intermediate step, this pattern will appear throughout Part III, for example with the prognostic index being computed in linear models before being transformed into a survival distribution prediction (some algorithmic examples in @sec-classical).

Despite their close connection, it is essential to keep discussion of prediction types distinct as they are not directly comparable.
For example, it is not meaningful to compare a relative risk score from one model to a survival distribution prediction of another without first transforming the distribution prediction.
Even within a single prediction type, interpretations can be confused.
For example, in some literature a larger value of a risk score implies higher risk of event, whereas in other sources, a larger value implies lower risk.
Distinction of prediction types is also critical for evaluation as each prediction type naturally aligns with different types of metrics, a topic returned to throughout Part II.

In applied predictive modelling, _direct_ survival time prediction is uncommon as time-to-event predictions are difficult to interpret and evaluate under censoring.
Instead, practitioners often report distribution-derived summaries such as $\tau$-year survival probabilities or the predicted median survival time.
Similarly, the prognostic index is more commonly used for model interpretation or inference, whereas relative risk predictions are common in applications such as resource allocation and risk stratification.
Though, as will be seen below, a prognostic index can usually be interpreted as a relative risk.

@fig-survtsk-overview illustrates the different information provided by the different prediction types; the prognostic index is omitted as it would visually look the same as the relative risk prediction type.
An example of tabular survival data is in the top-left panel.
The top-right panel shows predicted survival times, for each observation this is a single scalar value representing the estimated time the event will take place.
The bottom-left panel visualizes relative risk predictions, each subject's score is defined relative to a baseline (an individual with covariates set to zero) and scores can be compared in direction and magnitude.
Finally, the bottom-right panel shows survival distribution predictions, where each observation's survival probability is estimated over time.

![Illustration of prediction types. Tabular survival data (top-left) can be used by an algorithm to make various prediction types, each conveying different information. Survival times (top-right) provide a single number estimating the time until an event takes place. Relative risk scores (bottom-left) compare the risk of event between subjects within the same sample. Survival distributions (bottom-right) estimate the probability of the event taking place over time.](Figures/survtsk/predict_types.png){#fig-survtsk-overview width=100% fig-alt="Graphical illustration of prediction types. Top-left panel is an example of survival data in a table. Top-right panel is horizontal bars for each subject in the data ranging from 0 to approximately their real survival time. Bottom-left panel is vertical bars ranging from -4 to +8, indicating different risk profiles for each subject. Bottom-right panel is step functions, one for each subject, illustrating individual survival function probabilities decreasing over time."}

## Predicting distributions {#sec-survtsk-dist}

Predicting a survival distribution means estimating the probability of an individual experiencing the event of interest from time-point $0$ to $\infty$.
In principle, such predictions are defined over the continuous $\NNReals$.
However, in practice it is more common for predictions to be made over the discrete $\Naturals$.
This reflects the fact that many algorithms rely on discrete, non-parametric estimators or piecewise-constant representations of the underlying distribution prediction.

Theoretically, distributional prediction can target any of the distribution defining functions introduced in @sec-distributions, though predicting $S(t)$ or $h(t)$ is most common.
Mathematically, the survival task associated with the distribution prediction type is defined by $f_S: \calX \rightarrow \calS$, where $\calS \subseteq \Distr(\NNReals)$ denotes a set of distributions on $\NNReals$.
In the most general multi-state setting, this generalizes to $f_S: \calX \rightarrow [0,1]^{q\times q}$ for $q$ different states, this simplifies to $f_S: \calX \rightarrow \calS^q$ in the competing risks setting.

In applied settings, communicating a predicted distribution over time is a daunting task for both clinician and patient.
Instead, distribution predictions are commonly used to derive time-specific survival probabilities, which represent the probability of surviving beyond a relevant time point, for example the probability of being alive ten years after a diagnosis of Huntingdon's disease.
Predicting '$\tau$-year survival probabilities' is sometimes mistakenly framed as a classification problem, in which a model predicts whether an event will occur by a fixed time.
This is misleading as traditional classification models cannot incorporate observations censored before the time horizon of interest, and discarding such observations would bias any results [@DeRong2025].

Survival distributions can also be used for decision making by establishing thresholds on survival probabilities.
For example, in an engineering context, a survival model might be used to estimate the reliability of a jet engine over time, with a maintenance rule defined such that the engine is serviced once the predicted survival probability falls below a predefined reliability threshold (which could be as high as 0.95).

Another source of potential confusion can arise when trying to interpret a survival distribution prediction for an individual in the single-event setting.
In reality, an event either does or does not occur at a specific time, so it is natural to ask what it means to predict an individual's survival probability distribution.
@fig-survtsk-heaviside visualizes what the survival distribution prediction aims to achieve.
The top-left panel shows the idealized 'real-world' survival curves for multiple individuals, each represented by a Heaviside step function that drops from $1$ to $0$ when the individual experiences the event.
The top-right panel highlights a curve for a single event.
The bottom-left panel shows the goal of survival distribution predictions: a smooth survival function that captures the average behavior of these individual events across the population.
Finally, the bottom-right panel shows the same events stratified by a single binary covariate, producing one survival distribution prediction for each subgroup.
In a machine learning task, this stratification process is generalized by conditioning on the full covariate vector, yielding one predicted survival distribution for each individual.

![Demonstrating the relationship from theoretical real-world event curves to survival distribution predictions.](Figures/survtsk/heavisides.png){#fig-survtsk-heaviside width=80% fig-alt="Four graphs with 'survival probability S(t)' on the y-axis and 't' on the x-axis. The top left shows 10 random heaviside functions. The top right shows 1 of these highlighted. The bottom left shows a smooth curve superimposed across all of the same lines. The bottom right shows the same 10 lines but split between red and blue with two smooth curves in the same colors superimposed on top."}

## Predicting relative risks {#sec-survtsk-risk}

Predicting relative risk scores refers to estimating a value that ranks individuals in a cohort according to their predicted risk of experiencing the event.
These scores are meaningful only in comparison to other individuals in the same cohort used to train the model; they cannot be interpreted in isolation, nor can they be compared to scores produced by a different model, except under very strong assumptions.
The interpretation of these scores can also differ across model classes, parameterizations, and even software implementations.
For example, some models produce scores where larger values correspond to higher risk, whereas others produce scores where smaller values correspond to higher risk. 
To avoid ambiguity, throughout this book larger values always correspond to higher risk and smaller values correspond to lower risk.
In machine learning terms, the relative risks prediction is the problem of estimating $f_S: \calX \rightarrow \Reals$.

As an example of this prediction type, consider three individuals, $\{i,j,k\}$ with predicted risks $\{0.5, 10, 0.1\}$, respectively.
From these values, two broad types of conclusion can be drawn.

1. Conclusions comparing individuals

* The corresponding ranks for $\{i,j,k\}$ are $\{2,3,1\}$.
* $k$ has the lowest risk and $j$ the highest risk.
* The risk of $i$ is slightly higher than that of $k$, whereas $j$'s risk is substantially higher than both.

2. Conclusions comparing risk groups:

* Thresholding at $0.4$ classifies $k$ as low-risk and $i$ and $j$ as high-risk.
* Thresholding at $1.0$ classifies $i$ and $k$ as low-risk and $j$ as high-risk.

As in other domains, differences in relative risks should always be interpreted cautiously.
In the example above, $j$'s relative risk is 100 times that of $k$; however, if $k$'s absolute probability of experiencing the event is $0.0001$, then $j$'s absolute probability remains small at $0.01$.

Estimation and interpretation of risks in the competing risks settings follows similar principles.
Though, one must take care to clearly identify if the task of interest is to predict risks for each of the $q$ causes, $f_S: \calX \rightarrow \Reals^q$, or a single all-cause risk.
In multi-state models, the notion of a single scalar 'risk' is less clearly defined and any risk-based summaries derived from survival probabilities should be interpreted with caution.

### Distributions and risks

In general it is not possible to uniquely recover a survival distribution from a relative risk score, except in very specific cases (discussed in @sec-survtsk-PI).
The reverse direction, deriving a risk score from a predicted survival distribution, is more common.
One stable approach to compute a risk score is by calculating the 'ensemble mortality' or 'expected mortality' [@Ishwaran2008].
The expected mortality for an individual $i$ is defined as

$$
\sum_{\tau \in \calT} -\log(\hatS_i(\tau)) = \sum_{\tau \in \calT} \hatH_i(\tau),
$$

where $\hatS_i$ is the predicted survival function, $\hatH_i$ is the corresponding cumulative hazard, and $\calT$ is the set of observed time points.
This quantity represents the expected number of events among individuals with similar covariate profiles to $i$.
A larger value therefore indicates that $i$ has a higher risk profile, hence being a suitable quantity to represent a relative risk score.
As a concrete example, consider two individuals, $i$ and $j$, with predicted survival probabilities at times $\calT = \{0,1,2,3\}$:

$$
\begin{aligned}
&(\tau, \hatS_i(\tau)) = (0, 1), (1, 0.8), (2, 0.4), (3, 0.15), \\
&(\tau, \hatS_j(\tau)) = (0, 1), (1, 0.6), (2, 0.4), (3, 0.35).
\end{aligned}
$$

From these values alone, it is not immediately obvious which individual would be considered at higher risk.
The corresponding cumulative hazards are

$$
\begin{aligned}
&(\tau, \hatH_i(\tau)) = (0, 0), (1, 0.10), (2, 0.40), (3, 0.82), \\
&(\tau, \hatH_j(\tau)) = (0, 0), (1, 0.22), (2, 0.40), (3, 0.46).
\end{aligned}
$$

Using the ensemble mortality approach, this yields relative risk scores of 

$$
\begin{aligned}
&\sum_{\tau \in \calT} \hatH_i(\tau) = 0 + 0.10 + 0.40 + 0.82 = 1.32, \\
&\sum_{\tau \in \calT} \hatH_j(\tau) = 0 + 0.22 + 0.40 + 0.46 = 1.08.
\end{aligned}
$$

Under this method, individual $i$ is considered to be at 1.2 times higher risk than individual $j$.

## Predicting survival times {#sec-survtsk-time}

Predicting a survival time refers to estimating when an individual will experience the event of interest.
Mathematically, this corresponds to estimating $f_S: \calX \rightarrow \PReals$, that is, predicting a single non-negative value on $[0,\infty]$.

From a practical perspective, the expected time-to-event may appears to be an attractive prediction type as it initially appears simple to interpret and communicate.
However, evaluating survival time point predictions is challenging and generally ill-advised.
To illustrate this, consider an individual censored at time $t=5$.
There is no way to know if the event would have occurred at $\tau=6$ or $\tau=600$; all that is known is that the event did not occur before $t=5$.
As a result, it is impossible to assess how close a time prediction is to the true, unobserved event time.

Even when a prediction is clearly incorrect, its degree of error cannot be quantified.
For the same individual censored at $t=5$, suppose a model predicts a survival time of $\hat{t} = 3$.
This prediction is clearly wrong as the event did not occur before $t=5$.
However, the prediction might only be slightly wrong if the true event time were $\tau=6$, or extremely wrong if the true event time were $\tau=600$.
Consequently, any evaluation of survival time point predictions is misleading.
As such, this book recommends either directly predicting survival times and treating them as a special case of relative risk prediction, or directly predicting and evaluating a survival distribution and then deriving time-oriented summaries.

In the competing risks setting, 'survival time' is even mre ill-defined as it is ambiguous whether this refers to the time until a specific event or until any event takes place.
For multi-state models, there is no single notion of a 'survival time', instead one could estimate the sojourn time, the expected time spent in a given state, using the estimated transition probabilities.
Sojourn times are particularly well-defined in Markov or semi-Markov models, where sojourn times follow from standard stochastic process theory.
These derivations are beyond the scope of this book; for further detail, see for example [@Ibe2013].

### Times and risks

Converting a time-to-event prediction to a risk prediction is trivial as the former is a special case of the latter.
An individual with a longer survival time will have a lower overall risk: if $\hat{y}_i,\hat{y}_j$ and $\hat{r}_i,\hat{r}_j$ are survival time and ranking predictions for subjects $i$ and $j$ respectively, then $\hat{y}_i > \hat{y}_j \Rightarrow \hat{r}_i < \hat{r}_j$.
It is not possible to make the transformation in the opposite direction without making significant assumptions as risk predictions are usually abstract quantities that rarely map to realistic survival times.

### Times and distributions

Moving from a survival time to a distribution prediction is rare given the reasons outlined above.
In analogy to regression, one could take a survival time point prediction and construct a survival distribution by assuming a distributional form, for example $\operatorname{TruncatedNormal}(\haty, \sigma, a=0, b=\infty)$ where $\haty$ is the predicted expected survival time, $\sigma$ is a parameter representing variance to be estimated or assumed, and $\{a, b\}$ is the distribution support.
In survival analysis, this method clearly has drawbacks given the number of required assumptions and as such is not commonly seen in practice.

In the other direction, it is more common to reduce a distribution prediction to a survival time prediction by *attempting* to compute the mean or median of the distribution.
When there is no censoring, one can calculate the expectation from the predicted survival function using the 'Darth Vader rule' [@Muldowney2012]:

$$
\EE[Y] = \int^\infty_0 S_Y(y) \ \dy
$$ {#eq-darth}

However, this rule is often not usable in practice as the presence of censoring results in estimated survival distributions being 'improper'.
A valid probability distribution for a random variable $Y$ satisfies: $\int f_Y = 1$, $S_Y(0) = 1$ and $S_Y(\infty) = 0$.
This last condition is often violated in survival distribution predictions, which often use non-parametric estimators as an interim step before making full distribution predictions (some examples in @sec-classical-cox), resulting in improper distributions.
To see why this is the case, recall from @sec-surv-km that the Kaplan-Meier estimator is defined as:

$$
\KMS(\tau) = \prod_{k:t_{(k)} \leq \tau}\left(1-\frac{d_{t_{(k)}}}{n_{t_{(k)}}}\right)
$$ 

This only reaches zero if every individual at risk at the last observed time-point experiences the event: $d_{t_{(k)}} = n_{t_{(k)}}$.
In practice, due to administrative censoring, there will almost always be censoring at the final time-point.
As a result, $d_{t_{(k)}} < n_{t_{(k)}}$ and $\hatS(\infty) > 0$.
Heuristics have been proposed to address this including linear extrapolation to zero, or dropping the curve to zero at the final time-point, however these can introduce significant bias in the estimated survival time [@Han2022; @Sonabend2022].
Another possibility is to instead report the median survival time, but this is only defined if the survival curves drop below $0.5$ within the observed period, which is not guaranteed [@Haider2020].

One alternative is to estimate the *restricted mean survival time* (RMST) [@Han2022; @andersen.regression.2004].
In contrast to (@eq-darth), which integrates the survival curve over the entire time axis, the RMST places an upper-bound on the integral:

$$
\RMST(\tau) = \int^\tau_0 S_Y(y) \ \dy
$$ {#eq-rmst}

It follows from (@eq-darth) that $\RMST(\infty) = \EE[Y]$ .
Whereas (@eq-darth) represents the average survival over $[0,\infty)$, (@eq-rmst) represents the average survival time up to $\tau$.
Equivalently, the RMST is the average amount of time each individual spends without experiencing the event up to $\tau$.
The RMST treats all events happening after $\tau$ as if they happened at $\tau$.
Hence, it is a truncated expectation, estimating: $\EE[\min(Y, \tau)]$

For example, say individuals are observed over times $[0,100]$ and administrative censoring is present in the data, then $\hatS(\tau)$ is unknown for $\tau > 100$ and $\EE[Y]$ cannot be reliably computed.
However, one can compute $\RMST(100)$ which provides an interpretable lower bound for the mean survival time: $\RMST(100) \leq \EE[Y]$.
This avoids assumptions beyond $\tau=100$ and offers an interpretable prediction: "the average survival time is at least $\RMST(100)$" (@fig-survtsk-rmst).
The RMST avoids the pitfalls of computing the mean and median by remaining valid even when the predicted distribution is improper, provided that $\tau$ is chosen within the range of observed follow-up times.
Note this whilst this results in a prediction on the scale of a survival time, it is _not_ a survival time prediction as it does not represent $\EE[Y]$.

As a worked example, say for an individual, $i$, we have: $(t, \hatS_i(t)) = (0, 1), (1, 0.8), (2, 0.4), (3, 0.15)$.
Then, $\RMST(3) \approx 1 + 0.8 + 0.4 = 2.2$ and $\RMST(4) \approx 1 + 0.8 + 0.4 + 0.15 = 2.35$.
$\RMST(3)$ reflects the expected time without experiencing the event up to $\tau=3$, which means treating all observations as if the event occurred at $\tau=3$ (unless it occurred sooner).
$\RMST(4)$ incorporates one more unit of follow-up, including the fourth survival probability in this case.
In this way, the $\RMST(\tau)$ summarizes the average survival experience up until $\tau$, smaller values of $\tau$ emphasize near-term survival whereas larger values approach the full mean survival time (if estimable).
The actual choice of $\tau$ varies by the use-case.

![Illustrating the RMST at the final observed time-point. The RMST is the area under the survival curve up to the point of interest. The red vertical line represents the final observed time-point, the survival curve (blue) after that point is unknown.](Figures/survtsk/rmst.png){#fig-survtsk-rmst width=80% fig-alt="Graph with 'survival probability S(t)' on the y-axis and 'Time' on the x-axis. A vertical red-line at x=100 represents the cut-off point. The area under the curve before the cut-off point is highlighted in blue, representing the RMST(100)."}

## Prognostic index predictions {#sec-survtsk-PI}

In medical terminology (often used in survival analysis), a prognostic index is a tool that predicts outcomes based on risk factors.
Given covariates, $\XX \in \Reals^{n \times p}$, and coefficients, $\bsbeta \in \Reals^p$, the *linear predictor* is defined as $\bseta := \XX\bsbeta$.
Applying some function $g$, which could simply be the identity function $g(x) = x$, yields a *prognostic index*, $g(\bseta)$.
A prognostic index can serve several purposes, including:

1. Scaling or normalization: simple functions to scale the linear predictor can better support interpretation and visualisation;
2. Ensuring meaningful results: for example the transformation $g(\bseta) = \exp(\bseta)$ has the effect that covariates then act multiplicatively on the resulting prognostic score, which is useful for models where the covariates rescale the underlying risk instead of additive shifts (explored further in @sec-classical-cox);
3. Aiding in interpretability: in some cases this could simply be $g(\bseta) = -\bseta$ to ensure the 'higher value implies higher risk' interpretation.

Interpretation and treatment of prognostic indices in the event history analysis setting follows in the same way as above but with a cause-specific framing.

### Prognostic index, risks, and times

As above, a prognostic index is designed to provide a quantitative summary for assessing the risk of an observation experiencing an event and is therefore naturally interpreted as a relative risk score.
The distinction between prognostic index and relative risk is relevant when moving beyond linear models; for example, @sec-boost and @sec-svm will introduce models that directly predict risk in a way that cannot be expressed as a transformation of covariates.
Therefore, it is meaningful to refer to something as prognostic insofar as it tells a practitioner that the quantity is interpretable in and of itself, similarly with survival times.

When treating a prognostic index as a relative risk, it is important to ensure that both the magnitude and sign of the index are concordant with the above definition of a relative risk.
Meaning, larger values should correspond to a higher risk of experiencing the event.

As with relative risk predictions more generally, there is no direct relationship between the prognostic index and survival time, though a prognostic index is often a first step to a survival distribution prediction.

### Prognostic index and distributions

In general, a prognostic index cannot be uniquely recovered from a predicted survival distribution without additional modelling assumptions.
By contrast, construction of a survival distribution conditional on a prognostic index is very common in survival analysis.
Many survival models predict survival distributions by first making a group-wise survival distribution estimate (often with non-parametric estimators such as those in @sec-surv-estimation-non-param) and then combining this estimate with a prediction of an individual's prognostic index.
The precise manner in which these components are combined is algorithm-specific and as such is explored in detail in Part III.
To give a concrete illustration in this section, one class of model known as proportional hazards models, construct survival predictions as

$$
S(\tau|\xx) = S_0(\tau)^{\exp(\eta)},
$$

where $S_0(\tau)$ is known as the baseline survival function, and $\eta$ is the prognostic index.

## Conclusion

:::: {.callout-warning icon=false}

## Key takeaways

* Survival prediction tasks fall into three categories: probabilistic (predicting survival distributions), deterministic (predicting survival times), and ranking (predicting relative risks or prognostic indices).
* Prediction types are not directly interchangeable; transforming between them requires assumptions and often changes the quantity being estimated.
* Distribution predictions are the most informative and under suitable assumptions can be used to derive other prediction types.
* Ranking predictions are widely used in practice, but their interpretation is relative and restricted to within-sample comparisons.

::::


:::: {.callout-important icon=false}

## Limitations

* Transformations between prediction types generally rely on modeling assumptions that may not be testable from the data alone.
* Some prediction types, such as survival time predictions, whilst seeming intuitive on the surface, are generally very difficult to precisely estimate and can be harder to interpret.
* In many cases, extensions to event history analysis are unnatural and poorly defined.
* In applied settings, practical constraints (such as available software or institutional preferences) may dictate prediction types.

::::

:::: {.callout-tip icon=false}

## Further reading

* @Sonabend2022 and @Haider2020 discuss methods methods to transforming survival distribution predictions to relative risk and survival time predictions.
* For deeper discussion of the restricted mean survival time, see @Uno2014, @Han2022, and @Royston2011.
* @VanHouwelingen2007 provides a comprehensive overview of dynamic survival tasks that update predictions over time.
* See @Kalbfleisch1980 for more academic discussion about different ways to transform linear predictors to survival distributions and their relationships.
* See @Candido2017 for a real-world example of how survival distribution predictions can be computed in a healthcare setting.

::::
