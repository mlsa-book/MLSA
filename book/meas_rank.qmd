---
abstract: TODO (150-200 WORDS)
---

{{< include _setup.qmd >}}

# Evaluating Continuous Rankings {#sec-eval-crank}

{{< include _wip.qmd >}}

The next category of measures evaluate the performance of survival models based on continuous ranking predictions.
Established measures in this category are exclusively measures of discrimination, which identify how well a model can separate observations into different risk groups.
A model has perfect discrimination if it correctly predicts that observation $i$ is at higher risk of the event of interest than observation $j$ if observation $i$ experiences the event first, where 'risk' is taken to be the continuous ranking prediction.
All discrimination measures are ranking measures, which means that the exact predicted value is irrelevant, only its relative ordering is required.
For example given predictions $\{100,2,299.3\}$, only their rankings, $\{2,1,3\}$, are used by measures of discrimination.
This chapter begins with time-independent measures, which measure concordance between pairs of observations at a single observed time point.
The next section focuses on time-dependent measures, which are primarily AUC-type measures that evaluate discrimination over all possible unique time-points and integrate the results for a single metric.

## Concordance Indices {#sec-eval-crank-disc-conc}

The simplest form of discrimination measures are concordance indices, which, in general, measure the proportion of cases in which the model correctly separates a pair of observations into 'low' and 'high' risk.
Concordance indices can be best understood in terms of two key definitions: 'comparable', and 'concordant'.

::: {#def-concordance}

## Concordance

Let $(i,j)$ be a pair of observations with outcomes $\{(t_i,\delta_i),(t_j,\delta_j)\} \iid (T,\Delta)$ and let $y_i,y_j \in \Reals$ be their respective risk predictions. Then $(i,j)$ are called [@Harrell1984; @Harrell1982]:

* *Comparable* if $t_i < t_j$ and $\delta_i = 1$;
* *Concordant* if $y_i > y_j$.^[Recall (@sec-surv-set-types) this book defines the risk ranking such that a higher value implies higher risk of death and so a pair is concordant if $\II(t_i < t_j, y_i > y_j)$, whereas this would be $\II(t_i < t_j, y_i < y_j)$ if a higher value implied a lower risk of death.]

:::

A concordance index (C-index) is a weighted proportion of the number of concordant pairs over the number of comparable pairs.
As such, a C-index value will always be between $[0, 1]$ with $1$ indicating perfect separation, $0.5$ indicating no separation, and $0$ being separation in the 'wrong direction', i.e. all high risk observations being ranked lower than all low risk observations.
Concordance measures may either be reported as a value in $[0,1]$, a percentage, or as 'discriminatory power', which refers to the percentage improvement of a model's discrimination above the baseline value of $0.5$.
For example, if a model has a concordance of $0.8$ then its discriminatory power is $(0.8-0.5)/0.5 = 60%$.
This representation of discrimination provides more information by encoding the model's improvement over some baseline although is often confused with reporting concordance as a percentage (e.g. reporting a concordance of 0.8 as 80%), this representation closely relates to the ERV representation scoring rules.

```{r, echo=FALSE,warning=FALSE}
learn("sec-eval-distr-score-base", "calculating measures with respect to an arbitrary baseline", ttl_fmt = "Learn more about baseline comparison")
```

### Survival Concordance Indices

Common concordance indices in survival analysis can be expressed as a general measure:

Let $y = y_1,...,y_m$ be predicted risks, $(t, \delta) = (t_1, \delta_1),...,(t_m, \delta_m)$ be observed outcomes, let $W$ be some weighting function, and let $\tau$ be a cut-off time.
Then, the *survival concordance index* is defined by,

$$
C(y, t, \delta|\tau) \mapsto \frac{\sum_{i\neq j} W(t_i)\II(t_i < t_j, y_i > y_j, t_i < \tau)\delta_i}{\sum_{i\neq j}W(t_i)\II(t_i < t_j, t_i < \tau)\delta_i}
$$

The choice of $W$ specifies a particular evaluation measure (see below).
The use of the cut-off $\tau$ mitigates against decreased sample size (and therefore high variance) over time due to the removal of censored observations.
For $\tau$ to be comparable across datasets, a common choice would be to set $\tau$ as the time at which 80\%, or perhaps 90\% of the data have been censored or experienced the event.

There are multiple methods for dealing with tied predictions and times.
Strictly, tied times are incomparable given the definition of 'comparable' given above and hence are usually ignored in the numerator.
On the other hand, ties in the prediction are more problematic but a common method is to set a value of $0.5$ for observations when $y_i = y_j$ [@Therneau2020].
Specific concordance indices can be constructed by assigning a weighting scheme for $W$ which generally depends on the Kaplan-Meier estimate of the survival function of the censoring distribution fit on training data, $\KMG$, or the Kaplan-Meier estimate for the survival function of the survival distribution fit on training data, $\KMS$, or both.
Measures that use $\KMG$ are referred to as Inverse Probability of Censoring Weighted (IPCW) measures as the estimated censoring distribution is utilised to weight the measure in order to compensate for removed censored observations.
This is visualised in @fig-ipcw where $\KMS$, $\KMG$, and $\KMG^{-2}$ are computed based on the `whas` dataset [@dataapplied].

```{r, echo=FALSE,messages=FALSE,warnings=FALSE}
#| fig-cap: "Kaplan-Meier estimates trained on the `whas` dataset. x-axis is time variable. y-axis is outputs from one of three functions: S(t), survival function based on original `whas` dataset (blue), G(t), survival function based on the censoring distribution of the `whas` dataset (red), and 1/G(t)^2 (green). The vertical gray line at t=1267 represents the point at which G(t)<0.6."
#| fig-alt: "Line graph with three lines in green, red, and blue. x-axis is labelled 't' and ranges from 0 to 6000. y-axis is labelled 'W(t)' and ranges from 0 to 5. Legend for lines is titled 'W' with entries 'KMG' for the red line, 'KMG^-2' for the green line, and 'KMS' for the blue line. The blue line starts at (0,1), moves to around (1000, 0.5) then is relatively flat. The red line roughly linearly decreases from (0,1) to (6000,0). The green line sharply increases between (1, 1000) to (5, 3500). A vertical gray line passes through (0, 1267)."
#| label: fig-ipcw
library(dplyr)
library(ggplot2)
library(mlr3)
library(mlr3proba)

s_t = tsk("whas")
time = s_t$unique_times()
c_t = s_t$data() %>% mutate(status = 1 - status) %>% as_task_surv(event = "status")

s_d = data.frame(t = time, surv = s_t$kaplan()$surv, W = "KMS")
c_d = data.frame(t = time, surv = c_t$kaplan()$surv, W = "KMG")
w_d = data.frame(t = time, surv = 1 / (c_t$kaplan()$surv^2), W = "KMG^-2")

cutoff = time[which(s_t$kaplan()$surv < 0.6)[1]]

d = rbind(s_d, c_d, w_d) %>% as.data.frame()
ggplot(d, aes(x = t, y = surv, color = W)) +
  geom_line() +
  ylim(0, 5) +
  theme_bw() +
  labs(y = "W(t)", title = "Kaplan-Meier estimates and weighting on `whas` data") +
  geom_vline(xintercept = cutoff, lty = 2, color = "gray")
```
```{r, echo=FALSE, include=FALSE}
ids = c("W=1", "W=G^-1", "W=G^-2")
m_inf = c(msr("surv.cindex"),
msr("surv.cindex", weight_meth = "G"),
msr("surv.cindex", weight_meth = "G2"))

m_80 = c(msr("surv.cindex", id = "W=1", cutoff = cutoff),
msr("surv.cindex", weight_meth = "G", id = "W=G^-1", cutoff = cutoff),
msr("surv.cindex", weight_meth = "G2", id = "W=G^-2", cutoff = cutoff))

m = c(m_inf, m_80)

set.seed(20231207)
res = round(resample(s_t, lrn("surv.coxph"), rsmp("cv", folds = 3))$aggregate(m), 2)
```

The following weights have been proposed for the concordance index:

* $W(t_i) = 1$ -- Harrell's concordance index, $C_H$ [@Harrell1984; @Harrell1982], which is widely accepted to be the most common survival measure [@Collins2014; @Gonen2005; @Rahman2017] and imposes no weighting on the definition of concordance. The original measure given by Harrell has no cut-off, $\tau = \infty$, however applying a cut-off is now more widely accepted in practice.
* $W(t_i) = [\KMG(t_i)]^{-2}$ -- Uno's C, $C_U$ [@Uno2011].
* $W(t_i) = [\KMG(t_i)]^{-1}$
* $W(t_i) = \KMS(t_i)$. $
* $W(t_i) = \KMS(t_i)/\KMG(t_i)$

All methods assume that censoring is conditionally-independent of the event given the features (@sec-surv-set-cens), otherwise weighting by $\KMS$ or $\KMG$ would not be applicable. It is assumed here that $\KMS$ and $\KMG$ are estimated on the training data and not the testing data (though the latter may be seen in implementation, e.g. [@pkgsurvival]).

### Choosing concordance measures

Several papers have shown that $C_H$ is affected by the precense of censoring [@Koziol2009; @Pencina2012; @Royston2013; @Uno2011] as the measure ignores pairs in which the shorter survival time is censored.
Despite this, $C_H$ is still the most widely utilised measure and moreover if a suitable cut-of $\tau$ is chosen, then all these weightings perform very similarly [@Rahman2017; @Schmid2012].
For example, @tbl-ipcw uses the `whas` data again to compare Harrell's C with measures that include IPCW weighting, when no cutoff is applied (top row) and when a cutoff is applied when G(t)=0.6 (grey line in @fig-ipcw).
The results are almost identical when the cutoff is applied but still not massively different without the cutoff.

```{r, echo=FALSE, results='asis'}
#| label: tbl-ipcw
#| tbl-cap: Comparing c-index measures (calculated on the `whas` dataset using a Cox model with three-fold cross-validation) with no cut-off (top) and a cut-off when G(t)=0.6 (bottom). First column is Harrell's C, second is the weighting 1/G(t), third is Uno's C.
knitr::kable(matrix(res, 2, 3, TRUE, dimnames = list(c("tau=Inf", paste0("tau=", cutoff)), ids)))
```

Measures that utilise other weightings have been demonstrated to be less affected by censoring than $C_H$ [@Rahman2017].
However if a poor choice is selected for $\tau$ then IPCW measures (which include $\KMG$ in the weighting) can be highly unstable [@Rahman2017].
For example, the variance of $C_U$ has been shown to drastically increase more than other measures with increased censoring [@Schmid2012].
None of these measures are perfect and all have been shown to be affected to some extent by censoring [@Schmid2012], which can lead to both under-confidence and over-confidence in the model's discriminatory ability.

In practice, the choice of C-index is less important than the transparency in reporting.
'C-hacking' [@Sonabend2022] is the unethical process of calculating multiple C-indices and reporting one or more results to promote a particular model or result.
To avoid 'C-hacking': i) the choice of C-index should be made before experiments have begun and the choice of C-index should be clearly reported; ii) when ranking predictions are composed from distribution predictions, the composition method should be chosen and clearly described before experiments have begun.
As the C-index is highly dependent on censoring within a dataset, results between experiments should be interpreted with care.

```{r, echo=FALSE, warning=FALSE}
learn("sec-car-pipelines", "creating ranking predictions from distribution predictions using composition", ttl_fmt = "Learn about distribution to ranking compositions.")
```

As well as the concordance indices discussed here, another promiment alterntive was derived by  G\"onen and Heller (2005) [@Gonen2005]. However as this is only applicable to the Cox PH it is out of scope for this book, which is primarily concerned with generalisable measures for model comparison.

<!-- FIXME: EDITED UP TO HERE -->

## AUC Measures {#sec-eval-crank-disc-auc}

AUC, or AUROC, measures calculate the Area Under the Receiver Operating Characteristic (ROC) Curve, which is a plot of the *sensitivity* (or true positive rate (TPR)) against $1 - $*specificity* (or true negative rate (TNR)) at varying thresholds (described below) for the predicted probability (or risk) of event. @fig-eval-rocs visualises ROC curves for two classification models. The blue line is a featureless baseline that has no discrimination. The red line is a decision tree with better discrimination as it comes closer to the top-left corner.

![ROC Curves for a classification example. Red is a decision tree with good discrimination as it 'hugs' the top-left corner. Blue is a featureless baseline with no discrimination as it sits on $y = x$.](Figures/evaluation/rocs.png){#fig-eval-rocs fig-alt="Image shows graph with '1 - Specificity' on the x-axis from 0 to 1 and 'Sensitivity' on the y-axis from 0 to 1. There is a blue line from the bottom left (0,0) to the top right (1,1) of the graph and a red line that forms a curve from (0,0) to around (0.2,0.8) then (1,1)."}

In a classification setting with no censoring, the AUC has the same interpretation as Harrell's C [@Uno2011]. AUC measures for survival analysis have been developed in order to provide a time-dependent measure of discriminatory ability [@Heagerty2000]. The proposed concordance indices described above are time-independent, which is useful for producing a single statistic. However, in a survival setting it can reasonably be expected for a model to perform differently over time and therefore time-dependent measures are advantageous. First discussion around computation of TPR and TNR are provided and then how these are incorporated into the AUC equation.

The AUC, TPR, and TNR are derived from the *confusion matrix* in a binary classification setting. Let $b,\hat{b} \in \{0, 1\}$ be the true and predicted binary outcomes respectively. The confusion matrix is

||||
|----|----|-----|
| | $b = 1$ | $b = 0$ |
| $\hat{b} = 1$ | TP | FP |
| $\hat{b} = 0$ | FN | TN |

where $TN := \sum_i \II(b = 0, \hatb = 0)$ is the number of (\#) true negatives, $TP := \sum_i \II(b = 1, \hatb = 1)$ is \# true positives, $FP := \sum_i \II(b = 0, \hatb = 1)$ is \# false positives, and $FN := \sum_i \II(b = 1, \hatb = 0)$ is \# false negatives. From these are derived
\begin{align}
& TPR := \frac{TP}{TP + FN} \\
& TNR := \frac{TN}{TN + FP}
\end{align}

In classification, a probabilistic prediction of an event can simply be *thresholded* (or 'binarised') to obtain a deterministic prediction. For a predicted $\hat{p} := \hat{P}(b = 1)$, and threshold $\alpha$, the thresholded binary prediction is given by $\hat{b} := \II(\hat{p} > \alpha)$. In survival analysis, this is complicated as either models only predict a continuous ranking (and not a probability of death), or a full survival distribution, which implies that the probability of death changes over time; it is the first of these that is utilised in AUC measures. Two primary methods for doing so have emerged, the first is to use an IPCW method to weight the thresholded linear predictor by an estimated censoring distribution at a given time, the second is to first classify cases and controls then compute estimators based on these classes. All measures of TPR, TNR and AUC are in the range $[0,1]$ with larger values preferred.

Weighting the linear predictor was proposed by Uno $\etal$ (2007) [@Uno2007] and provides a method for estimating TPR and TNR via

$$
\begin{split}
&TPR_U: \Reals^m \times \NNReals^m \times \bset^m \times \NNReals \times \Reals \rightarrow [0,1]; \\
&(\hat{\eta}, t, \delta | \tau, \alpha) \mapsto  \frac{\sum^m_{i=1} \delta_i \II(k(\hat{\eta}_i) > \alpha, t_i \leq \tau)[\KMG(t_i)]^{-1}}{\sum^m_{i=1}\delta_i\II(t_i \leq \tau)[\KMG(t_i)]^{-1}}
\end{split}
$$
and

$$
\begin{split}
&TNR_U: \Reals^m \times \NNReals^m \times \NNReals \times \Reals \rightarrow [0,1]; \\
&(\hat{\eta}, t | \tau, \alpha) \mapsto \frac{\sum^m_{i=1} \II(k(\hat{\eta}_i) \leq \alpha, t_i > \tau)}{\sum^m_{i=1}\II(t_i > \tau)}
\end{split}
$$
where $\tau$ is the time at which to evaluate the measure, $\alpha$ is a cut-off for the linear predictor, and $k$ is a known, strictly increasing, differentiable function. $k$ is chosen depending on the model choice, for example if the fitted model is PH then $k(x) = 1 - \exp(-\exp(x))$ [@Uno2007]. Similarities can be drawn between these equations and Uno's concordance index, in particular the use of IPCW. Censoring is again assumed to be at least random once conditioned on features. Plotting $TPR_U$ against $1 - TNR_U$ for varying values of $\alpha$ provides the ROC.

The second method, which appears to be more prominent in the literature, is derived from Heagerty and Zheng (2005) [@Heagerty2005]. They define four distinct classes, in which observations are split into controls and cases.

An observation is a *case* at a given time-point if they are dead, otherwise they are a *control*. These definitions imply that all observations begin as controls and (hypothetically) become cases over time. Cases are then split into *incident* or *cumulative* and controls are split into *static* or *dynamic*. The choice between modelling static or dynamic controls is dependent on the question of interest. Modelling static controls implies that a 'subject does not change disease status' [@Heagerty2005], and few methods have been developed for this setting [@Kamarudin2017], as such the focus here is on *dynamic* controls. The incident/cumulative cases choice is discussed in more detail below.^[All measures discussed in this section evaluate model discrimination from 'markers', which may be a *predictive* marker (model predictions) or a *prognostic* marker (a single covariate). This section always defines a marker as a ranking prediction, which is valid for all measures discussed here with the exception of one given at the end.]

The TNR for dynamic cases is defined as

$$
TNR_D(y, N | \alpha, \tau) = P(y_i \leq \alpha | N_i(\tau) = 0)
$$
where $y = (y_1,...,y_n)$ is some deterministic prediction and $N(\tau)$ is a count of the number of events in $[0,\tau)$. Heagerty and Zheng further specify $y$ to be the predicted linear predictor $\hat{\eta}$.  Cumulative/dynamic and incident/dynamic measures are available in software packages 'off-shelf', these are respectively defined by

$$
TPR_C(y, N | \alpha, \tau) = P(y_i > \alpha | N_i(\tau) = 1)
$$
and

$$
TPR_I(y, N | \alpha, \tau) = P(y_i > \alpha | dN_i(\tau) = 1)
$$
where $dN_i(\tau) = N_i(\tau) - N_i(\tau-)$. Practical estimation of these quantities is not discussed here.

The choice between the incident/dynamic (I/D) and cumulative/dynamic (C/D) measures primarily relates to the use-case. The C/D measures are preferred if a specific time-point is of interest [@Heagerty2005] and is implemented in several applications for this purpose [@Kamarudin2017]. The I/D measures are preferred when the true survival time is known and discrimination is desired at the given event time [@Heagerty2005].

Defining a time-specific AUC is now possible with

$$
AUC(y, N | \tau) = \int^1_0 TPR(y, N | 1 - TNR^{-1}(p|\tau), \tau) \ dp
$$

Finally, integrating over all time-points produces a time-dependent AUC and as usual a cut-off is applied for the upper limit,

$$
AUC^*(y,N|\tau^*) = \int^{\tau^*}_0 AUC(y,N|\tau)\frac{2\hatp_{KM}(\tau)\KMS(\tau)}{1 - \KMS^2(\tau^*)} \ d\tau
$$
where $\KMS,\hatp_{KM}$ are survival and mass functions estimated with a Kaplan-Meier model on training data.

Since Heagerty and Zheng's paper, other methods for calculating the time-dependent AUC have been devised, including by Chambless and Diao [@Chambless2006], Song and Zhou [@Song2008], and Hung and Chiang [@Hung2010]. These either stem from the Heagerty and Zheng paper or ignore the case/control distinction and derive the AUC via different estimation methods of TPR and TNR. Blanche $\etal$ (2012) [@Blanche2012] surveyed these and concluded ''regarding the choice of the retained definition for cases and controls, no clear guidance has really emerged in the literature'', but agree with Heagerty and Zeng on the use of C/D for clinical trials and I/D for 'pure' evaluation of the marker.
Blanche $\etal$ (2013) [@Blanche2013] published a survey of C/D AUC measures with an emphasis on non-parametric estimators with marker-dependent censoring, including their own Conditional IPCW (CIPCW) AUC,

$$
AUC_B(y, t, \delta, \hat{G}|\tau) = \frac{\sum_{i \neq j} \II(y_i > y_j)\II(t_i \leq \tau, t_j > \tau)\frac{\delta_i}{m^2\hat{G}(t_i|y_i)\hat{G}(\tau|y_j)}}{\Big(\sum^m_{i=1}\II(t_i \leq \tau)\frac{\delta_i}{m\hat{G}(t_i|y_i)}\Big)\Big(\sum^m_{j=1}\II(t_j>\tau)\frac{1}{m\hat{G}(\tau|y_j)}\Big)}
$$
where $t = (t_1,...,t_m)$, and $\hatG$ is the Akritas [@Akritas1994] estimator of the censoring distribution (@sec-surv-models-uncond). It can be shown that setting the $\lambda$ parameter of the Akritas estimator to $1$ results in the IPCW estimators [@Blanche2013]. However unlike the previous measures in which a deterministic prediction can be substituted for the marker, this is not valid for this estimator and as such this cannot be used for predictions. This is clear from the weights, $\hat{G}(t|y)$, in the equation which are dependent on the prediction itself. The purpose of the CIPCW method is to adapt the IPCW weights to be conditioned on the data covariates, which is not the case when $y$ is a predictive marker. Hence the following adaptation is considered instead,

$$
AUC^*_B(y, x, t, \delta, \hat{G}|\tau) = \frac{\sum_{i \neq j} \II(y_i > y_j)\II(t_i \leq \tau, t_j > \tau)\frac{\delta_i}{m^2\hat{G}(t_i|x_i)\hat{G}(\tau|x_j)}}{\Big(\sum^m_{i=1}\II(t_i \leq \tau)\frac{\delta_i}{m\hat{G}(t_i|x_i)}\Big)\Big(\sum^m_{j=1}\II(t_j>\tau)\frac{1}{m\hat{G}(\tau|x_j)}\Big)}
$$
where $x$ are random covariates (possibly from a separate training dataset).

AUC measures are less transparent and less accessible than the simpler time-independent concordance indices, only the $\pkg{survAUC}$ [@pkgsurvauc] package could be found that implements these measures. For performance, reviews of these measures have produced (sometimes markedly) different results [@Blanche2012; @Li2018; @Kamarudin2017] with no clear consensus on how and when these measures should be used. The primary advantage of these measures is to extend discrimination metrics to be time-dependent. However it is unclear how to interpret a threshold of a linear predictor and moreover if this is even the 'correct' quantity to threshold, especially when survival distribution predictions are the more natural object to evaluate over time. Methods for evaluating these distribution predictions are now discussed.
