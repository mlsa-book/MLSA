---
abstract: TODO (150-200 WORDS)
---

::: {.content-visible when-format="html"}
{{< include _macros.tex >}}
:::

# Reductions {#sec-reduction-techniques}

{{< include _wip.qmd >}}


In this part of the book we will introduce and formalize the concept of *reduction techniques* for survival analysis. 
According to Langford, a reduction is ''a complex problem decomposed into simpler subproblems so that a solution to the subproblems gives a solution to the complex problem''  [@Langford2016].
Here, we refer to reduction techniques as the transformation of a survival task to a more standard regression or classification task.

While the techniques discussed here also introduce some additional complexity, for example the need to perform a specific type of data pre-processing, we argue that they can still simplify the application of machine learning methods to different survival problems for the following reasons: 

- There is often a delay between the development of a new machine learning method for classification or regression and its adaptation to survival analysis.
- The interface of many popular implementations of machine learning algorithms is often not designed to handle complex survival data (for example they expect a one dimensional vector as target variable).
- Current extensions of machine learning methods to survival analysis are often restricted to a subset of relevant survival problems, often the single event, right-censored data setting.

It should be emphasized that the reductions discussed in this part of the book go beyond the simple and often erroneous reductions like considering the observed event indicator the target for a classification task or directly using the observed event time as a target for a regression task, ignoring the censoring status. 
Instead, the reductions introduced here are valid methods for survival analysis that appropriately deal with censoring and/or truncation.
Additionally, they 

- do not make (strong) assumptions about the underlying distribution of event times, and thus have the same advantages as survival-specific semi-parametric methods,
- are applicable to many survival tasks, including competing risks and multi-state settings,
- can predict different quantities of interest, including (discrete) hazards, survival probabilities and cumulative incidence functions conditional on features,
- can use any off-the-shelf implementation of ML or DL methods for regression or classification (depending on the reduction technique),
- can (explicitly) model time-varying effects and thus deal with non-proportional hazards.

Details about the individual reduction techniques will be provided later.
Following @pillerReductionTechniquesSurvival2025, here we jointly consider them as reduction techniques for machine learning survival analysis. 
The general pipeline is depicted in @fig-reductions-pipeline .

 <!-- FIXME: When finalizing the figure below, check if there are actual differences to the figure in Piller et al., 2025 and how to properly cite. -->

![A general pipeline for reduction techniques in the context of survival analysis (close adaptation of @pillerReductionTechniquesSurvival2025).](Figures/reductions/sa-reductions-pipeline.drawio.png){#fig-reductions-pipeline fig-alt="Illustratoin of a general reduction pipeline in the context of survival analysis."}

In the training phase, the data is transformed into a different format. 
The specifics of the transformation will depend on the reduction technique and the survival task at hand.
Once the data is transformed, the target variable becomes a one-dimensional vector of a regression or classification task (again depending on the reduction technique). 
At this stage, a standard machine learning model for regression or classification can be applied to the transformed data without any additional changes to the model or its implementation.

In the prediction phase, if necessary,the test data is transformed into the same format as the training data (using the pre-specified or trained parameters of the data transformation during the training phase).
This yields a data set which can be passed to the previously learned regression or classification model to generate predictions. 
Depending on the reduction technique and the quantity of interest, the predictions may need additional post-processing to obtain the desired survival quantity of interest.

In the following chapters we introduce specific reduction techniques. 
In particular we will consider IPC-weighted classification (@sec-icpw-reduction), pseudo-value based regression (@sec-pseudo-value-reduction), discrete-time reduction (@sec-discrete-time-reduction) and piecewise exponential models (@sec-pem-reduction). 

These can again be roughly grouped into two categories: 

- techniques that estimate a quantity of interest (like survival probability or restricted mean survival time) at a specific time point (IPCW and pseudo-value based reductions)
- techniques that estimate the entire (discrete) distribution of event times (discrete-time and piecewise exponential models)


