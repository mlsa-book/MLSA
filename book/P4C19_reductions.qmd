---
abstract: TODO (150-200 WORDS)
---

::: {.content-visible when-format="html"}
{{< include _macros.tex >}}
:::

# Reduction Techniques for Survival Analysis {#sec-reduction-techniques}

{{< include _wip_minor.qmd >}}

This part of the book introduces and formalizes the concept of *reduction* for survival analysis. 
A reduction is defined as "a complex problem decomposed into simpler subproblems so that a solution to the subproblems gives a solution to the complex problem" [@beygelzimerLearningReductionsThat2016].
Reduction techniques are designed to simplify the application of machine learning methods to survival analysis, particularly when

- the interface of a machine learning method of choice is not designed to handle complex survival data; for example, if it expects a one dimensional vector as target variable, whereas survival outcomes are defined as tuples of two or more elements.
- a novel machine learning method has been developed for classification or regression but without an adaptation to survival analysis;
- a machine learning method only exists for a restricted subset of survival analysis problems, most commonly, the single event, right-censored data setting.

Survival analysis reductions encompass a wide range of methods, including transforming the event-history setting to single-event and vice versa; converting between survival, regression, and classification; and transforming the time horizon between continuous and discrete time.

It is not uncommon to see poorly designed and mathematically invalid 'reduction' techniques in the literature.
For example, treating the event indicator as a target for a classification task or directly using the observed event time as a target for a regression task whilst ignoring the censoring status [@Schwarzer2000]. 
The reduction methods in this book are based on clear theory and are constructed so that the resulting predictions can be meaningfully interpreted for the intended prediction type.
Furthermore, the reductions in the next chapters do not make (strong) assumptions about the underlying distribution of event times and thus have similar advantages as non-parametric (@sec-classical-nonpar) and semi-parametric methods (@sec-classical-cox).
The included reductions are also those that are flexible and can be applied to many survival tasks, including competing risks and multi-state settings (@sec-eha), and can predict the most common survival prediction types (@sec-survtsk).

The general pipeline for survival reduction techniques is depicted in @fig-reductions-pipeline.
In the training phase (@fig-reductions-pipeline, top), the data is transformed into a different format with the specifics of the transformation dependent on the reduction technique and survival task at hand.
Once the data is transformed, the target variable becomes a one-dimensional vector for a regression or classification task, whilst encoding censored event-time information.
At this stage, a standard machine learning model for regression or classification can be applied to the transformed data without any additional changes to the model or its implementation.
In the prediction phase (@fig-reductions-pipeline, bottom), if necessary, the test data is transformed into the same format as the training data (using the pre-specified or trained parameters of the data transformation during the training phase).
This yields a data set which can be passed to the previously learned regression or classification model to generate predictions. 
Depending on the reduction technique and the quantity of interest, the predictions may need additional post-processing to obtain the desired survival quantity of interest.

<!-- FIXME: When finalizing the figure below, check if there are actual differences to the figure in Piller et al., 2025 and how to properly cite. Also: Transformation box between prediction and survival prediction"-->

![A general pipeline for reduction techniques in the context of survival analysis [close adaptation of @pillerReductionTechniquesSurvival2025].](Figures/reductions/sa-reductions-pipeline.drawio.png){#fig-reductions-pipeline fig-alt="A flow chart mapping an example survival reduction pipeline. Top: a survival task is passed to a training set which is transformed for a regression or classification task that can be passed to a regression or classification algorithm. Bottom: the survival task is now passed to a test set which is transformed using parameters found from the training stage. This transformation again allows use of regression or classification methods and the trained model makes predictions from this transformed data. These predictions may require a final transformation."}

The following chapters introduce specific reduction techniques.
The first reductions make use of classification (@sec-icpw-reduction) and regression (@sec-pseudo-value-reduction) respectively to estimate survival probabilities at a set of fixed times.
In contrast, the partition-based reductions in @sec-partition-based-reductions aim to estimate the entire event time distribution.
Finally, @sec-reductions-eha introduces reductions that allow event history analysis to be tackled using single event learners, which is required to apply many of the models in Part III to competing risks and multi-state data.
