---
abstract: TODO (150-200 WORDS)
---

::: {.content-visible when-format="html"}
{{< include _macros.tex >}}
:::

# Reductions {#sec-car}

{{< include _wip.qmd >}}


In this part of the book we will introduce and formalize the concept of *reduction techniques* for survival analysis. 
According to Langford, a reduction is ''a complex problem decomposed into simpler subproblems so that a solution to the subproblems gives a solution to the complex problem''  [@Langford2016].
Here, we refer to reduction techniques as the transformation of a survival task to a more standard regression or classification task.

While the techniques discussed in this part of the book also introduce some additional complexity, for example the need to perform a specific type of data pre-processing, we argue that they can still simplify the application of machine learning methods to different survival problems for the following reasons: 

- There is often a delay between the development of a new machine learning method for classification or regression and its adaptation to survival analysis.
- The interface of many popular implementations of machine learning algorithms is often not designed to handle complex survival data (for example they expect a one dimensional vector as target variable).
- Current extensions of machine learning methods to survival analysis are often restricted to a subset of relevant survival problems, often the single event, right-censored data setting.

The reduction techniques discussed in this part of the book on the other hand

- are applicable to many survival tasks, including competing risks and multi-state settings,
- can predict different quantities of interest in SA, including (discrete) hazards, survival probabilities, cumulative incidence functions, conditional on features,
- can use any off-the-shelf implementation of ML or DL methods for regression or classification (depending on the reduction technique),
- can (explicitly) model time-varying effects and thus deal with non-proportional hazards,
- and have competitive performance compared to specialized survival learners.

It should be emphasized that these reductions go beyond the simple and often erroneous reductions like considering the observed event indicator the target for a classification task or directly using the observed event time as a target for a regression task, ignoring the censoring status. Instead, the reductions introduced here are 
valid methods for survival analysis that appropriately deal with censoring and/or truncation.
Additionally, these techniques do not make (strong) assumptions about the underlying distribution of event times,
and thus have the same advantages as survival-specific semi-parametric methods. 


Details about the individual reduction techniques will be provided later, in particular we will consider IPCW-weighted classification, pseudo-value based regression, discrete-time survival analysis and piecewise exponential models. While these methods have been treated extensively in the literature as stand-alone methods for survival analysis, we base our discussion on recent work that considers those methods jointly as reduction techniques [@pillerReductionTechniquesSurvival2025], as depicted in @fig-reductions-pipeline which illustrates a general pipeline for reduction techniques in the context of machine learning survival analysis.

In the training phase, the data is transformed into a different format. 
The specifics of the transformation will depend on the reduction technique.
Once the data is transformed, the target variable becomes a one-dimensional vector of a regression or classification task (again depending on the reduction technique). 
At this stage, a standard machine learning model for regression or classification can be applied to the transformed data without any additional changes to the model or its implementation.

In the prediction phase, the test data transformed into the same format as the training data (using the pre-specified or trained parameters of the data transformation during the training phase).
This yields a data set which can be passed to the previously learned regression or classification model to generate predictions. 
Depending on the reduction technique and the quantity of interest, the predictions may need additional post-processing to obtain the desired survival quantity of interest.




![A general pipeline for reduction techniques in the context of survival analysis. The data is split into train and test set.](Figures/reductions/sa-reductions-pipeline.drawio.png){#fig-reductions-pipeline fig-alt="Illustratoin of a general reduction pipeline in the context of survival analysis."}





In general, we differentiate between two classes of reductions:

1) Reductions that estimate a specific quantity of interest at a specific time point, e.g. $S(\tau)$
2) Reductions that estimate the entire distribution of event times

