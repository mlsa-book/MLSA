---
abstract: TODO (150-200 WORDS)
---

{{< include _setup.qmd >}}

# Random Forests {#sec-surv-ml-models-ranfor}

{{< include _wip.qmd >}}

Random forests are a composite (or ensemble) algorithm built by fitting many simpler component models, *decision trees*, and then averaging the results of predictions from these trees.
Due to in-built variable importance properties, random forests are commonly used in high-dimensional settings when the number of variables in a dataset far exceeds the number of rows.
High-dimensional datasets are very common in survival analysis, especially when considering omics, genetic and financial data.
It is therefore no surprise that *random survival forests*, remain a popular and well-performing model in the survival setting.

## Random Forests for Regression

Training of decision trees can include a large number of hyper-parameters and different training steps including 'growing' and subsequently 'pruning'.
However, when utilised in random forests, many of these parameters and steps can be safely ignored, hence this section only focuses on the components that primarily influence the resulting random forest.
This section will start by discussing decision trees and will then introduce the *bagging* algorithm used to create random forests.

### Decision Trees

*Decision trees* are a (relatively) simple machine learning model that are comparatively easy to implement in software and are highly interpretable.
The decision tree algorithm takes an input, a dataset, selects a variable that is used to partition the data according to some *splitting rule* into distinct non-overlapping datasets or *nodes* or *leaves*, and repeats this step for the resulting partitions, or *branches*, until some criterion has been reached.
The final nodes are referred to as *terminal nodes*.

This is made clearer by example, (@fig-surv-ranfor) demonstrates a decision tree predicting the age of passengers on the Titanic using as variables: the class the passenger was on (first, second, third) (`Pclass`), their sex, and whether they survived (`Survived`).
It can be seen that the algorithm completely ignored the 'Sex' variable and only utilises class and survival status.
During training, the algorithm identified that the first optimal variable to split the data was `Pclass`, and that the optimal partition occurs at `Pclass>=1.5`, i.e., one dataset is created for observations that are in first class (split to the right), and another for observations in second and third class (split to the left).
Passengers in first class are split once again by survival status and a passenger in first class who survived is predicted to be 35 whereas one who died is predicted to be 44.
In contrast, passengers in cheaper classes are split by survival and then passengers who did not survive are split again by class.

The graphic highlights several core features of decision trees:

1. They can model non-linear and interaction effects: The hierarchical structure allows for complex interactions between variables and variables can be used multiple times at different levels;
2. They are highly interpretable: it is easy to visualise the tree and see how predictions are made;
3. They perform variable selection: not all variables were used to train the model.

To understand how random forests work, it is worth looking a bit more into the most important components of decision trees: splitting rules, stopping rules, and terminal node predictions.

![Demonstrating regression trees using the `titanic_train` dataset from the \Rstats package **titanic**. Rounded rectangles are leaves, which indicate the variable that is being split. Edges are branches, which indicate the cut-off at which the variable is split. Each leaf contains information about the predicted age, number of observations in the leaf, and the proportion of data contained in the leaf.](Figures/forests/titanic.png){#fig-surv-ranfor fig-alt="Decision tree diagram with 9 green boxes in a hierarchical top-down structure. Top box says '30 n=714 100% and underneath it 'Pclass>=1.5' with 'yes' on the left and 'no' on the right. One level below are two further boxes indicator passengers in first class '38 n=186 26%' and other classes '27 n=528 74%'. The first class leaf splits again based on survival into passengers that do not survive '44 n=64 9%' and others '35 n=122 17%'. The leaf with other classes splits based on survival with surviving passengers ending in the final leaf '23 n=168 24%'. Passengers that die are split again based on class with dying passengers in third class '27 n=279 38%' and those in second class '34 n=90 13%'."}

#### Splitting and Stopping Rules {.unnumbered .unlisted}

Precisely how the data partitions/splits are derived and which variables are utilised is determined by the *splitting rule*.
The goal in each partition is to find two resulting leaves/nodes that have the greatest difference between them and thus the maximal homogeneity within each leaf, hence with each split, the data in each node should become increasingly similar.
The splitting rule provides a way to measure the homogeneity within the resulting nodes.
In regression, the most common splitting rule is to select a variable and cut-off (i.e., a threshold on the variable at which to separate observations) that minimises the mean squared error in the two potential resulting leaves.

For all decision tree and random forest algorithms going forward, let $L$ denote some leaf, then let $L_{xy}, L_x, L_y$ respectively be the set of observations, features, and outcomes in leaf $L$.
Let $L_{y;i}$ be the $i$th outcome in $L_y$ and finally let $L_{\bar{y}} = \mean[|L_y|]{L_{y;i}}$ be the mean outcome in leaf $L$.
To simplify notation, $i \in L$ is taken to be equivalent to $i \in \{i: X_i \in L_X\}$, i.e. the indices of the observations in leaf $L$.

Let $c \in \Reals$ be some cutoff parameter and let $L^a_{xy}(j,c) := \{(X_i,Y_i)|X_{ij} < c, i = 1,...,n\}, L^b_{xy}(j,c) = \{(X_i,Y_i)|X_{ij} \geq c, i = 1,...,n\}$ be the two leaves containing the set of observations resulting from partitioning variable $j$ at cutoff $c$.
Then a split is determined by finding the arguments, $(j^*,c^*)$ that minimise the sum of the mean squared errors (MSE) in both leaves  [@Hastie2013],
$$
(j^*, c^*) = \argmin_{j, c} \sum_{y \in L^a_{y}(j,c)} (y - L^a_{\bar{y}}(j,c))^2 + \sum_{y \in L^b_{y}(j,c)} (y - L^b_{\bar{y}}(j,c))^2
$$ {#eq-dt-min}

This method is repeated from the first leaf to the last such that observations are included in a given leaf $L$ if they satisfy all conditions from all previous branches (splits); features may be considered multiple times in the growing process allowing complex interaction effects to be captured.

Leaves are repeatedly split until a *stopping rule* has been triggered -- i.e., a criterion that tells the algorithm to stop partitioning data.
The stopping rule is usually a condition on the number of observations in each leaf such that leaves will continue to be split until some minimum number of observations has been reached in a leaf.
Other conditions may be on the 'depth' of the tree, which corresponds to the number of levels of splitting.
Stopping rules are often used together, for example by setting a maximum tree depth *and* determining a minimum number of observations per leaf.
Deciding the number of minimum observations and/or the maximum depth can be performed with automated hyper-parameter optimisation.

#### Terminal Node Predictions {.unnumbered .unlisted}

The final major component of decision trees are *terminal node predictions*.
As the name suggests, this is part of the algorithm that determines how to actually make a prediction for a new observation.
A prediction is made for some new data by 'dropping' the new data 'down' the tree according to the optimal splits that were found during training.
Returning to @fig-surv-ranfor, say a new data point is $x = \{Pclass = 2, Survived = 0\}$, then in the first split the left branch is taken as `Pclass` $= 2 \geq 1.5$, in the second split the right branch is taken as `Survived` $= 0 < 0.5$, finally as `Pclass` $= 2 < 2.5$ the new data point 'lands' in the third terminal leaf.

The resulting prediction is then a simple baseline statistic computed from the training data that fell into the corresponding node.
In regression, this is most commonly (and simply) the sample mean of the training outcome data, but other terminal node predictions could be the sample median, a weighted average, or even a simple linear regression prediction from a model trained on the training data in the corresponding final leaf.
In the example above, the final prediction would be $y = 34$, note how the final predictions are statistics based on training data, which means all potential predictions can be saved in the original trained mode and no complex computations are required during prediction.

### Random Forests

Decision trees often overfit the training data, hence they have high variance, perform poorly on new data, and are not robust to even small changes in the original training data.
Moreover, important variables can end up being ignored as only subsets of dominant variables are selected for splitting.

To counter these problems, *random forests* are preferred to improve prediction accuracy and decrease variance.
Random forests utilise bootstrap aggregation, or *bagging*  [@Breiman1996a], to aggregate many decision trees.
Bagging is a relatively simple algorithm, as follows:

1. **For** $b = 1,...,B$:
2. $D_b \gets \text{ Randomly sample with replacement } \dtrain$
3. $D_{b;p} \gets \text{ Randomly subset features of } D_b$
4. $\hatg_b \gets$ \text{ Train a decision tree on } $D_b$
5. **end For**
6. $g_B \gets \{\hatg_b\}^B_{b=1}$
7. **return** $\hatg = g_B$

Step 2 is known as *bootstrapping*, which is the process of sampling a dataset *with* replacement -- which is in contrast to more standard subsampling where data is sampled *without* replacement.
Commonly, the bootstrapped sample size is the same as the original.
However, as the same value may be sampled multiple times, on average the resulting data only contains around 63.2\% unique observations [@Efron1997].
After data is bootstrapped, randomness is further injected to decorrelate the trees by randomly subsetting the data features (Step 3).
The resulting dataset is used to train a decision tree (Step 4), and this is repeated for $B$ trees, with the final output being a collection of trained decision trees.

Prediction from a random forest follows by making predictions from the individual trees and aggregating the results by some function $\sigma$, which is usually the sample mean for regression:

$$
\hatg(X^*) = \sigma(\hatg_1(X^*),...,\hatg_B(X^*)) = \frac{1}{B} \sum^B_{b=1} \hatg_b(X^*)
$$

where $\hatg_b(X^*)$ is the terminal node prediction from the $b$th tree and $B$ are the total number of grown trees.

As discussed above, individual decision trees result in predictions with high variance that are not robust to small changes in the underlying data.
Random forests decrease this variance by aggregating predictions over a large sample of independent trees, where a high degree of independence between trees is promoted through the use of bootstrapped samples and random candidate feature selection at each split.

Usually many (hundreds or thousands) trees are grown, which makes random forests robust to changes in data and 'confident' about individual predictions.
Other advantages include having tunable and meaningful hyper-parameters, including: the number of variables to consider for a single tree, the splitting rule, and the stopping rule.
By treating trees as *weak learners*, random forests remove a lot of decisions required when fitting decision trees, such as which variables to split and how.
Weak learners, learn a small amount about the data but do not try to capture all relationships, making it less important how individual trees are grown.

Whilst random forests are considered a 'black-box', in that one cannot be reasonably expected to inspect thousands of individual trees, variable importance can still be aggregated across trees, for example by counting the variables that were selected across trees.
Hence the model remains more interpretable than many alternative methods.
Finally, random forests are less prone to overfitting and this can be relatively easily controlled by using *early-stopping* methods, for example by continually growing trees until the performance of the model stops improving.

## Random Survival Forests

Unlike other machine learning methods that may require complex changes to underlying algorithms, random forests can be relatively simply adapted to *random survival forests* by updating the splitting rules and terminal node predictions to those that can handle censoring and can make survival predictions.
This chapter is therefore focused on outlining different choices of splitting rules and terminal node predictions, which can then be flexibly combined into different models.

### Splitting Rules

Survival trees and RSFs have been studied for the past four decades and whilst there are many possible splitting rules [@Bou-Hamad2011], only two broad classes are commonly utilised (as judged by number of available implementations, e.g., @pkgsksurvival; @pkgranger; @Ishwaran2011).
The first class rely on hypothesis tests, and primarily the log-rank test, to maximise dissimilarity between splits, the second class utilises likelihood-based measures.
The first is discussed in more detail as this is common in practice and is relatively straightforward to implement and understand, moreover it has been demonstrated to outperform other splitting rules [@Bou-Hamad2011].
Likelihood rules are more complex and require assumptions that may not be realistic, these are discussed briefly.

#### Hypothesis Tests {.unnumbered .unlisted}

The log-rank test statistic has been widely utilised as the 'natural' splitting-rule for survival analysis  [@Ciampi1986; @Ishwaran2008; @LeBlanc1993; @Segal1988].
The log-rank test compares the survival distributions of two groups and has the null-hypothesis that both groups have the same underlying risk of (immediate) events, i.e. identical hazard functions.

Let $L^A$ and $L^B$ be two leaves and let $h^A,h^B$ be the (theoretical, true) hazard functions in the two leaves respectively.
Further, define:

* $\calU_D$, the set of unique event times across the data (in both leaves)

* $n_\tau^A$, the number of observations at risk at $\tau$ in leaf $A$

$$
n_\tau^A = \sum_{i \in L^A} \II(t_i \geq \tau)
$$

* $o^A_{\tau}$, the observed number of events in leaf $A$ at $\tau$

$$
o^A_{\tau} = \sum_{i \in L^A} \II(t_i = \tau, \delta_i = 1)
$$

* $n_\tau = n_\tau^A + n_\tau^B$, the number of observations at risk at $\tau$ in both leaves
* $o_\tau = o^A_{\tau} + o^B_{\tau}$, the observed number of events at $\tau$ in both leaves


Then, the log-rank hypothesis test is given by $H_0: h^A = h^B$ with test statistic  [@Segal1988],
$$
LR(L^A) = \frac{\sum_{\tau \in \calU_D} (o^A_{\tau} - e^A_{\tau})}{\sqrt{\sum_{\tau \in \calU_D} v_\tau^A}}
$$

where:

* $e^A_{\tau}$ is the expected number of events in leaf $A$ at $\tau$

$$
e^A_{\tau} := \frac{n_\tau^A o_\tau}{n_\tau}
$$

* $v^A_\tau$ is the variance of the number of events in leaf $A$ at $\tau$

$$
v^A_{\tau} := e^A_{\tau} \Big(\frac{n_\tau - o_\tau}{n_\tau}\Big)\Big(\frac{n_\tau - n^A_\tau}{n_\tau - 1}\Big)
$$

These results follow as the number of events in a leaf is distributed according to a Hypergeometric distribution.
The same statistic results if $L^B$ is instead considered.

The higher the log-rank statistic, the greater the dissimilarity between the two groups, thereby making it a sensible splitting rule for survival, moreover it has been shown that it works well for splitting censored data  [@LeBlanc1993].
Additionally, the log-rank test requires no knowledge about the shape of the survival curves or distribution of the outcomes in either group  [@Bland2004], making it ideal for an automated process that requires no user intervention.

The log-rank *score* rule  [@Hothorn2003] is a standardized version of the log-rank rule that could be considered as a splitting rule, though simulation studies have demonstrated non-significant predictive performance when comparing the two  [@Ishwaran2008].
Alternative dissimiliarity measures and tests have also been suggested as splitting rules, including modified Kolmogorov-Smirnov test and Gehan-Wilcoxon tests  [@Ciampi1988].
Simulation studies have demonstrated that both of these may have higher power and produce 'better' results than the log-rank statistic  [@Fleming1980], however neither appears to be commonly used.

In a competing risk setting, Gray's test [@Gray1988] can be used instead of the log-rank test, as it compares cumulative incidence functions rather than all-cause hazards.
Similarly to the log-rank test, Gray's test also compares survival distributions using hypothesis tests to determine if there are significant differences between the groups, thus making it a suitable option to build competing risk RSFs.

#### Alternative Splitting Rules {.unnumbered .unlisted}

A common alternative to the log-rank test is to instead use *likelihood ratio*, or *deviance*, statistics.
When building RSFs, the likelihood-ratio statistic can be used to test if the model fit is improved or worsened with each split, thus providing a way to partition data.
However, as discussed in @sec-surv-obj, there are many different likelihoods that can be assumed for survival data, and there is no obvious way to determine if one is more sensible than another.
Sensible choices could include the Cox PH partial likehood, a full-likelihood form proposed by @LeBlanc1992, or any of the other objective functions discussed in @sec-surv-obj.
These methods require assumptions that may not be accurate and could be hard to justify - hence we tend to discourage these as splitting rules, and in fact they are implemented in very few off-shelf software packages.

Other rules have also been studied including comparison of residuals  [@Therneau1990], scoring rules [@pkgrfsrc], distance metrics [@Gordon1985], and concordance metrics [@Schmid2016].
Experiments have shown different splitting rules may perform better or worse depending on the underlying data [@Schmid2016], hence one could even consider treating the splitting rule as a hyper-parameter for tuning.
However, if there is a clear goal in prediction, then the choice of splitting rule can be informed by the prediction type.
For example, if the goal is to maximise separation, then a log-rank splitting rule to maximise homogeneity in terminal nodes is a natural starting point.
Whereas if the goal is to accurately rank observations, then a concordance splitting rule may be optimal.

### Terminal Node Prediction {#sec-surv-ml-models-ranfor-nodes}

As in the regression setting, the usual strategy for predictions is to create a simple estimate based on the training data that lands in the terminal nodes.
However, as seen throughout this book, the choice of estimator in the survival setting depends on the prediction task of interest, which are now considered in turn.
First, note that all terminal node predictions can only yield useful results if there are a sufficient number of uncensored observations in each terminal node.
Hence, a common RSF stopping rule is the minimum number of *uncensored* observations per leaf, i.e., a leaf is not split if that would result in too few uncensored observations in the resulting leaves.


#### Probabilistic Predictions {.unnumbered .unlisted}

Starting with the most common survival prediction type, the algorithm requires a simple estimate for the underlying survival distribution in each of the terminal nodes, which can be estimated using the Kaplan-Meier or Nelson-Aalen methods [@Hothorn2004; @Ishwaran2008; @LeBlanc1993; @Segal1988].

<!-- FIXME: REF KM DEFINITION ABOVE -->

By convention, the Nelson-Aalen estimator is used more commonly for RSFs and is thus focused on in this section, but the same logic follows for the Kaplan-Meier estimator.

Once the Nelson-Aalen estimate for the cumulative hazard function is estimated for individual trees, the question is then how to combine them to create a single random forests prediction.
As Nelson-Aalen estimates produce discrete hazard functions, the same bagging algorithm can be used relatively simply by averaging the estimated hazard probability at each observed time-point [@Hothorn2004].
See @fig-surv-ranfor-lung for an example using the `lung` dataset [@pkgsurvival].

Let $b_m \in \{1,...,b_M\}$ be a terminal node in a survival decision tree, $b$, with $b_M \in \PReals$ terminal nodes, then if an observation, $x$, lands in terminal node $b_m$, its predicted cumulative hazard is given by,

$$
\hat{H}_b(\tau) = \sum_{\{i: i \in L^{b_m} \cap t_i \leq \tau\}} \frac{o_i}{n_i}
$$ {#eq-surv-nelson}

where $o_i$ and $n_i$ are the observed number of events, and the observations at risk, respectively at time $t_i$.
The bootstrapped Nelson-Aalen estimator is then defined as [@Ishwaran2008]

$$
\hat{H}_{Boot}(\tau) = \frac{1}{B} \sum^B_{b=1} \hat{H}_b(\tau)
$$ {#eq-surv-nelson-boot}

where $B$ is the total number of bootstrapped estimators.
The bootstrapped Kaplan-Meier estimator is calculated analogously.
More generally these can be considered as a uniform mixture of $B$ distributions (@sec-car).
Extensions to competing risks follow naturally using bootstrapped cause-specific cumulative incidence functions.

<!-- FIXME - ANDREAS TO ADD DETAILS ON COMPETING RISKS -->

![Survival tree trained on the `lung` dataset from the \Rstats package **survival**. The terminal node predictions are bootstrapped survival curves.](Figures/forests/lung.png){#fig-surv-ranfor-lung fig-alt="Decision tree with two splits, the first is 'ph.ecog' with a p-value of <0.001, when ph.ecog > 1 a terminal prediction is made, otherwise the data is split at 'sex' with - = 0.015. Terminal node predictions are plots of survival functions."}

#### Deterministic Predictions {.unnumbered .unlisted}

Whilst predicting survival times is often a complex and fairly under-researched area, it becomes trivial when using RSFs.
In this case a prediction could simply be the median survival time for uncensored observations in the corresponding terminal node.
Note however that even though prediction becomes trivial, evaluating these predictions still carries its own difficulties (see @sec-eval-det).

As discussed, relative risks are arbitrary values where only the resulting rank comparing observations matters.
In RSFs, each terminal node should be as homogeneous as possible, hence within a terminal node, the risk between observation should be the same.
Hence, one could theoretically assign a constant risk value to all terminal nodes, compare these using some concordant type metric, and shuffle repeatedly until maximum concordance is achieved.
However, this would clearly be cumbersome and sub-optimal.
Another approach would be to generate some heuristics based on the observations in the terminal nodes, for example the total number of events occurring in the terminal node, or the total number of events divided by the total time at risk, which gives an overall probability of the event occurring over time.

In practice, the most common method appears to be a composition from the Nelson-Aalen method [@Ishwaran2008], which exploits results from counting process to provide a measure of expected mortality [@dataapplied].
The relative risk predicted from decision tree $b$ is calculated as

$$
\phi_b := \sum_{\tau \in \calT} \hat{H}_b(\tau)
$$

where $\calT$ is the set of unique time-points in the leaf.
The final random forest prediction is simply

$$
\phi_{Boot} = \frac{1}{B} \sum^B_{b=1} \phi_b
$$ {#eq-surv-nelson-boot}

More complex methods have also been proposed that are based on the likelihood-based splitting rule and assume a PH model form  [@Ishwaran2004; @LeBlanc1992].
However, these do not appear to be in wide-spread usage.

## Conclusion


:::: {.callout-warning icon=false}

## Key takeaways

* Random forests are a highly flexible algorithm that allow the various components to be adapted and altered without major changes to the underlying algorithm, this means that random survival forests (RSFs) are readily available 'off-shelf' in many open-source packages;
* RSFs have in-built variable selection methods that mean they tend to perform well on high-dimensional data, routinely outperforming other models [@Herrmann2020, @Spooner2020, @Burk2024];
* Despite having many potential hyper-parameters to tune, all are intuitive and many can even be ignored as sensible defaults exist in most off-shelf software implementations.

::::

:::: {.callout-important icon=false}

## Limitations

* Due to the number of trees and the constant bootstrapping procedures, RSFs can be more computationally intensive than other models, though still much less intensive than neural networks and other deep learning methods.
* Despite having some in-built methods for model interpretation, RSFs are still black-boxes that can be difficult to fully interpret.
* With too few trees random forests can have similar limitations to decision trees and with too many random forests can overfit the data. Though most software has sensible defaults to prevent either scenario.

::::

:::: {.callout-tip icon=false}

## Further reading

* A comprehensive review of random survival forests (RSFs) is provided in Bou-Hamad (2011) [@Bou-Hamad2011], which includes extensions to time-varying covariates and different censoring types.
* The discussion of decision trees omitted many methods for growing and pruning trees, if you are interest in those technical details see @Breiman1984.
* RSFs have been shown to perform well in benchmark experiments on high-dimensional data, see @Herrmann2020 and @Spooner2020 for examples.
* This chapter considered the most 'traditional' forms of RSFs. Conditional inference forests are popular in the regression setting and whilst they are under-researched in survival, see @Hothorn2005 for literature on the topic. A more recent method that seems to perform well is the (accelerated) oblique random survival forest discussed in @Jaeger2024.

::::
