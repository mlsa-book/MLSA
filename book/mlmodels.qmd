{{< include _setup.qmd >}}

# Machine Learning Survival Models

\section{A Survey of Machine Learning Models for Survival Analysis}
\label{sec:surv_ml}

These next sections provide a technical, critical survey of machine learning models proposed for survival analysis with the focus on the `simpler' setup of non-competing risks. Models are separated into their different `classes' \see{tab:surv_ml_returns}, which exists as a natural taxonomy in machine learning. Each class review is then further separated by first discussing the simpler and more standard regression setting, before expanding into their survival framework. The focus is once again on the different predict types of the model, which enables clear exposition and discussion around how some areas have successfully dealt with the survival predictive problem, whereas others have fallen short.

This is not the first survey of machine learning models for survival analysis. A recent 2017 survey~\cite{Wang2017} focused on covering the breadth of machine learning models for survival analysis and this survey is recommended to the reader as a strong starting point to understand which ML models are available for survival analysis. However whilst this provides a comprehensive review and a `big-picture' view, there is no discussion about how successful the discussed models are in solving the survival task.

A comprehensive survey of neural networks was presented by Schwarzer \etal~(2000)~\cite{Schwarzer2000} in which the authors collected the many ways in which neural networks have been `misused' in the context of survival analysis. This level of criticism is vital in the context of survival analysis and healthcare data as transparency and understanding are often prioritised over predictive performance. Whilst the survey in this thesis will try not to be as critical as the Schwarzer review, it will aim to discuss models and how well they actually solve the survival problem.

In line with the core topic of this thesis, this survey aims to demonstrate if each model is APT \see{sec:intro_motobj_tap}. Historically, surveys have focused primarily on predictive performance, which is generally preferred for complex classification and regression tasks. However in the context of survival analysis, transparency is of the utmost importance and any model that does not solve the task it claims to, despite strong predictive performance, can be considered sub-optimal. The survey will also examine the accessibility of survival models. A model need not be open-source to be accessible, but it should be `user-friendly' and not require expert cross-domain knowledge. For example, a neural network may require knowledge of complex model building, but if set-up correctly could be handled without medical or survival knowledge. Whereas a Gaussian Process requires knowledge of the model class, simulation, (usually) Bayesian modelling, and also survival analysis.
\\\\
\Cref{tab:surv_ml_returns} provides information about the models reviewed in this survey, including a model reference for use in the \cref{chap:bench} benchmark experiment, the predict types of the model, and in which \Rstats{} package it is implemented.

\begin{landscape}
\begin{longtable}{ccccc}
\caption[Machine learning survival models by class and survival task]{Summarising the models discussed in \cref{sec:surv_ml} by their model class and respective survival task.}.\label{tab:surv_ml_returns}\\
\toprule
\textbf{Class}$^1$ &  \textbf{Name (Page)}$^2$ & \textbf{Authors (Year)}$^3$ & \textbf{Task}$^4$ & \textbf{Implementation}$^5$ \\
\midrule
\endfirsthead
\caption[]{(continued)}\\
\toprule
\textbf{Class}$^1$ &  \textbf{Name (Page)}$^2$ & \textbf{Authors (Year)}$^3$ & \textbf{Task}$^4$ & \textbf{Implementation}$^5$ \\
\midrule
\endhead

\hline
\multicolumn{5}{r}{\emph{Continued on next page...}} \\ \midrule
\endfoot
\bottomrule
\endlastfoot

RF & RRT \pr{mod:rrt} & LeBlanc and Crowley (1992)~\cite{LeBlanc1992} & Rank & \pkg{rpart}~\cite{pkgrpart} \\
RF & RSDF-DEV \pr{mod:rsdfdev} & Hothorn \etal~(2004)~\cite{Hothorn2004} & Prob. & \pkg{ipred}~\cite{pkgipred} \\
RF & RRF \pr{mod:rrf} & Ishwaran \etal~(2004)~\cite{Ishwaran2004} & Rank & - \\
RF & RSCIFF \pr{mod:rsciff} & Hothorn \etal~(2006)~\cite{Hothorn2005} & Det., Prob. & \pkg{party}~\cite{pkgparty}, \pkg{partykit}~\cite{pkgpartykit} \\
RF & RSDF-STAT \pr{mod:rsdfstat} & Ishwaran \etal~(2008)~\cite{Ishwaran2008} & Prob. & \pkg{randomForestSRC}~\cite{pkgrfsrc}, \pkg{ranger}~\cite{pkgranger} \\

\midrule

GBM & GBM-COX \pr{mod:gbmcox} & Ridgeway (1999)~\cite{Ridgeway1999} \& Buhlmann (2007)~\cite{Buhlmann2007} & Prob. & \pkg{mboost}~\cite{pkgmboost}, \pkg{xgboost}~\cite{pkgxgboost}, \pkg{gbm}~\cite{pkggbm} \\
GBM & CoxBoost \pr{mod:coxboost} & Binder \& Schumacher (2008)~\cite{Binder2008} & Prob. & \pkg{CoxBoost}~\cite{pkgcoxboost} \\
GBM & GBM-AFT \pr{mod:gbmaft} & Schmid \& Hothorn (2008)~\cite{Schmid2008b} & Det. & \pkg{mboost}, \pkg{xgboost} \\
GBM & GBM-BUJAR \pr{mod:gbmbujar} & Wang \& Wang (2010)~\cite{Wang2010} & Det. & \pkg{bujar}~\cite{pkgbujar} \\
GBM & GBM-GEH \pr{mod:gbmgeh} & Johnson \& Long (2011)~\cite{Johnson2011} & Det. & \pkg{mboost} \\
GBM & GBM-UNO \pr{mod:gbmuno} & Mayr \& Schmid (2014)~\cite{Mayr2014} & Rank & \pkg{mboost} \\

\midrule

SVM & SVCR \pr{mod:svcr} & Shivaswamy \etal~(2007)~\cite{Shivaswamy2007} & Det. & \pkg{survivalsvm}~\cite{pkgsurvivalsvm} \\
SVM & SSVM-Rank \pr{mod:ranksvmc} & Van Belle \etal~(2007)~\cite{VanBelle2007} & Rank & \pkg{survivalsvm} \\
SVM & SVRc \pr{mod:svrc} & Khan and Zubek (2008)~\cite{Khan2008} & Det. & - \\
SVM & SSVM-Hybrid \pr{mod:ssvmhybrid} & Van Belle (2011)~\cite{VanBelle2011b} & Det. & \pkg{survivalsvm} \\
SVM & SSVR-MRL \pr{mod:ssvrmrl} & Goli \etal~(2016)~\cite{Goli2016a, Goli2016b} & Det. & - \\

\midrule

ANN & ANN-CDP \pr{mod:anncdp} & Liest\o l \etal~(1994)~\cite{Liestol1994} & Prob. & - \\
ANN & ANN-COX \pr{mod:anncox} & Faraggi and Simon (1995)~\cite{Faraggi1995} & Rank & -\\
ANN & PLANN \pr{mod:plann} & Biganzoli \etal~(1998)~\cite{Biganzoli1998} & Prob. & - \\
ANN & COX-NNET \pr{mod:coxnnet} & Ching \etal~(2018)~\cite{Ching2018a} & Prob. & \pkg{cox-nnet}$^*$~\cite{pkgcoxnnet}\\
ANN & DeepSurv \pr{mod:deepsurv} & Katzman \etal~(2018)~\cite{Katzman2018} & Prob. & \pkg{survivalmodels}~\cite{pkgsurvivalmodels}\\
ANN & DeepHit \pr{mod:deephit} & Lee \etal~(2018)~\cite{Lee2018a} & Prob. & \pkg{survivalmodels}\\
ANN & Nnet-survival \pr{mod:nnetsurvival} & Gensheimer \& Narasimhan (2019)~\cite{Gensheimer2019} & Prob. & \pkg{survivalmodels}\\
ANN & Cox-Time \pr{mod:coxtime} & Kvamme \etal~(2019)~\cite{Kvamme2019a} & Prob. & \pkg{survivalmodels}\\
ANN & PC-Hazard \pr{mod:pchazard} & Kvamme \& Borgan (2019)~\cite{Kvamme2019} & Prob. & \pkg{survivalmodels}\\
ANN & RankDeepSurv \pr{mod:rankdeepsurv} & Jing \etal~(2019)~\cite{Jing2019} & Det. & \pkg{RankDeepSurv}$^{\ast, \dagger}$~\cite{pkgrankdeepsurv}\\
ANN & DNNSurv \pr{mod:dnnsurv} & Zhao \& Fend (2020)~\cite{Zhao2020} & Prob. & \pkg{survivalmodels} \\

\end{longtable}
\begin{tablenotes}
\footnotesize
\item 1. Model Class. RSF -- Random Survival Forest; GBM -- Gradient Boosting Machine; SVM -- Support Vector Machine; ANN -- Artificial Neural Network. There is some abuse of notation here as some of the RSFs are actually decision trees and some GBMs do not use gradient boosting.
\item 2. Model identifier used in this section and \cref{chap:bench}.
\item 3. Authors and year of publication, for RSFs this is the paper most attributed to the algorithm.
\item 4. Survival task type: Deterministic (Det.), Probabilistic (Prob.), Ranking (Rank).
\item 5. If available in \Rstats then the package in which the model is implemented, otherwise `$\ast$' signifies a model is only available in Python. With the exception of DNNSurv, all ANNs in \pkg{survivalmodels} are implemented from the Python package \pkg{pycox}~\cite{pkgpycox} with \pkg{reticulate}~\cite{pkgreticulate}.
\item $\dagger$ -- Code available to create model but not implemented `off-shelf'.
\end{tablenotes}
\end{landscape}
